{"2023-07-06T00:00:00Z":{"Sound":[{"id":"http://arxiv.org/abs/2307.03183v1","updated":"2023-07-06T17:58:28Z","published":"2023-07-06T17:58:28Z","title":"Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong\n  General Audio Event Taggers","summary":"  In this paper, we focus on Whisper, a recent automatic speech recognition\nmodel trained with a massive 680k hour labeled speech corpus recorded in\ndiverse conditions. We first show an interesting finding that while Whisper is\nvery robust against real-world background sounds (e.g., music), its audio\nrepresentation is actually not noise-invariant, but is instead highly\ncorrelated to non-speech sounds, indicating that Whisper recognizes speech\nconditioned on the noise type. With this finding, we build a unified audio\ntagging and speech recognition model Whisper-AT by freezing the backbone of\nWhisper, and training a lightweight audio tagging model on top of it. With <1%\nextra computational cost, Whisper-AT can recognize audio events, in addition to\nspoken text, in a single forward pass.\n","authors":["Yuan Gong","Sameer Khurana","Leonid Karlinsky","James Glass"],"pdf_url":"https://arxiv.org/pdf/2307.03183v1.pdf","comment":"Accepted at Interspeech 2023. Code at\n  https://github.com/yuangongnd/whisper-at"},{"id":"http://arxiv.org/abs/2307.03045v1","updated":"2023-07-06T15:10:29Z","published":"2023-07-06T15:10:29Z","title":"Track Mix Generation on Music Streaming Services using Transformers","summary":"  This paper introduces Track Mix, a personalized playlist generation system\nreleased in 2022 on the music streaming service Deezer. Track Mix automatically\ngenerates \"mix\" playlists inspired by initial music tracks, allowing users to\ndiscover music similar to their favorite content. To generate these mixes, we\nconsider a Transformer model trained on millions of track sequences from user\nplaylists. In light of the growing popularity of Transformers in recent years,\nwe analyze the advantages, drawbacks, and technical challenges of using such a\nmodel for mix generation on the service, compared to a more traditional\ncollaborative filtering approach. Since its release, Track Mix has been\ngenerating playlists for millions of users daily, enhancing their music\ndiscovery experience on Deezer.\n","authors":["Walid Bendada","Théo Bontempelli","Mathieu Morlon","Benjamin Chapus","Thibault Cador","Thomas Bouabça","Guillaume Salha-Galvan"],"pdf_url":"https://arxiv.org/pdf/2307.03045v1.pdf","comment":"RecSys 2023 - Industry track with oral presentation"},{"id":"http://arxiv.org/abs/2306.03307v2","updated":"2023-07-06T13:44:20Z","published":"2023-06-05T23:27:39Z","title":"Reef Elegy: An Auditory Display of Hawaii's 2019 Coral Bleaching Data","summary":"  This paper describes an auditory display of Hawaii's 2019 coral bleaching\ndata via means of spatial audio and parameter mapping methods. Selected data\nfields spanning 78 days are mapped to sound surrogates of coral reefs' natural\nsoundscapes, which are progressively altered in their constituent elements as\nthe corresponding coral locations undergo bleaching. For some of these\nelements, this process outlines a trajectory from a dense to a sparser, reduced\nsoundscape, while for others it translates moving away from harmonic tones and\ntowards complex spectra. This experiment is accompanied by a short evaluation\nstudy to contextualize it in an established aesthetic perspective space and to\nprobe its potential for public engagement in the discourse around climate\nchange.\n","authors":["Stefano Kalonaris"],"pdf_url":"https://arxiv.org/pdf/2306.03307v2.pdf","comment":"To appear in: Proceedings of the 28th International Conference on\n  Auditory Display (ICAD 2023) NOTE: This version (v2) replaces Figure 2, which\n  was incorrectly rendered. Do not use or cite the previous version (v1)"},{"id":"http://arxiv.org/abs/2305.12263v2","updated":"2023-07-06T13:43:56Z","published":"2023-05-20T18:41:13Z","title":"Self-supervised representations in speech-based depression detection","summary":"  This paper proposes handling training data sparsity in speech-based automatic\ndepression detection (SDD) using foundation models pre-trained with\nself-supervised learning (SSL). An analysis of SSL representations derived from\ndifferent layers of pre-trained foundation models is first presented for SDD,\nwhich provides insight to suitable indicator for depression detection.\nKnowledge transfer is then performed from automatic speech recognition (ASR)\nand emotion recognition to SDD by fine-tuning the foundation models. Results\nshow that the uses of oracle and ASR transcriptions yield similar SDD\nperformance when the hidden representations of the ASR model is incorporated\nalong with the ASR textual information. By integrating representations from\nmultiple foundation models, state-of-the-art SDD results based on real ASR were\nachieved on the DAIC-WOZ dataset.\n","authors":["Wen Wu","Chao Zhang","Philip C. Woodland"],"pdf_url":"https://arxiv.org/pdf/2305.12263v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02975v1","updated":"2023-07-06T13:19:27Z","published":"2023-07-06T13:19:27Z","title":"Transfer Learning for the Efficient Detection of COVID-19 from\n  Smartphone Audio Data","summary":"  Disease detection from smartphone data represents an open research challenge\nin mobile health (m-health) systems. COVID-19 and its respiratory symptoms are\nan important case study in this area and their early detection is a potential\nreal instrument to counteract the pandemic situation. The efficacy of this\nsolution mainly depends on the performances of AI algorithms applied to the\ncollected data and their possible implementation directly on the users' mobile\ndevices. Considering these issues, and the limited amount of available data, in\nthis paper we present the experimental evaluation of 3 different deep learning\nmodels, compared also with hand-crafted features, and of two main approaches of\ntransfer learning in the considered scenario: both feature extraction and\nfine-tuning. Specifically, we considered VGGish, YAMNET, and\nL\\textsuperscript{3}-Net (including 12 different configurations) evaluated\nthrough user-independent experiments on 4 different datasets (13,447 samples in\ntotal). Results clearly show the advantages of L\\textsuperscript{3}-Net in all\nthe experimental settings as it overcomes the other solutions by 12.3\\% in\nterms of Precision-Recall AUC as features extractor, and by 10\\% when the model\nis fine-tuned. Moreover, we note that to fine-tune only the fully-connected\nlayers of the pre-trained models generally leads to worse performances, with an\naverage drop of 6.6\\% with respect to feature extraction. %highlighting the\nneed for further investigations. Finally, we evaluate the memory footprints of\nthe different models for their possible applications on commercial mobile\ndevices.\n","authors":["Mattia Giovanni Campana","Franca Delmastro","Elena Pagani"],"pdf_url":"https://arxiv.org/pdf/2307.02975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02909v1","updated":"2023-07-06T10:50:46Z","published":"2023-07-06T10:50:46Z","title":"Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation\n  and Recognition","summary":"  Accurate recognition of cocktail party speech containing overlapping\nspeakers, noise and reverberation remains a highly challenging task to date.\nMotivated by the invariance of visual modality to acoustic signal corruption,\nan audio-visual multi-channel speech separation, dereverberation and\nrecognition approach featuring a full incorporation of visual information into\nall system components is proposed in this paper. The efficacy of the video\ninput is consistently demonstrated in mask-based MVDR speech separation,\nDNN-WPE or spectral mapping (SpecM) based speech dereverberation front-end and\nConformer ASR back-end. Audio-visual integrated front-end architectures\nperforming speech separation and dereverberation in a pipelined or joint\nfashion via mask-based WPD are investigated. The error cost mismatch between\nthe speech enhancement front-end and ASR back-end components is minimized by\nend-to-end jointly fine-tuning using either the ASR cost function alone, or its\ninterpolation with the speech enhancement loss. Experiments were conducted on\nthe mixture overlapped and reverberant speech data constructed using simulation\nor replay of the Oxford LRS2 dataset. The proposed audio-visual multi-channel\nspeech separation, dereverberation and recognition systems consistently\noutperformed the comparable audio-only baseline by 9.1% and 6.2% absolute\n(41.7% and 36.0% relative) word error rate (WER) reductions. Consistent speech\nenhancement improvements were also obtained on PESQ, STOI and SRMR scores.\n","authors":["Guinan Li","Jiajun Deng","Mengzhe Geng","Zengrui Jin","Tianzi Wang","Shujie Hu","Mingyu Cui","Helen Meng","Xunying Liu"],"pdf_url":"https://arxiv.org/pdf/2307.02909v1.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing"},{"id":"http://arxiv.org/abs/2307.02892v1","updated":"2023-07-06T09:54:35Z","published":"2023-07-06T09:54:35Z","title":"The Relationship Between Speech Features Changes When You Get Depressed:\n  Feature Correlations for Improving Speed and Performance of Depression\n  Detection","summary":"  This work shows that depression changes the correlation between features\nextracted from speech. Furthermore, it shows that using such an insight can\nimprove the training speed and performance of depression detectors based on\nSVMs and LSTMs. The experiments were performed over the Androids Corpus, a\npublicly available dataset involving 112 speakers, including 58 people\ndiagnosed with depression by professional psychiatrists. The results show that\nthe models used in the experiments improve in terms of training speed and\nperformance when fed with feature correlation matrices rather than with feature\nvectors. The relative reduction of the error rate ranges between 23.1% and\n26.6% depending on the model. The probable explanation is that feature\ncorrelation matrices appear to be more variable in the case of depressed\nspeakers. Correspondingly, such a phenomenon can be thought of as a depression\nmarker.\n","authors":["Fuxiang Tao","Wei Ma","Xuri Ge","Anna Esposito","Alessandro Vinciarelli"],"pdf_url":"https://arxiv.org/pdf/2307.02892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14422v2","updated":"2023-07-06T08:17:31Z","published":"2023-06-26T05:04:58Z","title":"The Singing Voice Conversion Challenge 2023","summary":"  We present the latest iteration of the voice conversion challenge (VCC)\nseries, a bi-annual scientific event aiming to compare and understand different\nvoice conversion (VC) systems based on a common dataset. This year we shifted\nour focus to singing voice conversion (SVC), thus named the challenge the\nSinging Voice Conversion Challenge (SVCC). A new database was constructed for\ntwo tasks, namely in-domain and cross-domain SVC. The challenge was run for two\nmonths, and in total we received 26 submissions, including 2 baselines. Through\na large-scale crowd-sourced listening test, we observed that for both tasks,\nalthough human-level naturalness was achieved by the top system, no team was\nable to obtain a similarity score as high as the target speakers. Also, as\nexpected, cross-domain SVC is harder than in-domain SVC, especially in the\nsimilarity aspect. We also investigated whether existing objective measurements\nwere able to predict perceptual performance, and found that only few of them\ncould reach a significant correlation.\n","authors":["Wen-Chin Huang","Lester Phillip Violeta","Songxiang Liu","Jiatong Shi","Tomoki Toda"],"pdf_url":"https://arxiv.org/pdf/2306.14422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02820v1","updated":"2023-07-06T07:27:59Z","published":"2023-07-06T07:27:59Z","title":"Evaluating raw waveforms with deep learning frameworks for speech\n  emotion recognition","summary":"  Speech emotion recognition is a challenging task in speech processing field.\nFor this reason, feature extraction process has a crucial importance to\ndemonstrate and process the speech signals. In this work, we represent a model,\nwhich feeds raw audio files directly into the deep neural networks without any\nfeature extraction stage for the recognition of emotions utilizing six\ndifferent data sets, EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS. To\ndemonstrate the contribution of proposed model, the performance of traditional\nfeature extraction techniques namely, mel-scale spectogram, mel-frequency\ncepstral coefficients, are blended with machine learning algorithms, ensemble\nlearning methods, deep and hybrid deep learning techniques. Support vector\nmachine, decision tree, naive Bayes, random forests models are evaluated as\nmachine learning algorithms while majority voting and stacking methods are\nassessed as ensemble learning techniques. Moreover, convolutional neural\nnetworks, long short-term memory networks, and hybrid CNN- LSTM model are\nevaluated as deep learning techniques and compared with machine learning and\nensemble learning methods. To demonstrate the effectiveness of proposed model,\nthe comparison with state-of-the-art studies are carried out. Based on the\nexperiment results, CNN model excels existent approaches with 95.86% of\naccuracy for TESS+RAVDESS data set using raw audio files, thence determining\nthe new state-of-the-art. The proposed model performs 90.34% of accuracy for\nEMO-DB with CNN model, 90.42% of accuracy for RAVDESS with CNN model, 99.48% of\naccuracy for TESS with LSTM model, 69.72% of accuracy for CREMA with CNN model,\n85.76% of accuracy for SAVEE with CNN model in speaker-independent audio\ncategorization problems.\n","authors":["Zeynep Hilal Kilimci","Ulku Bayraktar","Ayhan Kucukmanisa"],"pdf_url":"https://arxiv.org/pdf/2307.02820v1.pdf","comment":"14 pages, 6 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2307.01715v2","updated":"2023-07-06T07:02:45Z","published":"2023-07-04T13:34:47Z","title":"Align With Purpose: Optimize Desired Properties in CTC Models with a\n  General Plug-and-Play Framework","summary":"  Connectionist Temporal Classification (CTC) is a widely used criterion for\ntraining supervised sequence-to-sequence (seq2seq) models. It enables learning\nthe relations between input and output sequences, termed alignments, by\nmarginalizing over perfect alignments (that yield the ground truth), at the\nexpense of imperfect alignments. This binary differentiation of perfect and\nimperfect alignments falls short of capturing other essential alignment\nproperties that hold significance in other real-world applications. Here we\npropose $\\textit{Align With Purpose}$, a $\\textbf{general Plug-and-Play\nframework}$ for enhancing a desired property in models trained with the CTC\ncriterion. We do that by complementing the CTC with an additional loss term\nthat prioritizes alignments according to a desired property. Our method does\nnot require any intervention in the CTC loss function, enables easy\noptimization of a variety of properties, and allows differentiation between\nboth perfect and imperfect alignments. We apply our framework in the domain of\nAutomatic Speech Recognition (ASR) and show its generality in terms of property\nselection, architectural choice, and scale of training dataset (up to 280,000\nhours). To demonstrate the effectiveness of our framework, we apply it to two\nunrelated properties: emission time and word error rate (WER). For the former,\nwe report an improvement of up to 570ms in latency optimization with a minor\nreduction in WER, and for the latter, we report a relative improvement of 4.5%\nWER over the baseline models. To the best of our knowledge, these applications\nhave never been demonstrated to work on a scale of data as large as ours.\nNotably, our method can be implemented using only a few lines of code, and can\nbe extended to other alignment-free loss functions and to domains other than\nASR.\n","authors":["Eliya Segev","Maya Alroy","Ronen Katsir","Noam Wies","Ayana Shenhav","Yael Ben-Oren","David Zar","Oren Tadmor","Jacob Bitterman","Amnon Shashua","Tal Rosenwein"],"pdf_url":"https://arxiv.org/pdf/2307.01715v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02751v1","updated":"2023-07-06T03:19:40Z","published":"2023-07-06T03:19:40Z","title":"DSARSR: Deep Stacked Auto-encoders Enhanced Robust Speaker Recognition","summary":"  Speaker recognition is a biometric modality that utilizes the speaker's\nspeech segments to recognize the identity, determining whether the test speaker\nbelongs to one of the enrolled speakers. In order to improve the robustness of\nthe i-vector framework on cross-channel conditions and explore the nova method\nfor applying deep learning to speaker recognition, the Stacked Auto-encoders\nare used to get the abstract extraction of the i-vector instead of applying\nPLDA. After pre-processing and feature extraction, the speaker and\nchannel-independent speeches are employed for UBM training. The UBM is then\nused to extract the i-vector of the enrollment and test speech. Unlike the\ntraditional i-vector framework, which uses linear discriminant analysis (LDA)\nto reduce dimension and increase the discrimination between speaker subspaces,\nthis research use stacked auto-encoders to reconstruct the i-vector with lower\ndimension and different classifiers can be chosen to achieve final\nclassification. The experimental results show that the proposed method achieves\nbetter performance than the state-of-the-art method.\n","authors":["Zhifeng Wang","Chunyan Zeng","Surong Duan","Hongjie Ouyang","Hongmin Xu"],"pdf_url":"https://arxiv.org/pdf/2307.02751v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2307.02720v1","updated":"2023-07-06T02:03:31Z","published":"2023-07-06T02:03:31Z","title":"On-Device Constrained Self-Supervised Speech Representation Learning for\n  Keyword Spotting via Knowledge Distillation","summary":"  Large self-supervised models are effective feature extractors, but their\napplication is challenging under on-device budget constraints and biased\ndataset collection, especially in keyword spotting. To address this, we\nproposed a knowledge distillation-based self-supervised speech representation\nlearning (S3RL) architecture for on-device keyword spotting. Our approach used\na teacher-student framework to transfer knowledge from a larger, more complex\nmodel to a smaller, light-weight model using dual-view cross-correlation\ndistillation and the teacher's codebook as learning objectives. We evaluated\nour model's performance on an Alexa keyword spotting detection task using a\n16.6k-hour in-house dataset. Our technique showed exceptional performance in\nnormal and noisy conditions, demonstrating the efficacy of knowledge\ndistillation methods in constructing self-supervised models for keyword\nspotting tasks while working within on-device resource constraints.\n","authors":["Gene-Ping Yang","Yue Gu","Qingming Tang","Dongsu Du","Yuzong Liu"],"pdf_url":"https://arxiv.org/pdf/2307.02720v1.pdf","comment":"Accepted to Interspeech 2023"},{"id":"http://arxiv.org/abs/2307.03296v1","updated":"2023-07-06T21:10:50Z","published":"2023-07-06T21:10:50Z","title":"Gammatonegram Representation for End-to-End Dysarthric Speech Processing\n  Tasks: Speech Recognition, Speaker Identification, and Intelligibility\n  Assessment","summary":"  Dysarthria is a disability that causes a disturbance in the human speech\nsystem and reduces the quality and intelligibility of a person's speech.\nBecause of this effect, the normal speech processing systems can not work\nproperly on impaired speech. This disability is usually associated with\nphysical disabilities. Therefore, designing a system that can perform some\ntasks by receiving voice commands in the smart home can be a significant\nachievement. In this work, we introduce gammatonegram as an effective method to\nrepresent audio files with discriminative details, which is used as input for\nthe convolutional neural network. On the other word, we convert each speech\nfile into an image and propose image recognition system to classify speech in\ndifferent scenarios. Proposed CNN is based on the transfer learning method on\nthe pre-trained Alexnet. In this research, the efficiency of the proposed\nsystem for speech recognition, speaker identification, and intelligibility\nassessment is evaluated. According to the results on the UA dataset, the\nproposed speech recognition system achieved 91.29% accuracy in\nspeaker-dependent mode, the speaker identification system acquired 87.74%\naccuracy in text-dependent mode, and the intelligibility assessment system\nachieved 96.47% accuracy in two-class mode. Finally, we propose a multi-network\nspeech recognition system that works fully automatically. This system is\nlocated in a cascade arrangement with the two-class intelligibility assessment\nsystem, and the output of this system activates each one of the speech\nrecognition networks. This architecture achieves an accuracy of 92.3% WRR. The\nsource code of this paper is available.\n","authors":["Aref Farhadipour","Hadi Veisi"],"pdf_url":"https://arxiv.org/pdf/2307.03296v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2305.11397v2","updated":"2023-07-06T20:57:53Z","published":"2023-05-19T02:47:51Z","title":"Are Microphone Signals Alone Sufficient for Self-Positioning?","summary":"  In an era where asynchronous environments pose challenges to traditional\nself-positioning methods, we propose a new transformation to the existing\nparadigm. Traditionally, time of arrival (TOA) measurements require both\nmicrophone and source signals, limiting their applicability in environments\nwith unknown emission time of human voices or sources and unknown recording\nstart time of independent microphones. To address this issue, our research\npioneers a mapping function capable of transforming both TOA and time\ndifference of arrival (TDOA) formulas, demonstrating, for the first time, that\nthey can be identical to one another. This implies that microphone signals\nalone are sufficient for self-positioning without the need for source signal\nwaveforms, a groundbreaking advancement in the field that carries the potential\nto revolutionize self-positioning techniques, expanding their applicability in\nchallenging environments. Supported by a robust mathematical proof and\ncompelling experimental results, this research represents a timely and\nsignificant contribution to the current discourse in signal, and audio\nprocessing.\n","authors":["Faxian Cao","Yongqiang Cheng","Adil Mehmood Khan","Zhijing Yang"],"pdf_url":"https://arxiv.org/pdf/2305.11397v2.pdf","comment":"1 figure, including 3 sub-figures"},{"id":"http://arxiv.org/abs/2304.04596v3","updated":"2023-07-06T20:07:49Z","published":"2023-04-10T14:05:22Z","title":"ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit","summary":"  ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by\nthe broadening interests of the spoken language translation community.\nESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2)\nsimultaneous speech-to-text translation (SST), and 3) offline speech-to-speech\ntranslation (S2ST) -- each task is supported with a wide variety of approaches,\ndifferentiating ESPnet-ST-v2 from other open source spoken language translation\ntoolkits. This toolkit offers state-of-the-art architectures such as\ntransducers, hybrid CTC/attention, multi-decoders with searchable\nintermediates, time-synchronous blockwise CTC/attention, Translatotron models,\nand direct discrete unit models. In this paper, we describe the overall design,\nexample models for each task, and performance benchmarking behind ESPnet-ST-v2,\nwhich is publicly available at https://github.com/espnet/espnet.\n","authors":["Brian Yan","Jiatong Shi","Yun Tang","Hirofumi Inaguma","Yifan Peng","Siddharth Dalmia","Peter Polák","Patrick Fernandes","Dan Berrebbi","Tomoki Hayashi","Xiaohui Zhang","Zhaoheng Ni","Moto Hira","Soumi Maiti","Juan Pino","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2304.04596v3.pdf","comment":"ACL 2023; System Demonstration"},{"id":"http://arxiv.org/abs/2307.04765v1","updated":"2023-07-06T21:01:18Z","published":"2023-07-06T21:01:18Z","title":"Performance Comparison of Pre-trained Models for Speech-to-Text in\n  Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M","summary":"  In this study, the performances of the Whisper-Small and Wav2Vec2-XLS-R-300M\nmodels which are two pre-trained multilingual models for speech to text were\nexamined for the Turkish language. Mozilla Common Voice version 11.0 which is\nprepared in Turkish language and is an open-source data set, was used in the\nstudy. The multilingual models, Whisper- Small and Wav2Vec2-XLS-R-300M were\nfine-tuned with this data set which contains a small amount of data. The speech\nto text performance of the two models was compared. WER values are calculated\nas 0.28 and 0.16 for the Wav2Vec2-XLS- R-300M and the Whisper-Small models\nrespectively. In addition, the performances of the models were examined with\nthe test data prepared with call center records that were not included in the\ntraining and validation dataset.\n","authors":["Oyku Berfin Mercan","Sercan Cepni","Davut Emre Tasar","Sukru Ozan"],"pdf_url":"https://arxiv.org/pdf/2307.04765v1.pdf","comment":"10 Pages, in Turkish language, Pre-Print"}],"Audio and Speech Processing":[{"id":"http://arxiv.org/abs/2307.03183v1","updated":"2023-07-06T17:58:28Z","published":"2023-07-06T17:58:28Z","title":"Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong\n  General Audio Event Taggers","summary":"  In this paper, we focus on Whisper, a recent automatic speech recognition\nmodel trained with a massive 680k hour labeled speech corpus recorded in\ndiverse conditions. We first show an interesting finding that while Whisper is\nvery robust against real-world background sounds (e.g., music), its audio\nrepresentation is actually not noise-invariant, but is instead highly\ncorrelated to non-speech sounds, indicating that Whisper recognizes speech\nconditioned on the noise type. With this finding, we build a unified audio\ntagging and speech recognition model Whisper-AT by freezing the backbone of\nWhisper, and training a lightweight audio tagging model on top of it. With <1%\nextra computational cost, Whisper-AT can recognize audio events, in addition to\nspoken text, in a single forward pass.\n","authors":["Yuan Gong","Sameer Khurana","Leonid Karlinsky","James Glass"],"pdf_url":"https://arxiv.org/pdf/2307.03183v1.pdf","comment":"Accepted at Interspeech 2023. Code at\n  https://github.com/yuangongnd/whisper-at"},{"id":"http://arxiv.org/abs/2307.03168v1","updated":"2023-07-06T17:49:08Z","published":"2023-07-06T17:49:08Z","title":"Recovering implicit pitch contours from formants in whispered speech","summary":"  Whispered speech is characterised by a noise-like excitation that results in\nthe lack of fundamental frequency. Considering that prosodic phenomena such as\nintonation are perceived through f0 variation, the perception of whispered\nprosody is relatively difficult. At the same time, studies have shown that\nspeakers do attempt to produce intonation when whispering and that prosodic\nvariability is being transmitted, suggesting that intonation \"survives\" in\nwhispered formant structure. In this paper, we aim to estimate the way in which\nformant contours correlate with an \"implicit\" pitch contour in whisper, using a\nmachine learning model. We propose a two-step method: using a parallel corpus,\nwe first transform the whispered formants into their phonated equivalents using\na denoising autoencoder. We then analyse the formant contours to predict\nphonated pitch contour variation. We observe that our method is effective in\nestablishing a relationship between whispered and phonated formants and in\nuncovering implicit pitch contours in whisper.\n","authors":["Pablo Pérez Zarazaga","Zofia Malisz"],"pdf_url":"https://arxiv.org/pdf/2307.03168v1.pdf","comment":"5 pages, 3 figures, 2 tables, Accepted at ICPhS 2023"},{"id":"http://arxiv.org/abs/2306.01425v2","updated":"2023-07-06T17:32:50Z","published":"2023-06-02T10:31:23Z","title":"Active Noise Control in The New Century: The Role and Prospect of Signal\n  Processing","summary":"  Since Paul Leug's 1933 patent application for a system for the active control\nof sound, the field of active noise control (ANC) has not flourished until the\nadvent of digital signal processors forty years ago. Early theoretical\nadvancements in digital signal processing and processors laid the groundwork\nfor the phenomenal growth of the field, particularly over the past\nquarter-century. The widespread commercial success of ANC in aircraft cabins,\nautomobile cabins, and headsets demonstrates the immeasurable public health and\neconomic benefits of ANC. This article continues where Elliott and Nelson's\n1993 Signal Processing Magazine article and Elliott's 1997 50th anniversary\ncommentary on ANC left off, tracing the technical developments and applications\nin ANC spurred by the seminal texts of Nelson and Elliott (1991), Kuo and\nMorgan (1996), Hansen and Snyder (1996), and Elliott (2001) since the turn of\nthe century. This article focuses on technical developments pertaining to\nreal-world implementations, such as improving algorithmic convergence, reducing\nsystem latency, and extending control to non-stationary and/or broadband noise,\nas well as the commercial transition challenges from analog to digital ANC\nsystems. Finally, open issues and the future of ANC in the era of artificial\nintelligence are discussed.\n","authors":["Dongyuan Shi","Bhan Lam","Woon-Seng Gan","Jordan Cheer","Stephen J. Elliott"],"pdf_url":"https://arxiv.org/pdf/2306.01425v2.pdf","comment":"Submitted to inter.noise 2023, Chiba, Japan"},{"id":"http://arxiv.org/abs/2007.12069v4","updated":"2023-07-06T17:04:17Z","published":"2020-07-23T15:28:58Z","title":"Version Control of Speaker Recognition Systems","summary":"  This paper discusses one of the most challenging practical engineering\nproblems in speaker recognition systems - the version control of models and\nuser profiles. A typical speaker recognition system consists of two stages: the\nenrollment stage, where a profile is generated from user-provided enrollment\naudio; and the runtime stage, where the voice identity of the runtime audio is\ncompared against the stored profiles. As technology advances, the speaker\nrecognition system needs to be updated for better performance. However, if the\nstored user profiles are not updated accordingly, version mismatch will result\nin meaningless recognition results. In this paper, we describe different\nversion control strategies for speaker recognition systems that had been\ncarefully studied at Google from years of engineering practice. These\nstrategies are categorized into three groups according to how they are deployed\nin the production environment: device-side deployment, server-side deployment,\nand hybrid deployment. To compare different strategies with quantitative\nmetrics under various network configurations, we present SpeakerVerSim, an\neasily-extensible Python-based simulation framework for different server-side\ndeployment strategies of speaker recognition systems.\n","authors":["Quan Wang","Ignacio Lopez Moreno"],"pdf_url":"https://arxiv.org/pdf/2007.12069v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03088v1","updated":"2023-07-06T16:01:10Z","published":"2023-07-06T16:01:10Z","title":"Label-Synchronous Neural Transducer for End-to-End ASR","summary":"  Neural transducers provide a natural approach to streaming ASR. However, they\naugment output sequences with blank tokens which leads to challenges for domain\nadaptation using text data. This paper proposes a label-synchronous neural\ntransducer (LS-Transducer), which extracts a label-level encoder representation\nbefore combining it with the prediction network output. Hence blank tokens are\nno longer needed and the prediction network can be easily adapted using text\ndata. An Auto-regressive Integrate-and-Fire (AIF) mechanism is proposed to\ngenerate the label-level encoder representation while retaining the streaming\nproperty. In addition, a streaming joint decoding method is designed to improve\nASR accuracy. Experiments show that compared to standard neural transducers,\nthe proposed LS-Transducer gave a 10% relative WER reduction (WERR) for\nintra-domain Librispeech-100h data, as well as 17% and 19% relative WERRs on\ncross-domain TED-LIUM 2 and AESRC2020 data with an adapted prediction network.\n","authors":["Keqi Deng","Philip C. Woodland"],"pdf_url":"https://arxiv.org/pdf/2307.03088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03045v1","updated":"2023-07-06T15:10:29Z","published":"2023-07-06T15:10:29Z","title":"Track Mix Generation on Music Streaming Services using Transformers","summary":"  This paper introduces Track Mix, a personalized playlist generation system\nreleased in 2022 on the music streaming service Deezer. Track Mix automatically\ngenerates \"mix\" playlists inspired by initial music tracks, allowing users to\ndiscover music similar to their favorite content. To generate these mixes, we\nconsider a Transformer model trained on millions of track sequences from user\nplaylists. In light of the growing popularity of Transformers in recent years,\nwe analyze the advantages, drawbacks, and technical challenges of using such a\nmodel for mix generation on the service, compared to a more traditional\ncollaborative filtering approach. Since its release, Track Mix has been\ngenerating playlists for millions of users daily, enhancing their music\ndiscovery experience on Deezer.\n","authors":["Walid Bendada","Théo Bontempelli","Mathieu Morlon","Benjamin Chapus","Thibault Cador","Thomas Bouabça","Guillaume Salha-Galvan"],"pdf_url":"https://arxiv.org/pdf/2307.03045v1.pdf","comment":"RecSys 2023 - Industry track with oral presentation"},{"id":"http://arxiv.org/abs/2306.03307v2","updated":"2023-07-06T13:44:20Z","published":"2023-06-05T23:27:39Z","title":"Reef Elegy: An Auditory Display of Hawaii's 2019 Coral Bleaching Data","summary":"  This paper describes an auditory display of Hawaii's 2019 coral bleaching\ndata via means of spatial audio and parameter mapping methods. Selected data\nfields spanning 78 days are mapped to sound surrogates of coral reefs' natural\nsoundscapes, which are progressively altered in their constituent elements as\nthe corresponding coral locations undergo bleaching. For some of these\nelements, this process outlines a trajectory from a dense to a sparser, reduced\nsoundscape, while for others it translates moving away from harmonic tones and\ntowards complex spectra. This experiment is accompanied by a short evaluation\nstudy to contextualize it in an established aesthetic perspective space and to\nprobe its potential for public engagement in the discourse around climate\nchange.\n","authors":["Stefano Kalonaris"],"pdf_url":"https://arxiv.org/pdf/2306.03307v2.pdf","comment":"To appear in: Proceedings of the 28th International Conference on\n  Auditory Display (ICAD 2023) NOTE: This version (v2) replaces Figure 2, which\n  was incorrectly rendered. Do not use or cite the previous version (v1)"},{"id":"http://arxiv.org/abs/2305.12263v2","updated":"2023-07-06T13:43:56Z","published":"2023-05-20T18:41:13Z","title":"Self-supervised representations in speech-based depression detection","summary":"  This paper proposes handling training data sparsity in speech-based automatic\ndepression detection (SDD) using foundation models pre-trained with\nself-supervised learning (SSL). An analysis of SSL representations derived from\ndifferent layers of pre-trained foundation models is first presented for SDD,\nwhich provides insight to suitable indicator for depression detection.\nKnowledge transfer is then performed from automatic speech recognition (ASR)\nand emotion recognition to SDD by fine-tuning the foundation models. Results\nshow that the uses of oracle and ASR transcriptions yield similar SDD\nperformance when the hidden representations of the ASR model is incorporated\nalong with the ASR textual information. By integrating representations from\nmultiple foundation models, state-of-the-art SDD results based on real ASR were\nachieved on the DAIC-WOZ dataset.\n","authors":["Wen Wu","Chao Zhang","Philip C. Woodland"],"pdf_url":"https://arxiv.org/pdf/2305.12263v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02975v1","updated":"2023-07-06T13:19:27Z","published":"2023-07-06T13:19:27Z","title":"Transfer Learning for the Efficient Detection of COVID-19 from\n  Smartphone Audio Data","summary":"  Disease detection from smartphone data represents an open research challenge\nin mobile health (m-health) systems. COVID-19 and its respiratory symptoms are\nan important case study in this area and their early detection is a potential\nreal instrument to counteract the pandemic situation. The efficacy of this\nsolution mainly depends on the performances of AI algorithms applied to the\ncollected data and their possible implementation directly on the users' mobile\ndevices. Considering these issues, and the limited amount of available data, in\nthis paper we present the experimental evaluation of 3 different deep learning\nmodels, compared also with hand-crafted features, and of two main approaches of\ntransfer learning in the considered scenario: both feature extraction and\nfine-tuning. Specifically, we considered VGGish, YAMNET, and\nL\\textsuperscript{3}-Net (including 12 different configurations) evaluated\nthrough user-independent experiments on 4 different datasets (13,447 samples in\ntotal). Results clearly show the advantages of L\\textsuperscript{3}-Net in all\nthe experimental settings as it overcomes the other solutions by 12.3\\% in\nterms of Precision-Recall AUC as features extractor, and by 10\\% when the model\nis fine-tuned. Moreover, we note that to fine-tune only the fully-connected\nlayers of the pre-trained models generally leads to worse performances, with an\naverage drop of 6.6\\% with respect to feature extraction. %highlighting the\nneed for further investigations. Finally, we evaluate the memory footprints of\nthe different models for their possible applications on commercial mobile\ndevices.\n","authors":["Mattia Giovanni Campana","Franca Delmastro","Elena Pagani"],"pdf_url":"https://arxiv.org/pdf/2307.02975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02909v1","updated":"2023-07-06T10:50:46Z","published":"2023-07-06T10:50:46Z","title":"Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation\n  and Recognition","summary":"  Accurate recognition of cocktail party speech containing overlapping\nspeakers, noise and reverberation remains a highly challenging task to date.\nMotivated by the invariance of visual modality to acoustic signal corruption,\nan audio-visual multi-channel speech separation, dereverberation and\nrecognition approach featuring a full incorporation of visual information into\nall system components is proposed in this paper. The efficacy of the video\ninput is consistently demonstrated in mask-based MVDR speech separation,\nDNN-WPE or spectral mapping (SpecM) based speech dereverberation front-end and\nConformer ASR back-end. Audio-visual integrated front-end architectures\nperforming speech separation and dereverberation in a pipelined or joint\nfashion via mask-based WPD are investigated. The error cost mismatch between\nthe speech enhancement front-end and ASR back-end components is minimized by\nend-to-end jointly fine-tuning using either the ASR cost function alone, or its\ninterpolation with the speech enhancement loss. Experiments were conducted on\nthe mixture overlapped and reverberant speech data constructed using simulation\nor replay of the Oxford LRS2 dataset. The proposed audio-visual multi-channel\nspeech separation, dereverberation and recognition systems consistently\noutperformed the comparable audio-only baseline by 9.1% and 6.2% absolute\n(41.7% and 36.0% relative) word error rate (WER) reductions. Consistent speech\nenhancement improvements were also obtained on PESQ, STOI and SRMR scores.\n","authors":["Guinan Li","Jiajun Deng","Mengzhe Geng","Zengrui Jin","Tianzi Wang","Shujie Hu","Mingyu Cui","Helen Meng","Xunying Liu"],"pdf_url":"https://arxiv.org/pdf/2307.02909v1.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing"},{"id":"http://arxiv.org/abs/2307.02892v1","updated":"2023-07-06T09:54:35Z","published":"2023-07-06T09:54:35Z","title":"The Relationship Between Speech Features Changes When You Get Depressed:\n  Feature Correlations for Improving Speed and Performance of Depression\n  Detection","summary":"  This work shows that depression changes the correlation between features\nextracted from speech. Furthermore, it shows that using such an insight can\nimprove the training speed and performance of depression detectors based on\nSVMs and LSTMs. The experiments were performed over the Androids Corpus, a\npublicly available dataset involving 112 speakers, including 58 people\ndiagnosed with depression by professional psychiatrists. The results show that\nthe models used in the experiments improve in terms of training speed and\nperformance when fed with feature correlation matrices rather than with feature\nvectors. The relative reduction of the error rate ranges between 23.1% and\n26.6% depending on the model. The probable explanation is that feature\ncorrelation matrices appear to be more variable in the case of depressed\nspeakers. Correspondingly, such a phenomenon can be thought of as a depression\nmarker.\n","authors":["Fuxiang Tao","Wei Ma","Xuri Ge","Anna Esposito","Alessandro Vinciarelli"],"pdf_url":"https://arxiv.org/pdf/2307.02892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14422v2","updated":"2023-07-06T08:17:31Z","published":"2023-06-26T05:04:58Z","title":"The Singing Voice Conversion Challenge 2023","summary":"  We present the latest iteration of the voice conversion challenge (VCC)\nseries, a bi-annual scientific event aiming to compare and understand different\nvoice conversion (VC) systems based on a common dataset. This year we shifted\nour focus to singing voice conversion (SVC), thus named the challenge the\nSinging Voice Conversion Challenge (SVCC). A new database was constructed for\ntwo tasks, namely in-domain and cross-domain SVC. The challenge was run for two\nmonths, and in total we received 26 submissions, including 2 baselines. Through\na large-scale crowd-sourced listening test, we observed that for both tasks,\nalthough human-level naturalness was achieved by the top system, no team was\nable to obtain a similarity score as high as the target speakers. Also, as\nexpected, cross-domain SVC is harder than in-domain SVC, especially in the\nsimilarity aspect. We also investigated whether existing objective measurements\nwere able to predict perceptual performance, and found that only few of them\ncould reach a significant correlation.\n","authors":["Wen-Chin Huang","Lester Phillip Violeta","Songxiang Liu","Jiatong Shi","Tomoki Toda"],"pdf_url":"https://arxiv.org/pdf/2306.14422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02820v1","updated":"2023-07-06T07:27:59Z","published":"2023-07-06T07:27:59Z","title":"Evaluating raw waveforms with deep learning frameworks for speech\n  emotion recognition","summary":"  Speech emotion recognition is a challenging task in speech processing field.\nFor this reason, feature extraction process has a crucial importance to\ndemonstrate and process the speech signals. In this work, we represent a model,\nwhich feeds raw audio files directly into the deep neural networks without any\nfeature extraction stage for the recognition of emotions utilizing six\ndifferent data sets, EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS. To\ndemonstrate the contribution of proposed model, the performance of traditional\nfeature extraction techniques namely, mel-scale spectogram, mel-frequency\ncepstral coefficients, are blended with machine learning algorithms, ensemble\nlearning methods, deep and hybrid deep learning techniques. Support vector\nmachine, decision tree, naive Bayes, random forests models are evaluated as\nmachine learning algorithms while majority voting and stacking methods are\nassessed as ensemble learning techniques. Moreover, convolutional neural\nnetworks, long short-term memory networks, and hybrid CNN- LSTM model are\nevaluated as deep learning techniques and compared with machine learning and\nensemble learning methods. To demonstrate the effectiveness of proposed model,\nthe comparison with state-of-the-art studies are carried out. Based on the\nexperiment results, CNN model excels existent approaches with 95.86% of\naccuracy for TESS+RAVDESS data set using raw audio files, thence determining\nthe new state-of-the-art. The proposed model performs 90.34% of accuracy for\nEMO-DB with CNN model, 90.42% of accuracy for RAVDESS with CNN model, 99.48% of\naccuracy for TESS with LSTM model, 69.72% of accuracy for CREMA with CNN model,\n85.76% of accuracy for SAVEE with CNN model in speaker-independent audio\ncategorization problems.\n","authors":["Zeynep Hilal Kilimci","Ulku Bayraktar","Ayhan Kucukmanisa"],"pdf_url":"https://arxiv.org/pdf/2307.02820v1.pdf","comment":"14 pages, 6 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2307.01715v2","updated":"2023-07-06T07:02:45Z","published":"2023-07-04T13:34:47Z","title":"Align With Purpose: Optimize Desired Properties in CTC Models with a\n  General Plug-and-Play Framework","summary":"  Connectionist Temporal Classification (CTC) is a widely used criterion for\ntraining supervised sequence-to-sequence (seq2seq) models. It enables learning\nthe relations between input and output sequences, termed alignments, by\nmarginalizing over perfect alignments (that yield the ground truth), at the\nexpense of imperfect alignments. This binary differentiation of perfect and\nimperfect alignments falls short of capturing other essential alignment\nproperties that hold significance in other real-world applications. Here we\npropose $\\textit{Align With Purpose}$, a $\\textbf{general Plug-and-Play\nframework}$ for enhancing a desired property in models trained with the CTC\ncriterion. We do that by complementing the CTC with an additional loss term\nthat prioritizes alignments according to a desired property. Our method does\nnot require any intervention in the CTC loss function, enables easy\noptimization of a variety of properties, and allows differentiation between\nboth perfect and imperfect alignments. We apply our framework in the domain of\nAutomatic Speech Recognition (ASR) and show its generality in terms of property\nselection, architectural choice, and scale of training dataset (up to 280,000\nhours). To demonstrate the effectiveness of our framework, we apply it to two\nunrelated properties: emission time and word error rate (WER). For the former,\nwe report an improvement of up to 570ms in latency optimization with a minor\nreduction in WER, and for the latter, we report a relative improvement of 4.5%\nWER over the baseline models. To the best of our knowledge, these applications\nhave never been demonstrated to work on a scale of data as large as ours.\nNotably, our method can be implemented using only a few lines of code, and can\nbe extended to other alignment-free loss functions and to domains other than\nASR.\n","authors":["Eliya Segev","Maya Alroy","Ronen Katsir","Noam Wies","Ayana Shenhav","Yael Ben-Oren","David Zar","Oren Tadmor","Jacob Bitterman","Amnon Shashua","Tal Rosenwein"],"pdf_url":"https://arxiv.org/pdf/2307.01715v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02751v1","updated":"2023-07-06T03:19:40Z","published":"2023-07-06T03:19:40Z","title":"DSARSR: Deep Stacked Auto-encoders Enhanced Robust Speaker Recognition","summary":"  Speaker recognition is a biometric modality that utilizes the speaker's\nspeech segments to recognize the identity, determining whether the test speaker\nbelongs to one of the enrolled speakers. In order to improve the robustness of\nthe i-vector framework on cross-channel conditions and explore the nova method\nfor applying deep learning to speaker recognition, the Stacked Auto-encoders\nare used to get the abstract extraction of the i-vector instead of applying\nPLDA. After pre-processing and feature extraction, the speaker and\nchannel-independent speeches are employed for UBM training. The UBM is then\nused to extract the i-vector of the enrollment and test speech. Unlike the\ntraditional i-vector framework, which uses linear discriminant analysis (LDA)\nto reduce dimension and increase the discrimination between speaker subspaces,\nthis research use stacked auto-encoders to reconstruct the i-vector with lower\ndimension and different classifiers can be chosen to achieve final\nclassification. The experimental results show that the proposed method achieves\nbetter performance than the state-of-the-art method.\n","authors":["Zhifeng Wang","Chunyan Zeng","Surong Duan","Hongjie Ouyang","Hongmin Xu"],"pdf_url":"https://arxiv.org/pdf/2307.02751v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2307.02720v1","updated":"2023-07-06T02:03:31Z","published":"2023-07-06T02:03:31Z","title":"On-Device Constrained Self-Supervised Speech Representation Learning for\n  Keyword Spotting via Knowledge Distillation","summary":"  Large self-supervised models are effective feature extractors, but their\napplication is challenging under on-device budget constraints and biased\ndataset collection, especially in keyword spotting. To address this, we\nproposed a knowledge distillation-based self-supervised speech representation\nlearning (S3RL) architecture for on-device keyword spotting. Our approach used\na teacher-student framework to transfer knowledge from a larger, more complex\nmodel to a smaller, light-weight model using dual-view cross-correlation\ndistillation and the teacher's codebook as learning objectives. We evaluated\nour model's performance on an Alexa keyword spotting detection task using a\n16.6k-hour in-house dataset. Our technique showed exceptional performance in\nnormal and noisy conditions, demonstrating the efficacy of knowledge\ndistillation methods in constructing self-supervised models for keyword\nspotting tasks while working within on-device resource constraints.\n","authors":["Gene-Ping Yang","Yue Gu","Qingming Tang","Dongsu Du","Yuzong Liu"],"pdf_url":"https://arxiv.org/pdf/2307.02720v1.pdf","comment":"Accepted to Interspeech 2023"},{"id":"http://arxiv.org/abs/2307.03296v1","updated":"2023-07-06T21:10:50Z","published":"2023-07-06T21:10:50Z","title":"Gammatonegram Representation for End-to-End Dysarthric Speech Processing\n  Tasks: Speech Recognition, Speaker Identification, and Intelligibility\n  Assessment","summary":"  Dysarthria is a disability that causes a disturbance in the human speech\nsystem and reduces the quality and intelligibility of a person's speech.\nBecause of this effect, the normal speech processing systems can not work\nproperly on impaired speech. This disability is usually associated with\nphysical disabilities. Therefore, designing a system that can perform some\ntasks by receiving voice commands in the smart home can be a significant\nachievement. In this work, we introduce gammatonegram as an effective method to\nrepresent audio files with discriminative details, which is used as input for\nthe convolutional neural network. On the other word, we convert each speech\nfile into an image and propose image recognition system to classify speech in\ndifferent scenarios. Proposed CNN is based on the transfer learning method on\nthe pre-trained Alexnet. In this research, the efficiency of the proposed\nsystem for speech recognition, speaker identification, and intelligibility\nassessment is evaluated. According to the results on the UA dataset, the\nproposed speech recognition system achieved 91.29% accuracy in\nspeaker-dependent mode, the speaker identification system acquired 87.74%\naccuracy in text-dependent mode, and the intelligibility assessment system\nachieved 96.47% accuracy in two-class mode. Finally, we propose a multi-network\nspeech recognition system that works fully automatically. This system is\nlocated in a cascade arrangement with the two-class intelligibility assessment\nsystem, and the output of this system activates each one of the speech\nrecognition networks. This architecture achieves an accuracy of 92.3% WRR. The\nsource code of this paper is available.\n","authors":["Aref Farhadipour","Hadi Veisi"],"pdf_url":"https://arxiv.org/pdf/2307.03296v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2305.11397v2","updated":"2023-07-06T20:57:53Z","published":"2023-05-19T02:47:51Z","title":"Are Microphone Signals Alone Sufficient for Self-Positioning?","summary":"  In an era where asynchronous environments pose challenges to traditional\nself-positioning methods, we propose a new transformation to the existing\nparadigm. Traditionally, time of arrival (TOA) measurements require both\nmicrophone and source signals, limiting their applicability in environments\nwith unknown emission time of human voices or sources and unknown recording\nstart time of independent microphones. To address this issue, our research\npioneers a mapping function capable of transforming both TOA and time\ndifference of arrival (TDOA) formulas, demonstrating, for the first time, that\nthey can be identical to one another. This implies that microphone signals\nalone are sufficient for self-positioning without the need for source signal\nwaveforms, a groundbreaking advancement in the field that carries the potential\nto revolutionize self-positioning techniques, expanding their applicability in\nchallenging environments. Supported by a robust mathematical proof and\ncompelling experimental results, this research represents a timely and\nsignificant contribution to the current discourse in signal, and audio\nprocessing.\n","authors":["Faxian Cao","Yongqiang Cheng","Adil Mehmood Khan","Zhijing Yang"],"pdf_url":"https://arxiv.org/pdf/2305.11397v2.pdf","comment":"1 figure, including 3 sub-figures"},{"id":"http://arxiv.org/abs/2304.04596v3","updated":"2023-07-06T20:07:49Z","published":"2023-04-10T14:05:22Z","title":"ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit","summary":"  ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by\nthe broadening interests of the spoken language translation community.\nESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2)\nsimultaneous speech-to-text translation (SST), and 3) offline speech-to-speech\ntranslation (S2ST) -- each task is supported with a wide variety of approaches,\ndifferentiating ESPnet-ST-v2 from other open source spoken language translation\ntoolkits. This toolkit offers state-of-the-art architectures such as\ntransducers, hybrid CTC/attention, multi-decoders with searchable\nintermediates, time-synchronous blockwise CTC/attention, Translatotron models,\nand direct discrete unit models. In this paper, we describe the overall design,\nexample models for each task, and performance benchmarking behind ESPnet-ST-v2,\nwhich is publicly available at https://github.com/espnet/espnet.\n","authors":["Brian Yan","Jiatong Shi","Yun Tang","Hirofumi Inaguma","Yifan Peng","Siddharth Dalmia","Peter Polák","Patrick Fernandes","Dan Berrebbi","Tomoki Hayashi","Xiaohui Zhang","Zhaoheng Ni","Moto Hira","Soumi Maiti","Juan Pino","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2304.04596v3.pdf","comment":"ACL 2023; System Demonstration"},{"id":"http://arxiv.org/abs/2307.04765v1","updated":"2023-07-06T21:01:18Z","published":"2023-07-06T21:01:18Z","title":"Performance Comparison of Pre-trained Models for Speech-to-Text in\n  Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M","summary":"  In this study, the performances of the Whisper-Small and Wav2Vec2-XLS-R-300M\nmodels which are two pre-trained multilingual models for speech to text were\nexamined for the Turkish language. Mozilla Common Voice version 11.0 which is\nprepared in Turkish language and is an open-source data set, was used in the\nstudy. The multilingual models, Whisper- Small and Wav2Vec2-XLS-R-300M were\nfine-tuned with this data set which contains a small amount of data. The speech\nto text performance of the two models was compared. WER values are calculated\nas 0.28 and 0.16 for the Wav2Vec2-XLS- R-300M and the Whisper-Small models\nrespectively. In addition, the performances of the models were examined with\nthe test data prepared with call center records that were not included in the\ntraining and validation dataset.\n","authors":["Oyku Berfin Mercan","Sercan Cepni","Davut Emre Tasar","Sukru Ozan"],"pdf_url":"https://arxiv.org/pdf/2307.04765v1.pdf","comment":"10 Pages, in Turkish language, Pre-Print"},{"id":"http://arxiv.org/abs/2307.04532v1","updated":"2023-07-06T08:02:45Z","published":"2023-07-06T08:02:45Z","title":"Read, Look or Listen? What's Needed for Solving a Multimodal Dataset","summary":"  The prevalence of large-scale multimodal datasets presents unique challenges\nin assessing dataset quality. We propose a two-step method to analyze\nmultimodal datasets, which leverages a small seed of human annotation to map\neach multimodal instance to the modalities required to process it. Our method\nsheds light on the importance of different modalities in datasets, as well as\nthe relationship between them. We apply our approach to TVQA, a video\nquestion-answering dataset, and discover that most questions can be answered\nusing a single modality, without a substantial bias towards any specific\nmodality. Moreover, we find that more than 70% of the questions are solvable\nusing several different single-modality strategies, e.g., by either looking at\nthe video or listening to the audio, highlighting the limited integration of\nmultiple modalities in TVQA. We leverage our annotation and analyze the MERLOT\nReserve, finding that it struggles with image-based questions compared to text\nand audio, but also with auditory speaker identification. Based on our\nobservations, we introduce a new test set that necessitates multiple\nmodalities, observing a dramatic drop in model performance. Our methodology\nprovides valuable insights into multimodal datasets and highlights the need for\nthe development of more robust models.\n","authors":["Netta Madvil","Yonatan Bitton","Roy Schwartz"],"pdf_url":"https://arxiv.org/pdf/2307.04532v1.pdf","comment":null}],"Signal Processing":[{"id":"http://arxiv.org/abs/2306.01425v2","updated":"2023-07-06T17:32:50Z","published":"2023-06-02T10:31:23Z","title":"Active Noise Control in The New Century: The Role and Prospect of Signal\n  Processing","summary":"  Since Paul Leug's 1933 patent application for a system for the active control\nof sound, the field of active noise control (ANC) has not flourished until the\nadvent of digital signal processors forty years ago. Early theoretical\nadvancements in digital signal processing and processors laid the groundwork\nfor the phenomenal growth of the field, particularly over the past\nquarter-century. The widespread commercial success of ANC in aircraft cabins,\nautomobile cabins, and headsets demonstrates the immeasurable public health and\neconomic benefits of ANC. This article continues where Elliott and Nelson's\n1993 Signal Processing Magazine article and Elliott's 1997 50th anniversary\ncommentary on ANC left off, tracing the technical developments and applications\nin ANC spurred by the seminal texts of Nelson and Elliott (1991), Kuo and\nMorgan (1996), Hansen and Snyder (1996), and Elliott (2001) since the turn of\nthe century. This article focuses on technical developments pertaining to\nreal-world implementations, such as improving algorithmic convergence, reducing\nsystem latency, and extending control to non-stationary and/or broadband noise,\nas well as the commercial transition challenges from analog to digital ANC\nsystems. Finally, open issues and the future of ANC in the era of artificial\nintelligence are discussed.\n","authors":["Dongyuan Shi","Bhan Lam","Woon-Seng Gan","Jordan Cheer","Stephen J. Elliott"],"pdf_url":"https://arxiv.org/pdf/2306.01425v2.pdf","comment":"Submitted to inter.noise 2023, Chiba, Japan"},{"id":"http://arxiv.org/abs/2307.03081v1","updated":"2023-07-06T15:49:12Z","published":"2023-07-06T15:49:12Z","title":"Power-Aperture Resource Allocation for a MPAR with Communications\n  Capabilities","summary":"  Multifunction phased array radars (MPARs) exploit the intrinsic flexibility\nof their active electronically steered array (ESA) to perform, at the same\ntime, a multitude of operations, such as search, tracking, fire control,\nclassification, and communications. This paper aims at addressing the MPAR\nresource allocation so as to satisfy the quality of service (QoS) demanded by\nboth line of sight (LOS) and non line of sight (NLOS) search operations along\nwith communications tasks. To this end, the ranges at which the cumulative\ndetection probability and the channel capacity per bandwidth reach a desired\nvalue are introduced as task quality metrics for the search and communication\nfunctions, respectively. Then, to quantify the satisfaction level of each task,\nfor each of them a bespoke utility function is defined to map the associated\nquality metric into the corresponding perceived utility. Hence, assigning\ndifferent priority weights to each task, the resource allocation problem, in\nterms of radar power aperture (PAP) specification, is formulated as a\nconstrained optimization problem whose solution optimizes the global radar QoS.\nSeveral simulations are conducted in scenarios of practical interest to prove\nthe effectiveness of the approach.\n","authors":["Augusto Aubry","Antonio De Maio","Luca Pallotta"],"pdf_url":"https://arxiv.org/pdf/2307.03081v1.pdf","comment":"12 pages, 14 figures"},{"id":"http://arxiv.org/abs/2307.03070v1","updated":"2023-07-06T15:35:55Z","published":"2023-07-06T15:35:55Z","title":"Hybrid Knowledge-Data Driven Channel Semantic Acquisition and\n  Beamforming for Cell-Free Massive MIMO","summary":"  This paper focuses on advancing outdoor wireless systems to better support\nubiquitous extended reality (XR) applications, and close the gap with current\nindoor wireless transmission capabilities. We propose a hybrid knowledge-data\ndriven method for channel semantic acquisition and multi-user beamforming in\ncell-free massive multiple-input multiple-output (MIMO) systems. Specifically,\nwe firstly propose a data-driven multiple layer perceptron (MLP)-Mixer-based\nauto-encoder for channel semantic acquisition, where the pilot signals, CSI\nquantizer for channel semantic embedding, and CSI reconstruction for channel\nsemantic extraction are jointly optimized in an end-to-end manner. Moreover,\nbased on the acquired channel semantic, we further propose a knowledge-driven\ndeep-unfolding multi-user beamformer, which is capable of achieving good\nspectral efficiency with robustness to imperfect CSI in outdoor XR scenarios.\nBy unfolding conventional successive over-relaxation (SOR)-based linear\nbeamforming scheme with deep learning, the proposed beamforming scheme is\ncapable of adaptively learning the optimal parameters to accelerate convergence\nand improve the robustness to imperfect CSI. The proposed deep unfolding\nbeamforming scheme can be used for access points (APs) with fully-digital array\nand APs with hybrid analog-digital array structure. Simulation results\ndemonstrate the effectiveness of our proposed scheme in improving the accuracy\nof channel acquisition, as well as reducing complexity in both CSI acquisition\nand beamformer design. The proposed beamforming method achieves approximately\n96% of the converged spectrum efficiency performance after only three\niterations in downlink transmission, demonstrating its efficacy and potential\nto improve outdoor XR applications.\n","authors":["Zhen Gao","Shicong Liu","Yu Su","Zhongxiang Li","Dezhi Zheng"],"pdf_url":"https://arxiv.org/pdf/2307.03070v1.pdf","comment":"15 pages, 15 figures"},{"id":"http://arxiv.org/abs/2307.03068v1","updated":"2023-07-06T15:35:14Z","published":"2023-07-06T15:35:14Z","title":"A Hybrid End-to-End Spatio-Temporal Attention Neural Network with\n  Graph-Smooth Signals for EEG Emotion Recognition","summary":"  Recently, physiological data such as electroencephalography (EEG) signals\nhave attracted significant attention in affective computing. In this context,\nthe main goal is to design an automated model that can assess emotional states.\nLately, deep neural networks have shown promising performance in emotion\nrecognition tasks. However, designing a deep architecture that can extract\npractical information from raw data is still a challenge. Here, we introduce a\ndeep neural network that acquires interpretable physiological representations\nby a hybrid structure of spatio-temporal encoding and recurrent attention\nnetwork blocks. Furthermore, a preprocessing step is applied to the raw data\nusing graph signal processing tools to perform graph smoothing in the spatial\ndomain. We demonstrate that our proposed architecture exceeds state-of-the-art\nresults for emotion classification on the publicly available DEAP dataset. To\nexplore the generality of the learned model, we also evaluate the performance\nof our architecture towards transfer learning (TL) by transferring the model\nparameters from a specific source to other target domains. Using DEAP as the\nsource dataset, we demonstrate the effectiveness of our model in performing\ncross-modality TL and improving emotion classification accuracy on DREAMER and\nthe Emotional English Word (EEWD) datasets, which involve EEG-based emotion\nclassification tasks with different stimuli.\n","authors":["Shadi Sartipi","Mastaneh Torkamani-Azar","Mujdat Cetin"],"pdf_url":"https://arxiv.org/pdf/2307.03068v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.01661v2","updated":"2023-07-06T15:12:54Z","published":"2023-04-04T09:33:01Z","title":"Energy-Saving Precoder Design for Narrowband and Wideband Massive MIMO","summary":"  In this work, we study massive multiple-input multiple-output (MIMO)\nprecoders optimizing power consumption while achieving the users' rate\nrequirements. We first characterize analytically the solutions for narrowband\nand wideband systems minimizing the power amplifiers (PAs) consumption in low\nsystem load, where the per-antenna power constraints are not binding. After, we\nfocus on the asymptotic wideband regime. The power consumed by the whole base\nstation (BS) and the high-load scenario are then also investigated. We obtain\nsimple solutions, and the optimal strategy in the asymptotic case reduces to\nfinding the optimal number of active antennas, relying on known precoders among\nthe active antennas. Numerical results show that large savings in power\nconsumption are achievable in the narrowband system by employing antenna\nselection, while all antennas need to be activated in the wideband system when\nconsidering only the PAs consumption, and this implies lower savings. When\nconsidering the overall BS power consumption and a large number of subcarriers,\nwe show that significant savings are achievable in the low-load regime by using\na subset of the BS antennas. While optimization based on transmit power pushes\nto activate all antennas, optimization based on consumed power activates a\nnumber of antennas proportional to the load.\n","authors":["Emanuele Peschiera","François Rottenberg"],"pdf_url":"https://arxiv.org/pdf/2304.01661v2.pdf","comment":"To appear in IEEE Transactions on Green Communications and Networking"},{"id":"http://arxiv.org/abs/2304.00567v2","updated":"2023-07-06T15:00:40Z","published":"2023-04-02T16:24:04Z","title":"Real-Time Prediction of Gas Flow Dynamics in Diesel Engines using a Deep\n  Neural Operator Framework","summary":"  We develop a data-driven deep neural operator framework to approximate\nmultiple output states for a diesel engine and generate real-time predictions\nwith reasonable accuracy. As emission norms become more stringent, the need for\nfast and accurate models that enable analysis of system behavior have become an\nessential requirement for system development. The fast transient processes\ninvolved in the operation of a combustion engine make it difficult to develop\naccurate physics-based models for such systems. As an alternative to physics\nbased models, we develop an operator-based regression model (DeepONet) to learn\nthe relevant output states for a mean-value gas flow engine model using the\nengine operating conditions as input variables. We have adopted a mean-value\nmodel as a benchmark for comparison, simulated using Simulink. The developed\napproach necessitates using the initial conditions of the output states to\npredict the accurate sequence over the temporal domain. To this end, a\nsequence-to-sequence approach is embedded into the proposed framework. The\naccuracy of the model is evaluated by comparing the prediction output to ground\ntruth generated from Simulink model. The maximum $\\mathcal L_2$ relative error\nobserved was approximately $6.5\\%$. The sensitivity of the DeepONet model is\nevaluated under simulated noise conditions and the model shows relatively low\nsensitivity to noise. The uncertainty in model prediction is further assessed\nby using a mean ensemble approach. The worst-case error at the $(\\mu +\n2\\sigma)$ boundary was found to be $12\\%$. The proposed framework provides the\nability to predict output states in real-time and enables data-driven learning\nof complex input-output operator mapping. As a result, this model can be\napplied during initial development stages, where accurate models may not be\navailable.\n","authors":["Varun Kumar","Somdatta Goswami","Daniel J. Smith","George Em Karniadakis"],"pdf_url":"https://arxiv.org/pdf/2304.00567v2.pdf","comment":"Updated manuscript title to better reflect this work and field of\n  study"},{"id":"http://arxiv.org/abs/2307.03028v1","updated":"2023-07-06T14:45:41Z","published":"2023-07-06T14:45:41Z","title":"Performance Analysis and Approximate Message Passing Detection of\n  Orthogonal Time Sequency Multiplexing Modulation","summary":"  In orthogonal time sequency multiplexing (OTSM) modulation, the information\nsymbols are conveyed in the delay-sequency domain upon exploiting the inverse\nWalsh Hadamard transform (IWHT). It has been shown that OTSM is capable of\nattaining a bit error ratio (BER) similar to that of orthogonal time-frequency\nspace (OTFS) modulation at a lower complexity, since the saving of\nmultiplication operations in the IWHT. Hence we provide its BER performance\nanalysis and characterize its detection complexity. We commence by deriving its\ngeneralized input-output relationship and its unconditional pairwise error\nprobability (UPEP). Then, its BER upper bound is derived in closed form under\nboth ideal and imperfect channel estimation conditions, which is shown to be\ntight at moderate to high signal-to-noise ratios (SNRs). Moreover, a novel\napproximate message passing (AMP) aided OTSM detection framework is proposed.\nSpecifically, to circumvent the high residual BER of the conventional AMP\ndetector, we proposed a vector AMP-based expectation-maximization (VAMP-EM)\ndetector for performing joint data detection and noise variance estimation. The\nvariance auto-tuning algorithm based on the EM algorithm is designed for the\nVAMP-EM detector to further improve the convergence performance. The simulation\nresults illustrate that the VAMP-EM detector is capable of striking an\nattractive BER vs. complexity trade-off than the state-of-the-art schemes as\nwell as providing a better convergence. Finally, we propose AMP and VAMP-EM\nturbo receivers for low-density parity-check (LDPC)-coded OTSM systems. It is\ndemonstrated that our proposed VAMP-EM turbo receiver is capable of providing\nboth BER and convergence performance improvements over the conventional AMP\nsolution.\n","authors":["Zeping Sui","Shefeng Yan","Hongming Zhang","Sumei Sun","Yonghong Zeng","Lie-Liang Yang","Lajos Hanzo"],"pdf_url":"https://arxiv.org/pdf/2307.03028v1.pdf","comment":"Accepted in IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2305.09517v3","updated":"2023-07-06T13:54:29Z","published":"2023-05-16T15:11:37Z","title":"Single-Input Polarization-Sensitive Optical Coherence Tomography Through\n  a Catheter","summary":"  Intravascular polarimetry with catheter-based polarization-sensitive optical\ncoherence tomography (PS-OCT) complements the high-resolution structural\ntomograms of OCT with morphological contrast available through polarimetry. Its\nclinical translation has been complicated by the need for modification of\nconventional OCT hardware to enable polarimetric measurements. Here, we present\na signal processing method to reconstruct polarization properties of tissue\nfrom measurements with a single input polarization state, bypassing the need\nfor modulation or multiplexing of input states. Our method relies on a\npolarization symmetry intrinsic to round-trip measurements and uses the\nresidual spectral variation of the polarization states incident on the tissue\nto avoid measurement ambiguities. We demonstrate depth-resolved birefringence\nand optic axis orientation maps reconstructed from in-vivo data of human\ncoronary arteries. We validate our method through comparison with conventional\ndual-input state measurements and find a mean cumulative retardance error of\n13.2deg without observable bias. The 95% limit of agreement between\ndepth-resolved birefringence is 2.80 x 10^(-4), which is less than the\nagreement between two repeat pullbacks of conventional PS-OCT (3.14 x 10^(-4)),\nindicating that the two methods can be used interchangeably. The hardware\nsimplification arising from using a single input state may be decisive in\nrealizing the potential of polarimetric measurements for assessing coronary\natherosclerosis in clinical practice.\n","authors":["Georgia L. Jones","Qiaozhou Xiong","Xinyu Liu","Brett E. Bouma","Martin Villiger"],"pdf_url":"https://arxiv.org/pdf/2305.09517v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02988v1","updated":"2023-07-06T13:42:21Z","published":"2023-07-06T13:42:21Z","title":"UAV Swarms for Joint Data Ferrying and Dynamic Cell Coverage via Optimal\n  Transport Descent and Quadratic Assignment","summary":"  Both data ferrying with disruption-tolerant networking (DTN) and mobile\ncellular base stations constitute important techniques for UAV-aided\ncommunication in situations of crises where standard communication\ninfrastructure is unavailable. For optimal use of a limited number of UAVs, we\npropose providing both DTN and a cellular base station on each UAV. Here, DTN\nis used for large amounts of low-priority data, while capacity-constrained cell\ncoverage remains reserved for emergency calls or command and control. We\noptimize cell coverage via a novel optimal transport-based formulation using\nalternating minimization, while for data ferrying we periodically deliver data\nbetween dynamic clusters by solving quadratic assignment problems. In our\nevaluation, we consider different scenarios with varying mobility models and a\nwide range of flight patterns. Overall, we tractably achieve optimal cell\ncoverage under quality-of-service costs with DTN-based data ferrying, enabling\nlarge-scale deployment of UAV swarms for crisis communication.\n","authors":["Kai Cui","Lars Baumgärtner","Burak Yilmaz","Mengguang Li","Christian Fabian","Benjamin Becker","Lin Xiang","Maximilian Bauer","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2307.02988v1.pdf","comment":"Accepted to IEEE LCN 2023 as full paper, pre-final version"},{"id":"http://arxiv.org/abs/2307.02906v1","updated":"2023-07-06T10:38:14Z","published":"2023-07-06T10:38:14Z","title":"A Real-time Human Pose Estimation Approach for Optimal Sensor Placement\n  in Sensor-based Human Activity Recognition","summary":"  Sensor-based Human Activity Recognition facilitates unobtrusive monitoring of\nhuman movements. However, determining the most effective sensor placement for\noptimal classification performance remains challenging. This paper introduces a\nnovel methodology to resolve this issue, using real-time 2D pose estimations\nderived from video recordings of target activities. The derived skeleton data\nprovides a unique strategy for identifying the optimal sensor location. We\nvalidate our approach through a feasibility study, applying inertial sensors to\nmonitor 13 different activities across ten subjects. Our findings indicate that\nthe vision-based method for sensor placement offers comparable results to the\nconventional deep learning approach, demonstrating its efficacy. This research\nsignificantly advances the field of Human Activity Recognition by providing a\nlightweight, on-device solution for determining the optimal sensor placement,\nthereby enhancing data anonymization and supporting a multimodal classification\napproach.\n","authors":["Orhan Konak","Alexander Wischmann","Robin van de Water","Bert Arnrich"],"pdf_url":"https://arxiv.org/pdf/2307.02906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02900v1","updated":"2023-07-06T10:21:14Z","published":"2023-07-06T10:21:14Z","title":"Meta Federated Reinforcement Learning for Distributed Resource\n  Allocation","summary":"  In cellular networks, resource allocation is usually performed in a\ncentralized way, which brings huge computation complexity to the base station\n(BS) and high transmission overhead. This paper explores a distributed resource\nallocation method that aims to maximize energy efficiency (EE) while ensuring\nthe quality of service (QoS) for users. Specifically, in order to address\nwireless channel conditions, we propose a robust meta federated reinforcement\nlearning (\\textit{MFRL}) framework that allows local users to optimize transmit\npower and assign channels using locally trained neural network models, so as to\noffload computational burden from the cloud server to the local users, reducing\ntransmission overhead associated with local channel state information. The BS\nperforms the meta learning procedure to initialize a general global model,\nenabling rapid adaptation to different environments with improved EE\nperformance. The federated learning technique, based on decentralized\nreinforcement learning, promotes collaboration and mutual benefits among users.\nAnalysis and numerical results demonstrate that the proposed \\textit{MFRL}\nframework accelerates the reinforcement learning process, decreases\ntransmission overhead, and offloads computation, while outperforming the\nconventional decentralized reinforcement learning algorithm in terms of\nconvergence speed and EE performance across various scenarios.\n","authors":["Zelin Ji","Zhijin Qin","Xiaoming Tao"],"pdf_url":"https://arxiv.org/pdf/2307.02900v1.pdf","comment":"Submitted to TWC"},{"id":"http://arxiv.org/abs/2307.02827v1","updated":"2023-07-06T07:50:47Z","published":"2023-07-06T07:50:47Z","title":"Cell-Free XL-MIMO Meets Multi-Agent Reinforcement Learning:\n  Architectures, Challenges, and Future Directions","summary":"  Cell-free massive multiple-input multiple-output (mMIMO) and extremely\nlarge-scale MIMO (XL-MIMO) are regarded as promising innovations for the\nforthcoming generation of wireless communication systems. Their significant\nadvantages in augmenting the number of degrees of freedom have garnered\nconsiderable interest. In this article, we first review the essential\nopportunities and challenges induced by XL-MIMO systems. We then propose the\nenhanced paradigm of cell-free XL-MIMO, which incorporates multi-agent\nreinforcement learning (MARL) to provide a distributed strategy for tackling\nthe problem of high-dimension signal processing and costly energy consumption.\nBased on the unique near-field characteristics, we propose two categories of\nthe low-complexity design, i.e., antenna selection and power control, to adapt\nto different cell-free XL-MIMO scenarios and achieve the maximum data rate. For\ninspiration, several critical future research directions pertaining to green\ncell-free XL-MIMO systems are presented.\n","authors":["Zhilong Liu","Jiayi Zhang","Ziheng Liu","Hongyang Du","Zhe Wang","Dusit Niyato","Mohsen Guizani","Bo Ai"],"pdf_url":"https://arxiv.org/pdf/2307.02827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02806v1","updated":"2023-07-06T06:50:10Z","published":"2023-07-06T06:50:10Z","title":"A Singular-value-based Marker for the Detection of Atrial Fibrillation\n  Using High-resolution Electrograms and Multi-lead ECG","summary":"  The severity of atrial fibrillation (AF) can be assessed from intra-operative\nepicardial measurements (high-resolution electrograms), using metrics such as\nconduction block (CB) and continuous conduction delay and block (cCDCB). These\nfeatures capture differences in conduction velocity and wavefront propagation.\nHowever, they do not clearly differentiate patients with various degrees of AF\nwhile they are in sinus rhythm, and complementary features are needed. In this\nwork, we focus on the morphology of the action potentials, and derive features\nto detect variations in the atrial potential waveforms. Methods: We show that\nthe spatial variation of atrial potential morphology during a single beat may\nbe described by changes in the singular values of the epicardial measurement\nmatrix. The method is non-parametric and requires little preprocessing. A\ncorresponding singular value map points at areas subject to fractionation and\nblock. Further, we developed an experiment where we simultaneously measure\nelectrograms (EGMs) and a multi-lead ECG. Results: The captured data showed\nthat the normalized singular values of the heartbeats during AF are higher than\nduring SR, and that this difference is more pronounced for the (non-invasive)\nECG data than for the EGM data, if the electrodes are positioned at favorable\nlocations. Conclusion: Overall, the singular value-based features are a useful\nindicator to detect and evaluate AF. Significance: The proposed method might be\nbeneficial for identifying electropathological regions in the tissue without\nestimating the local activation time.\n","authors":["Hanie Moghaddasi","Richard C. Hendriks","Borbala Hunyadi","Paul Knops","Mathijs S van Schie","Natasja M. S. de Groot","Alle-Jan van der Veen"],"pdf_url":"https://arxiv.org/pdf/2307.02806v1.pdf","comment":"11 pages, 17 figures"},{"id":"http://arxiv.org/abs/2204.00588v6","updated":"2023-07-06T06:35:32Z","published":"2022-04-01T17:30:01Z","title":"Time-invariant Prefix Coding for LQG Control","summary":"  Motivated by control with communication constraints, in this work we develop\na time-invariant data compression architecture for linear-quadratic-Gaussian\n(LQG) control with minimum bitrate prefix-free feedback. For any fixed control\nperformance, the approach we propose nearly achieves known directed information\n(DI) lower bounds on the time-average expected codeword length. We refine the\nanalysis of a classical achievability approach, which required quantized plant\nmeasurements to be encoded via a time-varying lossless source code. We prove\nthat the sequence of random variables describing the quantizations has a\nlimiting distribution and that the quantizations may be encoded with a fixed\nsource code optimized for this distribution without added time-asymptotic\nredundancy. Our result follows from analyzing the long-term stochastic behavior\nof the system, and permits us to additionally guarantee that the time-average\ncodeword length (as opposed to expected length) is almost surely within a few\nbits of the minimum DI. To our knowledge, this time-invariant achievability\nresult is the first in the literature.\n  The originally published version of the supplementary material included a\nproof that contained an error that turned out to be inconsequential. This\nupdated preprint corrects this error, which originally appeared under Lemma\nA.7.\n","authors":["Travis C. Cuvelier","Takashi Tanaka","Robert W. Heath Jr"],"pdf_url":"https://arxiv.org/pdf/2204.00588v6.pdf","comment":"Version as accepted to the IEEE Journal on Selected Areas in\n  Information Theory (Special Issue on Modern Compression), modulo an\n  additional correction to the proof of Lemma A.7. Official version:\n  https://ieeexplore.ieee.org/document/10002900. 14 page main paper, 4 pages\n  appendix, 3 figures"},{"id":"http://arxiv.org/abs/2307.02784v1","updated":"2023-07-06T05:22:37Z","published":"2023-07-06T05:22:37Z","title":"On the Spatial-Wideband Effects in Millimeter-Wave Cell-Free Massive\n  MIMO","summary":"  In this paper, we investigate the spatial-wideband effects in cell-free\nmassive MIMO (CF-mMIMO) systems in mmWave bands. The utilization of mmWave\nfrequencies brings challenges such as signal attenuation and the need for\ndenser networks like ultra-dense networks (UDN) to maintain communication\nperformance. CF-mMIMO is introduced as a solution, where distributed access\npoints (APs) transmit signals to a central processing unit (CPU) for joint\nprocessing. CF-mMIMO offers advantages in reducing non-line-of-sight (NLOS)\nconditions and overcoming signal blockage. We investigate the synchronization\nproblem in CF-mMIMO due to time delays between APs. It proposes a minimum\ncyclic prefix length to mitigate inter-symbol interference (ISI) in OFDM\nsystems. Furthermore, the spatial correlations of channel responses are\nanalyzed in the frequency-phase domain. The impact of these correlations on\nsystem performance is examined. The findings contribute to improving the\nperformance of CF-mMIMO systems and enhancing the effective utilization of\nmmWave communication.\n","authors":["Seyoung Ahn","Soohyeong Kim","Yongseok Kwon","Joohan Park","Jiseung Youn","Sunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2307.02784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02779v1","updated":"2023-07-06T05:16:55Z","published":"2023-07-06T05:16:55Z","title":"Large Language Models Empowered Autonomous Edge AI for Connected\n  Intelligence","summary":"  The evolution of wireless networks gravitates towards connected intelligence,\na concept that envisions seamless interconnectivity among humans, objects, and\nintelligence in a hyper-connected cyber-physical world. Edge AI emerges as a\npromising solution to achieve connected intelligence by delivering\nhigh-quality, low-latency, and privacy-preserving AI services at the network\nedge. In this article, we introduce an autonomous edge AI system that\nautomatically organizes, adapts, and optimizes itself to meet users' diverse\nrequirements. The system employs a cloud-edge-client hierarchical architecture,\nwhere the large language model, i.e., Generative Pretrained Transformer (GPT),\nresides in the cloud, and other AI models are co-deployed on devices and edge\nservers. By leveraging the powerful abilities of GPT in language understanding,\nplanning, and code generation, we present a versatile framework that\nefficiently coordinates edge AI models to cater to users' personal demands\nwhile automatically generating code to train new models via edge federated\nlearning. Experimental results demonstrate the system's remarkable ability to\naccurately comprehend user demands, efficiently execute AI models with minimal\ncost, and effectively create high-performance AI models through federated\nlearning.\n","authors":["Yifei Shen","Jiawei Shao","Xinjie Zhang","Zehong Lin","Hao Pan","Dongsheng Li","Jun Zhang","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2307.02779v1.pdf","comment":"Magazine paper"},{"id":"http://arxiv.org/abs/2307.02748v1","updated":"2023-07-06T03:16:36Z","published":"2023-07-06T03:16:36Z","title":"Dynamic Multi-time Scale User Admission and Resource Allocation for\n  Semantic Extraction in MEC Systems","summary":"  This paper investigates the semantic extraction task-oriented dynamic\nmulti-time scale user admission and resourceallocation in mobile edge computing\n(MEC) systems. Amid prevalence artifi cial intelligence applications in various\nindustries,the offloading of semantic extraction tasks which are mainlycomposed\nof convolutional neural networks of computer vision isa great challenge for\ncommunication bandwidth and computing capacity allocation in MEC systems.\nConsidering the stochasticnature of the semantic extraction tasks, we formulate\na stochastic optimization problem by modeling it as the dynamic arrival of\ntasks in the temporal domain. We jointly optimize the system revenue and cost\nwhich are represented as user admission in the long term and resource\nallocation in the short term respectively. To handle the proposed stochastic\noptimization problem, we decompose it into short-time-scale subproblems and a\nlong-time-scale subproblem by using the Lyapunov optimization technique. After\nthat, the short-time-scale optimization variables of resource allocation,\nincluding user association, bandwidth allocation, and computing capacity\nallocation are obtained in closed form. The user admission optimization on\nlong-time scales is solved by a heuristic iteration method. Then, the\nmulti-time scale user admission and resource allocation algorithm is proposed\nfor dynamic semantic extraction task computing in MEC systems. Simulation\nresults demonstrate that, compared with the benchmarks, the proposed algorithm\nimproves the performance of user admission and resource allocation efficiently\nand achieves a flexible trade-off between system revenue and cost at multi-time\nscales and considering semantic extraction tasks.\n","authors":["Yuanpeng Zheng","Tiankui Zhang","Jonathan Loo"],"pdf_url":"https://arxiv.org/pdf/2307.02748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02747v1","updated":"2023-07-06T03:15:58Z","published":"2023-07-06T03:15:58Z","title":"Computing Offloading and Semantic Compression for Intelligent Computing\n  Tasks in MEC Systems","summary":"  This paper investigates the intelligent computing task-oriented computing\noffloading and semantic compression in mobile edge computing (MEC) systems.\nWith the popularity of intelligent applications in various industries,\nterminals increasingly need to offload intelligent computing tasks with complex\ndemands to MEC servers for computing, which is a great challenge for bandwidth\nand computing capacity allocation in MEC systems. Considering the accuracy\nrequirement of intelligent computing tasks, we formulate an optimization\nproblem of computing offloading and semantic compression. We jointly optimize\nthe system utility which are represented as computing accuracy and task delay\nrespectively to acquire the optimized system utility. To solve the proposed\noptimization problem, we decompose it into computing capacity allocation\nsubproblem and compression offloading subproblem and obtain solutions through\nconvex optimization and successive convex approximation. After that, the\noffloading decisions, computing capacity and compressed ratio are obtained in\nclosed forms. We design the computing offloading and semantic compression\nalgorithm for intelligent computing tasks in MEC systems then. Simulation\nresults represent that our algorithm converges quickly and acquires better\nperformance and resource utilization efficiency through the trend with total\nnumber of users and computing capacity compared with benchmarks.\n","authors":["Yuanpeng Zheng","Tiankui Zhang","Rong Huang","Yapeng Wang"],"pdf_url":"https://arxiv.org/pdf/2307.02747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02745v1","updated":"2023-07-06T03:11:11Z","published":"2023-07-06T03:11:11Z","title":"ALPCAH: Sample-wise Heteroscedastic PCA with Tail Singular Value\n  Regularization","summary":"  Principal component analysis (PCA) is a key tool in the field of data\ndimensionality reduction that is useful for various data science problems.\nHowever, many applications involve heterogeneous data that varies in quality\ndue to noise characteristics associated with different sources of the data.\nMethods that deal with this mixed dataset are known as heteroscedastic methods.\nCurrent methods like HePPCAT make Gaussian assumptions of the basis\ncoefficients that may not hold in practice. Other methods such as Weighted PCA\n(WPCA) assume the noise variances are known, which may be difficult to know in\npractice. This paper develops a PCA method that can estimate the sample-wise\nnoise variances and use this information in the model to improve the estimate\nof the subspace basis associated with the low-rank structure of the data. This\nis done without distributional assumptions of the low-rank component and\nwithout assuming the noise variances are known. Simulations show the\neffectiveness of accounting for such heteroscedasticity in the data, the\nbenefits of using such a method with all of the data versus retaining only good\ndata, and comparisons are made against other PCA methods established in the\nliterature like PCA, Robust PCA (RPCA), and HePPCAT. Code available at\nhttps://github.com/javiersc1/ALPCAH\n","authors":["Javier Salazar Cavazos","Jeffrey A. Fessler","Laura Balzano"],"pdf_url":"https://arxiv.org/pdf/2307.02745v1.pdf","comment":"This article has been accepted for publication in the Fourteenth\n  International Conference on Sampling Theory and Applications, accessible via\n  IEEE XPlore"},{"id":"http://arxiv.org/abs/2208.00837v2","updated":"2023-07-06T02:57:14Z","published":"2022-07-22T16:50:20Z","title":"The feasibility of Q-band millimeter wave on hand-gesture recognition\n  for indoor FTTR scenario","summary":"  The generalization for different scenarios and dif-ferent users is an urgent\nproblem for millimeter wave gesture recognition for indoor fiber-to-the-room\n(FTTR) scenario. In order to solve this problem and verify the feasibility of\nFTTR Q-band millimeter wave in gesture recognition, we build a real-time\nmillimeter wave gesture recognition system. The moving hand-gestures are\nrepresented as a variety of time-variant spec-trum features, such as\nmicro-Doppler feature, and then the feature learning and classification is\nrealized by using a convo-lution neural network (CNN). The experimental results\nshow that the millimeter wave gesture recognition system can achieve the\ngeneralized gesture recognition for 2 scenarios and 4 users.\n","authors":["Yuxuan Hu","Zhaoyang Xia","Yanbo Zhao","Feng Xu"],"pdf_url":"https://arxiv.org/pdf/2208.00837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02724v1","updated":"2023-07-06T02:18:41Z","published":"2023-07-06T02:18:41Z","title":"Massive MIMO with Cauchy Noise: Channel Estimation, Achievable Rate and\n  Data Decoding","summary":"  We consider massive multiple-input multiple-output (MIMO) systems in the\npresence of Cauchy noise. First, we focus on the channel estimation problem. In\nthe standard massive MIMO setup, the users transmit orthonormal pilots during\nthe training phase and the received signal at the base station is projected\nonto each pilot. This processing is optimum when the noise is Gaussian. We show\nthat this processing is not optimal when the noise is Cauchy and as a remedy\npropose a channel estimation technique that operates on the raw received\nsignal. Second, we derive uplink-downlink achievable rates in the presence of\nCauchy noise for perfect and imperfect channel state information. Finally, we\nderive log-likelihood ratio expressions for soft bit detection for both uplink\nand downlink, and simulate coded bit-error-rate curves. In addition to this, we\nderive and compare the symbol detectors in the presence of both Gaussian and\nCauchy noises. An important observation is that the detector constructed for\nCauchy noise performs well with both Gaussian and Cauchy noises; on the other\nhand, the detector for Gaussian noise works poorly in the presence of Cauchy\nnoise. That is, the Cauchy detector is robust against heavy-tailed noise,\nwhereas the Gaussian detector is not.\n","authors":["Ziya Gulgun","Erik G. Larsson"],"pdf_url":"https://arxiv.org/pdf/2307.02724v1.pdf","comment":"To appear in the IEEE Transactions on Wireless Communications, 2023"},{"id":"http://arxiv.org/abs/2307.02701v1","updated":"2023-07-06T00:32:42Z","published":"2023-07-06T00:32:42Z","title":"Touch, press and stroke: a soft capacitive sensor skin","summary":"  Soft sensors that can discriminate shear and normal force could help provide\nmachines the fine control desirable for safe and effective physical\ninteractions with people. A capacitive sensor is made for this purpose,\ncomposed of patterned elastomer and containing both fixed and sliding pillars\nthat allow the sensor to deform and buckle, much like skin itself. The sensor\ndifferentiates between simultaneously applied pressure and shear. In addition,\nfinger proximity is detectable up to 15 mm, with a pressure and shear\nsensitivity of 1 kPa and a displacement resolution of 50 $\\mu$m. The operation\nis demonstrated on a simple gripper holding a cup. The combination of features\nand the straightforward fabrication method make this sensor a candidate for\nimplementation as a sensing skin for humanoid robotics applications.\n","authors":["Mirza S. Sarwar","Ryusuke Ishizaki","Kieran Morton","Claire Preston","Tan Nguyen","Xu Fan","Bertille Dupont","Leanna Hogarth","Takahide Yoshiike","Shahriar Mirabbasi","John D. W. Madden"],"pdf_url":"https://arxiv.org/pdf/2307.02701v1.pdf","comment":"9 pages, 5 figures, submitted to Scientific Reports Nature"},{"id":"http://arxiv.org/abs/2307.03327v1","updated":"2023-07-06T22:59:52Z","published":"2023-07-06T22:59:52Z","title":"Encoder-Decoder Networks for Self-Supervised Pretraining and Downstream\n  Signal Bandwidth Regression on Digital Antenna Arrays","summary":"  This work presents the first applications of self-supervised learning applied\nto data from digital antenna arrays. Encoder-decoder networks are pretrained on\ndigital array data to perform a self-supervised noisy-reconstruction task\ncalled channel in-painting, in which the network infers the contents of array\ndata that has been masked with zeros. The self-supervised step requires no\nhuman-labeled data. The encoder architecture and weights from pretraining are\nthen transferred to a new network with a task-specific decoder, and the new\nnetwork is trained on a small volume of labeled data. We show that pretraining\non the unlabeled data allows the new network to perform the task of bandwidth\nregression on the digital array data better than an equivalent network that is\ntrained on the same labeled data from random initialization.\n","authors":["Rajib Bhattacharjea","Nathan West"],"pdf_url":"https://arxiv.org/pdf/2307.03327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03205v1","updated":"2023-07-06T03:17:06Z","published":"2023-07-06T03:17:06Z","title":"Joint Computing Offloading and Resource Allocation for Classification\n  Intelligent Tasks in MEC Systems","summary":"  Mobile edge computing (MEC) enables low-latency and high-bandwidth\napplications by bringing computation and data storage closer to end-users.\nIntelligent computing is an important application of MEC, where computing\nresources are used to solve intelligent task-related problems based on task\nrequirements. However, efficiently offloading computing and allocating\nresources for intelligent tasks in MEC systems is a challenging problem due to\ncomplex interactions between task requirements and MEC resources. To address\nthis challenge, we investigate joint computing offloading and resource\nallocation for intelligent tasks in MEC systems. Our goal is to optimize system\nutility by jointly considering computing accuracy and task delay to achieve\nmaximum system performance. We focus on classification intelligence tasks and\nformulate an optimization problem that considers both the accuracy requirements\nof tasks and the parallel computing capabilities of MEC systems. To solve the\noptimization problem, we decompose it into three subproblems: subcarrier\nallocation, computing capacity allocation, and compression offloading. We use\nconvex optimization and successive convex approximation to derive closed-form\nexpressions for the subcarrier allocation, offloading decisions, computing\ncapacity, and compressed ratio. Based on our solutions, we design an efficient\ncomputing offloading and resource allocation algorithm for intelligent tasks in\nMEC systems. Our simulation results demonstrate that our proposed algorithm\nsignificantly improves the performance of intelligent tasks in MEC systems and\nachieves a flexible trade-off between system revenue and cost considering\nintelligent tasks compared with the benchmarks.\n","authors":["Yuanpeng Zheng","Tiankui Zhang","Jonathan Loo","Yapeng Wang","Arumugam Nallanathan"],"pdf_url":"https://arxiv.org/pdf/2307.03205v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2307.02747"},{"id":"http://arxiv.org/abs/2307.05385v1","updated":"2023-07-06T18:11:58Z","published":"2023-07-06T18:11:58Z","title":"Learned Kernels for Interpretable and Efficient PPG Signal Quality\n  Assessment and Artifact Segmentation","summary":"  Photoplethysmography (PPG) provides a low-cost, non-invasive method to\ncontinuously monitor various cardiovascular parameters. PPG signals are\ngenerated by wearable devices and frequently contain large artifacts caused by\nexternal factors, such as motion of the human subject. In order to ensure\nrobust and accurate extraction of physiological parameters, corrupted areas of\nthe signal need to be identified and handled appropriately. Previous\nmethodology relied either on handcrafted feature detectors or signal metrics\nwhich yield sub-optimal performance, or relied on machine learning techniques\nsuch as deep neural networks (DNN) which lack interpretability and are\ncomputationally and memory intensive. In this work, we present a novel method\nto learn a small set of interpretable convolutional kernels that has\nperformance similar to -- and often better than -- the state-of-the-art DNN\napproach with several orders of magnitude fewer parameters. This work allows\nfor efficient, robust, and interpretable signal quality assessment and artifact\nsegmentation on low-power devices.\n","authors":["Sully F. Chen","Zhicheng Guo","Cheng Ding","Xiao Hu","Cynthia Rudin"],"pdf_url":"https://arxiv.org/pdf/2307.05385v1.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2307.05355v1","updated":"2023-07-06T05:26:49Z","published":"2023-07-06T05:26:49Z","title":"UniCoRN: Unified Cognitive Signal ReconstructioN bridging cognitive\n  signals and human language","summary":"  Decoding text stimuli from cognitive signals (e.g. fMRI) enhances our\nunderstanding of the human language system, paving the way for building\nversatile Brain-Computer Interface. However, existing studies largely focus on\ndecoding individual word-level fMRI volumes from a restricted vocabulary, which\nis far too idealized for real-world application. In this paper, we propose\nfMRI2text, the first openvocabulary task aiming to bridge fMRI time series and\nhuman language. Furthermore, to explore the potential of this new task, we\npresent a baseline solution, UniCoRN: the Unified Cognitive Signal\nReconstructioN for Brain Decoding. By reconstructing both individual time\npoints and time series, UniCoRN establishes a robust encoder for cognitive\nsignals (fMRI & EEG). Leveraging a pre-trained language model as decoder,\nUniCoRN proves its efficacy in decoding coherent text from fMRI series across\nvarious split settings. Our model achieves a 34.77% BLEU score on fMRI2text,\nand a 37.04% BLEU when generalized to EEGto-text decoding, thereby surpassing\nthe former baseline. Experimental results indicate the feasibility of decoding\nconsecutive fMRI volumes, and the effectiveness of decoding different cognitive\nsignals using a unified structure.\n","authors":["Nuwa Xi","Sendong Zhao","Haochun Wang","Chi Liu","Bing Qin","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2307.05355v1.pdf","comment":"the 61st Annual Meeting of the Association for Computational\n  Linguistics"},{"id":"http://arxiv.org/abs/2307.05393v1","updated":"2023-07-06T03:48:18Z","published":"2023-07-06T03:48:18Z","title":"Pattern and Polarization Diversity Multi-Sector Annular Antenna for IoT\n  Applications","summary":"  This work proposes a small pattern and polarization diversity multi-sector\nannular antenna with electrical size and profile of ${ka=1.2}$ and\n${0.018\\lambda}$, respectively. The antenna is planar and comprises annular\nsectors that are fed using different ports to enable digital beamforming\ntechniques, with efficiency and gain of up to 78% and 4.62 dBi, respectively.\nThe cavity mode analysis is used to describe the design concept and the antenna\ndiversity. The proposed method can produce different polarization states (e.g.\nlinearly and circularly polarized patterns), and pattern diversity\ncharacteristics covering the elevation plane. Owing to its small electrical\nsize, low-profile and diversity properties, the solution shows good promise to\nenable advanced radio applications like wireless physical layer security in\nmany emerging and size-constrained Internet of Things (IoT) devices.\n","authors":["Abel Zandamela","Nicola Marchetti","Max J. Ammann","Adam Narbudowicz"],"pdf_url":"https://arxiv.org/pdf/2307.05393v1.pdf","comment":"IEEE Transactions on Antennas and Propagation"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2007.12069v4","updated":"2023-07-06T17:04:17Z","published":"2020-07-23T15:28:58Z","title":"Version Control of Speaker Recognition Systems","summary":"  This paper discusses one of the most challenging practical engineering\nproblems in speaker recognition systems - the version control of models and\nuser profiles. A typical speaker recognition system consists of two stages: the\nenrollment stage, where a profile is generated from user-provided enrollment\naudio; and the runtime stage, where the voice identity of the runtime audio is\ncompared against the stored profiles. As technology advances, the speaker\nrecognition system needs to be updated for better performance. However, if the\nstored user profiles are not updated accordingly, version mismatch will result\nin meaningless recognition results. In this paper, we describe different\nversion control strategies for speaker recognition systems that had been\ncarefully studied at Google from years of engineering practice. These\nstrategies are categorized into three groups according to how they are deployed\nin the production environment: device-side deployment, server-side deployment,\nand hybrid deployment. To compare different strategies with quantitative\nmetrics under various network configurations, we present SpeakerVerSim, an\neasily-extensible Python-based simulation framework for different server-side\ndeployment strategies of speaker recognition systems.\n","authors":["Quan Wang","Ignacio Lopez Moreno"],"pdf_url":"https://arxiv.org/pdf/2007.12069v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03126v1","updated":"2023-07-06T16:52:20Z","published":"2023-07-06T16:52:20Z","title":"Context-Aware Configuration and Management of WiFi Direct Groups for\n  Real Opportunistic Networks","summary":"  Wi-Fi Direct is a promising technology for the support of device-to-device\ncommunications (D2D) on commercial mobile devices. However, the standard\nas-it-is is not sufficient to support the real deployment of networking\nsolutions entirely based on D2D such as opportunistic networks. In fact, WiFi\nDirect presents some characteristics that could limit the autonomous creation\nof D2D connections among users' personal devices. Specifically, the standard\nexplicitly requires the user's authorization to establish a connection between\ntwo or more devices, and it provides a limited support for inter-group\ncommunication. In some cases, this might lead to the creation of isolated\ngroups of nodes which cannot communicate among each other. In this paper, we\npropose a novel middleware-layer protocol for the efficient configuration and\nmanagement of WiFi Direct groups (WiFi Direct Group Manager, WFD-GM) to enable\nautonomous connections and inter-group communication. This enables\nopportunistic networks in real conditions (e.g., variable mobility and network\nsize). WFD-GM defines a context function that takes into account heterogeneous\nparameters for the creation of the best group configuration in a specific time\nwindow, including an index of nodes' stability and power levels. We evaluate\nthe protocol performances by simulating three reference scenarios including\ndifferent mobility models, geographical areas and number of nodes. Simulations\nare also supported by experimental results related to the evaluation in a real\ntestbed of the involved context parameters. We compare WFD-GM with the\nstate-of-the-art solutions and we show that it performs significantly better\nthan a Baseline approach in scenarios with medium/low mobility, and it is\ncomparable with it in case of high mobility, without introducing additional\noverhead.\n","authors":["Valerio Arnaboldi","Mattia Giovanni Campana","Franca Delmastro"],"pdf_url":"https://arxiv.org/pdf/2307.03126v1.pdf","comment":"Accepted by the IEEE 14th International Conference on Mobile Ad Hoc\n  and Sensor Systems (MASS), 2017"},{"id":"http://arxiv.org/abs/2307.02988v1","updated":"2023-07-06T13:42:21Z","published":"2023-07-06T13:42:21Z","title":"UAV Swarms for Joint Data Ferrying and Dynamic Cell Coverage via Optimal\n  Transport Descent and Quadratic Assignment","summary":"  Both data ferrying with disruption-tolerant networking (DTN) and mobile\ncellular base stations constitute important techniques for UAV-aided\ncommunication in situations of crises where standard communication\ninfrastructure is unavailable. For optimal use of a limited number of UAVs, we\npropose providing both DTN and a cellular base station on each UAV. Here, DTN\nis used for large amounts of low-priority data, while capacity-constrained cell\ncoverage remains reserved for emergency calls or command and control. We\noptimize cell coverage via a novel optimal transport-based formulation using\nalternating minimization, while for data ferrying we periodically deliver data\nbetween dynamic clusters by solving quadratic assignment problems. In our\nevaluation, we consider different scenarios with varying mobility models and a\nwide range of flight patterns. Overall, we tractably achieve optimal cell\ncoverage under quality-of-service costs with DTN-based data ferrying, enabling\nlarge-scale deployment of UAV swarms for crisis communication.\n","authors":["Kai Cui","Lars Baumgärtner","Burak Yilmaz","Mengguang Li","Christian Fabian","Benjamin Becker","Lin Xiang","Maximilian Bauer","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2307.02988v1.pdf","comment":"Accepted to IEEE LCN 2023 as full paper, pre-final version"},{"id":"http://arxiv.org/abs/2307.02896v1","updated":"2023-07-06T10:03:08Z","published":"2023-07-06T10:03:08Z","title":"Robust Deployment and Resource Allocation for Robotic Aerial Base\n  Station Enabled OFDM Integrated Sensing and Communication","summary":"  The envisioned robotic aerial base station (RABS) concept is expected to\nbring further flexibility to integrated sensing and communication (ISAC)\nsystems. In this letter, characterizing the spatial traffic distribution on a\ngrid-based model, the RABS-assisted ISAC system is formulated as a robust\noptimization problem to maximize the minimum satisfaction rate (SR) under a\ncardinality constrained uncertainty set. The problem is reformulated as a\nmixed-integer linear programming (MILP) and solved approximately by the\niterative linear programming rounding algorithm. Numerical investigations show\nthat the minimum SR can be improved by 28.61% on average compared to fixed\nsmall cells.\n","authors":["Yuan Liao","Vasilis Friderikos","Halim Yanikomeroglu"],"pdf_url":"https://arxiv.org/pdf/2307.02896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.06454v2","updated":"2023-07-06T09:09:04Z","published":"2021-01-16T15:19:21Z","title":"AGChain: A Blockchain-based Gateway for Trustworthy App Delegation from\n  Mobile App Markets","summary":"  The popularity of smartphones has led to the growth of mobile app markets,\ncreating a need for enhanced transparency, global access, and secure\ndownloading. This paper introduces AGChain, a blockchain-based gateway that\nenables trustworthy app delegation within existing markets. AGChain ensures\nthat markets can continue providing services while users benefit from\npermanent, distributed, and secure app delegation. During its development, we\naddress two key challenges: significantly reducing smart contract gas costs and\nenabling fully distributed IPFS-based file storage. Additionally, we tackle\nthree system issues related to security and sustainability. We have implemented\na prototype of AGChain on Ethereum and Polygon blockchains, achieving effective\nsecurity and decentralization with a minimal gas cost of around 0.002 USD per\napp upload (no cost for app download). The system also exhibits reasonable\nperformance with an average overhead of 12%.\n","authors":["Mengjie Chen","Xiao Yi","Daoyuan Wu","Jianliang Xu","Yingjiu Li","Debin Gao"],"pdf_url":"https://arxiv.org/pdf/2101.06454v2.pdf","comment":"This is a technical report submitted to the Special Issue of the\n  Elsevier Journal of Systems Architecture (JSA)"},{"id":"http://arxiv.org/abs/2307.00319v2","updated":"2023-07-06T08:22:57Z","published":"2023-07-01T12:10:18Z","title":"A Survey on Explainable AI for 6G O-RAN: Architecture, Use Cases,\n  Challenges and Research Directions","summary":"  The recent O-RAN specifications promote the evolution of RAN architecture by\nfunction disaggregation, adoption of open interfaces, and instantiation of a\nhierarchical closed-loop control architecture managed by RAN Intelligent\nControllers (RICs) entities. This paves the road to novel data-driven network\nmanagement approaches based on programmable logic. Aided by Artificial\nIntelligence (AI) and Machine Learning (ML), novel solutions targeting\ntraditionally unsolved RAN management issues can be devised. Nevertheless, the\nadoption of such smart and autonomous systems is limited by the current\ninability of human operators to understand the decision process of such AI/ML\nsolutions, affecting their trust in such novel tools. eXplainable AI (XAI) aims\nat solving this issue, enabling human users to better understand and\neffectively manage the emerging generation of artificially intelligent schemes,\nreducing the human-to-machine barrier. In this survey, we provide a summary of\nthe XAI methods and metrics before studying their deployment over the O-RAN\nAlliance RAN architecture along with its main building blocks. We then present\nvarious use-cases and discuss the automation of XAI pipelines for O-RAN as well\nas the underlying security aspects. We also review some projects/standards that\ntackle this area. Finally, we identify different challenges and research\ndirections that may arise from the heavy adoption of AI/ML decision entities in\nthis context, focusing on how XAI can help to interpret, understand, and\nimprove trust in O-RAN operational networks.\n","authors":["Bouziane Brik","Hatim Chergui","Lanfranco Zanzi","Francesco Devoti","Adlen Ksentini","Muhammad Shuaib Siddiqui","Xavier Costa-Pérez","Christos Verikoukis"],"pdf_url":"https://arxiv.org/pdf/2307.00319v2.pdf","comment":"33 pages, 13 figures"},{"id":"http://arxiv.org/abs/2307.02784v1","updated":"2023-07-06T05:22:37Z","published":"2023-07-06T05:22:37Z","title":"On the Spatial-Wideband Effects in Millimeter-Wave Cell-Free Massive\n  MIMO","summary":"  In this paper, we investigate the spatial-wideband effects in cell-free\nmassive MIMO (CF-mMIMO) systems in mmWave bands. The utilization of mmWave\nfrequencies brings challenges such as signal attenuation and the need for\ndenser networks like ultra-dense networks (UDN) to maintain communication\nperformance. CF-mMIMO is introduced as a solution, where distributed access\npoints (APs) transmit signals to a central processing unit (CPU) for joint\nprocessing. CF-mMIMO offers advantages in reducing non-line-of-sight (NLOS)\nconditions and overcoming signal blockage. We investigate the synchronization\nproblem in CF-mMIMO due to time delays between APs. It proposes a minimum\ncyclic prefix length to mitigate inter-symbol interference (ISI) in OFDM\nsystems. Furthermore, the spatial correlations of channel responses are\nanalyzed in the frequency-phase domain. The impact of these correlations on\nsystem performance is examined. The findings contribute to improving the\nperformance of CF-mMIMO systems and enhancing the effective utilization of\nmmWave communication.\n","authors":["Seyoung Ahn","Soohyeong Kim","Yongseok Kwon","Joohan Park","Jiseung Youn","Sunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2307.02784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02779v1","updated":"2023-07-06T05:16:55Z","published":"2023-07-06T05:16:55Z","title":"Large Language Models Empowered Autonomous Edge AI for Connected\n  Intelligence","summary":"  The evolution of wireless networks gravitates towards connected intelligence,\na concept that envisions seamless interconnectivity among humans, objects, and\nintelligence in a hyper-connected cyber-physical world. Edge AI emerges as a\npromising solution to achieve connected intelligence by delivering\nhigh-quality, low-latency, and privacy-preserving AI services at the network\nedge. In this article, we introduce an autonomous edge AI system that\nautomatically organizes, adapts, and optimizes itself to meet users' diverse\nrequirements. The system employs a cloud-edge-client hierarchical architecture,\nwhere the large language model, i.e., Generative Pretrained Transformer (GPT),\nresides in the cloud, and other AI models are co-deployed on devices and edge\nservers. By leveraging the powerful abilities of GPT in language understanding,\nplanning, and code generation, we present a versatile framework that\nefficiently coordinates edge AI models to cater to users' personal demands\nwhile automatically generating code to train new models via edge federated\nlearning. Experimental results demonstrate the system's remarkable ability to\naccurately comprehend user demands, efficiently execute AI models with minimal\ncost, and effectively create high-performance AI models through federated\nlearning.\n","authors":["Yifei Shen","Jiawei Shao","Xinjie Zhang","Zehong Lin","Hao Pan","Dongsheng Li","Jun Zhang","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2307.02779v1.pdf","comment":"Magazine paper"},{"id":"http://arxiv.org/abs/2307.02754v1","updated":"2023-07-06T03:26:11Z","published":"2023-07-06T03:26:11Z","title":"Intent-driven Intelligent Control and Orchestration in O-RAN Via\n  Hierarchical Reinforcement Learning","summary":"  rApps and xApps need to be controlled and orchestrated well in the open radio\naccess network (O-RAN) so that they can deliver a guaranteed network\nperformance in a complex multi-vendor environment. This paper proposes a novel\nintent-driven intelligent control and orchestration scheme based on\nhierarchical reinforcement learning (HRL). The proposed scheme can orchestrate\nmultiple rApps or xApps according to the operator's intent of optimizing\ncertain key performance indicators (KPIs), such as throughput, energy\nefficiency, and latency. Specifically, we propose a bi-level architecture with\na meta-controller and a controller. The meta-controller provides the target\nperformance in terms of KPIs, while the controller performs xApp orchestration\nat the lower level. Our simulation results show that the proposed HRL-based\nintent-driven xApp orchestration mechanism achieves 7.5% and 21.4% increase in\naverage system throughput with respect to two baselines, i.e., a single xApp\nbaseline and a non-machine learning-based algorithm, respectively. Similarly,\n17.3% and 37.9% increase in energy efficiency are observed in comparison to the\nsame baselines.\n","authors":["Md Arafat Habib","Hao Zhou","Pedro Enrique Iturria-Rivera","Medhat Elsayed","Majid Bavand","Raimundas Gaigalas","Yigit Ozcan","Melike Erol-Kantarci"],"pdf_url":"https://arxiv.org/pdf/2307.02754v1.pdf","comment":"Accepted by IEEE MASS 2023"},{"id":"http://arxiv.org/abs/2307.02748v1","updated":"2023-07-06T03:16:36Z","published":"2023-07-06T03:16:36Z","title":"Dynamic Multi-time Scale User Admission and Resource Allocation for\n  Semantic Extraction in MEC Systems","summary":"  This paper investigates the semantic extraction task-oriented dynamic\nmulti-time scale user admission and resourceallocation in mobile edge computing\n(MEC) systems. Amid prevalence artifi cial intelligence applications in various\nindustries,the offloading of semantic extraction tasks which are mainlycomposed\nof convolutional neural networks of computer vision isa great challenge for\ncommunication bandwidth and computing capacity allocation in MEC systems.\nConsidering the stochasticnature of the semantic extraction tasks, we formulate\na stochastic optimization problem by modeling it as the dynamic arrival of\ntasks in the temporal domain. We jointly optimize the system revenue and cost\nwhich are represented as user admission in the long term and resource\nallocation in the short term respectively. To handle the proposed stochastic\noptimization problem, we decompose it into short-time-scale subproblems and a\nlong-time-scale subproblem by using the Lyapunov optimization technique. After\nthat, the short-time-scale optimization variables of resource allocation,\nincluding user association, bandwidth allocation, and computing capacity\nallocation are obtained in closed form. The user admission optimization on\nlong-time scales is solved by a heuristic iteration method. Then, the\nmulti-time scale user admission and resource allocation algorithm is proposed\nfor dynamic semantic extraction task computing in MEC systems. Simulation\nresults demonstrate that, compared with the benchmarks, the proposed algorithm\nimproves the performance of user admission and resource allocation efficiently\nand achieves a flexible trade-off between system revenue and cost at multi-time\nscales and considering semantic extraction tasks.\n","authors":["Yuanpeng Zheng","Tiankui Zhang","Jonathan Loo"],"pdf_url":"https://arxiv.org/pdf/2307.02748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02747v1","updated":"2023-07-06T03:15:58Z","published":"2023-07-06T03:15:58Z","title":"Computing Offloading and Semantic Compression for Intelligent Computing\n  Tasks in MEC Systems","summary":"  This paper investigates the intelligent computing task-oriented computing\noffloading and semantic compression in mobile edge computing (MEC) systems.\nWith the popularity of intelligent applications in various industries,\nterminals increasingly need to offload intelligent computing tasks with complex\ndemands to MEC servers for computing, which is a great challenge for bandwidth\nand computing capacity allocation in MEC systems. Considering the accuracy\nrequirement of intelligent computing tasks, we formulate an optimization\nproblem of computing offloading and semantic compression. We jointly optimize\nthe system utility which are represented as computing accuracy and task delay\nrespectively to acquire the optimized system utility. To solve the proposed\noptimization problem, we decompose it into computing capacity allocation\nsubproblem and compression offloading subproblem and obtain solutions through\nconvex optimization and successive convex approximation. After that, the\noffloading decisions, computing capacity and compressed ratio are obtained in\nclosed forms. We design the computing offloading and semantic compression\nalgorithm for intelligent computing tasks in MEC systems then. Simulation\nresults represent that our algorithm converges quickly and acquires better\nperformance and resource utilization efficiency through the trend with total\nnumber of users and computing capacity compared with benchmarks.\n","authors":["Yuanpeng Zheng","Tiankui Zhang","Rong Huang","Yapeng Wang"],"pdf_url":"https://arxiv.org/pdf/2307.02747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02703v1","updated":"2023-07-06T00:37:30Z","published":"2023-07-06T00:37:30Z","title":"A Logical Way to Negotiate Services","summary":"  Service providers commonly provide only a fixed catalog of services to their\nclients. Both clients and service providers can benefit from service\nnegotiation, in which a client makes a query for a specific service, and the\nprovider counters with an offer. The query could include parameters that\ncontrol the performance, reliability, and function of the service. However, a\nproblem with service negotiation is that it can be expensive for a service\nprovider to support.\n  In this paper we define a formal negotiation policy language that enables\nautomated service negotiation. In the model supported by the language, service\nproviders can recursively obtain the services they need from sub-providers. The\nqueries made by clients, and the offers returned from service providers, are\nexpressed in quantifier-free first-order logic. Quantifier elimination is used\nto transform constraints between providers and sub-providers. The pattern of\ninteraction between clients and service providers is defined in process\nalgebra. We show a correctness property of our language: if sub-providers\nrespond positively to queries, then so does the provider itself.\n","authors":["Glenn Bruns","Mauricio Cortes"],"pdf_url":"https://arxiv.org/pdf/2307.02703v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2307.03205v1","updated":"2023-07-06T03:17:06Z","published":"2023-07-06T03:17:06Z","title":"Joint Computing Offloading and Resource Allocation for Classification\n  Intelligent Tasks in MEC Systems","summary":"  Mobile edge computing (MEC) enables low-latency and high-bandwidth\napplications by bringing computation and data storage closer to end-users.\nIntelligent computing is an important application of MEC, where computing\nresources are used to solve intelligent task-related problems based on task\nrequirements. However, efficiently offloading computing and allocating\nresources for intelligent tasks in MEC systems is a challenging problem due to\ncomplex interactions between task requirements and MEC resources. To address\nthis challenge, we investigate joint computing offloading and resource\nallocation for intelligent tasks in MEC systems. Our goal is to optimize system\nutility by jointly considering computing accuracy and task delay to achieve\nmaximum system performance. We focus on classification intelligence tasks and\nformulate an optimization problem that considers both the accuracy requirements\nof tasks and the parallel computing capabilities of MEC systems. To solve the\noptimization problem, we decompose it into three subproblems: subcarrier\nallocation, computing capacity allocation, and compression offloading. We use\nconvex optimization and successive convex approximation to derive closed-form\nexpressions for the subcarrier allocation, offloading decisions, computing\ncapacity, and compressed ratio. Based on our solutions, we design an efficient\ncomputing offloading and resource allocation algorithm for intelligent tasks in\nMEC systems. Our simulation results demonstrate that our proposed algorithm\nsignificantly improves the performance of intelligent tasks in MEC systems and\nachieves a flexible trade-off between system revenue and cost considering\nintelligent tasks compared with the benchmarks.\n","authors":["Yuanpeng Zheng","Tiankui Zhang","Jonathan Loo","Yapeng Wang","Arumugam Nallanathan"],"pdf_url":"https://arxiv.org/pdf/2307.03205v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2307.02747"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2307.03162v1","updated":"2023-07-06T17:42:56Z","published":"2023-07-06T17:42:56Z","title":"BrickPal: Augmented Reality-based Assembly Instructions for Brick Models","summary":"  The assembly instruction is a mandatory component of Lego-like brick sets.The\nconventional production of assembly instructions requires a considerable amount\nof manual fine-tuning, which is intractable for casual users and customized\nbrick sets.Moreover, the traditional paper-based instructions lack\nexpressiveness and interactivity.To tackle the two problems above, we present\nBrickPal, an augmented reality-based system, which visualizes assembly\ninstructions in an augmented reality head-mounted display. It utilizes Natural\nLanguage Processing (NLP) techniques to generate plausible assembly sequences,\nand provide real-time guidance in the AR headset.Our user study demonstrates\nBrickPal's effectiveness at assisting users in brick assembly compared to\ntraditional assembly methods. Additionally, the NLP algorithm-generated\nassembly sequences achieve the same usability with manually adapted sequences.\n","authors":["Yao Shi","Xiaofeng Zhang","Ran zhang","Zhou Yang","Xiao Tang","Hongni Ye","Yi Wu"],"pdf_url":"https://arxiv.org/pdf/2307.03162v1.pdf","comment":"9 pages,7 figures. Project URL: https://origami.dance/brickpal"},{"id":"http://arxiv.org/abs/2307.03130v1","updated":"2023-07-06T16:58:27Z","published":"2023-07-06T16:58:27Z","title":"VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge\n  Base Question Answering","summary":"  We present Visual Knowledge oriented Programming platform (VisKoP), a\nknowledge base question answering (KBQA) system that integrates human into the\nloop to edit and debug the knowledge base (KB) queries. VisKoP not only\nprovides a neural program induction module, which converts natural language\nquestions into knowledge oriented program language (KoPL), but also maps KoPL\nprograms into graphical elements. KoPL programs can be edited with simple\ngraphical operators, such as dragging to add knowledge operators and slot\nfilling to designate operator arguments. Moreover, VisKoP provides\nauto-completion for its knowledge base schema and users can easily debug the\nKoPL program by checking its intermediate results. To facilitate the practical\nKBQA on a million-entity-level KB, we design a highly efficient KoPL execution\nengine for the back-end. Experiment results show that VisKoP is highly\nefficient and user interaction can fix a large portion of wrong KoPL programs\nto acquire the correct answer. The VisKoP online demo\nhttps://demoviskop.xlore.cn (Stable release of this paper) and\nhttps://viskop.xlore.cn (Beta release with new features), highly efficient KoPL\nengine https://pypi.org/project/kopl-engine, and screencast video\nhttps://youtu.be/zAbJtxFPTXo are now publicly available.\n","authors":["Zijun Yao","Yuanyong Chen","Xin Lv","Shulin Cao","Amy Xin","Jifan Yu","Hailong Jin","Jianjun Xu","Peng Zhang","Lei Hou","Juanzi Li"],"pdf_url":"https://arxiv.org/pdf/2307.03130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03021v1","updated":"2023-07-06T14:36:13Z","published":"2023-07-06T14:36:13Z","title":"Shadow operator: Effective dynamic load change operation training in air\n  separation processes based on industrial nonlinear MPC and Bloom's taxonomy","summary":"  A novel human-machine interactive training method for dynamic load change\noperation in air separation processes (ASPs) is proposed. A shadow operator\n(SO) is developed in this method to train ASP operators through industrial\nmodel predictive control (IMPC) and Bloom's taxonomy. First, a nonlinear\ntwo-layer IMPC machine algorithm is developed for dynamic load change\noperation. The IMPC uses a linear parameter varying prediction model and an\niterative multi-step linearization algorithm to compute accurate control\ndecisions. Second, a hierarchical human-machine cooperation model is\nestablished to improve the effectiveness of operation training. The model is\ninspired by an educational psychology framework (Bloom's taxonomy) and assists\nASP operators in enhancing their dynamic operational skills. Finally, five\ndynamic training modes of the SO are designed based on the IMPC algorithm and\nthe human-machine cooperation model. The practical application results\ndemonstrate that the SO improves the effectiveness of skill acquisition for\nnovice operators and the safety of dynamic operations.\n","authors":["Guanghui Yang","Zhijiang Shao","Rui Wang","Zuhua Xu","Lidan Cui"],"pdf_url":"https://arxiv.org/pdf/2307.03021v1.pdf","comment":"16 pages, 18 figures"},{"id":"http://arxiv.org/abs/2210.14896v4","updated":"2023-07-06T11:53:19Z","published":"2022-10-26T17:54:20Z","title":"DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image\n  Generative Models","summary":"  With recent advancements in diffusion models, users can generate high-quality\nimages by writing text prompts in natural language. However, generating images\nwith desired details requires proper prompts, and it is often unclear how a\nmodel reacts to different prompts or what the best prompts are. To help\nresearchers tackle these critical challenges, we introduce DiffusionDB, the\nfirst large-scale text-to-image prompt dataset totaling 6.5TB, containing 14\nmillion images generated by Stable Diffusion, 1.8 million unique prompts, and\nhyperparameters specified by real users. We analyze the syntactic and semantic\ncharacteristics of prompts. We pinpoint specific hyperparameter values and\nprompt styles that can lead to model errors and present evidence of potentially\nharmful model usage, such as the generation of misinformation. The\nunprecedented scale and diversity of this human-actuated dataset provide\nexciting research opportunities in understanding the interplay between prompts\nand generative models, detecting deepfakes, and designing human-AI interaction\ntools to help users more easily use these models. DiffusionDB is publicly\navailable at: https://poloclub.github.io/diffusiondb.\n","authors":["Zijie J. Wang","Evan Montoya","David Munechika","Haoyang Yang","Benjamin Hoover","Duen Horng Chau"],"pdf_url":"https://arxiv.org/pdf/2210.14896v4.pdf","comment":"Accepted to ACL 2023 (nominated for best paper, top 1.6% of\n  submissions, oral presentation). 17 pages, 11 figures. The dataset is\n  available at https://huggingface.co/datasets/poloclub/diffusiondb. The code\n  is at https://github.com/poloclub/diffusiondb. The interactive visualization\n  demo is at https://poloclub.github.io/diffusiondb/explorer/"},{"id":"http://arxiv.org/abs/2307.02933v1","updated":"2023-07-06T11:51:43Z","published":"2023-07-06T11:51:43Z","title":"In Time and Space: Towards Usable Adaptive Control for Assistive Robotic\n  Arms","summary":"  Robotic solutions, in particular robotic arms, are becoming more frequently\ndeployed for close collaboration with humans, for example in manufacturing or\ndomestic care environments. These robotic arms require the user to control\nseveral Degrees-of-Freedom (DoFs) to perform tasks, primarily involving\ngrasping and manipulating objects. Standard input devices predominantly have\ntwo DoFs, requiring time-consuming and cognitively demanding mode switches to\nselect individual DoFs. Contemporary Adaptive DoF Mapping Controls (ADMCs) have\nshown to decrease the necessary number of mode switches but were up to now not\nable to significantly reduce the perceived workload. Users still bear the\nmental workload of incorporating abstract mode switching into their workflow.\nWe address this by providing feed-forward multimodal feedback using updated\nrecommendations of ADMC, allowing users to visually compare the current and the\nsuggested mapping in real-time. We contrast the effectiveness of two new\napproaches that a) continuously recommend updated DoF combinations or b) use\ndiscrete thresholds between current robot movements and new recommendations.\nBoth are compared in a Virtual Reality (VR) in-person study against a classic\ncontrol method. Significant results for lowered task completion time, fewer\nmode switches, and reduced perceived workload conclusively establish that in\ncombination with feedforward, ADMC methods can indeed outperform classic mode\nswitching. A lack of apparent quantitative differences between Continuous and\nThreshold reveals the importance of user-centered customization options.\nIncluding these implications in the development process will improve usability,\nwhich is essential for successfully implementing robotic technologies with high\nuser acceptance.\n","authors":["Max Pascher","Kirill Kronhardt","Felix Ferdinand Goldau","Udo Frese","Jens Gerken"],"pdf_url":"https://arxiv.org/pdf/2307.02933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02924v1","updated":"2023-07-06T11:23:40Z","published":"2023-07-06T11:23:40Z","title":"The Emotional Dilemma: Influence of a Human-like Robot on Trust and\n  Cooperation","summary":"  Increasing anthropomorphic robot behavioral design could affect trust and\ncooperation positively. However, studies have shown contradicting results and\nsuggest a task-dependent relationship between robots that display emotions and\ntrust. Therefore, this study analyzes the effect of robots that display\nhuman-like emotions on trust, cooperation, and participants' emotions. In the\nbetween-group study, participants play the coin entrustment game with an\nemotional and a non-emotional robot. The results show that the robot that\ndisplays emotions induces more anxiety than the neutral robot. Accordingly, the\nparticipants trust the emotional robot less and are less likely to cooperate.\nFurthermore, the perceived intelligence of a robot increases trust, while a\ndesire to outcompete the robot can reduce trust and cooperation. Thus, the\ndesign of robots expressing emotions should be task dependent to avoid adverse\neffects that reduce trust and cooperation.\n","authors":["Dennis Becker","Diana Rueda","Felix Beese","Brenda Scarleth Gutierrez Torres","Myriem Lafdili","Kyra Ahrens","Di Fu","Erik Strahl","Tom Weber","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2307.02924v1.pdf","comment":"Accepted at 2023 32nd IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)"},{"id":"http://arxiv.org/abs/2212.10983v2","updated":"2023-07-06T10:52:49Z","published":"2022-12-21T12:36:17Z","title":"Computer says \"No\": The Case Against Empathetic Conversational AI","summary":"  Emotions are an integral part of human cognition and they guide not only our\nunderstanding of the world but also our actions within it. As such, whether we\nsoothe or flame an emotion is not inconsequential. Recent work in\nconversational AI has focused on responding empathetically to users, validating\nand soothing their emotions without a real basis. This AI-aided emotional\nregulation can have negative consequences for users and society, tending\ntowards a one-noted happiness defined as only the absence of \"negative\"\nemotions. We argue that we must carefully consider whether and how to respond\nto users' emotions.\n","authors":["Alba Curry","Amanda Cercas Curry"],"pdf_url":"https://arxiv.org/pdf/2212.10983v2.pdf","comment":"Accepted to Findings of the ACL 2023"},{"id":"http://arxiv.org/abs/2305.02224v4","updated":"2023-07-06T09:31:59Z","published":"2023-05-03T16:05:08Z","title":"Some Observations on Fact-Checking Work with Implications for\n  Computational Support","summary":"  Social media and user-generated content (UGC) have become increasingly\nimportant features of journalistic work in a number of different ways. However,\nthe growth of misinformation means that news organisations have had devote more\nand more resources to determining its veracity and to publishing corrections if\nit is found to be misleading. In this work, we present the results of\ninterviews with eight members of fact-checking teams from two organisations.\nTeam members described their fact-checking processes and the challenges they\ncurrently face in completing a fact-check in a robust and timely way. The\nformer reveals, inter alia, significant differences in fact-checking practices\nand the role played by collaboration between team members. We conclude with a\ndiscussion of the implications for the development and application of\ncomputational tools, including where computational tool support is currently\nlacking and the importance of being able to accommodate different fact-checking\npractices.\n","authors":["Rob Procter","Miguel Arana-Catania","Yulan He","Maria Liakata","Arkaitz Zubiaga","Elena Kochkina","Runcong Zhao"],"pdf_url":"https://arxiv.org/pdf/2305.02224v4.pdf","comment":"11 pages. International AAAI Conference on Web and Social Media,\n  Mediate 2023: News Media and Computational Journalism Workshop"},{"id":"http://arxiv.org/abs/2306.09817v3","updated":"2023-07-06T07:43:18Z","published":"2023-06-16T12:59:51Z","title":"INDCOR white paper 4: Evaluation of Interactive Narrative Design For\n  Complexity Representations","summary":"  While a strength of Interactive Digital Narratives (IDN) is its support for\nmultiperspectivity, this also poses a substantial challenge to its evaluation.\nMoreover, evaluation has to assess the system's ability to represent a complex\nreality as well as the user's understanding of that complex reality as a result\nof the experience of interacting with the system. This is needed to measure an\nIDN's efficiency and effectiveness in representing the chosen complex\nphenomenon. We here present some empirical methods employed by INDCOR members\nin their research including UX toolkits and scales. Particularly, we consider\nthe impact of IDN on transformative learning and its evaluation through\nself-reporting and other alternatives.\n","authors":["Christian Roth","Breanne Pitt","Lāsma Šķestere","Jonathan Barbara","Agnes Karolina Bakk","Kirsty Dunlop","Maria del Mar Grandio","Miguel Barreda","Despoina Sampatakou","Michael Schlauch"],"pdf_url":"https://arxiv.org/pdf/2306.09817v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2010.10135"},{"id":"http://arxiv.org/abs/2307.02819v1","updated":"2023-07-06T07:24:38Z","published":"2023-07-06T07:24:38Z","title":"Trends in Machine Learning and Electroencephalogram (EEG): A Review for\n  Undergraduate Researchers","summary":"  This paper presents a systematic literature review on Brain-Computer\nInterfaces (BCIs) in the context of Machine Learning. Our focus is on\nElectroencephalography (EEG) research, highlighting the latest trends as of\n2023. The objective is to provide undergraduate researchers with an accessible\noverview of the BCI field, covering tasks, algorithms, and datasets. By\nsynthesizing recent findings, our aim is to offer a fundamental understanding\nof BCI research, identifying promising avenues for future investigations.\n","authors":["Nathan Koome Murungi","Michael Vinh Pham","Xufeng Dai","Xiaodong Qu"],"pdf_url":"https://arxiv.org/pdf/2307.02819v1.pdf","comment":"14 pages, 1 figure, HCI International 2023 Conference"},{"id":"http://arxiv.org/abs/2307.02783v1","updated":"2023-07-06T05:22:20Z","published":"2023-07-06T05:22:20Z","title":"UIT-Saviors at MEDVQA-GI 2023: Improving Multimodal Learning with Image\n  Enhancement for Gastrointestinal Visual Question Answering","summary":"  In recent years, artificial intelligence has played an important role in\nmedicine and disease diagnosis, with many applications to be mentioned, one of\nwhich is Medical Visual Question Answering (MedVQA). By combining computer\nvision and natural language processing, MedVQA systems can assist experts in\nextracting relevant information from medical image based on a given question\nand providing precise diagnostic answers. The ImageCLEFmed-MEDVQA-GI-2023\nchallenge carried out visual question answering task in the gastrointestinal\ndomain, which includes gastroscopy and colonoscopy images. Our team approached\nTask 1 of the challenge by proposing a multimodal learning method with image\nenhancement to improve the VQA performance on gastrointestinal images. The\nmultimodal architecture is set up with BERT encoder and different pre-trained\nvision models based on convolutional neural network (CNN) and Transformer\narchitecture for features extraction from question and endoscopy image. The\nresult of this study highlights the dominance of Transformer-based vision\nmodels over the CNNs and demonstrates the effectiveness of the image\nenhancement process, with six out of the eight vision models achieving better\nF1-Score. Our best method, which takes advantages of BERT+BEiT fusion and image\nenhancement, achieves up to 87.25% accuracy and 91.85% F1-Score on the\ndevelopment test set, while also producing good result on the private test set\nwith accuracy of 82.01%.\n","authors":["Triet M. Thai","Anh T. Vo","Hao K. Tieu","Linh N. P. Bui","Thien T. B. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2307.02783v1.pdf","comment":"ImageCLEF2023"},{"id":"http://arxiv.org/abs/2307.02780v1","updated":"2023-07-06T05:17:45Z","published":"2023-07-06T05:17:45Z","title":"Brain Computer Interface (BCI) based on Electroencephalographic (EEG)\n  patterns due to new cognitive tasks","summary":"  New mental tasks were investigated for suitability in Brain-Computer\nInterface (BCI). Electroencephalography (EEG) signals were collected and\nanalyzed to identify these mental tasks. MS Windows-based software was\ndeveloped for investigating and classifying recorded EEG data with unnecessary\nfrequencies filtered out with Bandpass filtering. To identify the best feature\nvector construction method for a given mental task, feature vectors were\nconstructed using Bandpower, Principal Component Analysis, and Downsampling\nseparately. These feature vectors were then classified with Linear Discriminant\nAnalysis, Linear Support Vector Machines, Critical Distance Classifiers,\nNearest Neighbor Classifiers, and their Non-Linear counterparts to find the\nbest-performing classifier. For comparison purposes, performances of already\nwell-known mental tasks in the BCI community were computed along with that of\nnew mental tasks introduced in this thesis. In the preliminary studies, it was\nfound that the most promising new mental task which a BCI system could identify\nis the imagination of hitting a given square with an imaginary arrow from above\n(or below) and right, (or left) to the screen. The group of these mental tasks\nwas named as 'Hit Series' (HS). A detailed investigation of HS was carried out\nand compared with the performance of Motor Imagery (MI) events which are the\nmost heavily used mental tasks in EEG-based BCI systems. One subject achieved\nthe maximum average performance for HS, 100 pct in the binary classifications\nwhile 99 pct in overall combined performance. The best average performances of\nthe other two subjects for the same mental tasks were 93 pct and 87pct with the\noverall performance of 89 pct and 78 pct. Performances of the same three\nsubjects for mental tasks in MI were relatively poor. The average performances\nwere 92, 78, and 92 pct while overall performances were 87, 69, and 88 pct.\n","authors":["Zahmeeth Sayed Sakkaff"],"pdf_url":"https://arxiv.org/pdf/2307.02780v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1404.1100 by other authors"},{"id":"http://arxiv.org/abs/2307.02773v1","updated":"2023-07-06T04:49:47Z","published":"2023-07-06T04:49:47Z","title":"SeLiNet: Sentiment enriched Lightweight Network for Emotion Recognition\n  in Images","summary":"  In this paper, we propose a sentiment-enriched lightweight network SeLiNet\nand an end-to-end on-device pipeline for contextual emotion recognition in\nimages. SeLiNet model consists of body feature extractor, image aesthetics\nfeature extractor, and learning-based fusion network which jointly estimates\ndiscrete emotion and human sentiments tasks. On the EMOTIC dataset, the\nproposed approach achieves an Average Precision (AP) score of 27.17 in\ncomparison to the baseline AP score of 27.38 while reducing the model size by\n>85%. In addition, we report an on-device AP score of 26.42 with reduction in\nmodel size by >93% when compared to the baseline.\n","authors":["Tuneer Khargonkar","Shwetank Choudhary","Sumit Kumar","Barath Raj KR"],"pdf_url":"https://arxiv.org/pdf/2307.02773v1.pdf","comment":"Paper submitted in ISCAS 2023"},{"id":"http://arxiv.org/abs/2209.00879v3","updated":"2023-07-06T01:21:13Z","published":"2022-09-02T08:39:47Z","title":"Why Feedback Literacy Matters for Learning Analytics","summary":"  Learning analytics (LA) provides data-driven feedback that aims to improve\nlearning and inform action. For learners, LA-based feedback may scaffold\nself-regulated learning skills, which are crucial to learning success. For\nteachers, LA-based feedback may help the evaluation of teaching effects and the\nneed for interventions. However, the current development of LA has presented\nproblems related to the cognitive, social-affective, and structural dimensions\nof feedback. In light of this, this position paper argues that attention needs\nto shift from the design of LA as a feedback product to one that facilitates a\nprocess in which both teachers and students play active roles in\nmeaning-making. To this end, implications for feedback literacy in the context\nof LA are discussed.\n","authors":["Yi-Shan Tsai"],"pdf_url":"https://arxiv.org/pdf/2209.00879v3.pdf","comment":"8 pages. Accepted at the 2022 International Conference of the\n  Learning Sciences (ICLS).\n  https://repository.isls.org/bitstream/1/8799/1/ICLS2022_27-34.pdf"},{"id":"http://arxiv.org/abs/2306.04719v4","updated":"2023-07-06T19:03:47Z","published":"2023-06-07T18:31:39Z","title":"Don't trust your eyes: on the (un)reliability of feature visualizations","summary":"  How do neural networks extract patterns from pixels? Feature visualizations\nattempt to answer this important question by visualizing highly activating\npatterns through optimization. Today, visualization methods form the foundation\nof our knowledge about the internal workings of neural networks, as a type of\nmechanistic interpretability. Here we ask: How reliable are feature\nvisualizations? We start our investigation by developing network circuits that\ntrick feature visualizations into showing arbitrary patterns that are\ncompletely disconnected from normal network behavior on natural input. We then\nprovide evidence for a similar phenomenon occurring in standard, unmanipulated\nnetworks: feature visualizations are processed very differently from standard\ninput, casting doubt on their ability to \"explain\" how neural networks process\nnatural images. We underpin this empirical finding by theory proving that the\nset of functions that can be reliably understood by feature visualization is\nextremely small and does not include general black-box neural networks.\nTherefore, a promising way forward could be the development of networks that\nenforce certain structures in order to ensure more reliable feature\nvisualizations.\n","authors":["Robert Geirhos","Roland S. Zimmermann","Blair Bilodeau","Wieland Brendel","Been Kim"],"pdf_url":"https://arxiv.org/pdf/2306.04719v4.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2307.03175v1","updated":"2023-07-06T17:55:28Z","published":"2023-07-06T17:55:28Z","title":"Push Past Green: Learning to Look Behind Plant Foliage by Moving It","summary":"  Autonomous agriculture applications (e.g., inspection, phenotyping, plucking\nfruits) require manipulating the plant foliage to look behind the leaves and\nthe branches. Partial visibility, extreme clutter, thin structures, and unknown\ngeometry and dynamics for plants make such manipulation challenging. We tackle\nthese challenges through data-driven methods. We use self-supervision to train\nSRPNet, a neural network that predicts what space is revealed on execution of a\ncandidate action on a given plant. We use SRPNet with the cross-entropy method\nto predict actions that are effective at revealing space beneath plant foliage.\nFurthermore, as SRPNet does not just predict how much space is revealed but\nalso where it is revealed, we can execute a sequence of actions that\nincrementally reveal more and more space beneath the plant foliage. We\nexperiment with a synthetic (vines) and a real plant (Dracaena) on a physical\ntest-bed across 5 settings including 2 settings that test generalization to\nnovel plant configurations. Our experiments reveal the effectiveness of our\noverall method, PPG, over a competitive hand-crafted exploration method, and\nthe effectiveness of SRPNet over a hand-crafted dynamics model and relevant\nablations.\n","authors":["Xiaoyu Zhang","Saurabh Gupta"],"pdf_url":"https://arxiv.org/pdf/2307.03175v1.pdf","comment":"for project website with video, see\n  https://sites.google.com/view/pushpastgreen/"},{"id":"http://arxiv.org/abs/2307.03171v1","updated":"2023-07-06T17:52:29Z","published":"2023-07-06T17:52:29Z","title":"LEO: Learning Efficient Orderings for Multiobjective Binary Decision\n  Diagrams","summary":"  Approaches based on Binary decision diagrams (BDDs) have recently achieved\nstate-of-the-art results for multiobjective integer programming problems. The\nvariable ordering used in constructing BDDs can have a significant impact on\ntheir size and on the quality of bounds derived from relaxed or restricted BDDs\nfor single-objective optimization problems. We first showcase a similar impact\nof variable ordering on the Pareto frontier (PF) enumeration time for the\nmultiobjective knapsack problem, suggesting the need for deriving variable\nordering methods that improve the scalability of the multiobjective BDD\napproach. To that end, we derive a novel parameter configuration space based on\nvariable scoring functions which are linear in a small set of interpretable and\neasy-to-compute variable features. We show how the configuration space can be\nefficiently explored using black-box optimization, circumventing the curse of\ndimensionality (in the number of variables and objectives), and finding good\norderings that reduce the PF enumeration time. However, black-box optimization\napproaches incur a computational overhead that outweighs the reduction in time\ndue to good variable ordering. To alleviate this issue, we propose LEO, a\nsupervised learning approach for finding efficient variable orderings that\nreduce the enumeration time. Experiments on benchmark sets from the knapsack\nproblem with 3-7 objectives and up to 80 variables show that LEO is ~30-300%\nand ~10-200% faster at PF enumeration than common ordering strategies and\nalgorithm configuration. Our code and instances are available at\nhttps://github.com/khalil-research/leo.\n","authors":["Rahul Patel","Elias B. Khalil"],"pdf_url":"https://arxiv.org/pdf/2307.03171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03170v1","updated":"2023-07-06T17:52:10Z","published":"2023-07-06T17:52:10Z","title":"Focused Transformer: Contrastive Training for Context Scaling","summary":"  Large language models have an exceptional capability to incorporate new\ninformation in a contextual manner. However, the full potential of such an\napproach is often restrained due to a limitation in the effective context\nlength. One solution to this issue is to endow an attention layer with access\nto an external memory, which comprises of (key, value) pairs. Yet, as the\nnumber of documents increases, the proportion of relevant keys to irrelevant\nones decreases, leading the model to focus more on the irrelevant keys. We\nidentify a significant challenge, dubbed the distraction issue, where keys\nlinked to different semantic values might overlap, making them hard to\ndistinguish. To tackle this problem, we introduce the Focused Transformer\n(FoT), a technique that employs a training process inspired by contrastive\nlearning. This novel approach enhances the structure of the (key, value) space,\nenabling an extension of the context length. Our method allows for fine-tuning\npre-existing, large-scale models to lengthen their effective context. This is\ndemonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The\nresulting models, which we name LongLLaMA, exhibit advancements in tasks\nrequiring a long context. We further illustrate that our LongLLaMA models\nadeptly manage a $256 k$ context length for passkey retrieval.\n","authors":["Szymon Tworkowski","Konrad Staniszewski","Mikołaj Pacek","Yuhuai Wu","Henryk Michalewski","Piotr Miłoś"],"pdf_url":"https://arxiv.org/pdf/2307.03170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03162v1","updated":"2023-07-06T17:42:56Z","published":"2023-07-06T17:42:56Z","title":"BrickPal: Augmented Reality-based Assembly Instructions for Brick Models","summary":"  The assembly instruction is a mandatory component of Lego-like brick sets.The\nconventional production of assembly instructions requires a considerable amount\nof manual fine-tuning, which is intractable for casual users and customized\nbrick sets.Moreover, the traditional paper-based instructions lack\nexpressiveness and interactivity.To tackle the two problems above, we present\nBrickPal, an augmented reality-based system, which visualizes assembly\ninstructions in an augmented reality head-mounted display. It utilizes Natural\nLanguage Processing (NLP) techniques to generate plausible assembly sequences,\nand provide real-time guidance in the AR headset.Our user study demonstrates\nBrickPal's effectiveness at assisting users in brick assembly compared to\ntraditional assembly methods. Additionally, the NLP algorithm-generated\nassembly sequences achieve the same usability with manually adapted sequences.\n","authors":["Yao Shi","Xiaofeng Zhang","Ran zhang","Zhou Yang","Xiao Tang","Hongni Ye","Yi Wu"],"pdf_url":"https://arxiv.org/pdf/2307.03162v1.pdf","comment":"9 pages,7 figures. Project URL: https://origami.dance/brickpal"},{"id":"http://arxiv.org/abs/2307.03135v1","updated":"2023-07-06T17:05:26Z","published":"2023-07-06T17:05:26Z","title":"Distilling Large Vision-Language Model with Out-of-Distribution\n  Generalizability","summary":"  Large vision-language models have achieved outstanding performance, but their\nsize and computational requirements make their deployment on\nresource-constrained devices and time-sensitive tasks impractical. Model\ndistillation, the process of creating smaller, faster models that maintain the\nperformance of larger models, is a promising direction towards the solution.\nThis paper investigates the distillation of visual representations in large\nteacher vision-language models into lightweight student models using a small-\nor mid-scale dataset. Notably, this study focuses on open-vocabulary\nout-of-distribution (OOD) generalization, a challenging problem that has been\noverlooked in previous model distillation literature. We propose two principles\nfrom vision and language modality perspectives to enhance student's OOD\ngeneralization: (1) by better imitating teacher's visual representation space,\nand carefully promoting better coherence in vision-language alignment with the\nteacher; (2) by enriching the teacher's language representations with\ninformative and finegrained semantic attributes to effectively distinguish\nbetween different labels. We propose several metrics and conduct extensive\nexperiments to investigate their techniques. The results demonstrate\nsignificant improvements in zero-shot and few-shot student performance on\nopen-vocabulary out-of-distribution classification, highlighting the\neffectiveness of our proposed approaches. Our code will be released at\nhttps://github.com/xuanlinli17/large_vlm_distillation_ood\n","authors":["Xuanlin Li","Yunhao Fang","Minghua Liu","Zhan Ling","Zhuowen Tu","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2307.03135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04637v2","updated":"2023-07-06T16:55:36Z","published":"2023-06-07T17:59:31Z","title":"Transformers as Statisticians: Provable In-Context Learning with\n  In-Context Algorithm Selection","summary":"  Neural sequence models based on the transformer architecture have\ndemonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they\ncan perform new tasks when prompted with training and test examples, without\nany parameter update to the model. This work first provides a comprehensive\nstatistical theory for transformers to perform ICL. Concretely, we show that\ntransformers can implement a broad class of standard machine learning\nalgorithms in context, such as least squares, ridge regression, Lasso, learning\ngeneralized linear models, and gradient descent on two-layer neural networks,\nwith near-optimal predictive power on various in-context data distributions.\nUsing an efficient implementation of in-context gradient descent as the\nunderlying mechanism, our transformer constructions admit mild size bounds, and\ncan be learned with polynomially many pretraining sequences.\n  Building on these ``base'' ICL algorithms, intriguingly, we show that\ntransformers can implement more complex ICL procedures involving\n\\emph{in-context algorithm selection}, akin to what a statistician can do in\nreal life -- A \\emph{single} transformer can adaptively select different base\nICL algorithms -- or even perform qualitatively different tasks -- on different\ninput sequences, without any explicit prompting of the right algorithm or task.\nWe both establish this in theory by explicit constructions, and also observe\nthis phenomenon experimentally. In theory, we construct two general mechanisms\nfor algorithm selection with concrete examples: pre-ICL testing, and post-ICL\nvalidation. As an example, we use the post-ICL validation mechanism to\nconstruct a transformer that can perform nearly Bayes-optimal ICL on a\nchallenging task -- noisy linear models with mixed noise levels.\nExperimentally, we demonstrate the strong in-context algorithm selection\ncapabilities of standard transformer architectures.\n","authors":["Yu Bai","Fan Chen","Huan Wang","Caiming Xiong","Song Mei"],"pdf_url":"https://arxiv.org/pdf/2306.04637v2.pdf","comment":"V2 releases code"},{"id":"http://arxiv.org/abs/2206.04779v3","updated":"2023-07-06T16:46:11Z","published":"2022-06-09T22:08:47Z","title":"Challenges and Opportunities in Offline Reinforcement Learning from\n  Visual Observations","summary":"  Offline reinforcement learning has shown great promise in leveraging large\npre-collected datasets for policy learning, allowing agents to forgo\noften-expensive online data collection. However, offline reinforcement learning\nfrom visual observations with continuous action spaces remains under-explored,\nwith a limited understanding of the key challenges in this complex domain. In\nthis paper, we establish simple baselines for continuous control in the visual\ndomain and introduce a suite of benchmarking tasks for offline reinforcement\nlearning from visual observations designed to better represent the data\ndistributions present in real-world offline RL problems and guided by a set of\ndesiderata for offline RL from visual observations, including robustness to\nvisual distractions and visually identifiable changes in dynamics. Using this\nsuite of benchmarking tasks, we show that simple modifications to two popular\nvision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2,\nsuffice to outperform existing offline RL methods and establish competitive\nbaselines for continuous control in the visual domain. We rigorously evaluate\nthese algorithms and perform an empirical evaluation of the differences between\nstate-of-the-art model-based and model-free offline RL methods for continuous\ncontrol from visual observations. All code and data used in this evaluation are\nopen-sourced to facilitate progress in this domain.\n","authors":["Cong Lu","Philip J. Ball","Tim G. J. Rudner","Jack Parker-Holder","Michael A. Osborne","Yee Whye Teh"],"pdf_url":"https://arxiv.org/pdf/2206.04779v3.pdf","comment":"Published at TMLR, 2023"},{"id":"http://arxiv.org/abs/2307.03119v1","updated":"2023-07-06T16:45:40Z","published":"2023-07-06T16:45:40Z","title":"Learning Multi-Agent Intention-Aware Communication for Optimal\n  Multi-Order Execution in Finance","summary":"  Order execution is a fundamental task in quantitative finance, aiming at\nfinishing acquisition or liquidation for a number of trading orders of the\nspecific assets. Recent advance in model-free reinforcement learning (RL)\nprovides a data-driven solution to the order execution problem. However, the\nexisting works always optimize execution for an individual order, overlooking\nthe practice that multiple orders are specified to execute simultaneously,\nresulting in suboptimality and bias. In this paper, we first present a\nmulti-agent RL (MARL) method for multi-order execution considering practical\nconstraints. Specifically, we treat every agent as an individual operator to\ntrade one specific order, while keeping communicating with each other and\ncollaborating for maximizing the overall profits. Nevertheless, the existing\nMARL algorithms often incorporate communication among agents by exchanging only\nthe information of their partial observations, which is inefficient in\ncomplicated financial market. To improve collaboration, we then propose a\nlearnable multi-round communication protocol, for the agents communicating the\nintended actions with each other and refining accordingly. It is optimized\nthrough a novel action value attribution method which is provably consistent\nwith the original learning objective yet more efficient. The experiments on the\ndata from two real-world markets have illustrated superior performance with\nsignificantly better collaboration effectiveness achieved by our method.\n","authors":["Yuchen Fang","Zhenggang Tang","Kan Ren","Weiqing Liu","Li Zhao","Jiang Bian","Dongsheng Li","Weinan Zhang","Yong Yu","Tie-Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2307.03119v1.pdf","comment":"Accepted in KDD 2023; The website is at\n  https://seqml.github.io/marl4fin"},{"id":"http://arxiv.org/abs/2307.03109v1","updated":"2023-07-06T16:28:35Z","published":"2023-07-06T16:28:35Z","title":"A Survey on Evaluation of Large Language Models","summary":"  Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.\n","authors":["Yupeng Chang","Xu Wang","Jindong Wang","Yuan Wu","Kaijie Zhu","Hao Chen","Linyi Yang","Xiaoyuan Yi","Cunxiang Wang","Yidong Wang","Wei Ye","Yue Zhang","Yi Chang","Philip S. Yu","Qiang Yang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2307.03109v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2307.03104v1","updated":"2023-07-06T16:26:34Z","published":"2023-07-06T16:26:34Z","title":"Efficient Domain Adaptation of Sentence Embeddings using Adapters","summary":"  Sentence embeddings enable us to capture the semantic similarity of short\ntexts. Most sentence embedding models are trained for general semantic textual\nsimilarity (STS) tasks. Therefore, to use sentence embeddings in a particular\ndomain, the model must be adapted to it in order to achieve good results.\nUsually, this is done by fine-tuning the entire sentence embedding model for\nthe domain of interest. While this approach yields state-of-the-art results,\nall of the model's weights are updated during fine-tuning, making this method\nresource-intensive. Therefore, instead of fine-tuning entire sentence embedding\nmodels for each target domain individually, we propose to train lightweight\nadapters. These domain-specific adapters do not require fine-tuning all\nunderlying sentence embedding model parameters. Instead, we only train a small\nnumber of additional parameters while keeping the weights of the underlying\nsentence embedding model fixed. Training domain-specific adapters allows always\nusing the same base model and only exchanging the domain-specific adapters to\nadapt sentence embeddings to a specific domain. We show that using adapters for\nparameter-efficient domain adaptation of sentence embeddings yields competitive\nperformance within 1% of a domain-adapted, entirely fine-tuned sentence\nembedding model while only training approximately 3.6% of the parameters.\n","authors":["Tim Schopf","Dennis Schneider","Florian Matthes"],"pdf_url":"https://arxiv.org/pdf/2307.03104v1.pdf","comment":"Accepted to the International Conference on Recent Advances in\n  Natural Language Processing (RANLP 2023)"},{"id":"http://arxiv.org/abs/2307.03067v1","updated":"2023-07-06T15:35:02Z","published":"2023-07-06T15:35:02Z","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"  Applying deep learning techniques, particularly language models (LMs), in\nontology engineering has raised widespread attention. However, deep learning\nframeworks like PyTorch and Tensorflow are predominantly developed for Python\nprogramming, while widely-used ontology APIs, such as the OWL API and Jena, are\nprimarily Java-based. To facilitate seamless integration of these frameworks\nand APIs, we present Deeponto, a Python package designed for ontology\nengineering. The package encompasses a core ontology processing module founded\non the widely-recognised and reliable OWL API, encapsulating its fundamental\nfeatures in a more \"Pythonic\" manner and extending its capabilities to include\nother essential components including reasoning, verbalisation, normalisation,\nprojection, and more. Building on this module, Deeponto offers a suite of\ntools, resources, and algorithms that support various ontology engineering\ntasks, such as ontology alignment and completion, by harnessing deep learning\nmethodologies, primarily pre-trained LMs. In this paper, we also demonstrate\nthe practical utility of Deeponto through two use-cases: the Digital Health\nCoaching in Samsung Research UK and the Bio-ML track of the Ontology Alignment\nEvaluation Initiative (OAEI).\n","authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"pdf_url":"https://arxiv.org/pdf/2307.03067v1.pdf","comment":"under review at Semantic Web Journal"},{"id":"http://arxiv.org/abs/2305.09378v2","updated":"2023-07-06T15:28:53Z","published":"2023-05-16T12:01:08Z","title":"Capturing Emerging Complexity in Lenia","summary":"  This research project investigates Lenia, an artificial life platform that\nsimulates ecosystems of digital creatures. Lenia's ecosystem consists of\nsimple, artificial organisms that can move, consume, grow, and reproduce. The\nplatform is important as a tool for studying artificial life and evolution, as\nit provides a scalable and flexible environment for creating a diverse range of\norganisms with varying abilities and behaviors. Measuring complexity in Lenia\nis a key aspect of the study, which identifies the metrics for measuring\nlong-term complex emerging behavior of rules, with the aim of evolving better\nLenia behaviors which are yet not discovered. The Genetic Algorithm uses\nneighborhoods or kernels as genotype while keeping the rest of the parameters\nof Lenia as fixed, for example growth function, to produce different behaviors\nrespective to the population and then measures fitness value to decide the\ncomplexity of the resulting behavior. First, we use Variation over Time as a\nfitness function where higher variance between the frames are rewarded. Second,\nwe use Auto-encoder based fitness where variation of the list of reconstruction\nloss for the frames is rewarded. Third, we perform combined fitness where\nhigher variation of the pixel density of reconstructed frames is rewarded. All\nthree experiments are tweaked with pixel alive threshold and frames used.\nFinally, after performing nine experiments of each fitness for 500 generations,\nwe pick configurations from all experiments such that there is a scope of\nfurther evolution, and run it for 2500 generations. Results show that the\nkernel's center of mass increases with a specific set of pixels and together\nwith borders the kernel try to achieve a Gaussian distribution.\n","authors":["Sanyam Jain","Aarati Shrestha","Stefano Nichele"],"pdf_url":"https://arxiv.org/pdf/2305.09378v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03056v1","updated":"2023-07-06T15:19:53Z","published":"2023-07-06T15:19:53Z","title":"Generalizing Backpropagation for Gradient-Based Interpretability","summary":"  Many popular feature-attribution methods for interpreting deep neural\nnetworks rely on computing the gradients of a model's output with respect to\nits inputs. While these methods can indicate which input features may be\nimportant for the model's prediction, they reveal little about the inner\nworkings of the model itself. In this paper, we observe that the gradient\ncomputation of a model is a special case of a more general formulation using\nsemirings. This observation allows us to generalize the backpropagation\nalgorithm to efficiently compute other interpretable statistics about the\ngradient graph of a neural network, such as the highest-weighted path and\nentropy. We implement this generalized algorithm, evaluate it on synthetic\ndatasets to better understand the statistics it computes, and apply it to study\nBERT's behavior on the subject-verb number agreement task (SVA). With this\nmethod, we (a) validate that the amount of gradient flow through a component of\na model reflects its importance to a prediction and (b) for SVA, identify which\npathways of the self-attention mechanism are most important.\n","authors":["Kevin Du","Lucas Torroba Hennigen","Niklas Stoehr","Alexander Warstadt","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2307.03056v1.pdf","comment":"Long paper accepted at ACL 2023"},{"id":"http://arxiv.org/abs/2307.03039v1","updated":"2023-07-06T15:04:18Z","published":"2023-07-06T15:04:18Z","title":"Art Authentication with Vision Transformers","summary":"  In recent years, Transformers, initially developed for language, have been\nsuccessfully applied to visual tasks. Vision Transformers have been shown to\npush the state-of-the-art in a wide range of tasks, including image\nclassification, object detection, and semantic segmentation. While ample\nresearch has shown promising results in art attribution and art authentication\ntasks using Convolutional Neural Networks, this paper examines if the\nsuperiority of Vision Transformers extends to art authentication, improving,\nthus, the reliability of computer-based authentication of artworks. Using a\ncarefully compiled dataset of authentic paintings by Vincent van Gogh and two\ncontrast datasets, we compare the art authentication performances of Swin\nTransformers with those of EfficientNet. Using a standard contrast set\ncontaining imitations and proxies (works by painters with styles closely\nrelated to van Gogh), we find that EfficientNet achieves the best performance\noverall. With a contrast set that only consists of imitations, we find the Swin\nTransformer to be superior to EfficientNet by achieving an authentication\naccuracy of over 85%. These results lead us to conclude that Vision\nTransformers represent a strong and promising contender in art authentication,\nparticularly in enhancing the computer-based ability to detect artistic\nimitations.\n","authors":["Ludovica Schaerf","Carina Popovici","Eric Postma"],"pdf_url":"https://arxiv.org/pdf/2307.03039v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15782v2","updated":"2023-07-06T14:50:27Z","published":"2023-06-27T20:09:56Z","title":"UTRNet: High-Resolution Urdu Text Recognition In Printed Documents","summary":"  In this paper, we propose a novel approach to address the challenges of\nprinted Urdu text recognition using high-resolution, multi-scale semantic\nfeature extraction. Our proposed UTRNet architecture, a hybrid CNN-RNN model,\ndemonstrates state-of-the-art performance on benchmark datasets. To address the\nlimitations of previous works, which struggle to generalize to the intricacies\nof the Urdu script and the lack of sufficient annotated real-world data, we\nhave introduced the UTRSet-Real, a large-scale annotated real-world dataset\ncomprising over 11,000 lines and UTRSet-Synth, a synthetic dataset with 20,000\nlines closely resembling real-world and made corrections to the ground truth of\nthe existing IIITH dataset, making it a more reliable resource for future\nresearch. We also provide UrduDoc, a benchmark dataset for Urdu text line\ndetection in scanned documents. Additionally, we have developed an online tool\nfor end-to-end Urdu OCR from printed documents by integrating UTRNet with a\ntext detection model. Our work not only addresses the current limitations of\nUrdu OCR but also paves the way for future research in this area and\nfacilitates the continued advancement of Urdu OCR technology. The project page\nwith source code, datasets, annotations, trained models, and online tool is\navailable at abdur75648.github.io/UTRNet.\n","authors":["Abdur Rahman","Arjun Ghosh","Chetan Arora"],"pdf_url":"https://arxiv.org/pdf/2306.15782v2.pdf","comment":"Accepted at The 17th International Conference on Document Analysis\n  and Recognition (ICDAR 2023)"},{"id":"http://arxiv.org/abs/2307.03015v1","updated":"2023-07-06T14:24:17Z","published":"2023-07-06T14:24:17Z","title":"Sequential Neural Barriers for Scalable Dynamic Obstacle Avoidance","summary":"  There are two major challenges for scaling up robot navigation around dynamic\nobstacles: the complex interaction dynamics of the obstacles can be hard to\nmodel analytically, and the complexity of planning and control grows\nexponentially in the number of obstacles. Data-driven and learning-based\nmethods are thus particularly valuable in this context. However, data-driven\nmethods are sensitive to distribution drift, making it hard to train and\ngeneralize learned models across different obstacle densities. We propose a\nnovel method for compositional learning of Sequential Neural Control Barrier\nmodels (SNCBFs) to achieve scalability. Our approach exploits an important\nobservation: the spatial interaction patterns of multiple dynamic obstacles can\nbe decomposed and predicted through temporal sequences of states for each\nobstacle. Through decomposition, we can generalize control policies trained\nonly with a small number of obstacles, to environments where the obstacle\ndensity can be 100x higher. We demonstrate the benefits of the proposed methods\nin improving dynamic collision avoidance in comparison with existing methods\nincluding potential fields, end-to-end reinforcement learning, and\nmodel-predictive control. We also perform hardware experiments and show the\npractical effectiveness of the approach in the supplementary video.\n","authors":["Hongzhan Yu","Chiaki Hirayama","Chenning Yu","Sylvia Herbert","Sicun Gao"],"pdf_url":"https://arxiv.org/pdf/2307.03015v1.pdf","comment":"To be published in IROS 2023"},{"id":"http://arxiv.org/abs/2205.03447v7","updated":"2023-07-06T14:14:46Z","published":"2022-05-06T18:52:53Z","title":"Machine Learning-Friendly Biomedical Datasets for Equivalence and\n  Subsumption Ontology Matching","summary":"  Ontology Matching (OM) plays an important role in many domains such as\nbioinformatics and the Semantic Web, and its research is becoming increasingly\npopular, especially with the application of machine learning (ML) techniques.\nAlthough the Ontology Alignment Evaluation Initiative (OAEI) represents an\nimpressive effort for the systematic evaluation of OM systems, it still suffers\nfrom several limitations including limited evaluation of subsumption mappings,\nsuboptimal reference mappings, and limited support for the evaluation of\nML-based systems. To tackle these limitations, we introduce five new biomedical\nOM tasks involving ontologies extracted from Mondo and UMLS. Each task includes\nboth equivalence and subsumption matching; the quality of reference mappings is\nensured by human curation, ontology pruning, etc.; and a comprehensive\nevaluation framework is proposed to measure OM performance from various\nperspectives for both ML-based and non-ML-based OM systems. We report\nevaluation results for OM systems of different types to demonstrate the usage\nof these resources, all of which are publicly available as part of the new\nBioML track at OAEI 2022.\n","authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ernesto Jiménez-Ruiz","Ali Hadian","Ian Horrocks"],"pdf_url":"https://arxiv.org/pdf/2205.03447v7.pdf","comment":"Accepted paper (Best Resource Paper Candidate) in the 21st\n  International Semantic Web Conference (ISWC-2022); Bio-ML Dataset:\n  https://doi.org/10.5281/zenodo.6510086"},{"id":"http://arxiv.org/abs/2307.03007v1","updated":"2023-07-06T14:13:11Z","published":"2023-07-06T14:13:11Z","title":"Self-supervised Optimization of Hand Pose Estimation using Anatomical\n  Features and Iterative Learning","summary":"  Manual assembly workers face increasing complexity in their work.\nHuman-centered assistance systems could help, but object recognition as an\nenabling technology hinders sophisticated human-centered design of these\nsystems. At the same time, activity recognition based on hand poses suffers\nfrom poor pose estimation in complex usage scenarios, such as wearing gloves.\nThis paper presents a self-supervised pipeline for adapting hand pose\nestimation to specific use cases with minimal human interaction. This enables\ncheap and robust hand posebased activity recognition. The pipeline consists of\na general machine learning model for hand pose estimation trained on a\ngeneralized dataset, spatial and temporal filtering to account for anatomical\nconstraints of the hand, and a retraining step to improve the model. Different\nparameter combinations are evaluated on a publicly available and annotated\ndataset. The best parameter and model combination is then applied to unlabelled\nvideos from a manual assembly scenario. The effectiveness of the pipeline is\ndemonstrated by training an activity recognition as a downstream task in the\nmanual assembly scenario.\n","authors":["Christian Jauch","Timo Leitritz","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2307.03007v1.pdf","comment":"Manuscript accepted at IEEE SMC 2023"},{"id":"http://arxiv.org/abs/2307.02984v1","updated":"2023-07-06T13:35:48Z","published":"2023-07-06T13:35:48Z","title":"A Privacy-Preserving Walk in the Latent Space of Generative Models for\n  Medical Applications","summary":"  Generative Adversarial Networks (GANs) have demonstrated their ability to\ngenerate synthetic samples that match a target distribution. However, from a\nprivacy perspective, using GANs as a proxy for data sharing is not a safe\nsolution, as they tend to embed near-duplicates of real samples in the latent\nspace. Recent works, inspired by k-anonymity principles, address this issue\nthrough sample aggregation in the latent space, with the drawback of reducing\nthe dataset by a factor of k. Our work aims to mitigate this problem by\nproposing a latent space navigation strategy able to generate diverse synthetic\nsamples that may support effective training of deep models, while addressing\nprivacy concerns in a principled way. Our approach leverages an auxiliary\nidentity classifier as a guide to non-linearly walk between points in the\nlatent space, minimizing the risk of collision with near-duplicates of real\nsamples. We empirically demonstrate that, given any random pair of points in\nthe latent space, our walking strategy is safer than linear interpolation. We\nthen test our path-finding strategy combined to k-same methods and demonstrate,\non two benchmarks for tuberculosis and diabetic retinopathy classification,\nthat training a model using samples generated by our approach mitigate drops in\nperformance, while keeping privacy preservation.\n","authors":["Matteo Pennisi","Federica Proietto Salanitri","Giovanni Bellitto","Simone Palazzo","Ulas Bagci","Concetto Spampinato"],"pdf_url":"https://arxiv.org/pdf/2307.02984v1.pdf","comment":"Accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2307.02971v1","updated":"2023-07-06T13:17:55Z","published":"2023-07-06T13:17:55Z","title":"On the Cultural Gap in Text-to-Image Generation","summary":"  One challenge in text-to-image (T2I) generation is the inadvertent reflection\nof culture gaps present in the training data, which signifies the disparity in\ngenerated image quality when the cultural elements of the input text are rarely\ncollected in the training set. Although various T2I models have shown\nimpressive but arbitrary examples, there is no benchmark to systematically\nevaluate a T2I model's ability to generate cross-cultural images. To bridge the\ngap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive\nevaluation criteria, which can assess how well-suited a model is to a target\nculture. By analyzing the flawed images generated by the Stable Diffusion model\non the C3 benchmark, we find that the model often fails to generate certain\ncultural objects. Accordingly, we propose a novel multi-modal metric that\nconsiders object-text alignment to filter the fine-tuning data in the target\nculture, which is used to fine-tune a T2I model to improve cross-cultural\ngeneration. Experimental results show that our multi-modal metric provides\nstronger data selection performance on the C3 benchmark than existing metrics,\nin which the object-text alignment is crucial. We release the benchmark, data,\ncode, and generated images to facilitate future research on culturally diverse\nT2I generation (https://github.com/longyuewangdcu/C3-Bench).\n","authors":["Bingshuai Liu","Longyue Wang","Chenyang Lyu","Yong Zhang","Jinsong Su","Shuming Shi","Zhaopeng Tu"],"pdf_url":"https://arxiv.org/pdf/2307.02971v1.pdf","comment":"Equal contribution: Bingshuai Liu and Longyue Wang. Work done while\n  Bingshuai Liu and Chengyang Lyu were interning at Tencent AI Lab. Zhaopeng Tu\n  is the corresponding author"},{"id":"http://arxiv.org/abs/2306.04220v3","updated":"2023-07-06T13:05:46Z","published":"2023-06-07T07:51:05Z","title":"Look Beneath the Surface: Exploiting Fundamental Symmetry for\n  Sample-Efficient Offline RL","summary":"  Offline reinforcement learning (RL) offers an appealing approach to\nreal-world tasks by learning policies from pre-collected datasets without\ninteracting with the environment. However, the performance of existing offline\nRL algorithms heavily depends on the scale and state-action space coverage of\ndatasets. Real-world data collection is often expensive and uncontrollable,\nleading to small and narrowly covered datasets and posing significant\nchallenges for practical deployments of offline RL. In this paper, we provide a\nnew insight that leveraging the fundamental symmetry of system dynamics can\nsubstantially enhance offline RL performance under small datasets.\nSpecifically, we propose a Time-reversal symmetry (T-symmetry) enforced\nDynamics Model (TDM), which establishes consistency between a pair of forward\nand reverse latent dynamics. TDM provides both well-behaved representations for\nsmall datasets and a new reliability measure for OOD samples based on\ncompliance with the T-symmetry. These can be readily used to construct a new\noffline RL algorithm (TSRL) with less conservative policy constraints and a\nreliable latent space data augmentation procedure. Based on extensive\nexperiments, we find TSRL achieves great performance on small benchmark\ndatasets with as few as 1% of the original samples, which significantly\noutperforms the recent offline RL algorithms in terms of data efficiency and\ngeneralizability.\n","authors":["Peng Cheng","Xianyuan Zhan","Zhihao Wu","Wenjia Zhang","Shoucheng Song","Han Wang","Youfang Lin","Li Jiang"],"pdf_url":"https://arxiv.org/pdf/2306.04220v3.pdf","comment":"The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2307.02947v1","updated":"2023-07-06T12:33:34Z","published":"2023-07-06T12:33:34Z","title":"A Neuromorphic Architecture for Reinforcement Learning from Real-Valued\n  Observations","summary":"  Reinforcement Learning (RL) provides a powerful framework for decision-making\nin complex environments. However, implementing RL in hardware-efficient and\nbio-inspired ways remains a challenge. This paper presents a novel Spiking\nNeural Network (SNN) architecture for solving RL problems with real-valued\nobservations. The proposed model incorporates multi-layered event-based\nclustering, with the addition of Temporal Difference (TD)-error modulation and\neligibility traces, building upon prior work. An ablation study confirms the\nsignificant impact of these components on the proposed model's performance. A\ntabular actor-critic algorithm with eligibility traces and a state-of-the-art\nProximal Policy Optimization (PPO) algorithm are used as benchmarks. Our\nnetwork consistently outperforms the tabular approach and successfully\ndiscovers stable control policies on classic RL environments: mountain car,\ncart-pole, and acrobot. The proposed model offers an appealing trade-off in\nterms of computational and hardware implementation requirements. The model does\nnot require an external memory buffer nor a global error gradient computation,\nand synaptic updates occur online, driven by local learning rules and a\nbroadcasted TD-error signal. Thus, this work contributes to the development of\nmore hardware-efficient RL solutions.\n","authors":["Sergio F. Chevtchenko","Yeshwanth Bethi","Teresa B. Ludermir","Saeed Afshar"],"pdf_url":"https://arxiv.org/pdf/2307.02947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2008.02215v2","updated":"2023-07-06T12:28:37Z","published":"2020-08-05T16:33:41Z","title":"A Time Leap Challenge for SAT Solving","summary":"  We compare the impact of hardware advancement and algorithm advancement for\nSAT solving over the last two decades. In particular, we compare 20-year-old\nSAT-solvers on new computer hardware with modern SAT-solvers on 20-year-old\nhardware. Our findings show that the progress on the algorithmic side has at\nleast as much impact as the progress on the hardware side.\n","authors":["Johannes K. Fichte","Markus Hecher","Stefan Szeider"],"pdf_url":"https://arxiv.org/pdf/2008.02215v2.pdf","comment":"Authors' version of a paper which is to appear in the proceedings of\n  CP'2020"},{"id":"http://arxiv.org/abs/2210.14896v4","updated":"2023-07-06T11:53:19Z","published":"2022-10-26T17:54:20Z","title":"DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image\n  Generative Models","summary":"  With recent advancements in diffusion models, users can generate high-quality\nimages by writing text prompts in natural language. However, generating images\nwith desired details requires proper prompts, and it is often unclear how a\nmodel reacts to different prompts or what the best prompts are. To help\nresearchers tackle these critical challenges, we introduce DiffusionDB, the\nfirst large-scale text-to-image prompt dataset totaling 6.5TB, containing 14\nmillion images generated by Stable Diffusion, 1.8 million unique prompts, and\nhyperparameters specified by real users. We analyze the syntactic and semantic\ncharacteristics of prompts. We pinpoint specific hyperparameter values and\nprompt styles that can lead to model errors and present evidence of potentially\nharmful model usage, such as the generation of misinformation. The\nunprecedented scale and diversity of this human-actuated dataset provide\nexciting research opportunities in understanding the interplay between prompts\nand generative models, detecting deepfakes, and designing human-AI interaction\ntools to help users more easily use these models. DiffusionDB is publicly\navailable at: https://poloclub.github.io/diffusiondb.\n","authors":["Zijie J. Wang","Evan Montoya","David Munechika","Haoyang Yang","Benjamin Hoover","Duen Horng Chau"],"pdf_url":"https://arxiv.org/pdf/2210.14896v4.pdf","comment":"Accepted to ACL 2023 (nominated for best paper, top 1.6% of\n  submissions, oral presentation). 17 pages, 11 figures. The dataset is\n  available at https://huggingface.co/datasets/poloclub/diffusiondb. The code\n  is at https://github.com/poloclub/diffusiondb. The interactive visualization\n  demo is at https://poloclub.github.io/diffusiondb/explorer/"},{"id":"http://arxiv.org/abs/2307.02933v1","updated":"2023-07-06T11:51:43Z","published":"2023-07-06T11:51:43Z","title":"In Time and Space: Towards Usable Adaptive Control for Assistive Robotic\n  Arms","summary":"  Robotic solutions, in particular robotic arms, are becoming more frequently\ndeployed for close collaboration with humans, for example in manufacturing or\ndomestic care environments. These robotic arms require the user to control\nseveral Degrees-of-Freedom (DoFs) to perform tasks, primarily involving\ngrasping and manipulating objects. Standard input devices predominantly have\ntwo DoFs, requiring time-consuming and cognitively demanding mode switches to\nselect individual DoFs. Contemporary Adaptive DoF Mapping Controls (ADMCs) have\nshown to decrease the necessary number of mode switches but were up to now not\nable to significantly reduce the perceived workload. Users still bear the\nmental workload of incorporating abstract mode switching into their workflow.\nWe address this by providing feed-forward multimodal feedback using updated\nrecommendations of ADMC, allowing users to visually compare the current and the\nsuggested mapping in real-time. We contrast the effectiveness of two new\napproaches that a) continuously recommend updated DoF combinations or b) use\ndiscrete thresholds between current robot movements and new recommendations.\nBoth are compared in a Virtual Reality (VR) in-person study against a classic\ncontrol method. Significant results for lowered task completion time, fewer\nmode switches, and reduced perceived workload conclusively establish that in\ncombination with feedforward, ADMC methods can indeed outperform classic mode\nswitching. A lack of apparent quantitative differences between Continuous and\nThreshold reveals the importance of user-centered customization options.\nIncluding these implications in the development process will improve usability,\nwhich is essential for successfully implementing robotic technologies with high\nuser acceptance.\n","authors":["Max Pascher","Kirill Kronhardt","Felix Ferdinand Goldau","Udo Frese","Jens Gerken"],"pdf_url":"https://arxiv.org/pdf/2307.02933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.07729v2","updated":"2023-07-06T11:46:14Z","published":"2023-02-14T12:45:14Z","title":"Generation of Highlights from Research Papers Using Pointer-Generator\n  Networks and SciBERT Embeddings","summary":"  Nowadays many research articles are prefaced with research highlights to\nsummarize the main findings of the paper. Highlights not only help researchers\nprecisely and quickly identify the contributions of a paper, they also enhance\nthe discoverability of the article via search engines. We aim to automatically\nconstruct research highlights given certain segments of a research paper. We\nuse a pointer-generator network with coverage mechanism and a contextual\nembedding layer at the input that encodes the input tokens into SciBERT\nembeddings. We test our model on a benchmark dataset, CSPubSum, and also\npresent MixSub, a new multi-disciplinary corpus of papers for automatic\nresearch highlight generation. For both CSPubSum and MixSub, we have observed\nthat the proposed model achieves the best performance compared to related\nvariants and other models proposed in the literature. On the CSPubSum dataset,\nour model achieves the best performance when the input is only the abstract of\na paper as opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2\nand ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR score of\n32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On the\nnew MixSub dataset, where only the abstract is the input, our proposed model\n(when trained on the whole training corpus without distinguishing between the\nsubject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,\n9.76 and 29.3, respectively, METEOR score of 24.00, and BERTScore F1 of 85.25.\n","authors":["Tohida Rehman","Debarshi Kumar Sanyal","Samiran Chattopadhyay","Plaban Kumar Bhowmick","Partha Pratim Das"],"pdf_url":"https://arxiv.org/pdf/2302.07729v2.pdf","comment":"20 Pages, 9 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2302.09844v2","updated":"2023-07-06T11:35:31Z","published":"2023-02-20T09:02:24Z","title":"FederatedTrust: A Solution for Trustworthy Federated Learning","summary":"  The rapid expansion of the Internet of Things (IoT) and Edge Computing has\npresented challenges for centralized Machine and Deep Learning (ML/DL) methods\ndue to the presence of distributed data silos that hold sensitive information.\nTo address concerns regarding data privacy, collaborative and\nprivacy-preserving ML/DL techniques like Federated Learning (FL) have emerged.\nHowever, ensuring data privacy and performance alone is insufficient since\nthere is a growing need to establish trust in model predictions. Existing\nliterature has proposed various approaches on trustworthy ML/DL (excluding data\nprivacy), identifying robustness, fairness, explainability, and accountability\nas important pillars. Nevertheless, further research is required to identify\ntrustworthiness pillars and evaluation metrics specifically relevant to FL\nmodels, as well as to develop solutions that can compute the trustworthiness\nlevel of FL models. This work examines the existing requirements for evaluating\ntrustworthiness in FL and introduces a comprehensive taxonomy consisting of six\npillars (privacy, robustness, fairness, explainability, accountability, and\nfederation), along with over 30 metrics for computing the trustworthiness of FL\nmodels. Subsequently, an algorithm named FederatedTrust is designed based on\nthe pillars and metrics identified in the taxonomy to compute the\ntrustworthiness score of FL models. A prototype of FederatedTrust is\nimplemented and integrated into the learning process of FederatedScope, a\nwell-established FL framework. Finally, five experiments are conducted using\ndifferent configurations of FederatedScope to demonstrate the utility of\nFederatedTrust in computing the trustworthiness of FL models. Three experiments\nemploy the FEMNIST dataset, and two utilize the N-BaIoT dataset considering a\nreal-world IoT security use case.\n","authors":["Pedro Miguel Sánchez Sánchez","Alberto Huertas Celdrán","Ning Xie","Gérôme Bovet","Gregorio Martínez Pérez","Burkhard Stiller"],"pdf_url":"https://arxiv.org/pdf/2302.09844v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12313v2","updated":"2023-07-06T11:20:11Z","published":"2023-01-29T00:17:16Z","title":"Adapting Neural Link Predictors for Complex Query Answering","summary":"  Answering complex queries on incomplete knowledge graphs is a challenging\ntask where a model needs to answer complex logical queries in the presence of\nmissing knowledge. Recently, Arakelyan et al. (2021); Minervini et al. (2022)\nshowed that neural link predictors could also be used for answering complex\nqueries: their Continuous Query Decomposition (CQD) method works by decomposing\ncomplex queries into atomic sub-queries, answers them using neural link\npredictors and aggregates their scores via t-norms for ranking the answers to\neach complex query. However, CQD does not handle negations and only uses the\ntraining signal from atomic training queries: neural link prediction scores are\nnot calibrated to interact together via fuzzy logic t-norms during complex\nquery answering. In this work, we propose to address this problem by training a\nparameter-efficient score adaptation model to re-calibrate neural link\nprediction scores: this new component is trained on complex queries by\nback-propagating through the complex query-answering process. Our method,\nCQD$^{A}$, produces significantly more accurate results than current\nstate-of-the-art methods, improving from $34.4$ to $35.1$ Mean Reciprocal Rank\nvalues averaged across all datasets and query types while using $\\leq 35\\%$ of\nthe available training query types. We further show that CQD$^{A}$ is\ndata-efficient, achieving competitive results with only $1\\%$ of the training\ndata, and robust in out-of-domain evaluations.\n","authors":["Erik Arakelyan","Pasquale Minervini","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2301.12313v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00209v2","updated":"2023-07-06T11:19:22Z","published":"2023-07-01T03:23:56Z","title":"Image Matters: A New Dataset and Empirical Study for Multimodal\n  Hyperbole Detection","summary":"  Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection\nof hyperbole is an important part of understanding human expression. There have\nbeen several studies on hyperbole detection, but most of which focus on text\nmodality only. However, with the development of social media, people can create\nhyperbolic expressions with various modalities, including text, images, videos,\netc. In this paper, we focus on multimodal hyperbole detection. We create a\nmultimodal detection dataset\\footnote{The dataset will be released to the\ncommunity.} from Weibo (a Chinese social media) and carry out some studies on\nit. We treat the text and image from a piece of weibo as two modalities and\nexplore the role of text and image for hyperbole detection. Different\npre-trained multimodal encoders are also evaluated on this downstream task to\nshow their performance. Besides, since this dataset is constructed from five\ndifferent topics, we also evaluate the cross-domain performance of different\nmodels. These studies can serve as a benchmark and point out the direction of\nfurther study on multimodal hyperbole detection.\n","authors":["Huixuan Zhang","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2307.00209v2.pdf","comment":"11 pages, 6 figures. 6 tables"},{"id":"http://arxiv.org/abs/2307.02912v1","updated":"2023-07-06T10:53:50Z","published":"2023-07-06T10:53:50Z","title":"LEA: Improving Sentence Similarity Robustness to Typos Using Lexical\n  Attention Bias","summary":"  Textual noise, such as typos or abbreviations, is a well-known issue that\npenalizes vanilla Transformers for most downstream tasks. We show that this is\nalso the case for sentence similarity, a fundamental task in multiple domains,\ne.g. matching, retrieval or paraphrasing. Sentence similarity can be approached\nusing cross-encoders, where the two sentences are concatenated in the input\nallowing the model to exploit the inter-relations between them. Previous works\naddressing the noise issue mainly rely on data augmentation strategies, showing\nimproved robustness when dealing with corrupted samples that are similar to the\nones used for training. However, all these methods still suffer from the token\ndistribution shift induced by typos. In this work, we propose to tackle textual\nnoise by equipping cross-encoders with a novel LExical-aware Attention module\n(LEA) that incorporates lexical similarities between words in both sentences.\nBy using raw text similarities, our approach avoids the tokenization shift\nproblem obtaining improved robustness. We demonstrate that the attention bias\nintroduced by LEA helps cross-encoders to tackle complex scenarios with textual\nnoise, specially in domains with short-text descriptions and limited context.\nExperiments using three popular Transformer encoders in five e-commerce\ndatasets for product matching show that LEA consistently boosts performance\nunder the presence of noise, while remaining competitive on the original\n(clean) splits. We also evaluate our approach in two datasets for textual\nentailment and paraphrasing showing that LEA is robust to typos in domains with\nlonger sentences and more natural context. Additionally, we thoroughly analyze\nseveral design choices in our approach, providing insights about the impact of\nthe decisions made and fostering future research in cross-encoders dealing with\ntypos.\n","authors":["Mario Almagro","Emilio Almazán","Diego Ortego","David Jiménez"],"pdf_url":"https://arxiv.org/pdf/2307.02912v1.pdf","comment":"KDD'23 conference (main research track). (*) These authors\n  contributed equally"},{"id":"http://arxiv.org/abs/2307.02909v1","updated":"2023-07-06T10:50:46Z","published":"2023-07-06T10:50:46Z","title":"Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation\n  and Recognition","summary":"  Accurate recognition of cocktail party speech containing overlapping\nspeakers, noise and reverberation remains a highly challenging task to date.\nMotivated by the invariance of visual modality to acoustic signal corruption,\nan audio-visual multi-channel speech separation, dereverberation and\nrecognition approach featuring a full incorporation of visual information into\nall system components is proposed in this paper. The efficacy of the video\ninput is consistently demonstrated in mask-based MVDR speech separation,\nDNN-WPE or spectral mapping (SpecM) based speech dereverberation front-end and\nConformer ASR back-end. Audio-visual integrated front-end architectures\nperforming speech separation and dereverberation in a pipelined or joint\nfashion via mask-based WPD are investigated. The error cost mismatch between\nthe speech enhancement front-end and ASR back-end components is minimized by\nend-to-end jointly fine-tuning using either the ASR cost function alone, or its\ninterpolation with the speech enhancement loss. Experiments were conducted on\nthe mixture overlapped and reverberant speech data constructed using simulation\nor replay of the Oxford LRS2 dataset. The proposed audio-visual multi-channel\nspeech separation, dereverberation and recognition systems consistently\noutperformed the comparable audio-only baseline by 9.1% and 6.2% absolute\n(41.7% and 36.0% relative) word error rate (WER) reductions. Consistent speech\nenhancement improvements were also obtained on PESQ, STOI and SRMR scores.\n","authors":["Guinan Li","Jiajun Deng","Mengzhe Geng","Zengrui Jin","Tianzi Wang","Shujie Hu","Mingyu Cui","Helen Meng","Xunying Liu"],"pdf_url":"https://arxiv.org/pdf/2307.02909v1.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing"},{"id":"http://arxiv.org/abs/2306.15880v2","updated":"2023-07-06T10:45:39Z","published":"2023-06-28T02:33:06Z","title":"Towards Open Vocabulary Learning: A Survey","summary":"  In the field of visual scene understanding, deep neural networks have made\nimpressive advancements in various core tasks like segmentation, tracking, and\ndetection. However, most approaches operate on the close-set assumption,\nmeaning that the model can only identify pre-defined categories that are\npresent in the training set. Recently, open vocabulary settings were proposed\ndue to the rapid progress of vision language pre-training. These new approaches\nseek to locate and recognize categories beyond the annotated label space. The\nopen vocabulary approach is more general, practical, and effective compared to\nweakly supervised and zero-shot settings. This paper provides a thorough review\nof open vocabulary learning, summarizing and analyzing recent developments in\nthe field. In particular, we begin by comparing it to related concepts such as\nzero-shot learning, open-set recognition, and out-of-distribution detection.\nThen, we review several closely related tasks in the case of segmentation and\ndetection, including long-tail problems, few-shot, and zero-shot settings. For\nthe method survey, we first present the basic knowledge of detection and\nsegmentation in close-set as the preliminary knowledge. Next, we examine\nvarious scenarios in which open vocabulary learning is used, identifying common\ndesign elements and core ideas. Then, we compare the recent detection and\nsegmentation approaches in commonly used datasets and benchmarks. Finally, we\nconclude with insights, issues, and discussions regarding future research\ndirections. To our knowledge, this is the first comprehensive literature review\nof open vocabulary learning. We keep tracing related works at\nhttps://github.com/jianzongwu/Awesome-Open-Vocabulary.\n","authors":["Jianzong Wu","Xiangtai Li","Shilin Xu","Haobo Yuan","Henghui Ding","Yibo Yang","Xia Li","Jiangning Zhang","Yunhai Tong","Xudong Jiang","Bernard Ghanem","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2306.15880v2.pdf","comment":"Project page: https://github.com/jianzongwu/Awesome-Open-Vocabulary"},{"id":"http://arxiv.org/abs/2306.10077v2","updated":"2023-07-06T10:03:35Z","published":"2023-06-16T03:45:48Z","title":"Stacking of Hyperparameter Tuned Models for Tagging Coding Problems","summary":"  Coding problems are problems that require a solution in the form of a\ncomputer program. Coding problems are popular among students and professionals\nas it enhances their skills and career opportunities. An AI system that would\nhelp those who practice coding problems would be highly useful and there is a\nhuge potential for such a system. In this work, we propose a model which uses\nstacking of hyperparameter tuned boosting models to achieve impressive metric\nscores of 77.8% accuracy and 0.815 PR-AUC on the dataset that was scraped from\nCodeforces and Leetcode. We open source the dataset and the models developed\nfor this work.\n","authors":["Sathya Krishnan TS","S. Lakshmana Pandian","P. Shunmugapriya"],"pdf_url":"https://arxiv.org/pdf/2306.10077v2.pdf","comment":"Error corrections have to be made for certain metrics"},{"id":"http://arxiv.org/abs/2307.02891v1","updated":"2023-07-06T09:53:56Z","published":"2023-07-06T09:53:56Z","title":"BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables","summary":"  We consider the problem of unfair discrimination between two groups and\npropose a pre-processing method to achieve fairness. Corrective methods like\nstatistical parity usually lead to bad accuracy and do not really achieve\nfairness in situations where there is a correlation between the sensitive\nattribute S and the legitimate attribute E (explanatory variable) that should\ndetermine the decision. To overcome these drawbacks, other notions of fairness\nhave been proposed, in particular, conditional statistical parity and equal\nopportunity. However, E is often not directly observable in the data, i.e., it\nis a latent variable. We may observe some other variable Z representing E, but\nthe problem is that Z may also be affected by S, hence Z itself can be biased.\nTo deal with this problem, we propose BaBE (Bayesian Bias Elimination), an\napproach based on a combination of Bayes inference and the\nExpectation-Maximization method, to estimate the most likely value of E for a\ngiven Z for each group. The decision can then be based directly on the\nestimated E. We show, by experiments on synthetic and real data sets, that our\napproach provides a good level of fairness as well as high accuracy.\n","authors":["Ruta Binkyte","Daniele Gorla","Catuscia Palamidessi"],"pdf_url":"https://arxiv.org/pdf/2307.02891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02882v1","updated":"2023-07-06T09:36:54Z","published":"2023-07-06T09:36:54Z","title":"Contrast Is All You Need","summary":"  In this study, we analyze data-scarce classification scenarios, where\navailable labeled legal data is small and imbalanced, potentially hurting the\nquality of the results. We focused on two finetuning objectives; SetFit\n(Sentence Transformer Finetuning), a contrastive learning setup, and a vanilla\nfinetuning setup on a legal provision classification task. Additionally, we\ncompare the features that are extracted with LIME (Local Interpretable\nModel-agnostic Explanations) to see which particular features contributed to\nthe model's classification decisions. The results show that a contrastive setup\nwith SetFit performed better than vanilla finetuning while using a fraction of\nthe training samples. LIME results show that the contrastive learning approach\nhelps boost both positive and negative features which are legally informative\nand contribute to the classification results. Thus a model finetuned with a\ncontrastive objective seems to base its decisions more confidently on legally\ninformative features.\n","authors":["Burak Kilic","Florix Bex","Albert Gatt"],"pdf_url":"https://arxiv.org/pdf/2307.02882v1.pdf","comment":"10 pages + bib, 12 figures, ACAIL2023/ASAIL2023 Workshop"},{"id":"http://arxiv.org/abs/2209.05251v2","updated":"2023-07-06T09:16:57Z","published":"2022-09-07T16:40:45Z","title":"Spotting Virus from Satellites: Modeling the Circulation of West Nile\n  Virus Through Graph Neural Networks","summary":"  The occurrence of West Nile Virus (WNV) represents one of the most common\nmosquito-borne zoonosis viral infections. Its circulation is usually associated\nwith climatic and environmental conditions suitable for vector proliferation\nand virus replication. On top of that, several statistical models have been\ndeveloped to shape and forecast WNV circulation: in particular, the recent\nmassive availability of Earth Observation (EO) data, coupled with the\ncontinuous advances in the field of Artificial Intelligence, offer valuable\nopportunities.\n  In this paper, we seek to predict WNV circulation by feeding Deep Neural\nNetworks (DNNs) with satellite images, which have been extensively shown to\nhold environmental and climatic features. Notably, while previous approaches\nanalyze each geographical site independently, we propose a spatial-aware\napproach that considers also the characteristics of close sites. Specifically,\nwe build upon Graph Neural Networks (GNN) to aggregate features from\nneighbouring places, and further extend these modules to consider multiple\nrelations, such as the difference in temperature and soil moisture between two\nsites, as well as the geographical distance. Moreover, we inject time-related\ninformation directly into the model to take into account the seasonality of\nvirus spread.\n  We design an experimental setting that combines satellite images - from\nLandsat and Sentinel missions - with ground truth observations of WNV\ncirculation in Italy. We show that our proposed Multi-Adjacency Graph Attention\nNetwork (MAGAT) consistently leads to higher performance when paired with an\nappropriate pre-training stage. Finally, we assess the importance of each\ncomponent of MAGAT in our ablation studies.\n","authors":["Lorenzo Bonicelli","Angelo Porrello","Stefano Vincenzi","Carla Ippoliti","Federica Iapaolo","Annamaria Conte","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2209.05251v2.pdf","comment":"12 pages, 5 figures. Accepted at the IEEE Transactions On Geoscience\n  And Remote Sensing"},{"id":"http://arxiv.org/abs/2307.02867v1","updated":"2023-07-06T09:08:20Z","published":"2023-07-06T09:08:20Z","title":"Towards a safe MLOps Process for the Continuous Development and Safety\n  Assurance of ML-based Systems in the Railway Domain","summary":"  Traditional automation technologies alone are not sufficient to enable\ndriverless operation of trains (called Grade of Automation (GoA) 4) on\nnon-restricted infrastructure. The required perception tasks are nowadays\nrealized using Machine Learning (ML) and thus need to be developed and deployed\nreliably and efficiently. One important aspect to achieve this is to use an\nMLOps process for tackling improved reproducibility, traceability,\ncollaboration, and continuous adaptation of a driverless operation to changing\nconditions. MLOps mixes ML application development and operation (Ops) and\nenables high frequency software releases and continuous innovation based on the\nfeedback from operations. In this paper, we outline a safe MLOps process for\nthe continuous development and safety assurance of ML-based systems in the\nrailway domain. It integrates system engineering, safety assurance, and the ML\nlife-cycle in a comprehensive workflow. We present the individual stages of the\nprocess and their interactions. Moreover, we describe relevant challenges to\nautomate the different stages of the safe MLOps process.\n","authors":["Marc Zeller","Thomas Waschulzik","Reiner Schmid","Claus Bahlmann"],"pdf_url":"https://arxiv.org/pdf/2307.02867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01301v2","updated":"2023-07-06T09:05:45Z","published":"2023-07-03T19:10:45Z","title":"Reliable AI: Does the Next Generation Require Quantum Computing?","summary":"  In this survey, we aim to explore the fundamental question of whether the\nnext generation of artificial intelligence requires quantum computing.\nArtificial intelligence is increasingly playing a crucial role in many aspects\nof our daily lives and is central to the fourth industrial revolution. It is\ntherefore imperative that artificial intelligence is reliable and trustworthy.\nHowever, there are still many issues with reliability of artificial\nintelligence, such as privacy, responsibility, safety, and security, in areas\nsuch as autonomous driving, healthcare, robotics, and others. These problems\ncan have various causes, including insufficient data, biases, and robustness\nproblems, as well as fundamental issues such as computability problems on\ndigital hardware. The cause of these computability problems is rooted in the\nfact that digital hardware is based on the computing model of the Turing\nmachine, which is inherently discrete. Notably, our findings demonstrate that\ndigital hardware is inherently constrained in solving problems about\noptimization, deep learning, or differential equations. Therefore, these\nlimitations carry substantial implications for the field of artificial\nintelligence, in particular for machine learning. Furthermore, although it is\nwell known that the quantum computer shows a quantum advantage for certain\nclasses of problems, our findings establish that some of these limitations\npersist when employing quantum computing models based on the quantum circuit or\nthe quantum Turing machine paradigm. In contrast, analog computing models, such\nas the Blum-Shub-Smale machine, exhibit the potential to surmount these\nlimitations.\n","authors":["Aras Bacho","Holger Boche","Gitta Kutyniok"],"pdf_url":"https://arxiv.org/pdf/2307.01301v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02839v1","updated":"2023-07-06T08:13:53Z","published":"2023-07-06T08:13:53Z","title":"Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation","summary":"  News summary generation is an important task in the field of intelligence\nanalysis, which can provide accurate and comprehensive information to help\npeople better understand and respond to complex real-world events. However,\ntraditional news summary generation methods face some challenges, which are\nlimited by the model itself and the amount of training data, as well as the\ninfluence of text noise, making it difficult to generate reliable information\naccurately. In this paper, we propose a new paradigm for news summary\ngeneration using LLM with powerful natural language understanding and\ngenerative capabilities. We use LLM to extract multiple structured event\npatterns from the events contained in news paragraphs, evolve the event pattern\npopulation with genetic algorithm, and select the most adaptive event pattern\nto input into the LLM to generate news summaries. A News Summary Generator\n(NSG) is designed to select and evolve the event pattern populations and\ngenerate news summaries. The experimental results show that the news summary\ngenerator is able to generate accurate and reliable news summaries with some\ngeneralization ability.\n","authors":["Le Xiao","Xiaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2307.02839v1.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2307.02820v1","updated":"2023-07-06T07:27:59Z","published":"2023-07-06T07:27:59Z","title":"Evaluating raw waveforms with deep learning frameworks for speech\n  emotion recognition","summary":"  Speech emotion recognition is a challenging task in speech processing field.\nFor this reason, feature extraction process has a crucial importance to\ndemonstrate and process the speech signals. In this work, we represent a model,\nwhich feeds raw audio files directly into the deep neural networks without any\nfeature extraction stage for the recognition of emotions utilizing six\ndifferent data sets, EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS. To\ndemonstrate the contribution of proposed model, the performance of traditional\nfeature extraction techniques namely, mel-scale spectogram, mel-frequency\ncepstral coefficients, are blended with machine learning algorithms, ensemble\nlearning methods, deep and hybrid deep learning techniques. Support vector\nmachine, decision tree, naive Bayes, random forests models are evaluated as\nmachine learning algorithms while majority voting and stacking methods are\nassessed as ensemble learning techniques. Moreover, convolutional neural\nnetworks, long short-term memory networks, and hybrid CNN- LSTM model are\nevaluated as deep learning techniques and compared with machine learning and\nensemble learning methods. To demonstrate the effectiveness of proposed model,\nthe comparison with state-of-the-art studies are carried out. Based on the\nexperiment results, CNN model excels existent approaches with 95.86% of\naccuracy for TESS+RAVDESS data set using raw audio files, thence determining\nthe new state-of-the-art. The proposed model performs 90.34% of accuracy for\nEMO-DB with CNN model, 90.42% of accuracy for RAVDESS with CNN model, 99.48% of\naccuracy for TESS with LSTM model, 69.72% of accuracy for CREMA with CNN model,\n85.76% of accuracy for SAVEE with CNN model in speaker-independent audio\ncategorization problems.\n","authors":["Zeynep Hilal Kilimci","Ulku Bayraktar","Ayhan Kucukmanisa"],"pdf_url":"https://arxiv.org/pdf/2307.02820v1.pdf","comment":"14 pages, 6 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2212.09811v2","updated":"2023-07-06T07:01:50Z","published":"2022-12-19T19:29:40Z","title":"Memory-efficient NLLB-200: Language-specific Expert Pruning of a\n  Massively Multilingual Machine Translation Model","summary":"  Compared to conventional bilingual translation systems, massively\nmultilingual machine translation is appealing because a single model can\ntranslate into multiple languages and benefit from knowledge transfer for low\nresource languages. On the other hand, massively multilingual models suffer\nfrom the curse of multilinguality, unless scaling their size massively, which\nincreases their training and inference costs. Sparse Mixture-of-Experts models\nare a way to drastically increase model capacity without the need for a\nproportional amount of computing. The recently released NLLB-200 is an example\nof such a model. It covers 202 languages but requires at least four 32GB GPUs\njust for inference. In this work, we propose a pruning method that allows the\nremoval of up to 80\\% of experts with a negligible loss in translation quality,\nwhich makes it feasible to run the model on a single 32GB GPU. Further analysis\nsuggests that our pruning metrics allow to identify language-specific experts\nand prune non-relevant experts for a given language pair.\n","authors":["Yeskendir Koishekenov","Vassilina Nikoulina","Alexandre Berard"],"pdf_url":"https://arxiv.org/pdf/2212.09811v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13166v3","updated":"2023-07-06T06:25:33Z","published":"2023-01-30T18:37:32Z","title":"ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object\n  Navigation","summary":"  The ability to accurately locate and navigate to a specific object is a\ncrucial capability for embodied agents that operate in the real world and\ninteract with objects to complete tasks. Such object navigation tasks usually\nrequire large-scale training in visual environments with labeled objects, which\ngeneralizes poorly to novel objects in unknown environments. In this work, we\npresent a novel zero-shot object navigation method, Exploration with Soft\nCommonsense constraints (ESC), that transfers commonsense knowledge in\npre-trained models to open-world object navigation without any navigation\nexperience nor any other training on the visual environments. First, ESC\nleverages a pre-trained vision and language model for open-world prompt-based\ngrounding and a pre-trained commonsense language model for room and object\nreasoning. Then ESC converts commonsense knowledge into navigation actions by\nmodeling it as soft logic predicates for efficient exploration. Extensive\nexperiments on MP3D, HM3D, and RoboTHOR benchmarks show that our ESC method\nimproves significantly over baselines, and achieves new state-of-the-art\nresults for zero-shot object navigation (e.g., 288% relative Success Rate\nimprovement than CoW on MP3D).\n","authors":["Kaiwen Zhou","Kaizhi Zheng","Connor Pryor","Yilin Shen","Hongxia Jin","Lise Getoor","Xin Eric Wang"],"pdf_url":"https://arxiv.org/pdf/2301.13166v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00443v4","updated":"2023-07-06T06:18:01Z","published":"2022-12-01T11:25:36Z","title":"Unbiased Heterogeneous Scene Graph Generation with Relation-aware\n  Message Passing Neural Network","summary":"  Recent scene graph generation (SGG) frameworks have focused on learning\ncomplex relationships among multiple objects in an image. Thanks to the nature\nof the message passing neural network (MPNN) that models high-order\ninteractions between objects and their neighboring objects, they are dominant\nrepresentation learning modules for SGG. However, existing MPNN-based\nframeworks assume the scene graph as a homogeneous graph, which restricts the\ncontext-awareness of visual relations between objects. That is, they overlook\nthe fact that the relations tend to be highly dependent on the objects with\nwhich the relations are associated. In this paper, we propose an unbiased\nheterogeneous scene graph generation (HetSGG) framework that captures\nrelation-aware context using message passing neural networks. We devise a novel\nmessage passing layer, called relation-aware message passing neural network\n(RMP), that aggregates the contextual information of an image considering the\npredicate type between objects. Our extensive evaluations demonstrate that\nHetSGG outperforms state-of-the-art methods, especially outperforming on tail\npredicate classes.\n","authors":["Kanghoon Yoon","Kibum Kim","Jinyoung Moon","Chanyoung Park"],"pdf_url":"https://arxiv.org/pdf/2212.00443v4.pdf","comment":"9 pages; AAAI 2023"},{"id":"http://arxiv.org/abs/2307.02798v1","updated":"2023-07-06T06:13:22Z","published":"2023-07-06T06:13:22Z","title":"Semi-supervised Domain Adaptive Medical Image Segmentation through\n  Consistency Regularized Disentangled Contrastive Learning","summary":"  Although unsupervised domain adaptation (UDA) is a promising direction to\nalleviate domain shift, they fall short of their supervised counterparts. In\nthis work, we investigate relatively less explored semi-supervised domain\nadaptation (SSDA) for medical image segmentation, where access to a few labeled\ntarget samples can improve the adaptation performance substantially.\nSpecifically, we propose a two-stage training process. First, an encoder is\npre-trained in a self-learning paradigm using a novel domain-content\ndisentangled contrastive learning (CL) along with a pixel-level feature\nconsistency constraint. The proposed CL enforces the encoder to learn\ndiscriminative content-specific but domain-invariant semantics on a global\nscale from the source and target images, whereas consistency regularization\nenforces the mining of local pixel-level information by maintaining spatial\nsensitivity. This pre-trained encoder, along with a decoder, is further\nfine-tuned for the downstream task, (i.e. pixel-level segmentation) using a\nsemi-supervised setting. Furthermore, we experimentally validate that our\nproposed method can easily be extended for UDA settings, adding to the\nsuperiority of the proposed strategy. Upon evaluation on two domain adaptive\nimage segmentation tasks, our proposed method outperforms the SoTA methods,\nboth in SSDA and UDA settings. Code is available at\nhttps://github.com/hritam-98/GFDA-disentangled\n","authors":["Hritam Basak","Zhaozheng Yin"],"pdf_url":"https://arxiv.org/pdf/2307.02798v1.pdf","comment":"Paper accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2307.02797v1","updated":"2023-07-06T06:12:37Z","published":"2023-07-06T06:12:37Z","title":"BHEISR: Nudging from Bias to Balance -- Promoting Belief Harmony by\n  Eliminating Ideological Segregation in Knowledge-based Recommendations","summary":"  In the realm of personalized recommendation systems, the increasing concern\nis the amplification of belief imbalance and user biases, a phenomenon\nprimarily attributed to the filter bubble. Addressing this critical issue, we\nintroduce an innovative intermediate agency (BHEISR) between users and existing\nrecommendation systems to attenuate the negative repercussions of the filter\nbubble effect in extant recommendation systems. The main objective is to strike\na belief balance for users while minimizing the detrimental influence caused by\nfilter bubbles. The BHEISR model amalgamates principles from nudge theory while\nupholding democratic and transparent principles. It harnesses user-specific\ncategory information to stimulate curiosity, even in areas users might\ninitially deem uninteresting. By progressively stimulating interest in novel\ncategories, the model encourages users to broaden their belief horizons and\nexplore the information they typically overlook. Our model is time-sensitive\nand operates on a user feedback loop. It utilizes the existing recommendation\nalgorithm of the model and incorporates user feedback from the prior time\nframe. This approach endeavors to transcend the constraints of the filter\nbubble, enrich recommendation diversity, and strike a belief balance among\nusers while also catering to user preferences and system-specific business\nrequirements. To validate the effectiveness and reliability of the BHEISR\nmodel, we conducted a series of comprehensive experiments with real-world\ndatasets. These experiments compared the performance of the BHEISR model\nagainst several baseline models using nearly 200 filter bubble-impacted users\nas test subjects. Our experimental results conclusively illustrate the superior\nperformance of the BHEISR model in mitigating filter bubbles and balancing user\nperspectives.\n","authors":["Mengyan Wang","Yuxuan Hu","Zihan Yuan","Chenting Jiang","Weihua Li","Shiqing Wu","Quan Bai"],"pdf_url":"https://arxiv.org/pdf/2307.02797v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2307.02792v1","updated":"2023-07-06T06:07:29Z","published":"2023-07-06T06:07:29Z","title":"What Should Data Science Education Do with Large Language Models?","summary":"  The rapid advances of large language models (LLMs), such as ChatGPT, are\nrevolutionizing data science and statistics. These state-of-the-art tools can\nstreamline complex processes. As a result, it reshapes the role of data\nscientists. We argue that LLMs are transforming the responsibilities of data\nscientists, shifting their focus from hands-on coding, data-wrangling and\nconducting standard analyses to assessing and managing analyses performed by\nthese automated AIs. This evolution of roles is reminiscent of the transition\nfrom a software engineer to a product manager. We illustrate this transition\nwith concrete data science case studies using LLMs in this paper. These\ndevelopments necessitate a meaningful evolution in data science education.\nPedagogy must now place greater emphasis on cultivating diverse skillsets among\nstudents, such as LLM-informed creativity, critical thinking, AI-guided\nprogramming. LLMs can also play a significant role in the classroom as\ninteractive teaching and learning tools, contributing to personalized\neducation. This paper discusses the opportunities, resources and open\nchallenges for each of these directions. As with any transformative technology,\nintegrating LLMs into education calls for careful consideration. While LLMs can\nperform repetitive tasks efficiently, it's crucial to remember that their role\nis to supplement human intelligence and creativity, not to replace it.\nTherefore, the new era of data science education should balance the benefits of\nLLMs while fostering complementary human expertise and innovations. In\nconclusion, the rise of LLMs heralds a transformative period for data science\nand its education. This paper seeks to shed light on the emerging trends,\npotential opportunities, and challenges accompanying this paradigm shift,\nhoping to spark further discourse and investigation into this exciting,\nuncharted territory.\n","authors":["Xinming Tu","James Zou","Weijie J. Su","Linjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.02792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02791v1","updated":"2023-07-06T06:06:47Z","published":"2023-07-06T06:06:47Z","title":"The Role of Subgroup Separability in Group-Fair Medical Image\n  Classification","summary":"  We investigate performance disparities in deep classifiers. We find that the\nability of classifiers to separate individuals into subgroups varies\nsubstantially across medical imaging modalities and protected characteristics;\ncrucially, we show that this property is predictive of algorithmic bias.\nThrough theoretical analysis and extensive empirical evaluation, we find a\nrelationship between subgroup separability, subgroup disparities, and\nperformance degradation when models are trained on data with systematic bias\nsuch as underdiagnosis. Our findings shed new light on the question of how\nmodels become biased, providing important insights for the development of fair\nmedical imaging AI.\n","authors":["Charles Jones","Mélanie Roschewitz","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2307.02791v1.pdf","comment":"Accepted at MICCAI 2023. Code available under\n  https://github.com/biomedia-mira/subgroup-separability"},{"id":"http://arxiv.org/abs/2201.07856v2","updated":"2023-07-06T06:01:08Z","published":"2022-01-19T20:51:38Z","title":"Potential sources of dataset bias complicate investigation of\n  underdiagnosis by machine learning algorithms","summary":"  An increasing number of reports raise concerns about the risk that machine\nlearning algorithms could amplify health disparities due to biases embedded in\nthe training data. Seyyed-Kalantari et al. find that models trained on three\nchest X-ray datasets yield disparities in false-positive rates (FPR) across\nsubgroups on the 'no-finding' label (indicating the absence of disease). The\nmodels consistently yield higher FPR on subgroups known to be historically\nunderserved, and the study concludes that the models exhibit and potentially\neven amplify systematic underdiagnosis. We argue that the experimental setup in\nthe study is insufficient to study algorithmic underdiagnosis. In the absence\nof specific knowledge (or assumptions) about the extent and nature of the\ndataset bias, it is difficult to investigate model bias. Importantly, their use\nof test data exhibiting the same bias as the training data (due to random\nsplitting) severely complicates the interpretation of the reported disparities.\n","authors":["Mélanie Bernhardt","Charles Jones","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2201.07856v2.pdf","comment":"Published as Matters Arising in Nature Medicine"},{"id":"http://arxiv.org/abs/2112.13557v2","updated":"2023-07-06T05:16:20Z","published":"2021-12-27T07:53:21Z","title":"AGM Belief Revision, Semantically","summary":"  We establish a generic, model-theoretic characterization of belief revision\noperators implementing the paradigm of minimal change according to the seminal\nwork by Alchourr\\'{o}n, G\\\"{a}rdenfors, and Makinson (AGM). Our\ncharacterization applies to all Tarskian logics, that is, all logics with a\nclassical model-theoretic semantics, and hence a wide variety of formalisms\nused in knowledge representation and beyond, including many for which a\nmodel-theoretic characterization has hitherto been lacking. Our starting point\nis the approach by Katsuno and Mendelzon (K&M), who provided such a\ncharacterization for propositional logic over finite signatures. We generalize\nK&M's approach to the setting of AGM-style revision over bases in arbitrary\nTarskian logics, where base may refer to one of the various ways of\nrepresenting an agent's beliefs (such as belief sets, arbitrary or finite sets\nof sentences, or single sentences). Our first core result is a representation\ntheorem providing a two-way correspondence between AGM-style revision operators\nand specific assignments: functions associating every base to a \"preference\"\nrelation over interpretations, which must be total but is - in contrast to\nprior approaches - not always transitive. As our second core contribution, we\nprovide a characterization of all logics for which our result can be\nstrengthened to assignments producing transitive preference relations (as in\nK&M's original work). Alongside these main contributions, we discuss diverse\nvariants of our findings as well as ramifications for other areas of belief\nrevision theory.\n","authors":["Faiq Miftakhul Falakh","Sebastian Rudolph","Kai Sauerwald"],"pdf_url":"https://arxiv.org/pdf/2112.13557v2.pdf","comment":"71 pages"},{"id":"http://arxiv.org/abs/2306.14096v2","updated":"2023-07-06T05:14:39Z","published":"2023-06-25T02:24:30Z","title":"Chinese Fine-Grained Financial Sentiment Analysis with Large Language\n  Models","summary":"  Entity-level fine-grained sentiment analysis in the financial domain is a\ncrucial subtask of sentiment analysis and currently faces numerous challenges.\nThe primary challenge stems from the lack of high-quality and large-scale\nannotated corpora specifically designed for financial text sentiment analysis,\nwhich in turn limits the availability of data necessary for developing\neffective text processing techniques. Recent advancements in large language\nmodels (LLMs) have yielded remarkable performance in natural language\nprocessing tasks, primarily centered around language pattern matching. In this\npaper, we propose a novel and extensive Chinese fine-grained financial\nsentiment analysis dataset, FinChina SA, for enterprise early warning. We\nthoroughly evaluate and experiment with well-known existing open-source LLMs\nusing our dataset. We firmly believe that our dataset will serve as a valuable\nresource to advance the exploration of real-world financial sentiment analysis\ntasks, which should be the focus of future research. Our dataset and all code\nto replicate the experimental results will be released.\n","authors":["Yinyu Lan","Yanru Wu","Wang Xu","Weiqiang Feng","Youhao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.14096v2.pdf","comment":"FinLLM Symposium at IJCAI 2023"},{"id":"http://arxiv.org/abs/2307.02770v1","updated":"2023-07-06T04:45:14Z","published":"2023-07-06T04:45:14Z","title":"Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback","summary":"  Diffusion models have recently shown remarkable success in high-quality image\ngeneration. Sometimes, however, a pre-trained diffusion model exhibits partial\nmisalignment in the sense that the model can generate good images, but it\nsometimes outputs undesirable images. If so, we simply need to prevent the\ngeneration of the bad images, and we call this task censoring. In this work, we\npresent censored generation with a pre-trained diffusion model using a reward\nmodel trained on minimal human feedback. We show that censoring can be\naccomplished with extreme human feedback efficiency and that labels generated\nwith a mere few minutes of human feedback are sufficient. Code available at:\nhttps://github.com/tetrzim/diffusion-human-feedback.\n","authors":["TaeHo Yoon","Kibeom Myoung","Keon Lee","Jaewoong Cho","Albert No","Ernest K. Ryu"],"pdf_url":"https://arxiv.org/pdf/2307.02770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02762v1","updated":"2023-07-06T04:05:44Z","published":"2023-07-06T04:05:44Z","title":"PRD: Peer Rank and Discussion Improve Large Language Model based\n  Evaluations","summary":"  Nowadays, the quality of responses generated by different modern large\nlanguage models (LLMs) are hard to evaluate and compare automatically. Recent\nstudies suggest and predominantly use LLMs as a reference-free metric for\nopen-ended question answering. More specifically, they use the recognized\n\"strongest\" LLM as the evaluator, which conducts pairwise comparisons of\ncandidate models' answers and provides a ranking score. However, this intuitive\nmethod has multiple problems, such as bringing in self-enhancement (favoring\nits own answers) and positional bias. We draw insights and lessons from the\neducational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based\nevaluations. Specifically, we propose the (1) peer rank (PR) algorithm that\ntakes into account each peer LLM's pairwise preferences of all answer pairs,\nand outputs a final ranking of models; and (2) peer discussion (PD), where we\nprompt two LLMs to discuss and try to reach a mutual agreement on preferences\nof two answers. We conduct experiments on two benchmark datasets. We find that\nour approaches achieve higher accuracy and align better with human judgments,\nrespectively. Interestingly, PR can induce a relatively accurate self-ranking\nof models under the anonymous setting, where each model's name is unrevealed.\nOur work provides space to explore evaluating models that are hard to compare\nfor humans.\n","authors":["Ruosen Li","Teerth Patel","Xinya Du"],"pdf_url":"https://arxiv.org/pdf/2307.02762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02216v2","updated":"2023-07-06T03:53:17Z","published":"2023-03-03T21:15:22Z","title":"Denoise Pretraining on Nonequilibrium Molecules for Accurate and\n  Transferable Neural Potentials","summary":"  Recent advances in equivariant graph neural networks (GNNs) have made deep\nlearning amenable to developing fast surrogate models to expensive ab initio\nquantum mechanics (QM) approaches for molecular potential predictions. However,\nbuilding accurate and transferable potential models using GNNs remains\nchallenging, as the data is greatly limited by the expensive computational\ncosts and level of theory of QM methods, especially for large and complex\nmolecular systems. In this work, we propose denoise pretraining on\nnonequilibrium molecular conformations to achieve more accurate and\ntransferable GNN potential predictions. Specifically, atomic coordinates of\nsampled nonequilibrium conformations are perturbed by random noises and GNNs\nare pretrained to denoise the perturbed molecular conformations which recovers\nthe original coordinates. Rigorous experiments on multiple benchmarks reveal\nthat pretraining significantly improves the accuracy of neural potentials.\nFurthermore, we show that the proposed pretraining approach is model-agnostic,\nas it improves the performance of different invariant and equivariant GNNs.\nNotably, our models pretrained on small molecules demonstrate remarkable\ntransferability, improving performance when fine-tuned on diverse molecular\nsystems, including different elements, charged molecules, biomolecules, and\nlarger systems. These results highlight the potential for leveraging denoise\npretraining approaches to build more generalizable neural potentials for\ncomplex molecular systems.\n","authors":["Yuyang Wang","Changwen Xu","Zijie Li","Amir Barati Farimani"],"pdf_url":"https://arxiv.org/pdf/2303.02216v2.pdf","comment":"Published in Journal of Chemical Theory and Computation. 32 pages, 5\n  figures, 2 tables"},{"id":"http://arxiv.org/abs/2307.02759v1","updated":"2023-07-06T03:44:40Z","published":"2023-07-06T03:44:40Z","title":"Knowledge Graph Self-Supervised Rationalization for Recommendation","summary":"  In this paper, we introduce a new self-supervised rationalization method,\ncalled KGRec, for knowledge-aware recommender systems. To effectively identify\ninformative knowledge connections, we propose an attentive knowledge\nrationalization mechanism that generates rational scores for knowledge\ntriplets. With these scores, KGRec integrates generative and contrastive\nself-supervised tasks for recommendation through rational masking. To highlight\nrationales in the knowledge graph, we design a novel generative task in the\nform of masking-reconstructing. By masking important knowledge with high\nrational scores, KGRec is trained to rebuild and highlight useful knowledge\nconnections that serve as rationales. To further rationalize the effect of\ncollaborative interactions on knowledge graph learning, we introduce a\ncontrastive learning task that aligns signals from knowledge and user-item\ninteraction views. To ensure noise-resistant contrasting, potential noisy edges\nin both graphs judged by the rational scores are masked. Extensive experiments\non three real-world datasets demonstrate that KGRec outperforms\nstate-of-the-art methods. We also provide the implementation codes for our\napproach at https://github.com/HKUDS/KGRec.\n","authors":["Yuhao Yang","Chao Huang","Lianghao Xia","Chunzhen Huang"],"pdf_url":"https://arxiv.org/pdf/2307.02759v1.pdf","comment":"Accepted by KDD'23"},{"id":"http://arxiv.org/abs/2307.02752v1","updated":"2023-07-06T03:22:19Z","published":"2023-07-06T03:22:19Z","title":"Offline Reinforcement Learning with Imbalanced Datasets","summary":"  The prevalent use of benchmarks in current offline reinforcement learning\n(RL) research has led to a neglect of the imbalance of real-world dataset\ndistributions in the development of models. The real-world offline RL dataset\nis often imbalanced over the state space due to the challenge of exploration or\nsafety considerations. In this paper, we specify properties of imbalanced\ndatasets in offline RL, where the state coverage follows a power law\ndistribution characterized by skewed policies. Theoretically and empirically,\nwe show that typically offline RL methods based on distributional constraints,\nsuch as conservative Q-learning (CQL), are ineffective in extracting policies\nunder the imbalanced dataset. Inspired by natural intelligence, we propose a\nnovel offline RL method that utilizes the augmentation of CQL with a retrieval\nprocess to recall past related experiences, effectively alleviating the\nchallenges posed by imbalanced datasets. We evaluate our method on several\ntasks in the context of imbalanced datasets with varying levels of imbalance,\nutilizing the variant of D4RL. Empirical results demonstrate the superiority of\nour method over other baselines.\n","authors":["Li Jiang","Sijie Chen","Jielin Qiu","Haoran Xu","Wai Kin Chan","Zhao Ding"],"pdf_url":"https://arxiv.org/pdf/2307.02752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02738v1","updated":"2023-07-06T02:51:54Z","published":"2023-07-06T02:51:54Z","title":"RecallM: An Architecture for Temporal Context Understanding and Question\n  Answering","summary":"  The ideal long-term memory mechanism for Large Language Model (LLM) based\nchatbots, would lay the foundation for continual learning, complex reasoning\nand allow sequential and temporal dependencies to be learnt. Creating this type\nof memory mechanism is an extremely challenging problem. In this paper we\nexplore different methods of achieving the effect of long-term memory. We\npropose a new architecture focused on creating adaptable and updatable\nlong-term memory for AGI systems. We demonstrate through various experiments\nthe benefits of the RecallM architecture, particularly the improved temporal\nunderstanding it provides.\n","authors":["Brandon Kynoch","Hugo Latapie"],"pdf_url":"https://arxiv.org/pdf/2307.02738v1.pdf","comment":"10 pages, 4 figures Our code is publicly available online at:\n  https://github.com/cisco-open/DeepVision/tree/main/recallm"},{"id":"http://arxiv.org/abs/2303.03789v2","updated":"2023-07-06T02:49:12Z","published":"2023-03-07T10:52:59Z","title":"Fast and Multi-aspect Mining of Complex Time-stamped Event Streams","summary":"  Given a huge, online stream of time-evolving events with multiple attributes,\nsuch as online shopping logs: (item, price, brand, time), and local mobility\nactivities: (pick-up and drop-off locations, time), how can we summarize large,\ndynamic high-order tensor streams? How can we see any hidden patterns, rules,\nand anomalies? Our answer is to focus on two types of patterns, i.e.,\n''regimes'' and ''components'', for which we present CubeScope, an efficient\nand effective method over high-order tensor streams. Specifically, it\nidentifies any sudden discontinuity and recognizes distinct dynamical patterns,\n''regimes'' (e.g., weekday/weekend/holiday patterns). In each regime, it also\nperforms multi-way summarization for all attributes (e.g., item, price, brand,\nand time) and discovers hidden ''components'' representing latent groups (e.g.,\nitem/brand groups) and their relationship. Thanks to its concise but effective\nsummarization, CubeScope can also detect the sudden appearance of anomalies and\nidentify the types of anomalies that occur in practice. Our proposed method has\nthe following properties: (a) Effective: it captures dynamical multi-aspect\npatterns, i.e., regimes and components, and statistically summarizes all the\nevents; (b) General: it is practical for successful application to data\ncompression, pattern discovery, and anomaly detection on various types of\ntensor streams; (c) Scalable: our algorithm does not depend on the length of\nthe data stream and its dimensionality. Extensive experiments on real datasets\ndemonstrate that CubeScope finds meaningful patterns and anomalies correctly,\nand consistently outperforms the state-of-the-art methods as regards accuracy\nand execution speed.\n","authors":["Kota Nakamura","Yasuko Matsubara","Koki Kawabata","Yuhei Umeda","Yuichiro Wada","Yasushi Sakurai"],"pdf_url":"https://arxiv.org/pdf/2303.03789v2.pdf","comment":"Accepted by WWW 2023"},{"id":"http://arxiv.org/abs/2307.02730v1","updated":"2023-07-06T02:30:56Z","published":"2023-07-06T02:30:56Z","title":"Fine-grained Action Analysis: A Multi-modality and Multi-task Dataset of\n  Figure Skating","summary":"  The fine-grained action analysis of the existing action datasets is\nchallenged by insufficient action categories, low fine granularities, limited\nmodalities, and tasks. In this paper, we propose a Multi-modality and\nMulti-task dataset of Figure Skating (MMFS) which was collected from the World\nFigure Skating Championships. MMFS, which possesses action recognition and\naction quality assessment, captures RGB, skeleton, and is collected the score\nof actions from 11671 clips with 256 categories including spatial and temporal\nlabels. The key contributions of our dataset fall into three aspects as\nfollows. (1) Independently spatial and temporal categories are first proposed\nto further explore fine-grained action recognition and quality assessment. (2)\nMMFS first introduces the skeleton modality for complex fine-grained action\nquality assessment. (3) Our multi-modality and multi-task dataset encourage\nmore action analysis models. To benchmark our dataset, we adopt RGB-based and\nskeleton-based baseline methods for action recognition and action quality\nassessment.\n","authors":["Sheng-Lan Liu","Yu-Ning Ding","Si-Fan Zhang","Wen-Yue Chen","Ning Zhou","Hao Liu","Gui-Hong Lao"],"pdf_url":"https://arxiv.org/pdf/2307.02730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02728v1","updated":"2023-07-06T02:27:05Z","published":"2023-07-06T02:27:05Z","title":"Hierarchical Empowerment: Towards Tractable Empowerment-Based\n  Skill-Learning","summary":"  General purpose agents will require large repertoires of skills. Empowerment\n-- the maximum mutual information between skills and the states -- provides a\npathway for learning large collections of distinct skills, but mutual\ninformation is difficult to optimize. We introduce a new framework,\nHierarchical Empowerment, that makes computing empowerment more tractable by\nintegrating concepts from Goal-Conditioned Hierarchical Reinforcement Learning.\nOur framework makes two specific contributions. First, we introduce a new\nvariational lower bound on mutual information that can be used to compute\nempowerment over short horizons. Second, we introduce a hierarchical\narchitecture for computing empowerment over exponentially longer time scales.\nWe verify the contributions of the framework in a series of simulated robotics\ntasks. In a popular ant navigation domain, our four level agents are able to\nlearn skills that cover a surface area over two orders of magnitude larger than\nprior work.\n","authors":["Andrew Levy","Sreehari Rammohan","Alessandro Allievi","Scott Niekum","George Konidaris"],"pdf_url":"https://arxiv.org/pdf/2307.02728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02472v2","updated":"2023-07-06T02:16:33Z","published":"2023-07-05T17:45:48Z","title":"Deductive Additivity for Planning of Natural Language Proofs","summary":"  Current natural language systems designed for multi-step claim validation\ntypically operate in two phases: retrieve a set of relevant premise statements\nusing heuristics (planning), then generate novel conclusions from those\nstatements using a large language model (deduction). The planning step often\nrequires expensive Transformer operations and does not scale to arbitrary\nnumbers of premise statements. In this paper, we investigate whether an\nefficient planning heuristic is possible via embedding spaces compatible with\ndeductive reasoning. Specifically, we evaluate whether embedding spaces exhibit\na property we call deductive additivity: the sum of premise statement\nembeddings should be close to embeddings of conclusions based on those\npremises. We explore multiple sources of off-the-shelf dense embeddings in\naddition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25. We\nstudy embedding models both intrinsically, evaluating whether the property of\ndeductive additivity holds, and extrinsically, using them to assist planning in\nnatural language proof generation. Lastly, we create a dataset, Single-Step\nReasoning Contrast (SSRC), to further probe performance on various reasoning\ntypes. Our findings suggest that while standard embedding methods frequently\nembed conclusions near the sums of their premises, they fall short of being\neffective heuristics and lack the ability to model certain categories of\nreasoning.\n","authors":["Zayne Sprague","Kaj Bostrom","Swarat Chaudhuri","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2307.02472v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02717v1","updated":"2023-07-06T01:46:06Z","published":"2023-07-06T01:46:06Z","title":"TL-nvSRAM-CIM: Ultra-High-Density Three-Level ReRAM-Assisted\n  Computing-in-nvSRAM with DC-Power Free Restore and Ternary MAC Operations","summary":"  Accommodating all the weights on-chip for large-scale NNs remains a great\nchallenge for SRAM based computing-in-memory (SRAM-CIM) with limited on-chip\ncapacity. Previous non-volatile SRAM-CIM (nvSRAM-CIM) addresses this issue by\nintegrating high-density single-level ReRAMs on the top of high-efficiency\nSRAM-CIM for weight storage to eliminate the off-chip memory access. However,\nprevious SL-nvSRAM-CIM suffers from poor scalability for an increased number of\nSL-ReRAMs and limited computing efficiency. To overcome these challenges, this\nwork proposes an ultra-high-density three-level ReRAMs-assisted\ncomputing-in-nonvolatile-SRAM (TL-nvSRAM-CIM) scheme for large NN models. The\nclustered n-selector-n-ReRAM (cluster-nSnRs) is employed for reliable\nweight-restore with eliminated DC power. Furthermore, a ternary SRAM-CIM\nmechanism with differential computing scheme is proposed for energy-efficient\nternary MAC operations while preserving high NN accuracy. The proposed\nTL-nvSRAM-CIM achieves 7.8x higher storage density, compared with the\nstate-of-art works. Moreover, TL-nvSRAM-CIM shows up to 2.9x and 1.9x enhanced\nenergy-efficiency, respectively, compared to the baseline designs of SRAM-CIM\nand ReRAM-CIM, respectively.\n","authors":["Dengfeng Wang","Liukai Xu","Songyuan Liu","zhi Li","Yiming Chen","Weifeng He","Xueqing Li","Yanan Su"],"pdf_url":"https://arxiv.org/pdf/2307.02717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00968v2","updated":"2023-07-06T01:36:59Z","published":"2023-07-03T12:39:26Z","title":"REAL: A Representative Error-Driven Approach for Active Learning","summary":"  Given a limited labeling budget, active learning (AL) aims to sample the most\ninformative instances from an unlabeled pool to acquire labels for subsequent\nmodel training. To achieve this, AL typically measures the informativeness of\nunlabeled instances based on uncertainty and diversity. However, it does not\nconsider erroneous instances with their neighborhood error density, which have\ngreat potential to improve the model performance. To address this limitation,\nwe propose $REAL$, a novel approach to select data instances with\n$\\underline{R}$epresentative $\\underline{E}$rrors for $\\underline{A}$ctive\n$\\underline{L}$earning. It identifies minority predictions as \\emph{pseudo\nerrors} within a cluster and allocates an adaptive sampling budget for the\ncluster based on estimated error density. Extensive experiments on five text\nclassification datasets demonstrate that $REAL$ consistently outperforms all\nbest-performing baselines regarding accuracy and F1-macro scores across a wide\nrange of hyperparameter settings. Our analysis also shows that $REAL$ selects\nthe most representative pseudo errors that match the distribution of\nground-truth errors along the decision boundary. Our code is publicly available\nat https://github.com/withchencheng/ECML_PKDD_23_Real.\n","authors":["Cheng Chen","Yong Wang","Lizi Liao","Yueguo Chen","Xiaoyong Du"],"pdf_url":"https://arxiv.org/pdf/2307.00968v2.pdf","comment":"Accepted by ECML/PKDD 2023"},{"id":"http://arxiv.org/abs/2307.02709v1","updated":"2023-07-06T01:17:29Z","published":"2023-07-06T01:17:29Z","title":"Validation of the Practicability of Logical Assessment Formula for\n  Evaluations with Inaccurate Ground-Truth Labels","summary":"  Logical assessment formula (LAF) is a new theory proposed for evaluations\nwith inaccurate ground-truth labels (IAGTLs) to assess the predictive models\nfor various artificial intelligence applications. However, the practicability\nof LAF for evaluations with IAGTLs has not yet been validated in real-world\npractice. In this paper, to address this issue, we applied LAF to tumour\nsegmentation for breast cancer (TSfBC) in medical histopathology whole slide\nimage analysis (MHWSIA). Experimental results and analysis show the validity of\nLAF for evaluations with IAGTLs in the case of TSfBC and reflect the potentials\nof LAF applied to MHWSIA.\n","authors":["Yongquan Yang","Hong Bu"],"pdf_url":"https://arxiv.org/pdf/2307.02709v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2110.11567"},{"id":"http://arxiv.org/abs/2307.03315v1","updated":"2023-07-06T22:02:33Z","published":"2023-07-06T22:02:33Z","title":"Assisting Clinical Decisions for Scarcely Available Treatment via\n  Disentangled Latent Representation","summary":"  Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting\nmodality for COVID-19 patients who are refractory to conventional therapies.\nHowever, the proper treatment decision has been the subject of significant\ndebate and it remains controversial about who benefits from this scarcely\navailable and technically complex treatment option. To support clinical\ndecisions, it is a critical need to predict the treatment need and the\npotential treatment and no-treatment responses. Targeting this clinical\nchallenge, we propose Treatment Variational AutoEncoder (TVAE), a novel\napproach for individualized treatment analysis. TVAE is specifically designed\nto address the modeling challenges like ECMO with strong treatment selection\nbias and scarce treatment cases. TVAE conceptualizes the treatment decision as\na multi-scale problem. We model a patient's potential treatment assignment and\nthe factual and counterfactual outcomes as part of their intrinsic\ncharacteristics that can be represented by a deep latent variable model. The\nfactual and counterfactual prediction errors are alleviated via a\nreconstruction regularization scheme together with semi-supervision, and the\nselection bias and the scarcity of treatment cases are mitigated by the\ndisentangled and distribution-matched latent space and the label-balancing\ngenerative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an\ninternational dataset collected from 1651 hospitals across 63 countries, and a\ninstitutional dataset collected from 15 hospitals. The results show that TVAE\noutperforms state-of-the-art treatment effect models in predicting both the\npropensity scores and factual outcomes on heterogeneous COVID-19 datasets.\nAdditional experiments also show TVAE outperforms the best existing models in\nindividual treatment effect estimation on the synthesized IHDP benchmark\ndataset.\n","authors":["Bing Xue","Ahmed Sameh Said","Ziqi Xu","Hanyang Liu","Neel Shah","Hanqing Yang","Philip Payne","Chenyang Lu"],"pdf_url":"https://arxiv.org/pdf/2307.03315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03311v1","updated":"2023-07-06T21:49:04Z","published":"2023-07-06T21:49:04Z","title":"On Invariance, Equivariance, Correlation and Convolution of Spherical\n  Harmonic Representations for Scalar and Vectorial Data","summary":"  The mathematical representations of data in the Spherical Harmonic (SH)\ndomain has recently regained increasing interest in the machine learning\ncommunity. This technical report gives an in-depth introduction to the\ntheoretical foundation and practical implementation of SH representations,\nsummarizing works on rotation invariant and equivariant features, as well as\nconvolutions and exact correlations of signals on spheres. In extension, these\nmethods are then generalized from scalar SH representations to Vectorial\nHarmonics (VH), providing the same capabilities for 3d vector fields on spheres\n","authors":["Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2307.03311v1.pdf","comment":"106 pages, tech report"},{"id":"http://arxiv.org/abs/2307.03305v1","updated":"2023-07-06T21:38:13Z","published":"2023-07-06T21:38:13Z","title":"A Vulnerability of Attribution Methods Using Pre-Softmax Scores","summary":"  We discuss a vulnerability involving a category of attribution methods used\nto provide explanations for the outputs of convolutional neural networks\nworking as classifiers. It is known that this type of networks are vulnerable\nto adversarial attacks, in which imperceptible perturbations of the input may\nalter the outputs of the model. In contrast, here we focus on effects that\nsmall modifications in the model may cause on the attribution method without\naltering the model outputs.\n","authors":["Miguel Lerma","Mirtha Lucas"],"pdf_url":"https://arxiv.org/pdf/2307.03305v1.pdf","comment":"7 pages, 5 figures,"},{"id":"http://arxiv.org/abs/2307.03274v1","updated":"2023-07-06T20:23:17Z","published":"2023-07-06T20:23:17Z","title":"It is not Sexually Suggestive, It is Educative. Separating Sex Education\n  from Suggestive Content on TikTok Videos","summary":"  We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled\nas sexually suggestive (from the annotator's point of view), sex-educational\ncontent, or neither. Such a dataset is necessary to address the challenge of\ndistinguishing between sexually suggestive content and virtual sex education\nvideos on TikTok. Children's exposure to sexually suggestive videos has been\nshown to have adversarial effects on their development. Meanwhile, virtual sex\neducation, especially on subjects that are more relevant to the LGBTQIA+\ncommunity, is very valuable. The platform's current system removes or penalizes\nsome of both types of videos, even though they serve different purposes. Our\ndataset contains video URLs, and it is also audio transcribed. To validate its\nimportance, we explore two transformer-based models for classifying the videos.\nOur preliminary results suggest that the task of distinguishing between these\ntypes of videos is learnable but challenging. These experiments suggest that\nthis dataset is meaningful and invites further study on the subject.\n","authors":["Enfa George","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2307.03274v1.pdf","comment":"Accepted to ACL Findings 2023. 10 pages, 3 figures, 5 tables . Please\n  refer to https://github.com/enfageorge/SexTok for dataset and related details"},{"id":"http://arxiv.org/abs/2307.03254v1","updated":"2023-07-06T19:08:56Z","published":"2023-07-06T19:08:56Z","title":"Vision Language Transformers: A Survey","summary":"  Vision language tasks, such as answering questions about or generating\ncaptions that describe an image, are difficult tasks for computers to perform.\nA relatively recent body of research has adapted the pretrained transformer\narchitecture introduced in \\citet{vaswani2017attention} to vision language\nmodeling. Transformer models have greatly improved performance and versatility\nover previous vision language models. They do so by pretraining models on a\nlarge generic datasets and transferring their learning to new tasks with minor\nchanges in architecture and parameter values. This type of transfer learning\nhas become the standard modeling practice in both natural language processing\nand computer vision. Vision language transformers offer the promise of\nproducing similar advancements in tasks which require both vision and language.\nIn this paper, we provide a broad synthesis of the currently available research\non vision language transformer models and offer some analysis of their\nstrengths, limitations and some open questions that remain.\n","authors":["Clayton Fields","Casey Kennington"],"pdf_url":"https://arxiv.org/pdf/2307.03254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04719v4","updated":"2023-07-06T19:03:47Z","published":"2023-06-07T18:31:39Z","title":"Don't trust your eyes: on the (un)reliability of feature visualizations","summary":"  How do neural networks extract patterns from pixels? Feature visualizations\nattempt to answer this important question by visualizing highly activating\npatterns through optimization. Today, visualization methods form the foundation\nof our knowledge about the internal workings of neural networks, as a type of\nmechanistic interpretability. Here we ask: How reliable are feature\nvisualizations? We start our investigation by developing network circuits that\ntrick feature visualizations into showing arbitrary patterns that are\ncompletely disconnected from normal network behavior on natural input. We then\nprovide evidence for a similar phenomenon occurring in standard, unmanipulated\nnetworks: feature visualizations are processed very differently from standard\ninput, casting doubt on their ability to \"explain\" how neural networks process\nnatural images. We underpin this empirical finding by theory proving that the\nset of functions that can be reliably understood by feature visualization is\nextremely small and does not include general black-box neural networks.\nTherefore, a promising way forward could be the development of networks that\nenforce certain structures in order to ensure more reliable feature\nvisualizations.\n","authors":["Robert Geirhos","Roland S. Zimmermann","Blair Bilodeau","Wieland Brendel","Been Kim"],"pdf_url":"https://arxiv.org/pdf/2306.04719v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05953v2","updated":"2023-07-06T19:03:41Z","published":"2022-11-11T02:00:32Z","title":"Breadth-First Pipeline Parallelism","summary":"  We introduce Breadth-First Pipeline Parallelism, a novel training schedule\nwhich optimizes the combination of pipeline and data parallelism. Breadth-First\nPipeline Parallelism lowers training time, cost and memory usage by combining a\nhigh GPU utilization with a small batch size per GPU, and by making use of\nfully sharded data parallelism. Experimentally, we observed an increase of up\nto 43% in training throughput for a 52 billion-parameter model using a small\nbatch size per GPU compared to Megatron-LM, which would reduce the training\ntime and cost by the same amount on a large GPU cluster.\n","authors":["Joel Lamy-Poirier"],"pdf_url":"https://arxiv.org/pdf/2211.05953v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03718v1","updated":"2023-07-06T17:03:25Z","published":"2023-07-06T17:03:25Z","title":"Frontier AI Regulation: Managing Emerging Risks to Public Safety","summary":"  Advanced AI models hold the promise of tremendous benefits for humanity, but\nsociety needs to proactively manage the accompanying risks. In this paper, we\nfocus on what we term \"frontier AI\" models: highly capable foundation models\nthat could possess dangerous capabilities sufficient to pose severe risks to\npublic safety. Frontier AI models pose a distinct regulatory challenge:\ndangerous capabilities can arise unexpectedly; it is difficult to robustly\nprevent a deployed model from being misused; and, it is difficult to stop a\nmodel's capabilities from proliferating broadly. To address these challenges,\nat least three building blocks for the regulation of frontier models are\nneeded: (1) standard-setting processes to identify appropriate requirements for\nfrontier AI developers, (2) registration and reporting requirements to provide\nregulators with visibility into frontier AI development processes, and (3)\nmechanisms to ensure compliance with safety standards for the development and\ndeployment of frontier AI models. Industry self-regulation is an important\nfirst step. However, wider societal discussions and government intervention\nwill be needed to create standards and to ensure compliance with them. We\nconsider several options to this end, including granting enforcement powers to\nsupervisory authorities and licensure regimes for frontier AI models. Finally,\nwe propose an initial set of safety standards. These include conducting\npre-deployment risk assessments; external scrutiny of model behavior; using\nrisk assessments to inform deployment decisions; and monitoring and responding\nto new information about model capabilities and uses post-deployment. We hope\nthis discussion contributes to the broader conversation on how to balance\npublic safety risks and innovation benefits from advances at the frontier of AI\ndevelopment.\n","authors":["Markus Anderljung","Joslyn Barnhart","Jade Leung","Anton Korinek","Cullen O'Keefe","Jess Whittlestone","Shahar Avin","Miles Brundage","Justin Bullock","Duncan Cass-Beggs","Ben Chang","Tantum Collins","Tim Fist","Gillian Hadfield","Alan Hayes","Lewis Ho","Sara Hooker","Eric Horvitz","Noam Kolt","Jonas Schuett","Yonadav Shavit","Divya Siddarth","Robert Trager","Kevin Wolf"],"pdf_url":"https://arxiv.org/pdf/2307.03718v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03212v1","updated":"2023-07-06T16:38:43Z","published":"2023-07-06T16:38:43Z","title":"Region-Wise Attentive Multi-View Representation Learning for Urban\n  Region Embeddings","summary":"  Urban region embedding is an important and yet highly challenging issue due\nto the complexity and constantly changing nature of urban data. To address the\nchallenges, we propose a Region-Wise Multi-View Representation Learning (ROMER)\nto capture multi-view dependencies and learn expressive representations of\nurban regions without the constraints of rigid neighbourhood region conditions.\nOur model focus on learn urban region representation from multi-source urban\ndata. First, we capture the multi-view correlations from mobility flow\npatterns, POI semantics and check-in dynamics. Then, we adopt global graph\nattention networks to learn similarity of any two vertices in graphs. To\ncomprehensively consider and share features of multiple views, a two-stage\nfusion module is further proposed to learn weights with external attention to\nfuse multi-view embeddings. Extensive experiments for two downstream tasks on\nreal-world datasets demonstrate that our model outperforms state-of-the-art\nmethods by up to 17\\% improvement.\n","authors":["Weiliang Chan","Qianqian Ren"],"pdf_url":"https://arxiv.org/pdf/2307.03212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03591v1","updated":"2023-07-06T16:04:56Z","published":"2023-07-06T16:04:56Z","title":"Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph\n  Reasoning","summary":"  Multimodal knowledge graphs (MKGs), which intuitively organize information in\nvarious modalities, can benefit multiple practical downstream tasks, such as\nrecommendation systems, and visual question answering. However, most MKGs are\nstill far from complete, which motivates the flourishing of MKG reasoning\nmodels. Recently, with the development of general artificial architectures, the\npretrained transformer models have drawn increasing attention, especially for\nmultimodal scenarios. However, the research of multimodal pretrained\ntransformer (MPT) for knowledge graph reasoning (KGR) is still at an early\nstage. As the biggest difference between MKG and other multimodal data, the\nrich structural information underlying the MKG still cannot be fully leveraged\nin existing MPT models. Most of them only utilize the graph structure as a\nretrieval map for matching images and texts connected with the same entity.\nThis manner hinders their reasoning performances. To this end, we propose the\ngraph Structure Guided Multimodal Pretrained Transformer for knowledge graph\nreasoning, termed SGMPT. Specifically, the graph structure encoder is adopted\nfor structural feature encoding. Then, a structure-guided fusion module with\ntwo different strategies, i.e., weighted summation and alignment constraint, is\nfirst designed to inject the structural information into both the textual and\nvisual features. To the best of our knowledge, SGMPT is the first MPT model for\nmultimodal KGR, which mines the structural information underlying the knowledge\ngraph. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that\nour SGMPT outperforms existing state-of-the-art models, and prove the\neffectiveness of the designed strategies.\n","authors":["Ke Liang","Sihang Zhou","Yue Liu","Lingyuan Meng","Meng Liu","Xinwang Liu"],"pdf_url":"https://arxiv.org/pdf/2307.03591v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessed"},{"id":"http://arxiv.org/abs/2307.03070v1","updated":"2023-07-06T15:35:55Z","published":"2023-07-06T15:35:55Z","title":"Hybrid Knowledge-Data Driven Channel Semantic Acquisition and\n  Beamforming for Cell-Free Massive MIMO","summary":"  This paper focuses on advancing outdoor wireless systems to better support\nubiquitous extended reality (XR) applications, and close the gap with current\nindoor wireless transmission capabilities. We propose a hybrid knowledge-data\ndriven method for channel semantic acquisition and multi-user beamforming in\ncell-free massive multiple-input multiple-output (MIMO) systems. Specifically,\nwe firstly propose a data-driven multiple layer perceptron (MLP)-Mixer-based\nauto-encoder for channel semantic acquisition, where the pilot signals, CSI\nquantizer for channel semantic embedding, and CSI reconstruction for channel\nsemantic extraction are jointly optimized in an end-to-end manner. Moreover,\nbased on the acquired channel semantic, we further propose a knowledge-driven\ndeep-unfolding multi-user beamformer, which is capable of achieving good\nspectral efficiency with robustness to imperfect CSI in outdoor XR scenarios.\nBy unfolding conventional successive over-relaxation (SOR)-based linear\nbeamforming scheme with deep learning, the proposed beamforming scheme is\ncapable of adaptively learning the optimal parameters to accelerate convergence\nand improve the robustness to imperfect CSI. The proposed deep unfolding\nbeamforming scheme can be used for access points (APs) with fully-digital array\nand APs with hybrid analog-digital array structure. Simulation results\ndemonstrate the effectiveness of our proposed scheme in improving the accuracy\nof channel acquisition, as well as reducing complexity in both CSI acquisition\nand beamformer design. The proposed beamforming method achieves approximately\n96% of the converged spectrum efficiency performance after only three\niterations in downlink transmission, demonstrating its efficacy and potential\nto improve outdoor XR applications.\n","authors":["Zhen Gao","Shicong Liu","Yu Su","Zhongxiang Li","Dezhi Zheng"],"pdf_url":"https://arxiv.org/pdf/2307.03070v1.pdf","comment":"15 pages, 15 figures"}]},"2023-07-07T00:00:00Z":{"Sound":[{"id":"http://arxiv.org/abs/2306.17103v2","updated":"2023-07-07T16:32:26Z","published":"2023-06-29T17:01:51Z","title":"LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by\n  Whispering to ChatGPT","summary":"  We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic\nlyrics transcription method achieving state-of-the-art performance on various\nlyrics transcription datasets, even in challenging genres such as rock and\nmetal. Our novel, training-free approach utilizes Whisper, a weakly supervised\nrobust speech recognition model, and GPT-4, today's most performant chat-based\nlarge language model. In the proposed method, Whisper functions as the \"ear\" by\ntranscribing the audio, while GPT-4 serves as the \"brain,\" acting as an\nannotator with a strong performance for contextualized output selection and\ncorrection. Our experiments show that LyricWhiz significantly reduces Word\nError Rate compared to existing methods in English and can effectively\ntranscribe lyrics across multiple languages. Furthermore, we use LyricWhiz to\ncreate the first publicly available, large-scale, multilingual lyrics\ntranscription dataset with a CC-BY-NC-SA copyright license, based on\nMTG-Jamendo, and offer a human-annotated subset for noise level estimation and\nevaluation. We anticipate that our proposed method and dataset will advance the\ndevelopment of multilingual lyrics transcription, a challenging and emerging\ntask.\n","authors":["Le Zhuo","Ruibin Yuan","Jiahao Pan","Yinghao Ma","Yizhi LI","Ge Zhang","Si Liu","Roger Dannenberg","Jie Fu","Chenghua Lin","Emmanouil Benetos","Wenhu Chen","Wei Xue","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2306.17103v2.pdf","comment":"9 pages, 2 figures, 5 tables, accepted by ISMIR 2023"},{"id":"http://arxiv.org/abs/2111.08503v2","updated":"2023-07-07T14:31:08Z","published":"2021-11-14T16:11:26Z","title":"Binary classification of spoken words with passive phononic\n  metamaterials","summary":"  Mitigating the energy requirements of artificial intelligence requires novel\nphysical substrates for computation. Phononic metamaterials have a vanishingly\nlow power dissipation and hence are a prime candidate for green, always-on\ncomputers. However, their use in machine learning applications has not been\nexplored due to the complexity of their design process: Current phononic\nmetamaterials are restricted to simple geometries (e.g. periodic, tapered), and\nhence do not possess sufficient expressivity to encode machine learning tasks.\nWe design and fabricate a non-periodic phononic metamaterial, directly from\ndata samples, that can distinguish between pairs of spoken words in the\npresence of a simple readout nonlinearity; hence demonstrating that phononic\nmetamaterials are a viable avenue towards zero-power smart devices.\n","authors":["Tena Dubček","Daniel Moreno-Garcia","Thomas Haag","Parisa Omidvar","Henrik R. Thomsen","Theodor S. Becker","Lars Gebraad","Christoph Bärlocher","Fredrik Andersson","Sebastian D. Huber","Dirk-Jan van Manen","Luis Guillermo Villanueva","Johan O. A. Robertsson","Marc Serra-Garcia"],"pdf_url":"https://arxiv.org/pdf/2111.08503v2.pdf","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2307.03544v1","updated":"2023-07-07T12:20:56Z","published":"2023-07-07T12:20:56Z","title":"Roman Numeral Analysis with Graph Neural Networks: Onset-wise\n  Predictions from Note-wise Features","summary":"  Roman Numeral analysis is the important task of identifying chords and their\nfunctional context in pieces of tonal music. This paper presents a new approach\nto automatic Roman Numeral analysis in symbolic music. While existing\ntechniques rely on an intermediate lossy representation of the score, we\npropose a new method based on Graph Neural Networks (GNNs) that enable the\ndirect description and processing of each individual note in the score. The\nproposed architecture can leverage notewise features and interdependencies\nbetween notes but yield onset-wise representation by virtue of our novel edge\ncontraction algorithm. Our results demonstrate that ChordGNN outperforms\nexisting state-of-the-art models, achieving higher accuracy in Roman Numeral\nanalysis on the reference datasets. In addition, we investigate variants of our\nmodel using proposed techniques such as NADE, and post-processing of the chord\npredictions. The full source code for this work is available at\nhttps://github.com/manoskary/chordgnn\n","authors":["Emmanouil Karystinaios","Gerhard Widmer"],"pdf_url":"https://arxiv.org/pdf/2307.03544v1.pdf","comment":"submitted for ISMIR 2023 conference, 6 pages of content, 5 figures"},{"id":"http://arxiv.org/abs/2307.03533v1","updated":"2023-07-07T11:41:33Z","published":"2023-07-07T11:41:33Z","title":"The CHiME-7 UDASE task: Unsupervised domain adaptation for\n  conversational speech enhancement","summary":"  Supervised speech enhancement models are trained using artificially generated\nmixtures of clean speech and noise signals, which may not match real-world\nrecording conditions at test time. This mismatch can lead to poor performance\nif the test domain significantly differs from the synthetic training domain. In\nthis paper, we introduce the unsupervised domain adaptation for conversational\nspeech enhancement (UDASE) task of the 7th CHiME challenge. This task aims to\nleverage real-world noisy speech recordings from the target test domain for\nunsupervised domain adaptation of speech enhancement models. The target test\ndomain corresponds to the multi-speaker reverberant conversational speech\nrecordings of the CHiME-5 dataset, for which the ground-truth clean speech\nreference is not available. Given a CHiME-5 recording, the task is to estimate\nthe clean, potentially multi-speaker, reverberant speech, removing the additive\nbackground noise. We discuss the motivation for the CHiME-7 UDASE task and\ndescribe the data, the task, and the baseline system.\n","authors":["Simon Leglaive","Léonie Borne","Efthymios Tzinis","Mostafa Sadeghi","Matthieu Fraticelli","Scott Wisdom","Manuel Pariente","Daniel Pressnitzer","John R. Hershey"],"pdf_url":"https://arxiv.org/pdf/2307.03533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01571v2","updated":"2023-07-07T10:55:17Z","published":"2022-11-03T03:36:51Z","title":"Phonetic-assisted Multi-Target Units Modeling for Improving\n  Conformer-Transducer ASR system","summary":"  Exploiting effective target modeling units is very important and has always\nbeen a concern in end-to-end automatic speech recognition (ASR). In this work,\nwe propose a phonetic-assisted multi target units (PMU) modeling approach, to\nenhance the Conformer-Transducer ASR system in a progressive representation\nlearning manner. Specifically, PMU first uses the pronunciation-assisted\nsubword modeling (PASM) and byte pair encoding (BPE) to produce\nphonetic-induced and text-induced target units separately; Then, three new\nframeworks are investigated to enhance the acoustic encoder, including a basic\nPMU, a paraCTC and a pcaCTC, they integrate the PASM and BPE units at different\nlevels for CTC and transducer multi-task training. Experiments on both\nLibriSpeech and accented ASR tasks show that, the proposed PMU significantly\noutperforms the conventional BPE, it reduces the WER of LibriSpeech clean,\nother, and six accented ASR testsets by relative 12.7%, 6.0% and 7.7%,\nrespectively.\n","authors":["Li Li","Dongxing Xu","Haoran Wei","Yanhua Long"],"pdf_url":"https://arxiv.org/pdf/2211.01571v2.pdf","comment":"Accepted by Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.01304v2","updated":"2023-07-07T09:57:54Z","published":"2023-06-02T07:04:33Z","title":"JEPOO: Highly Accurate Joint Estimation of Pitch, Onset and Offset for\n  Music Information Retrieval","summary":"  Melody extraction is a core task in music information retrieval, and the\nestimation of pitch, onset and offset are key sub-tasks in melody extraction.\nExisting methods have limited accuracy, and work for only one type of data,\neither single-pitch or multipitch. In this paper, we propose a highly accurate\nmethod for joint estimation of pitch, onset and offset, named JEPOO. We address\nthe challenges of joint learning optimization and handling both single-pitch\nand multi-pitch data through novel model design and a new optimization\ntechnique named Pareto modulated loss with loss weight regularization. This is\nthe first method that can accurately handle both single-pitch and multi-pitch\nmusic data, and even a mix of them. A comprehensive experimental study on a\nwide range of real datasets shows that JEPOO outperforms state-ofthe-art\nmethods by up to 10.6%, 8.3% and 10.3% for the prediction of Pitch, Onset and\nOffset, respectively, and JEPOO is robust for various types of data and\ninstruments. The ablation study shows the effectiveness of each component of\nJEPOO.\n","authors":["Haojie Wei","Jun Yuan","Rui Zhang","Yueguo Chen","Gang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.01304v2.pdf","comment":"This paper has been accepted by IJCAI 2023; 11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2307.02892v2","updated":"2023-07-07T09:31:28Z","published":"2023-07-06T09:54:35Z","title":"The Relationship Between Speech Features Changes When You Get Depressed:\n  Feature Correlations for Improving Speed and Performance of Depression\n  Detection","summary":"  This work shows that depression changes the correlation between features\nextracted from speech. Furthermore, it shows that using such an insight can\nimprove the training speed and performance of depression detectors based on\nSVMs and LSTMs. The experiments were performed over the Androids Corpus, a\npublicly available dataset involving 112 speakers, including 58 people\ndiagnosed with depression by professional psychiatrists. The results show that\nthe models used in the experiments improve in terms of training speed and\nperformance when fed with feature correlation matrices rather than with feature\nvectors. The relative reduction of the error rate ranges between 23.1% and\n26.6% depending on the model. The probable explanation is that feature\ncorrelation matrices appear to be more variable in the case of depressed\nspeakers. Correspondingly, such a phenomenon can be thought of as a depression\nmarker.\n","authors":["Fuxiang Tao","Wei Ma","Xuri Ge","Anna Esposito","Alessandro Vinciarelli"],"pdf_url":"https://arxiv.org/pdf/2307.02892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09359v3","updated":"2023-07-07T04:56:14Z","published":"2022-12-19T10:49:35Z","title":"WACO: Word-Aligned Contrastive Learning for Speech Translation","summary":"  End-to-end Speech Translation (E2E ST) aims to directly translate source\nspeech into target text. Existing ST methods perform poorly when only extremely\nsmall speech-text data are available for training. We observe that an ST\nmodel's performance closely correlates with its embedding similarity between\nspeech and source transcript. In this paper, we propose Word-Aligned\nCOntrastive learning (WACO), a simple and effective method for extremely\nlow-resource speech-to-text translation. Our key idea is bridging word-level\nrepresentations for both speech and text modalities via contrastive learning.\nWe evaluate WACO and other methods on the MuST-C dataset, a widely used ST\nbenchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our\nexperiments demonstrate that WACO outperforms the best baseline by 9+ BLEU\npoints with only 1-hour parallel ST data. Code is available at\nhttps://github.com/owaski/WACO.\n","authors":["Siqi Ouyang","Rong Ye","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2212.09359v3.pdf","comment":"ACL 2023 Poster"},{"id":"http://arxiv.org/abs/2307.03354v1","updated":"2023-07-07T02:26:18Z","published":"2023-07-07T02:26:18Z","title":"Token-Level Serialized Output Training for Joint Streaming ASR and ST\n  Leveraging Textual Alignments","summary":"  In real-world applications, users often require both translations and\ntranscriptions of speech to enhance their comprehension, particularly in\nstreaming scenarios where incremental generation is necessary. This paper\nintroduces a streaming Transformer-Transducer that jointly generates automatic\nspeech recognition (ASR) and speech translation (ST) outputs using a single\ndecoder. To produce ASR and ST content effectively with minimal latency, we\npropose a joint token-level serialized output training method that interleaves\nsource and target words by leveraging an off-the-shelf textual aligner.\nExperiments in monolingual (it-en) and multilingual (\\{de,es,it\\}-en) settings\ndemonstrate that our approach achieves the best quality-latency balance. With\nan average ASR latency of 1s and ST latency of 1.3s, our model shows no\ndegradation or even improves output quality compared to separate ASR and ST\nmodels, yielding an average improvement of 1.1 WER and 0.4 BLEU in the\nmultilingual case.\n","authors":["Sara Papi","Peidong Wan","Junkun Chen","Jian Xue","Jinyu Li","Yashesh Gaur"],"pdf_url":"https://arxiv.org/pdf/2307.03354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04547v2","updated":"2023-07-07T19:40:13Z","published":"2022-09-09T22:48:35Z","title":"Defend Data Poisoning Attacks on Voice Authentication","summary":"  With the advances in deep learning, speaker verification has achieved very\nhigh accuracy and is gaining popularity as a type of biometric authentication\noption in many scenes of our daily life, especially the growing market of web\nservices. Compared to traditional passwords, \"vocal passwords\" are much more\nconvenient as they relieve people from memorizing different passwords. However,\nnew machine learning attacks are putting these voice authentication systems at\nrisk. Without a strong security guarantee, attackers could access legitimate\nusers' web accounts by fooling the deep neural network (DNN) based voice\nrecognition models. In this paper, we demonstrate an easy-to-implement data\npoisoning attack to the voice authentication system, which can hardly be\ncaptured by existing defense mechanisms. Thus, we propose a more robust defense\nmethod, called Guardian, which is a convolutional neural network-based\ndiscriminator. The Guardian discriminator integrates a series of novel\ntechniques including bias reduction, input augmentation, and ensemble learning.\nOur approach is able to distinguish about 95% of attacked accounts from normal\naccounts, which is much more effective than existing approaches with only 60%\naccuracy.\n","authors":["Ke Li","Cameron Baird","Dan Lin"],"pdf_url":"https://arxiv.org/pdf/2209.04547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04827v1","updated":"2023-07-07T16:25:59Z","published":"2023-07-07T16:25:59Z","title":"LaunchpadGPT: Language Model as Music Visualization Designer on\n  Launchpad","summary":"  Launchpad is a musical instrument that allows users to create and perform\nmusic by pressing illuminated buttons. To assist and inspire the design of the\nLaunchpad light effect, and provide a more accessible approach for beginners to\ncreate music visualization with this instrument, we proposed the LaunchpadGPT\nmodel to generate music visualization designs on Launchpad automatically. Based\non the language model with excellent generation ability, our proposed\nLaunchpadGPT takes an audio piece of music as input and outputs the lighting\neffects of Launchpad-playing in the form of a video (Launchpad-playing video).\nWe collect Launchpad-playing videos and process them to obtain music and\ncorresponding video frame of Launchpad-playing as prompt-completion pairs, to\ntrain the language model. The experiment result shows the proposed method can\ncreate better music visualization than random generation methods and hold the\npotential for a broader range of music visualization applications. Our code is\navailable at https://github.com/yunlong10/LaunchpadGPT/.\n","authors":["Siting Xu","Yunlong Tang","Feng Zheng"],"pdf_url":"https://arxiv.org/pdf/2307.04827v1.pdf","comment":"Accepted by International Computer Music Conference (ICMC) 2023"},{"id":"http://arxiv.org/abs/2307.05527v1","updated":"2023-07-07T22:00:32Z","published":"2023-07-07T22:00:32Z","title":"The Ethical Implications of Generative Audio Models: A Systematic\n  Literature Review","summary":"  Generative audio models typically focus their applications in music and\nspeech generation, with recent models having human-like quality in their audio\noutput. This paper conducts a systematic literature review of 884 papers in the\narea of generative audio models in order to both quantify the degree to which\nresearchers in the field are considering potential negative impacts and\nidentify the types of ethical implications researchers in this area need to\nconsider. Though 65% of generative audio research papers note positive\npotential impacts of their work, less than 10% discuss any negative impacts.\nThis jarringly small percentage of papers considering negative impact is\nparticularly worrying because the issues brought to light by the few papers\ndoing so are raising serious ethical implications and concerns relevant to the\nbroader field such as the potential for fraud, deep-fakes, and copyright\ninfringement. By quantifying this lack of ethical consideration in generative\naudio research and identifying key areas of potential harm, this paper lays the\ngroundwork for future work in the field at a critical point in time in order to\nguide more conscientious research as this field progresses.\n","authors":["Julia Barnett"],"pdf_url":"https://arxiv.org/pdf/2307.05527v1.pdf","comment":"In proceedings of the AAAI/ACM Conference on AI, Ethics, and Society\n  (AIES '23). 10 pages, 1 figure"}],"Audio and Speech Processing":[{"id":"http://arxiv.org/abs/2306.17103v2","updated":"2023-07-07T16:32:26Z","published":"2023-06-29T17:01:51Z","title":"LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by\n  Whispering to ChatGPT","summary":"  We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic\nlyrics transcription method achieving state-of-the-art performance on various\nlyrics transcription datasets, even in challenging genres such as rock and\nmetal. Our novel, training-free approach utilizes Whisper, a weakly supervised\nrobust speech recognition model, and GPT-4, today's most performant chat-based\nlarge language model. In the proposed method, Whisper functions as the \"ear\" by\ntranscribing the audio, while GPT-4 serves as the \"brain,\" acting as an\nannotator with a strong performance for contextualized output selection and\ncorrection. Our experiments show that LyricWhiz significantly reduces Word\nError Rate compared to existing methods in English and can effectively\ntranscribe lyrics across multiple languages. Furthermore, we use LyricWhiz to\ncreate the first publicly available, large-scale, multilingual lyrics\ntranscription dataset with a CC-BY-NC-SA copyright license, based on\nMTG-Jamendo, and offer a human-annotated subset for noise level estimation and\nevaluation. We anticipate that our proposed method and dataset will advance the\ndevelopment of multilingual lyrics transcription, a challenging and emerging\ntask.\n","authors":["Le Zhuo","Ruibin Yuan","Jiahao Pan","Yinghao Ma","Yizhi LI","Ge Zhang","Si Liu","Roger Dannenberg","Jie Fu","Chenghua Lin","Emmanouil Benetos","Wenhu Chen","Wei Xue","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2306.17103v2.pdf","comment":"9 pages, 2 figures, 5 tables, accepted by ISMIR 2023"},{"id":"http://arxiv.org/abs/2111.08503v2","updated":"2023-07-07T14:31:08Z","published":"2021-11-14T16:11:26Z","title":"Binary classification of spoken words with passive phononic\n  metamaterials","summary":"  Mitigating the energy requirements of artificial intelligence requires novel\nphysical substrates for computation. Phononic metamaterials have a vanishingly\nlow power dissipation and hence are a prime candidate for green, always-on\ncomputers. However, their use in machine learning applications has not been\nexplored due to the complexity of their design process: Current phononic\nmetamaterials are restricted to simple geometries (e.g. periodic, tapered), and\nhence do not possess sufficient expressivity to encode machine learning tasks.\nWe design and fabricate a non-periodic phononic metamaterial, directly from\ndata samples, that can distinguish between pairs of spoken words in the\npresence of a simple readout nonlinearity; hence demonstrating that phononic\nmetamaterials are a viable avenue towards zero-power smart devices.\n","authors":["Tena Dubček","Daniel Moreno-Garcia","Thomas Haag","Parisa Omidvar","Henrik R. Thomsen","Theodor S. Becker","Lars Gebraad","Christoph Bärlocher","Fredrik Andersson","Sebastian D. Huber","Dirk-Jan van Manen","Luis Guillermo Villanueva","Johan O. A. Robertsson","Marc Serra-Garcia"],"pdf_url":"https://arxiv.org/pdf/2111.08503v2.pdf","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2307.03533v1","updated":"2023-07-07T11:41:33Z","published":"2023-07-07T11:41:33Z","title":"The CHiME-7 UDASE task: Unsupervised domain adaptation for\n  conversational speech enhancement","summary":"  Supervised speech enhancement models are trained using artificially generated\nmixtures of clean speech and noise signals, which may not match real-world\nrecording conditions at test time. This mismatch can lead to poor performance\nif the test domain significantly differs from the synthetic training domain. In\nthis paper, we introduce the unsupervised domain adaptation for conversational\nspeech enhancement (UDASE) task of the 7th CHiME challenge. This task aims to\nleverage real-world noisy speech recordings from the target test domain for\nunsupervised domain adaptation of speech enhancement models. The target test\ndomain corresponds to the multi-speaker reverberant conversational speech\nrecordings of the CHiME-5 dataset, for which the ground-truth clean speech\nreference is not available. Given a CHiME-5 recording, the task is to estimate\nthe clean, potentially multi-speaker, reverberant speech, removing the additive\nbackground noise. We discuss the motivation for the CHiME-7 UDASE task and\ndescribe the data, the task, and the baseline system.\n","authors":["Simon Leglaive","Léonie Borne","Efthymios Tzinis","Mostafa Sadeghi","Matthieu Fraticelli","Scott Wisdom","Manuel Pariente","Daniel Pressnitzer","John R. Hershey"],"pdf_url":"https://arxiv.org/pdf/2307.03533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01571v2","updated":"2023-07-07T10:55:17Z","published":"2022-11-03T03:36:51Z","title":"Phonetic-assisted Multi-Target Units Modeling for Improving\n  Conformer-Transducer ASR system","summary":"  Exploiting effective target modeling units is very important and has always\nbeen a concern in end-to-end automatic speech recognition (ASR). In this work,\nwe propose a phonetic-assisted multi target units (PMU) modeling approach, to\nenhance the Conformer-Transducer ASR system in a progressive representation\nlearning manner. Specifically, PMU first uses the pronunciation-assisted\nsubword modeling (PASM) and byte pair encoding (BPE) to produce\nphonetic-induced and text-induced target units separately; Then, three new\nframeworks are investigated to enhance the acoustic encoder, including a basic\nPMU, a paraCTC and a pcaCTC, they integrate the PASM and BPE units at different\nlevels for CTC and transducer multi-task training. Experiments on both\nLibriSpeech and accented ASR tasks show that, the proposed PMU significantly\noutperforms the conventional BPE, it reduces the WER of LibriSpeech clean,\nother, and six accented ASR testsets by relative 12.7%, 6.0% and 7.7%,\nrespectively.\n","authors":["Li Li","Dongxing Xu","Haoran Wei","Yanhua Long"],"pdf_url":"https://arxiv.org/pdf/2211.01571v2.pdf","comment":"Accepted by Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.01304v2","updated":"2023-07-07T09:57:54Z","published":"2023-06-02T07:04:33Z","title":"JEPOO: Highly Accurate Joint Estimation of Pitch, Onset and Offset for\n  Music Information Retrieval","summary":"  Melody extraction is a core task in music information retrieval, and the\nestimation of pitch, onset and offset are key sub-tasks in melody extraction.\nExisting methods have limited accuracy, and work for only one type of data,\neither single-pitch or multipitch. In this paper, we propose a highly accurate\nmethod for joint estimation of pitch, onset and offset, named JEPOO. We address\nthe challenges of joint learning optimization and handling both single-pitch\nand multi-pitch data through novel model design and a new optimization\ntechnique named Pareto modulated loss with loss weight regularization. This is\nthe first method that can accurately handle both single-pitch and multi-pitch\nmusic data, and even a mix of them. A comprehensive experimental study on a\nwide range of real datasets shows that JEPOO outperforms state-ofthe-art\nmethods by up to 10.6%, 8.3% and 10.3% for the prediction of Pitch, Onset and\nOffset, respectively, and JEPOO is robust for various types of data and\ninstruments. The ablation study shows the effectiveness of each component of\nJEPOO.\n","authors":["Haojie Wei","Jun Yuan","Rui Zhang","Yueguo Chen","Gang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.01304v2.pdf","comment":"This paper has been accepted by IJCAI 2023; 11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2307.02892v2","updated":"2023-07-07T09:31:28Z","published":"2023-07-06T09:54:35Z","title":"The Relationship Between Speech Features Changes When You Get Depressed:\n  Feature Correlations for Improving Speed and Performance of Depression\n  Detection","summary":"  This work shows that depression changes the correlation between features\nextracted from speech. Furthermore, it shows that using such an insight can\nimprove the training speed and performance of depression detectors based on\nSVMs and LSTMs. The experiments were performed over the Androids Corpus, a\npublicly available dataset involving 112 speakers, including 58 people\ndiagnosed with depression by professional psychiatrists. The results show that\nthe models used in the experiments improve in terms of training speed and\nperformance when fed with feature correlation matrices rather than with feature\nvectors. The relative reduction of the error rate ranges between 23.1% and\n26.6% depending on the model. The probable explanation is that feature\ncorrelation matrices appear to be more variable in the case of depressed\nspeakers. Correspondingly, such a phenomenon can be thought of as a depression\nmarker.\n","authors":["Fuxiang Tao","Wei Ma","Xuri Ge","Anna Esposito","Alessandro Vinciarelli"],"pdf_url":"https://arxiv.org/pdf/2307.02892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09359v3","updated":"2023-07-07T04:56:14Z","published":"2022-12-19T10:49:35Z","title":"WACO: Word-Aligned Contrastive Learning for Speech Translation","summary":"  End-to-end Speech Translation (E2E ST) aims to directly translate source\nspeech into target text. Existing ST methods perform poorly when only extremely\nsmall speech-text data are available for training. We observe that an ST\nmodel's performance closely correlates with its embedding similarity between\nspeech and source transcript. In this paper, we propose Word-Aligned\nCOntrastive learning (WACO), a simple and effective method for extremely\nlow-resource speech-to-text translation. Our key idea is bridging word-level\nrepresentations for both speech and text modalities via contrastive learning.\nWe evaluate WACO and other methods on the MuST-C dataset, a widely used ST\nbenchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our\nexperiments demonstrate that WACO outperforms the best baseline by 9+ BLEU\npoints with only 1-hour parallel ST data. Code is available at\nhttps://github.com/owaski/WACO.\n","authors":["Siqi Ouyang","Rong Ye","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2212.09359v3.pdf","comment":"ACL 2023 Poster"},{"id":"http://arxiv.org/abs/2307.03354v1","updated":"2023-07-07T02:26:18Z","published":"2023-07-07T02:26:18Z","title":"Token-Level Serialized Output Training for Joint Streaming ASR and ST\n  Leveraging Textual Alignments","summary":"  In real-world applications, users often require both translations and\ntranscriptions of speech to enhance their comprehension, particularly in\nstreaming scenarios where incremental generation is necessary. This paper\nintroduces a streaming Transformer-Transducer that jointly generates automatic\nspeech recognition (ASR) and speech translation (ST) outputs using a single\ndecoder. To produce ASR and ST content effectively with minimal latency, we\npropose a joint token-level serialized output training method that interleaves\nsource and target words by leveraging an off-the-shelf textual aligner.\nExperiments in monolingual (it-en) and multilingual (\\{de,es,it\\}-en) settings\ndemonstrate that our approach achieves the best quality-latency balance. With\nan average ASR latency of 1s and ST latency of 1.3s, our model shows no\ndegradation or even improves output quality compared to separate ASR and ST\nmodels, yielding an average improvement of 1.1 WER and 0.4 BLEU in the\nmultilingual case.\n","authors":["Sara Papi","Peidong Wan","Junkun Chen","Jian Xue","Jinyu Li","Yashesh Gaur"],"pdf_url":"https://arxiv.org/pdf/2307.03354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00786v2","updated":"2023-07-07T23:48:04Z","published":"2023-03-01T19:20:01Z","title":"Building High-accuracy Multilingual ASR with Gated Language Experts and\n  Curriculum Training","summary":"  We propose gated language experts and curriculum training to enhance\nmultilingual transformer transducer models without requiring language\nidentification (LID) input from users during inference. Our method incorporates\na gating mechanism and LID loss, enabling transformer experts to learn\nlanguage-specific information. By combining gated transformer experts with\nshared transformer layers, we construct multilingual transformer blocks and\nutilize linear experts to effectively regularize the joint network. The\ncurriculum training scheme leverages LID to guide the gated experts in\nimproving their respective language performance. Experimental results on a\nbilingual task involving English and Spanish demonstrate significant\nimprovements, with average relative word error reductions of 12.5% and 7.3%\ncompared to the baseline bilingual and monolingual models, respectively.\nNotably, our method achieves performance comparable to the upper-bound model\ntrained and inferred with oracle LID. Extending our approach to trilingual,\nquadrilingual, and pentalingual models reveals similar advantages to those\nobserved in the bilingual models, highlighting its ease of extension to\nmultiple languages.\n","authors":["Eric Sun","Jinyu Li","Yuxuan Hu","Yimeng Zhu","Long Zhou","Jian Xue","Peidong Wang","Linquan Liu","Shujie Liu","Edward Lin","Yifan Gong"],"pdf_url":"https://arxiv.org/pdf/2303.00786v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04547v2","updated":"2023-07-07T19:40:13Z","published":"2022-09-09T22:48:35Z","title":"Defend Data Poisoning Attacks on Voice Authentication","summary":"  With the advances in deep learning, speaker verification has achieved very\nhigh accuracy and is gaining popularity as a type of biometric authentication\noption in many scenes of our daily life, especially the growing market of web\nservices. Compared to traditional passwords, \"vocal passwords\" are much more\nconvenient as they relieve people from memorizing different passwords. However,\nnew machine learning attacks are putting these voice authentication systems at\nrisk. Without a strong security guarantee, attackers could access legitimate\nusers' web accounts by fooling the deep neural network (DNN) based voice\nrecognition models. In this paper, we demonstrate an easy-to-implement data\npoisoning attack to the voice authentication system, which can hardly be\ncaptured by existing defense mechanisms. Thus, we propose a more robust defense\nmethod, called Guardian, which is a convolutional neural network-based\ndiscriminator. The Guardian discriminator integrates a series of novel\ntechniques including bias reduction, input augmentation, and ensemble learning.\nOur approach is able to distinguish about 95% of attacked accounts from normal\naccounts, which is much more effective than existing approaches with only 60%\naccuracy.\n","authors":["Ke Li","Cameron Baird","Dan Lin"],"pdf_url":"https://arxiv.org/pdf/2209.04547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04827v1","updated":"2023-07-07T16:25:59Z","published":"2023-07-07T16:25:59Z","title":"LaunchpadGPT: Language Model as Music Visualization Designer on\n  Launchpad","summary":"  Launchpad is a musical instrument that allows users to create and perform\nmusic by pressing illuminated buttons. To assist and inspire the design of the\nLaunchpad light effect, and provide a more accessible approach for beginners to\ncreate music visualization with this instrument, we proposed the LaunchpadGPT\nmodel to generate music visualization designs on Launchpad automatically. Based\non the language model with excellent generation ability, our proposed\nLaunchpadGPT takes an audio piece of music as input and outputs the lighting\neffects of Launchpad-playing in the form of a video (Launchpad-playing video).\nWe collect Launchpad-playing videos and process them to obtain music and\ncorresponding video frame of Launchpad-playing as prompt-completion pairs, to\ntrain the language model. The experiment result shows the proposed method can\ncreate better music visualization than random generation methods and hold the\npotential for a broader range of music visualization applications. Our code is\navailable at https://github.com/yunlong10/LaunchpadGPT/.\n","authors":["Siting Xu","Yunlong Tang","Feng Zheng"],"pdf_url":"https://arxiv.org/pdf/2307.04827v1.pdf","comment":"Accepted by International Computer Music Conference (ICMC) 2023"},{"id":"http://arxiv.org/abs/2307.05527v1","updated":"2023-07-07T22:00:32Z","published":"2023-07-07T22:00:32Z","title":"The Ethical Implications of Generative Audio Models: A Systematic\n  Literature Review","summary":"  Generative audio models typically focus their applications in music and\nspeech generation, with recent models having human-like quality in their audio\noutput. This paper conducts a systematic literature review of 884 papers in the\narea of generative audio models in order to both quantify the degree to which\nresearchers in the field are considering potential negative impacts and\nidentify the types of ethical implications researchers in this area need to\nconsider. Though 65% of generative audio research papers note positive\npotential impacts of their work, less than 10% discuss any negative impacts.\nThis jarringly small percentage of papers considering negative impact is\nparticularly worrying because the issues brought to light by the few papers\ndoing so are raising serious ethical implications and concerns relevant to the\nbroader field such as the potential for fraud, deep-fakes, and copyright\ninfringement. By quantifying this lack of ethical consideration in generative\naudio research and identifying key areas of potential harm, this paper lays the\ngroundwork for future work in the field at a critical point in time in order to\nguide more conscientious research as this field progresses.\n","authors":["Julia Barnett"],"pdf_url":"https://arxiv.org/pdf/2307.05527v1.pdf","comment":"In proceedings of the AAAI/ACM Conference on AI, Ethics, and Society\n  (AIES '23). 10 pages, 1 figure"}],"Signal Processing":[{"id":"http://arxiv.org/abs/2307.03726v1","updated":"2023-07-07T17:29:59Z","published":"2023-07-07T17:29:59Z","title":"LTE SFBC MIMO Transmitter Modelling and Performance Evaluation","summary":"  High data rates are one of the most prevalent requirements in current mobile\ncommunications. To cover this and other high standards regarding performance,\nincreasing coverage, capacity, and reliability, numerous works have proposed\nthe development of systems employing the combination of several techniques such\nas Multiple Input Multiple Output (MIMO) wireless technologies with Orthogonal\nFrequency Division Multiplexing (OFDM) in the evolving 4G wireless\ncommunications. Our proposed system is based on the 2x2 MIMO antenna technique,\nwhich is defined to enhance the performance of radio communication systems in\nterms of capacity and spectral efficiency, and the OFDM technique, which can be\nimplemented using two types of sub-carrier mapping modes: Space-Time Block\nCoding and Space Frequency Block Code. SFBC has been considered in our\ndeveloped model. The main advantage of SFBC over STBC is that SFBC encodes two\nmodulated symbols over two subcarriers of the same OFDM symbol, whereas STBC\nencodes two modulated symbols over two subcarriers of the same OFDM symbol;\nthus, the coding is performed in the frequency domain. Our solution aims to\ndemonstrate the performance analysis of the Space Frequency Block Codes scheme,\nincreasing the Signal Noise Ratio (SNR) at the receiver and decreasing the Bit\nError Rate (BER) through the use of 4 QAM, 16 QAM and 64QAM modulation over a\n2x2 MIMO channel for an LTE downlink transmission, in different channel radio\nenvironments. In this work, an analytical tool to evaluate the performance of\nSFBC - Orthogonal Frequency Division Multiplexing, using two transmit antennas\nand two receive antennas has been implemented, and the analysis using the\naverage SNR has been considered as a sufficient statistic to describe the\nperformance of SFBC in the 3GPP Long Term Evolution system over Multiple Input\nMultiple Output channels.\n","authors":["Gabriela Morillo","John Cosmas"],"pdf_url":"https://arxiv.org/pdf/2307.03726v1.pdf","comment":"11 pages, 20 figures, 5 tables"},{"id":"http://arxiv.org/abs/2307.03709v1","updated":"2023-07-07T16:45:56Z","published":"2023-07-07T16:45:56Z","title":"Exact recovery of the support of piecewise constant images via total\n  variation regularization","summary":"  This work is concerned with the recovery of piecewise constant images from\nnoisy linear measurements. We study the noise robustness of a variational\nreconstruction method, which is based on total (gradient) variation\nregularization. We show that, if the unknown image is the superposition of a\nfew simple shapes, and if a non-degenerate source condition holds, then, in the\nlow noise regime, the reconstructed images have the same structure: they are\nthe superposition of the same number of shapes, each a smooth deformation of\none of the unknown shapes. Moreover, the reconstructed shapes and the\nassociated intensities converge to the unknown ones as the noise goes to zero.\n","authors":["Yohann De Castro","Vincent Duval","Romain Petit"],"pdf_url":"https://arxiv.org/pdf/2307.03709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03668v1","updated":"2023-07-07T15:39:12Z","published":"2023-07-07T15:39:12Z","title":"Using electrical impedance spectroscopy to identify equivalent circuit\n  models of lubricated contacts with complex geometry: in-situ application to\n  mini traction machine","summary":"  Electrical contact resistance or capacitance as measured between a lubricated\ncontact has been used in tribometers, partially reflecting the lubrication\ncondition. In contrast, the electrical impedance provides rich information of\nmagnitude and phase, which can be interpreted using equivalent circuit models,\nenabling more comprehensive measurements, including the variation of lubricant\nfilm thickness and the asperity (metal to metal) contact area. An accurate\ncircuit model of the lubricated contact is critical as needed for the\nelectrical impedance analysis. However, existing circuit models are hand\nderived and suited to interfaces with simple geometry, such as parallel plates,\nconcentric and eccentric cylinders. Circuit model identification of lubricated\ncontacts with complex geometry is challenging. This work takes the ball-on-disc\nlubricated contact in a Mini Traction Machine (MTM) as an example, where screws\non the ball, grooves on the disc, and contact close to the disc edge make the\noverall interface geometry complicated. The electrical impedance spectroscopy\n(EIS) is used to capture its frequency response, with a group of load, speed,\nand temperature varied and tested separately. The results enable an\nidentification of equivalent circuit models by fitting parallel\nresistor-capacitor models, the dependence on the oil film thickness is further\ncalibrated using a high-accuracy optical interferometry, which is operated\nunder the same lubrication condition as in the MTM. Overall, the proposed\nmethod is applicable to general lubricated interfaces for the identification of\nequivalent circuit models, which in turn facilitates in-situ tribo-contacts\nwith electric impedance measurement of oil film thickness. It does not need\ntransparent materials as optical techniques do, or structural modifications for\npiezoelectric sensor mounting as ultrasound techniques do.\n","authors":["Min Yu","Jie Zhang","Arndt Joedicke","Tom Reddyhoff"],"pdf_url":"https://arxiv.org/pdf/2307.03668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2002.01629v2","updated":"2023-07-07T14:47:38Z","published":"2020-02-05T04:10:04Z","title":"Broadband Channel Estimation for Intelligent Reflecting Surface Aided\n  mmWave Massive MIMO Systems","summary":"  This paper investigates the broadband channel estimation (CE) for intelligent\nreflecting surface (IRS)-aided millimeter-wave (mmWave) massive MIMO systems.\nThe CE for such systems is a challenging task due to the large dimension of\nboth the active massive MIMO at the base station (BS) and passive IRS. To\naddress this problem, this paper proposes a compressive sensing (CS)-based CE\nsolution for IRS-aided mmWave massive MIMO systems, whereby the angular channel\nsparsity of large-scale array at mmWave is exploited for improved CE with\nreduced pilot overhead. Specifically, we first propose a downlink pilot\ntransmission framework. By designing the pilot signals based on the prior\nknowledge that the line-of-sight dominated BS-to-IRS channel is known, the\nhigh-dimensional channels for BS-to-user and IRS-to-user can be jointly\nestimated based on CS theory. Moreover, to efficiently estimate broadband\nchannels, a distributed orthogonal matching pursuit algorithm is exploited,\nwhere the common sparsity shared by the channels at different subcarriers is\nutilized. Additionally, the redundant dictionary to combat the power leakage is\nalso designed for the enhanced CE performance. Simulation results demonstrate\nthe effectiveness of the proposed scheme.\n","authors":["Ziwei Wan","Zhen Gao","Mohamed-Slim Alouini"],"pdf_url":"https://arxiv.org/pdf/2002.01629v2.pdf","comment":"6 pages, 4 figures. Accepted by IEEE International Conference on\n  Communications (ICC) 2020, Dublin, Ireland"},{"id":"http://arxiv.org/abs/2307.03629v1","updated":"2023-07-07T14:37:07Z","published":"2023-07-07T14:37:07Z","title":"An Anti-Jamming Strategy for Disco Intelligent Reflecting Surfaces Based\n  Fully-Passive Jamming Attacks","summary":"  Emerging intelligent reflecting surfaces (IRSs) significantly improve system\nperformance, while also pose a huge risk for physical layer security. A disco\nIRS (DIRS), i.e., an illegitimate IRS with random time-varying reflection\nproperties, can be employed by an attacker to actively age the channels of\nlegitimate users (LUs). Such active channel aging (ACA) generated by the\nDIRS-based fully-passive jammer (FPJ) can be applied to jam multi-user\nmultiple-input single-output (MU-MISO) systems without relying on either\njamming power or LU channel state information (CSI). To address the significant\nthreats posed by the DIRS-based FPJ, an anti-jamming strategy is proposed that\nrequires only the statistical characteristics of DIRS-jammed channels instead\nof their CSI. Statistical characteristics of DIRS-jammed channels are first\nderived, and then the anti-jamming precoder is given based on the derived\nstatistical characteristics. Numerical results are also presented to evaluate\nthe effectiveness of the proposed anti-jamming precoder against the DIRS-based\nFPJ.\n","authors":["Huan Huang","Hongliang Zhang","Yi Cai","A. Lee Swindlehurst","Zhu Han"],"pdf_url":"https://arxiv.org/pdf/2307.03629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.08503v2","updated":"2023-07-07T14:31:08Z","published":"2021-11-14T16:11:26Z","title":"Binary classification of spoken words with passive phononic\n  metamaterials","summary":"  Mitigating the energy requirements of artificial intelligence requires novel\nphysical substrates for computation. Phononic metamaterials have a vanishingly\nlow power dissipation and hence are a prime candidate for green, always-on\ncomputers. However, their use in machine learning applications has not been\nexplored due to the complexity of their design process: Current phononic\nmetamaterials are restricted to simple geometries (e.g. periodic, tapered), and\nhence do not possess sufficient expressivity to encode machine learning tasks.\nWe design and fabricate a non-periodic phononic metamaterial, directly from\ndata samples, that can distinguish between pairs of spoken words in the\npresence of a simple readout nonlinearity; hence demonstrating that phononic\nmetamaterials are a viable avenue towards zero-power smart devices.\n","authors":["Tena Dubček","Daniel Moreno-Garcia","Thomas Haag","Parisa Omidvar","Henrik R. Thomsen","Theodor S. Becker","Lars Gebraad","Christoph Bärlocher","Fredrik Andersson","Sebastian D. Huber","Dirk-Jan van Manen","Luis Guillermo Villanueva","Johan O. A. Robertsson","Marc Serra-Garcia"],"pdf_url":"https://arxiv.org/pdf/2111.08503v2.pdf","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2307.03600v1","updated":"2023-07-07T13:43:35Z","published":"2023-07-07T13:43:35Z","title":"Antenna Impedance Estimation in Correlated Rayleigh Fading Channels","summary":"  We formulate antenna impedance estimation in a classical estimation framework\nunder correlated Raleigh fading channels. Based on training sequences of\nmultiple packets, we derive the ML estimators for antenna impedance and channel\nvariance, treating the fading path gains as nuisance parameters. These ML\nestimators can be found via scalar optimization. We explore the efficiency of\nthese estimators against Cramer-Rao lower bounds by numerical examples. The\nimpact of channel correlation on impedance estimation accuracy is investigated.\n","authors":["Shaohan Wu","Brian Hughes"],"pdf_url":"https://arxiv.org/pdf/2307.03600v1.pdf","comment":"5 pages, 2 figures, ICASSP 2023. arXiv admin note: substantial text\n  overlap with arXiv:2006.11443"},{"id":"http://arxiv.org/abs/2307.03586v1","updated":"2023-07-07T13:28:29Z","published":"2023-07-07T13:28:29Z","title":"ContextLabeler Dataset: physical and virtual sensors data collected from\n  smartphone usage in-the-wild","summary":"  This paper describes a data collection campaign and the resulting dataset\nderived from smartphone sensors characterizing the daily life activities of 3\nvolunteers in a period of two weeks. The dataset is released as a collection of\nCSV files containing more than 45K data samples, where each sample is composed\nby 1332 features related to a heterogeneous set of physical and virtual\nsensors, including motion sensors, running applications, devices in proximity,\nand weather conditions. Moreover, each data sample is associated with a ground\ntruth label that describes the user activity and the situation in which she was\ninvolved during the sensing experiment (e.g., working, at restaurant, and doing\nsport activity). To avoid introducing any bias during the data collection, we\nperformed the sensing experiment in-the-wild, that is, by using the volunteers'\ndevices, and without defining any constraint related to the user's behavior.\nFor this reason, the collected dataset represents a useful source of real data\nto both define and evaluate a broad set of novel context-aware solutions (both\nalgorithms and protocols) that aim to adapt their behavior according to the\nchanges in the user's situation in a mobile environment.\n","authors":["Mattia Giovanni Campana","Franca Delmastro"],"pdf_url":"https://arxiv.org/pdf/2307.03586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.11007v2","updated":"2023-07-07T12:24:34Z","published":"2022-09-22T13:44:13Z","title":"Avoiding Post-Processing with Event-Based Detection in Biomedical\n  Signals","summary":"  Objective: Finding events of interest is a common task in biomedical signal\nprocessing. The detection of epileptic seizures and signal artefacts are two\nkey examples. Epoch-based classification is the typical machine learning\nframework to detect such signal events because of the straightforward\napplication of classical machine learning techniques. Usually, post-processing\nis required to achieve good performance and enforce temporal dependencies.\nDesigning the right post-processing scheme to convert these classification\noutputs into events is a tedious, and labor-intensive element of this\nframework. Methods: We propose an event-based modeling framework that directly\nworks with events as learning targets, stepping away from ad-hoc\npost-processing schemes to turn model outputs into events. We illustrate the\npractical power of this framework on simulated data and real-world data,\ncomparing it to epoch-based modeling approaches. Results: We show that\nevent-based modeling (without post-processing) performs on par with or better\nthan epoch-based modeling with extensive post-processing. Conclusion: These\nresults show the power of treating events as direct learning targets, instead\nof using ad-hoc post-processing to obtain them, severely reducing design\neffort. Significance: The event-based modeling framework can easily be applied\nto other event detection problems in signal processing, removing the need for\nintensive task-specific post-processing.\n","authors":["Nick Seeuws","Maarten De Vos","Alexander Bertrand"],"pdf_url":"https://arxiv.org/pdf/2209.11007v2.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2307.03517v1","updated":"2023-07-07T11:12:51Z","published":"2023-07-07T11:12:51Z","title":"Approximate Maximum a Posteriori Carrier Phase Estimator for Wiener\n  Phase Noise Channels using Belief Propagation","summary":"  The blind phase search (BPS) algorithm for carrier phase estimation is known\nto have sub-optimal performance for probabilistically shaped constellations. We\npresent a belief propagation based approximate maximum a posteriori carrier\nphase estimator and compare its performance with the standard and an improved\nBPS algorithm.\n","authors":["Shrinivas Chimmalgi","Andrej Rode","Luca Schmid","Laurent Schmalen"],"pdf_url":"https://arxiv.org/pdf/2307.03517v1.pdf","comment":"Accepted for presentation at European Conference on Optical\n  Communications 2023"},{"id":"http://arxiv.org/abs/2209.04848v3","updated":"2023-07-07T09:15:55Z","published":"2022-09-11T12:18:10Z","title":"Dynamic Hybrid Beamforming Design for Dual-Function Radar-Communication\n  Systems","summary":"  This paper investigates dynamic hybrid beamforming (HBF) for a dual-function\nradar-communication (DFRC) system, where the DFRC base station (BS)\nsimultaneously serves multiple single-antenna users and senses a target in the\npresence of multiple clutters. Particularly, we apply a HBF architecture with\ndynamic subarrays and double phase shifters in the DFRC BS. Aiming at\nmaximizing the radar mutual information, we consider jointly designing the\ndynamic HBF of the DFRC system, subject to the constraints of communication\nquality of service (QoS), transmit power, and analog beamformer. To solve the\ncomplicated non-convex optimization, an efficient alternating optimization\nalgorithm based on the majorization-minimization methods is developed.\nSimulation results verify the advancement of the considered HBF architecture\nand the effectiveness of the proposed design method.\n","authors":["Bowen Wang","Hongyu Li","Ziyang Cheng"],"pdf_url":"https://arxiv.org/pdf/2209.04848v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.07142v2","updated":"2023-07-07T09:03:32Z","published":"2023-02-12T07:48:04Z","title":"Semantic Importance-Aware Communications Using Pre-trained Language\n  Models","summary":"  This letter proposes a semantic importance-aware communication (SIAC) scheme\nusing pre-trained language models (e.g., ChatGPT, BERT, etc.). Specifically, we\npropose a cross-layer design with a pre-trained language model embedded\nin/connected by the cross-layer manager. The pre-trained language model is\nutilized to quantify the semantic importance of data frames. Based on the\nquantified semantic importance, we investigate semantic importance-aware power\nallocation. Unlike existing deep joint source-channel coding (Deep-JSCC)-based\nsemantic communication schemes, SIAC can be directly embedded into current\ncommunication systems by only introducing a cross-layer manager. Our\nexperimental results show that the proposed SIAC scheme can achieve lower\nsemantic loss than existing equal-priority communications.\n","authors":["Shuaishuai Guo","Yanhu Wang","Shujing Li","Nasir Saeed"],"pdf_url":"https://arxiv.org/pdf/2302.07142v2.pdf","comment":"Accepted by IEEE Communications Letters, Semantic communications,\n  pre-trained language model, ChatGPT, BERT, data importance"},{"id":"http://arxiv.org/abs/2201.05745v3","updated":"2023-07-07T08:14:38Z","published":"2022-01-15T03:13:02Z","title":"Deep Optimal Transport for Domain Adaptation on SPD Manifolds","summary":"  In recent years, there has been significant interest in solving the domain\nadaptation (DA) problem on symmetric positive definite (SPD) manifolds within\nthe machine learning community. This interest stems from the fact that complex\nneurophysiological data generated by medical equipment, such as\nelectroencephalograms, magnetoencephalograms, and diffusion tensor imaging,\noften exhibit a shift in data distribution across different domains. These data\nrepresentations, represented by signal covariance matrices, possess properties\nof symmetry and positive definiteness. However, directly applying previous\nexperiences and solutions to the DA problem poses challenges due to the\nmanipulation complexities of covariance matrices.To address this, our research\nintroduces a category of deep learning-based transfer learning approaches\ncalled deep optimal transport. This category utilizes optimal transport theory\nand leverages the Log-Euclidean geometry for SPD manifolds. Additionally, we\npresent a comprehensive categorization of existing geometric methods to tackle\nthese problems effectively. This categorization provides practical solutions\nfor specific DA problems, including handling discrepancies in marginal and\nconditional distributions between the source and target domains on the SPD\nmanifold. To evaluate the effectiveness, we conduct experiments on three\npublicly available highly non-stationary cross-session brain-computer interface\nscenarios. Moreover, we provide visualization results on the SPD cone to offer\nfurther insights into the framework.\n","authors":["Ce Ju","Cuntai Guan"],"pdf_url":"https://arxiv.org/pdf/2201.05745v3.pdf","comment":"15 pages, 4 figures, and 4 tables; This work has been submitted to\n  the IEEE for possible publication. Copyright may be transferred without\n  notice, after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2307.03438v1","updated":"2023-07-07T07:51:22Z","published":"2023-07-07T07:51:22Z","title":"RNN Based Channel Estimation in Doubly Selective Environments","summary":"  Doubly-selective channel estimation represents a key element in ensuring\ncommunication reliability in wireless systems. Due to the impact of multi-path\npropagation and Doppler interference in dynamic environments, doubly-selective\nchannel estimation becomes challenging. Conventional symbol-by-symbol (SBS) and\nframe-by-frame (FBF) channel estimation schemes encounter performance\ndegradation in high mobility scenarios due to the usage of limited training\npilots. Recently, deep learning (DL) has been utilized for doubly-selective\nchannel estimation, where long short-term memory (LSTM) and convolutional\nneural network (CNN) networks are employed in the SBS and FBF, respectively.\nHowever, their usage is not optimal, since LSTM suffers from long-term memory\nproblem, whereas, CNN-based estimators require high complexity. For this\npurpose, we overcome these issues by proposing an optimized recurrent neural\nnetwork (RNN)-based channel estimation schemes, where gated recurrent unit\n(GRU) and Bi-GRU units are used in SBS and FBF channel estimation,\nrespectively. The proposed estimators are based on the average correlation of\nthe channel in different mobility scenarios, where several\nperformance-complexity trade-offs are provided. Moreover, the performance of\nseveral RNN networks is analyzed. The performance superiority of the proposed\nestimators against the recently proposed DL-based SBS and FBF estimators is\ndemonstrated for different scenarios while recording a significant reduction in\ncomplexity.\n","authors":["Abdul Karim Gizzini","Marwa Chafii"],"pdf_url":"https://arxiv.org/pdf/2307.03438v1.pdf","comment":"This paper has been submitted to the IEEE Transactions on Machine\n  Learning in Communications and Networking (TMLCN). arXiv admin note: text\n  overlap with arXiv:2305.00208"},{"id":"http://arxiv.org/abs/2307.03403v1","updated":"2023-07-07T06:00:55Z","published":"2023-07-07T06:00:55Z","title":"An Improved Compound Gaussian Model for Bivariate Surface EMG Signals\n  Related to Strength Training","summary":"  Recent literature suggests that the surface electromyography (sEMG) signals\nhave non-stationary statistical characteristics specifically due to random\nnature of the covariance. Thus suitability of a statistical model for sEMG\nsignals is determined by the choice of an appropriate model for describing the\ncovariance. The purpose of this study is to propose a Compound-Gaussian (CG)\nmodel for multivariate sEMG signals in which latent variable of covariance is\nmodeled as a random variable that follows an exponential model. The parameters\nof the model are estimated using the iterative Expectation Maximization (EM)\nalgorithm. Further, a new dataset, electromyography analysis of human\nactivities database 2 (EMAHA-DB2) is developed. Based on the model fitting\nanalysis on the sEMG signals from EMAHA-DB2, it is found that the proposed CG\nmodel fits more closely to the empirical pdf of sEMG signals than the existing\nmodels. The proposed model is validated by visual inspection, further validated\nby matching central moments and better quantitative metrics in comparison with\nother models. The proposed compound model provides an improved fit to the\nstatistical behavior of sEMG signals. Further, the estimate of rate parameter\nof the exponential model shows clear relation to the training weights. Finally,\nthe average signal power estimates of the channels shows distinctive dependency\non the training weights, the subject's training experience and the type of\nactivity.\n","authors":["Durgesh Kusuru","Anish C. Turlapaty","Mainak Thakur"],"pdf_url":"https://arxiv.org/pdf/2307.03403v1.pdf","comment":"This article supersedes arXiv:2301.05417. This work has been\n  submitted to the IEEE for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2307.03387v1","updated":"2023-07-07T04:57:55Z","published":"2023-07-07T04:57:55Z","title":"A Joint Design for Full-duplex OFDM AF Relay System with Precoded Short\n  Guard Interval","summary":"  In-band full-duplex relay (FDR) has attracted much attention as an effective\nsolution to improve the coverage and spectral efficiency in wireless\ncommunication networks. The basic problem for FDR transmission is how to\neliminate the inherent self-interference and re-use the residual\nself-interference (RSI) at the relay to improve the end-to-end performance.\nConsidering the RSI at the FDR, the overall equivalent channel can be modeled\nas an infinite impulse response (IIR) channel. For this IIR channel, a joint\ndesign for precoding, power gain control and equalization of cooperative OFDM\nrelay systems is presented. Compared with the traditional OFDM systems, the\nlength of the guard interval for the proposed design can be distinctly reduced,\nthereby improving the spectral efficiency. By analyzing the noise sources, this\npaper evaluates the signal to noise ratio (SNR) of the proposed scheme and\npresents a power gain control algorithm at the FDR. Compared with the existing\nschemes, the proposed scheme shows a superior bit error rate (BER) performance.\n","authors":["Pu Yang","Xiang-Gen Xia","Qingyue Qu","Han Wang","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2307.03387v1.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2307.03368v1","updated":"2023-07-07T03:27:39Z","published":"2023-07-07T03:27:39Z","title":"Waveform-Domain Adaptive Matched Filtering: A Novel Approach to\n  Suppressing Interrupted-Sampling Repeater Jamming","summary":"  The inadequate adaptability to flexible interference scenarios remains an\nunresolved challenge in the majority of techniques utilized for mitigating\ninterrupted-sampling repeater jamming (ISRJ). Matched filtering system based\nmethods is desirable to incorporate anti-ISRJ measures based on prior ISRJ\nmodeling, either preceding or succeeding the matched filtering. Due to the\npartial matching nature of ISRJ, its characteristics are revealed during the\nprocess of matched filtering. Therefore, this paper introduces an extended\ndomain called the waveform domain within the matched filtering process. On this\ndomain, a novel matched filtering model, known as the waveform-domain adaptive\nmatched filtering (WD-AMF), is established to tackle the problem of ISRJ\nsuppression without relying on a pre-existing ISRJ model. The output of the\nWD-AMF encompasses an adaptive filtering term and a compensation term. The\nadaptive filtering term encompasses the adaptive integration outcomes in the\nwaveform domain, which are determined by an adaptive weighted function. This\nfunction, akin to a collection of bandpass filters, decomposes the integrated\nfunction into multiple components, some of which contain interference while\nothers do not. The compensation term adheres to an integrated guideline for\ndiscerning the presence of signal components or noise within the integrated\nfunction. The integration results are then concatenated to reconstruct a\ncompensated matched filter signal output. Simulations are conducted to showcase\nthe exceptional capability of the proposed method in suppressing ISRJ in\ndiverse interference scenarios, even in the absence of a pre-existing ISRJ\nmodel.\n","authors":["Hanning Su","Qinglong Bao","Jiameng Pan","Fucheng Guo","Weidong Hu"],"pdf_url":"https://arxiv.org/pdf/2307.03368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01445v2","updated":"2023-07-07T03:16:55Z","published":"2023-07-04T02:45:37Z","title":"Distributed fusion filter over lossy wireless sensor networks with the\n  presence of non-Gaussian noise","summary":"  The information transmission between nodes in a wireless sensor networks\n(WSNs) often causes packet loss due to denial-of-service (DoS) attack, energy\nlimitations, and environmental factors, and the information that is\nsuccessfully transmitted can also be contaminated by non-Gaussian noise. The\npresence of these two factors poses a challenge for distributed state\nestimation (DSE) over WSNs. In this paper, a generalized packet drop model is\nproposed to describe the packet loss phenomenon caused by DoS attacks and other\nfactors. Moreover, a modified maximum correntropy Kalman filter is given, and\nit is extended to distributed form (DM-MCKF). In addition, a distributed\nmodified maximum correntropy Kalman filter incorporating the generalized data\npacket drop (DM-MCKF-DPD) algorithm is provided to implement DSE with the\npresence of both non-Gaussian noise pollution and packet drop. A sufficient\ncondition to ensure the convergence of the fixed-point iterative process of the\nDM-MCKF-DPD algorithm is presented and the computational complexity of the\nDM-MCKF-DPD algorithm is analyzed. Finally, the effectiveness and feasibility\nof the proposed algorithms are verified by simulations.\n","authors":["Jiacheng He","Bei Peng","Zhenyu Feng","Xuemei Mao","Song Gao","Gang Wang"],"pdf_url":"https://arxiv.org/pdf/2307.01445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03343v1","updated":"2023-07-07T01:17:41Z","published":"2023-07-07T01:17:41Z","title":"Unified Modeling and Rate Coverage Analysis for Satellite-Terrestrial\n  Integrated Networks: Coverage Extension or Data Offloading?","summary":"  With the growing interest in satellite networks, satellite-terrestrial\nintegrated networks (STINs) have gained significant attention because of their\npotential benefits. However, due to the lack of a tractable network model for\nthe STIN architecture, analytical studies allowing one to investigate the\nperformance of such networks are not yet available. In this work, we propose a\nunified network model that jointly captures satellite and terrestrial networks\ninto one analytical framework. Our key idea is based on Poisson point processes\ndistributed on concentric spheres, assigning a random height to each point as a\nmark. This allows one to consider each point as a source of desired signal or a\nsource of interference while ensuring visibility to the typical user. Thanks to\nthis model, we derive the probability of coverage of STINs as a function of\nmajor system parameters, chiefly path-loss exponent, satellites and terrestrial\nbase stations' height distributions and density, transmit power and biasing\nfactors. Leveraging the analysis, we concretely explore two benefits that STINs\nprovide: i) coverage extension in remote rural areas and ii) data offloading in\ndense urban areas.\n","authors":["Jeonghun Park","Jinseok Choi","Namyoon Lee","François Baccelli"],"pdf_url":"https://arxiv.org/pdf/2307.03343v1.pdf","comment":"submitted to IEEE journal"},{"id":"http://arxiv.org/abs/2307.03337v1","updated":"2023-07-07T00:44:06Z","published":"2023-07-07T00:44:06Z","title":"Personalized Prediction of Recurrent Stress Events Using Self-Supervised\n  Learning on Multimodal Time-Series Data","summary":"  Chronic stress can significantly affect physical and mental health. The\nadvent of wearable technology allows for the tracking of physiological signals,\npotentially leading to innovative stress prediction and intervention methods.\nHowever, challenges such as label scarcity and data heterogeneity render stress\nprediction difficult in practice. To counter these issues, we have developed a\nmultimodal personalized stress prediction system using wearable biosignal data.\nWe employ self-supervised learning (SSL) to pre-train the models on each\nsubject's data, allowing the models to learn the baseline dynamics of the\nparticipant's biosignals prior to fine-tuning the stress prediction task. We\ntest our model on the Wearable Stress and Affect Detection (WESAD) dataset,\ndemonstrating that our SSL models outperform non-SSL models while utilizing\nless than 5% of the annotations. These results suggest that our approach can\npersonalize stress prediction to each user with minimal annotations. This\nparadigm has the potential to enable personalized prediction of a variety of\nrecurring health events using complex multimodal data streams.\n","authors":["Tanvir Islam","Peter Washington"],"pdf_url":"https://arxiv.org/pdf/2307.03337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15078v3","updated":"2023-07-07T23:33:38Z","published":"2022-10-26T23:24:44Z","title":"Age of Information in Downlink Systems: Broadcast or Unicast\n  Transmission?","summary":"  We analytically decide whether the broadcast transmission scheme or the\nunicast transmission scheme achieves the optimal age of information (AoI)\nperformance of a multiuser system where a base station (BS) generates and\ntransmits status updates to multiple user equipments (UEs). In the broadcast\ntransmission scheme, the status update for all UEs is jointly encoded into a\npacket for transmission, while in the unicast transmission scheme, the status\nupdate for each UE is encoded individually and transmitted by following the\nround robin policy. For both transmission schemes, we examine three packet\nmanagement strategies, namely the non-preemption strategy, the preemption in\nbuffer strategy, and the preemption in serving strategy. We first derive new\nclosed-form expressions for the average AoI achieved by two transmission\nschemes with three packet management strategies. Based on them, we compare the\nAoI performance of two transmission schemes in two systems, namely, the remote\ncontrol system and the dynamic system. Aided by simulation results, we verify\nour analysis and investigate the impact of system parameters on the average\nAoI. For example, the unicast transmission scheme is more appropriate for the\nsystem with a large number UEs. Otherwise, the broadcast transmission scheme is\nmore appropriate.\n","authors":["Zhifeng Tang","Nan Yang","Parastoo Sadeghi","Xiangyun Zhou"],"pdf_url":"https://arxiv.org/pdf/2210.15078v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03829v1","updated":"2023-07-07T20:52:09Z","published":"2023-07-07T20:52:09Z","title":"Robot Motion Prediction by Channel State Information","summary":"  Autonomous robotic systems have gained a lot of attention, in recent years.\nHowever, accurate prediction of robot motion in indoor environments with\nlimited visibility is challenging. While vision-based and light detection and\nranging (LiDAR) sensors are commonly used for motion detection and localization\nof robotic arms, they are privacy-invasive and depend on a clear line-of-sight\n(LOS) for precise measurements. In cases where additional sensors are not\navailable or LOS is not possible, these technologies may not be the best\noption. This paper proposes a novel method that employs channel state\ninformation (CSI) from WiFi signals affected by robotic arm motion. We\ndeveloped a convolutional neural network (CNN) model to classify four different\nactivities of a Franka Emika robotic arm. The implemented method seeks to\naccurately predict robot motion even in scenarios in which the robot is\nobscured by obstacles, without relying on any attached or internal sensors.\n","authors":["Rojin Zandi","Hojjat Salehinejad","Kian Behzad","Elaheh Motamedi","Milad Siami"],"pdf_url":"https://arxiv.org/pdf/2307.03829v1.pdf","comment":"6 pages, 10 figures, 2 tables, MLSP Conference"},{"id":"http://arxiv.org/abs/2307.03827v1","updated":"2023-07-07T20:51:38Z","published":"2023-07-07T20:51:38Z","title":"Effect of Intensity Standardization on Deep Learning for WML\n  Segmentation in Multi-Centre FLAIR MRI","summary":"  Deep learning (DL) methods for white matter lesion (WML) segmentation in MRI\nsuffer a reduction in performance when applied on data from a scanner or centre\nthat is out-of-distribution (OOD) from the training data. This is critical for\ntranslation and widescale adoption, since current models cannot be readily\napplied to data from new institutions. In this work, we evaluate several\nintensity standardization methods for MRI as a preprocessing step for WML\nsegmentation in multi-centre Fluid-Attenuated Inversion Recovery (FLAIR) MRI.\nWe evaluate a method specifically developed for FLAIR MRI called IAMLAB along\nwith other popular normalization techniques such as White-strip, Nyul and\nZ-score. We proposed an Ensemble model that combines predictions from each of\nthese models. A skip-connection UNet (SC UNet) was trained on the standardized\nimages, as well as the original data and segmentation performance was evaluated\nover several dimensions. The training (in-distribution) data consists of a\nsingle study, of 60 volumes, and the test (OOD) data is 128 unseen volumes from\nthree clinical cohorts. Results show IAMLAB and Ensemble provide higher WML\nsegmentation performance compared to models from original data or other\nnormalization methods. IAMLAB & Ensemble have the highest dice similarity\ncoefficient (DSC) on the in-distribution data (0.78 & 0.80) and on clinical OOD\ndata. DSC was significantly higher for IAMLAB compared to the original data\n(p<0.05) for all lesion categories (LL>25mL: 0.77 vs. 0.71; 10mL<= LL<25mL:\n0.66 vs. 0.61; LL<10mL: 0.53 vs. 0.52). The IAMLAB and Ensemble normalization\nmethods are mitigating MRI domain shift and are optimal for DL-based WML\nsegmentation in unseen FLAIR data.\n","authors":["Abdollah Ghazvanchahi","Pejman Jahbedar Maralani","Alan R. Moody","April Khademi"],"pdf_url":"https://arxiv.org/pdf/2307.03827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05357v1","updated":"2023-07-07T14:09:18Z","published":"2023-07-07T14:09:18Z","title":"Over-the-Air Computation in OFDM Systems with Imperfect Channel State\n  Information","summary":"  This paper studies the over-the-air computation (AirComp) in an orthogonal\nfrequency division multiplexing (OFDM) system with imperfect channel state\ninformation (CSI), in which multiple single-antenna wireless devices (WDs)\nsimultaneously send uncoded signals to a multi-antenna access point (AP) for\ndistributed functional computation over multiple subcarriers. In particular, we\nconsider two scenarios with best-effort and error-constrained computation\ntasks, with the objectives of minimizing the average computation mean squared\nerror (MSE) and the computation outage probability over the multiple\nsubcarriers, respectively. Towards this end, we jointly optimize the transmit\ncoefficients at the WDs and the receive beamforming vectors at the AP over\nsubcarriers, subject to the maximum transmit power constraints at individual\nWDs. First, for the special case with a single receive antenna at the AP, we\npropose the semi-closed-form globally optimal solutions to the two problems\nusing the Lagrange-duality method. It is shown that at each subcarrier, the\nWDs' optimized power control policy for average MSE minimization follows a\nregularized channel inversion structure, while that for computation outage\nprobability minimization follows an on-off regularized channel inversion, with\nthe regularization dependent on the transmit power budget and channel\nestimation error. Next, for the general case with multiple receive antennas at\nthe AP, we present efficient algorithms based on alternating optimization and\nconvex optimization to find converged solutions to both problems.\n","authors":["Yilong Chen","Huijun Xing","Jie Xu","Lexi Xu","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2307.05357v1.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2307.05339v1","updated":"2023-07-07T06:21:43Z","published":"2023-07-07T06:21:43Z","title":"A Self-Supervised Algorithm for Denoising Photoplethysmography Signals\n  for Heart Rate Estimation from Wearables","summary":"  Smart watches and other wearable devices are equipped with\nphotoplethysmography (PPG) sensors for monitoring heart rate and other aspects\nof cardiovascular health. However, PPG signals collected from such devices are\nsusceptible to corruption from noise and motion artifacts, which cause errors\nin heart rate estimation. Typical denoising approaches filter or reconstruct\nthe signal in ways that eliminate much of the morphological information, even\nfrom the clean parts of the signal that would be useful to preserve. In this\nwork, we develop an algorithm for denoising PPG signals that reconstructs the\ncorrupted parts of the signal, while preserving the clean parts of the PPG\nsignal. Our novel framework relies on self-supervised training, where we\nleverage a large database of clean PPG signals to train a denoising\nautoencoder. As we show, our reconstructed signals provide better estimates of\nheart rate from PPG signals than the leading heart rate estimation methods.\nFurther experiments show significant improvement in Heart Rate Variability\n(HRV) estimation from PPG signals using our algorithm. We conclude that our\nalgorithm denoises PPG signals in a way that can improve downstream analysis of\nmany different health metrics from wearable devices.\n","authors":["Pranay Jain","Cheng Ding","Cynthia Rudin","Xiao Hu"],"pdf_url":"https://arxiv.org/pdf/2307.05339v1.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2307.05746v1","updated":"2023-07-07T16:32:17Z","published":"2023-07-07T16:32:17Z","title":"Distributed Universal Adaptive Networks","summary":"  Adaptive networks (ANs) are effective real time techniques to process and\ntrack events observed by sensor networks and, more recently, to equip Internet\nof Things (IoT) applications. ANs operate over nodes equipped with\ncollaborative adaptive filters that solve distributively an estimation problem\ncommon to the whole network. However, they do not guarantee that nodes do not\nlose from cooperation, as compared to its non-cooperative operation; that poor\nnodes are rejected and exceptional nodes estimates reach the entire network;\nand that performance is uniform over all nodes. In order to enforce such\nproperties, this work introduces the concept of distributed universal\nestimation, which encompasses the new concepts of local universality, global\nuniversality and universality with respect to the non-cooperative operation. We\nthen construct a new cooperation protocol that is proven to be distributively\nuniversal, outperforming direct competitors from the literature, as shown by\nseveral simulations. Mean and mean-square analytical models are developed, with\ngood agreement between theory and simulations.\n","authors":["Cassio G. Lopes","Vítor H. Nascimento","Luiz F. O. Chamon"],"pdf_url":"https://arxiv.org/pdf/2307.05746v1.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2307.03726v1","updated":"2023-07-07T17:29:59Z","published":"2023-07-07T17:29:59Z","title":"LTE SFBC MIMO Transmitter Modelling and Performance Evaluation","summary":"  High data rates are one of the most prevalent requirements in current mobile\ncommunications. To cover this and other high standards regarding performance,\nincreasing coverage, capacity, and reliability, numerous works have proposed\nthe development of systems employing the combination of several techniques such\nas Multiple Input Multiple Output (MIMO) wireless technologies with Orthogonal\nFrequency Division Multiplexing (OFDM) in the evolving 4G wireless\ncommunications. Our proposed system is based on the 2x2 MIMO antenna technique,\nwhich is defined to enhance the performance of radio communication systems in\nterms of capacity and spectral efficiency, and the OFDM technique, which can be\nimplemented using two types of sub-carrier mapping modes: Space-Time Block\nCoding and Space Frequency Block Code. SFBC has been considered in our\ndeveloped model. The main advantage of SFBC over STBC is that SFBC encodes two\nmodulated symbols over two subcarriers of the same OFDM symbol, whereas STBC\nencodes two modulated symbols over two subcarriers of the same OFDM symbol;\nthus, the coding is performed in the frequency domain. Our solution aims to\ndemonstrate the performance analysis of the Space Frequency Block Codes scheme,\nincreasing the Signal Noise Ratio (SNR) at the receiver and decreasing the Bit\nError Rate (BER) through the use of 4 QAM, 16 QAM and 64QAM modulation over a\n2x2 MIMO channel for an LTE downlink transmission, in different channel radio\nenvironments. In this work, an analytical tool to evaluate the performance of\nSFBC - Orthogonal Frequency Division Multiplexing, using two transmit antennas\nand two receive antennas has been implemented, and the analysis using the\naverage SNR has been considered as a sufficient statistic to describe the\nperformance of SFBC in the 3GPP Long Term Evolution system over Multiple Input\nMultiple Output channels.\n","authors":["Gabriela Morillo","John Cosmas"],"pdf_url":"https://arxiv.org/pdf/2307.03726v1.pdf","comment":"11 pages, 20 figures, 5 tables"},{"id":"http://arxiv.org/abs/2305.03231v3","updated":"2023-07-07T15:46:46Z","published":"2023-05-05T01:19:41Z","title":"Resource Management in Quantum Virtual Private Networks","summary":"  In this study, we develop a resource management framework for a quantum\nvirtual private network (qVPN), which involves the sharing of an underlying\npublic quantum network by multiple organizations for quantum entanglement\ndistribution. Our approach involves resolving the issue of link entanglement\nresource allocation in a qVPN by utilizing a centralized optimization\nframework. We provide insights into the potential of genetic and learning-based\nalgorithms for optimizing qVPNs, and emphasize the significance of path\nselection and distillation in enabling efficient and reliable quantum\ncommunication in multi-organizational settings. Our findings demonstrate that\ncompared to traditional greedy based heuristics, genetic and learning-based\nalgorithms can identify better paths. Furthermore, these algorithms can\neffectively identify good distillation strategies to mitigate potential noises\nin gates and quantum channels, while ensuring the necessary quality of service\nfor end users.\n","authors":["Shahrooz Pouryousef","Nitish K. Panigrahy","Monimoy Deb Purkayastha","Sabyasachi Mukhopadhyay","Gert Grammel","Domenico Di Mola","Don Towsley"],"pdf_url":"https://arxiv.org/pdf/2305.03231v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03649v1","updated":"2023-07-07T15:14:53Z","published":"2023-07-07T15:14:53Z","title":"6LoRa: Full Stack IPv6 Networking with DSME-LoRa on Low Power IoT Nodes","summary":"  Long range wireless transmission techniques such as LoRa are preferential\ncandidates for a substantial class of IoT applications, as they avoid the\ncomplexity of multi-hop wireless forwarding. The existing network solutions for\nLoRa, however, are not suitable for peer-to-peer communication, which is a key\nrequirement for many IoT applications. In this work, we propose a networking\nsystem - 6LoRa, that enables IPv6 communication over LoRa. We present a full\nstack system implementation on RIOT OS and evaluate the system on a real\ntestbed using realistic application scenarios with CoAP. Our findings confirm\nthat our approach outperforms existing solutions in terms of transmission delay\nand packet reception ratio at comparable energy consumption.\n","authors":["José Álamos","Thomas Schmidt","Matthias Waehlisch"],"pdf_url":"https://arxiv.org/pdf/2307.03649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07368v2","updated":"2023-07-07T11:32:21Z","published":"2023-05-12T10:32:26Z","title":"Decentralized Learning over Wireless Networks: The Effect of Broadcast\n  with Random Access","summary":"  In this work, we focus on the communication aspect of decentralized learning,\nwhich involves multiple agents training a shared machine learning model using\ndecentralized stochastic gradient descent (D-SGD) over distributed data. In\nparticular, we investigate the impact of broadcast transmission and\nprobabilistic random access policy on the convergence performance of D-SGD,\nconsidering the broadcast nature of wireless channels and the link dynamics in\nthe communication topology. Our results demonstrate that optimizing the access\nprobability to maximize the expected number of successful links is a highly\neffective strategy for accelerating the system convergence.\n","authors":["Zheng Chen","Martin Dahl","Erik G. Larsson"],"pdf_url":"https://arxiv.org/pdf/2305.07368v2.pdf","comment":"5 pages, 5 figures, accepted in IEEE SPAWC 2023"},{"id":"http://arxiv.org/abs/2306.14328v2","updated":"2023-07-07T11:31:36Z","published":"2023-06-25T19:58:15Z","title":"ALBUS: a Probabilistic Monitoring Algorithm to Counter Burst-Flood\n  Attacks","summary":"  Modern DDoS defense systems rely on probabilistic monitoring algorithms to\nidentify flows that exceed a volume threshold and should thus be penalized.\nCommonly, classic sketch algorithms are considered sufficiently accurate for\nusage in DDoS defense. However, as we show in this paper, these algorithms\nachieve poor detection accuracy under burst-flood attacks, i.e., volumetric\nDDoS attacks composed of a swarm of medium-rate sub-second traffic bursts.\nUnder this challenging attack pattern, traditional sketch algorithms can only\ndetect a high share of the attack bursts by incurring a large number of false\npositives.\n  In this paper, we present ALBUS, a probabilistic monitoring algorithm that\novercomes the inherent limitations of previous schemes: ALBUS is highly\neffective at detecting large bursts while reporting no legitimate flows, and\ntherefore improves on prior work regarding both recall and precision. Besides\nimproving accuracy, ALBUS scales to high traffic rates, which we demonstrate\nwith an FPGA implementation, and is suitable for programmable switches, which\nwe showcase with a P4 implementation.\n","authors":["Simon Scherrer","Jo Vliegen","Arish Sateesan","Hsu-Chun Hsiao","Nele Mentens","Adrian Perrig"],"pdf_url":"https://arxiv.org/pdf/2306.14328v2.pdf","comment":"Accepted at the 42nd International Symposium on Reliable Distributed\n  Systems (SRDS 2023)"},{"id":"http://arxiv.org/abs/2307.03492v1","updated":"2023-07-07T10:01:08Z","published":"2023-07-07T10:01:08Z","title":"Large AI Model-Based Semantic Communications","summary":"  Semantic communication (SC) is an emerging intelligent paradigm, offering\nsolutions for various future applications like metaverse, mixed-reality, and\nthe Internet of everything. However, in current SC systems, the construction of\nthe knowledge base (KB) faces several issues, including limited knowledge\nrepresentation, frequent knowledge updates, and insecure knowledge sharing.\nFortunately, the development of the large AI model provides new solutions to\novercome above issues. Here, we propose a large AI model-based SC framework\n(LAM-SC) specifically designed for image data, where we first design the\nsegment anything model (SAM)-based KB (SKB) that can split the original image\ninto different semantic segments by universal semantic knowledge. Then, we\npresent an attention-based semantic integration (ASI) to weigh the semantic\nsegments generated by SKB without human participation and integrate them as the\nsemantic-aware image. Additionally, we propose an adaptive semantic compression\n(ASC) encoding to remove redundant information in semantic features, thereby\nreducing communication overhead. Finally, through simulations, we demonstrate\nthe effectiveness of the LAM-SC framework and the significance of the large AI\nmodel-based KB development in future SC paradigms.\n","authors":["Feibo Jiang","Yubo Peng","Li Dong","Kezhi Wang","Kun Yang","Cunhua Pan","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2307.03492v1.pdf","comment":"Plan to submit it to journal for possible publication"},{"id":"http://arxiv.org/abs/2307.00319v3","updated":"2023-07-07T08:28:47Z","published":"2023-07-01T12:10:18Z","title":"A Survey on Explainable AI for 6G O-RAN: Architecture, Use Cases,\n  Challenges and Research Directions","summary":"  The recent O-RAN specifications promote the evolution of RAN architecture by\nfunction disaggregation, adoption of open interfaces, and instantiation of a\nhierarchical closed-loop control architecture managed by RAN Intelligent\nControllers (RICs) entities. This paves the road to novel data-driven network\nmanagement approaches based on programmable logic. Aided by Artificial\nIntelligence (AI) and Machine Learning (ML), novel solutions targeting\ntraditionally unsolved RAN management issues can be devised. Nevertheless, the\nadoption of such smart and autonomous systems is limited by the current\ninability of human operators to understand the decision process of such AI/ML\nsolutions, affecting their trust in such novel tools. eXplainable AI (XAI) aims\nat solving this issue, enabling human users to better understand and\neffectively manage the emerging generation of artificially intelligent schemes,\nreducing the human-to-machine barrier. In this survey, we provide a summary of\nthe XAI methods and metrics before studying their deployment over the O-RAN\nAlliance RAN architecture along with its main building blocks. We then present\nvarious use-cases and discuss the automation of XAI pipelines for O-RAN as well\nas the underlying security aspects. We also review some projects/standards that\ntackle this area. Finally, we identify different challenges and research\ndirections that may arise from the heavy adoption of AI/ML decision entities in\nthis context, focusing on how XAI can help to interpret, understand, and\nimprove trust in O-RAN operational networks.\n","authors":["Bouziane Brik","Hatim Chergui","Lanfranco Zanzi","Francesco Devoti","Adlen Ksentini","Muhammad Shuaib Siddiqui","Xavier Costa-Pérez","Christos Verikoukis"],"pdf_url":"https://arxiv.org/pdf/2307.00319v3.pdf","comment":"33 pages, 13 figures"},{"id":"http://arxiv.org/abs/2203.02497v3","updated":"2023-07-07T07:50:33Z","published":"2022-03-04T18:52:43Z","title":"Computationally Efficient Worst-Case Analysis of Flow-Controlled\n  Networks with Network Calculus","summary":"  Networks with hop-by-hop flow control occur in several contexts, from data\ncenters to systems architectures (e.g., wormhole-routing networks on chip). A\nworst-case end-to-end delay in such networks can be computed using Network\nCalculus (NC), an algebraic theory where traffic and service guarantees are\nrepresented as curves in a Cartesian plane. NC uses transformation operations,\ne.g., the min-plus convolution, to model how the traffic profile changes with\nthe traversal of network nodes. NC allows one to model flow-controlled systems,\nhence one can compute the end-to-end service curve describing the minimum\nservice guaranteed to a flow traversing a tandem of flow-controlled nodes.\nHowever, while the algebraic expression of such an end-to-end service curve is\nquite compact, its computation is often intractable from an algorithmic\nstandpoint: data structures tend to grow quickly to unfeasibly large sizes,\nmaking operations intractable, even with as few as three hops. In this paper,\nwe propose computational and algebraic techniques to mitigate the above\nproblem. We show that existing techniques (such as reduction to compact\ndomains) cannot be used in this case, and propose an arsenal of solutions,\nwhich include methods to mitigate the data representation space explosion as\nwell as computationally efficient algorithms for the min-plus convolution\noperation. We show that our solutions allow a significant speedup, enable\nanalysis of previously unfeasible case studies, and -- since they do not rely\non any approximation -- still provide exact results.\n","authors":["Raffaele Zippo","Giovanni Stea"],"pdf_url":"https://arxiv.org/pdf/2203.02497v3.pdf","comment":"27 pages, 33 figures"},{"id":"http://arxiv.org/abs/2205.11449v2","updated":"2023-07-07T07:41:55Z","published":"2022-05-23T16:37:32Z","title":"Nancy: An efficient parallel Network Calculus library","summary":"  This paper describes Nancy, a Network Calculus (NC) library that allows users\nto perform complex min-plus and max-plus algebra operations efficiently. To the\nbest of our knowledge, Nancy is the only open-source library that implements\noperations working on arbitrary piecewise affine functions, as well as to\nimplement some of them (e.g. sub-additive closure and function composition).\nNancy allows researchers to compute NC results using a straightforward syntax,\nwhich matches the algebraic one. Moreover, it is designed having computational\nefficiency in mind: it exploits optimizations of data structures, it uses\ninheritance to allow for faster algorithms when they are available (e.g., for\nspecific subclasses of functions), and it is natively parallel, thus reaping\nthe benefit of multicore hardware. This makes it usable to solve NC problems\nwhich were previously considered beyond the realm of tractable.\n","authors":["Raffaele Zippo","Giovanni Stea"],"pdf_url":"https://arxiv.org/pdf/2205.11449v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03758v1","updated":"2023-07-07T02:14:46Z","published":"2023-07-07T02:14:46Z","title":"Federated Learning over a Wireless Network: Distributed User Selection\n  through Random Access","summary":"  User selection has become crucial for decreasing the communication costs of\nfederated learning (FL) over wireless networks. However, centralized user\nselection causes additional system complexity. This study proposes a network\nintrinsic approach of distributed user selection that leverages the radio\nresource competition mechanism in random access. Taking the carrier sensing\nmultiple access (CSMA) mechanism as an example of random access, we manipulate\nthe contention window (CW) size to prioritize certain users for obtaining radio\nresources in each round of training. Training data bias is used as a target\nscenario for FL with user selection. Prioritization is based on the distance\nbetween the newly trained local model and the global model of the previous\nround. To avoid excessive contribution by certain users, a counting mechanism\nis used to ensure fairness. Simulations with various datasets demonstrate that\nthis method can rapidly achieve convergence similar to that of the centralized\nuser selection approach.\n","authors":["Chen Sun","Shiyao Ma","Ce Zheng","Songtao Wu","Tao Cui","Lingjuan Lyu"],"pdf_url":"https://arxiv.org/pdf/2307.03758v1.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2307.03744v1","updated":"2023-07-07T17:53:07Z","published":"2023-07-07T17:53:07Z","title":"Comparing Traditional and LLM-based Search for Consumer Choice: A\n  Randomized Experiment","summary":"  Recent advances in the development of large language models are rapidly\nchanging how online applications function. LLM-based search tools, for\ninstance, offer a natural language interface that can accommodate complex\nqueries and provide detailed, direct responses. At the same time, there have\nbeen concerns about the veracity of the information provided by LLM-based tools\ndue to potential mistakes or fabrications that can arise in algorithmically\ngenerated text. In a set of online experiments we investigate how LLM-based\nsearch changes people's behavior relative to traditional search, and what can\nbe done to mitigate overreliance on LLM-based output. Participants in our\nexperiments were asked to solve a series of decision tasks that involved\nresearching and comparing different products, and were randomly assigned to do\nso with either an LLM-based search tool or a traditional search engine. In our\nfirst experiment, we find that participants using the LLM-based tool were able\nto complete their tasks more quickly, using fewer but more complex queries than\nthose who used traditional search. Moreover, these participants reported a more\nsatisfying experience with the LLM-based search tool. When the information\npresented by the LLM was reliable, participants using the tool made decisions\nwith a comparable level of accuracy to those using traditional search, however\nwe observed overreliance on incorrect information when the LLM erred. Our\nsecond experiment further investigated this issue by randomly assigning some\nusers to see a simple color-coded highlighting scheme to alert them to\npotentially incorrect or misleading information in the LLM responses. Overall\nwe find that this confidence-based highlighting substantially increases the\nrate at which users spot incorrect information, improving the accuracy of their\noverall decisions while leaving most other measures unaffected.\n","authors":["Sofia Eleni Spatharioti","David M. Rothschild","Daniel G. Goldstein","Jake M. Hofman"],"pdf_url":"https://arxiv.org/pdf/2307.03744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03733v1","updated":"2023-07-07T17:36:58Z","published":"2023-07-07T17:36:58Z","title":"\"How Did They Come Across?\" Lessons Learned from Continuous Affective\n  Ratings","summary":"  Social distance, or perception of the other, is recognized as a dynamic\ndimension of an interaction, but yet to be widely explored or understood.\nThrough CORAE, a novel web-based open-source tool for COntinuous Retrospective\nAffect Evaluation, we collected retrospective ratings of interpersonal\nperceptions between 12 participant dyads. In this work, we explore how\ndifferent aspects of these interactions reflect on the ratings collected,\nthrough a discourse analysis of individual and social behavior of the\ninteractants. We found that different events observed in the ratings can be\nmapped to complex interaction phenomena, shedding light on relevant interaction\nfeatures that may play a role in interpersonal understanding and grounding.\nThis paves the way for better, more seamless human-robot interactions, where\naffect is interpreted as highly dynamic and contingent on interaction history.\n","authors":["Maria Teresa Parreira","Michael J. Sack","Hifza Javed","Nawid Jamali","Malte Jung"],"pdf_url":"https://arxiv.org/pdf/2307.03733v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2306.16629"},{"id":"http://arxiv.org/abs/2307.03638v1","updated":"2023-07-07T14:57:34Z","published":"2023-07-07T14:57:34Z","title":"Physical-aware Cross-modal Adversarial Network for Wearable Sensor-based\n  Human Action Recognition","summary":"  Wearable sensor-based Human Action Recognition (HAR) has made significant\nstrides in recent times. However, the accuracy performance of wearable\nsensor-based HAR is currently still lagging behind that of visual\nmodalities-based systems, such as RGB video and depth data. Although diverse\ninput modalities can provide complementary cues and improve the accuracy\nperformance of HAR, wearable devices can only capture limited kinds of\nnon-visual time series input, such as accelerometers and gyroscopes. This\nlimitation hinders the deployment of multimodal simultaneously using visual and\nnon-visual modality data in parallel on current wearable devices. To address\nthis issue, we propose a novel Physical-aware Cross-modal Adversarial (PCA)\nframework that utilizes only time-series accelerometer data from four inertial\nsensors for the wearable sensor-based HAR problem. Specifically, we propose an\neffective IMU2SKELETON network to produce corresponding synthetic skeleton\njoints from accelerometer data. Subsequently, we imposed additional constraints\non the synthetic skeleton data from a physical perspective, as accelerometer\ndata can be regarded as the second derivative of the skeleton sequence\ncoordinates. After that, the original accelerometer as well as the constrained\nskeleton sequence were fused together to make the final classification. In this\nway, when individuals wear wearable devices, the devices can not only capture\naccelerometer data, but can also generate synthetic skeleton sequences for\nreal-time wearable sensor-based HAR applications that need to be conducted\nanytime and anywhere. To demonstrate the effectiveness of our proposed PCA\nframework, we conduct extensive experiments on Berkeley-MHAD, UTD-MHAD, and\nMMAct datasets. The results confirm that the proposed PCA approach has\ncompetitive performance compared to the previous methods on the mono\nsensor-based HAR classification problem.\n","authors":["Jianyuan Ni","Hao Tang","Anne H. H. Ngu","Gaowen Liu","Yan Yan"],"pdf_url":"https://arxiv.org/pdf/2307.03638v1.pdf","comment":"First IMU2SKELETON GANs approach for wearable HAR problem. arXiv\n  admin note: text overlap with arXiv:2208.08090"},{"id":"http://arxiv.org/abs/2307.03609v1","updated":"2023-07-07T14:02:48Z","published":"2023-07-07T14:02:48Z","title":"To Patch, or not To Patch? That is the Question: A Case Study of System\n  Administrators' Online Collaborative Behaviour","summary":"  System administrators, similar to end users, may delay or avoid software\npatches, also known as updates, despite the impact their timely application can\nhave on system security. These admins are responsible for large, complex,\namalgamated systems and must balance the security related needs of their\norganizations, which would benefit from the patch, with the need to ensure that\nsystems must continue to run unimpeded. In this paper, we present a case study\nwhich follows the online life-cycle of a pair of Microsoft patches. We find\nthat communities of sysadmins have evolved sophisticated mechanisms to perform\nrisk assessments that are centred around collecting, synthesizing, and\ngenerating information on patches. These communities span different Virtual\nCommunities of Practice, as well as influencers who monitor and report on the\nimpact of new patches. As information is propagated and aggregated across\nblogs, forums, web sites, and mailing lists, eventually resulting in a\nconsensus around the risk of a patch. Our findings highlight the role that\nthese communities play in informing risk management decisions: Patch\ninformation is not static, and it transforms as communities collaborate to\nunderstand patch issues.\n","authors":["Adam Jenkins","Maria Wolters","Kami Vaniea"],"pdf_url":"https://arxiv.org/pdf/2307.03609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03586v1","updated":"2023-07-07T13:28:29Z","published":"2023-07-07T13:28:29Z","title":"ContextLabeler Dataset: physical and virtual sensors data collected from\n  smartphone usage in-the-wild","summary":"  This paper describes a data collection campaign and the resulting dataset\nderived from smartphone sensors characterizing the daily life activities of 3\nvolunteers in a period of two weeks. The dataset is released as a collection of\nCSV files containing more than 45K data samples, where each sample is composed\nby 1332 features related to a heterogeneous set of physical and virtual\nsensors, including motion sensors, running applications, devices in proximity,\nand weather conditions. Moreover, each data sample is associated with a ground\ntruth label that describes the user activity and the situation in which she was\ninvolved during the sensing experiment (e.g., working, at restaurant, and doing\nsport activity). To avoid introducing any bias during the data collection, we\nperformed the sensing experiment in-the-wild, that is, by using the volunteers'\ndevices, and without defining any constraint related to the user's behavior.\nFor this reason, the collected dataset represents a useful source of real data\nto both define and evaluate a broad set of novel context-aware solutions (both\nalgorithms and protocols) that aim to adapt their behavior according to the\nchanges in the user's situation in a mobile environment.\n","authors":["Mattia Giovanni Campana","Franca Delmastro"],"pdf_url":"https://arxiv.org/pdf/2307.03586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03524v1","updated":"2023-07-07T11:20:57Z","published":"2023-07-07T11:20:57Z","title":"Investigating Perceived and Mechanical Challenge in Games Through\n  Cognitive Activity","summary":"  Game difficulty is a crucial aspect of game design, that can be directly\ninfluenced by tweaking game mechanics. Perceived difficulty can however also be\ninfluenced by simply altering the graphics to something more threatening. Here,\nwe present a study with 12 participants playing 4 different minigames with\neither altered graphics or mechanics to make the game more difficult. Using EEG\nbandpower analysis, we find that frontal lobe activity is heightened in all 4\nof the mechanically challenging versions and 2/4 of the visually altered\nversions, all differences that do not emerge from the self-reported player\nexperience. This suggests that EEG could aid researchers with a more sensitive\ntool for investigating challenge in games.\n","authors":["Christine Hegedues","Joao Pedro Dias Constantino","Laurits Dixen","Paolo Burelli"],"pdf_url":"https://arxiv.org/pdf/2307.03524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03351v1","updated":"2023-07-07T02:18:17Z","published":"2023-07-07T02:18:17Z","title":"Augmented Reality for Maintenance Tasks with ChatGPT for Automated\n  Text-to-Action","summary":"  Advancements in sensor technology, artificial intelligence (AI), and\naugmented reality (AR) have unlocked opportunities across various domains. AR\nand large language models like GPT have witnessed substantial progress and are\nincreasingly being employed in diverse fields. One such promising application\nis in operations and maintenance (O&M). O&M tasks often involve complex\nprocedures and sequences that can be challenging to memorize and execute\ncorrectly, particularly for novices or under high-stress situations. By\nmarrying the advantages of superimposing virtual objects onto the physical\nworld, and generating human-like text using GPT, we can revolutionize O&M\noperations. This study introduces a system that combines AR, Optical Character\nRecognition (OCR), and the GPT language model to optimize user performance\nwhile offering trustworthy interactions and alleviating workload in O&M tasks.\nThis system provides an interactive virtual environment controlled by the Unity\ngame engine, facilitating a seamless interaction between virtual and physical\nrealities. A case study (N=15) is conducted to illustrate the findings and\nanswer the research questions. The results indicate that users can complete\nsimilarly challenging tasks in less time using our proposed AR and AI system.\nMoreover, the collected data also suggests a reduction in cognitive load and an\nincrease in trust when executing the same operations using the AR and AI\nsystem.\n","authors":["Fang Xu","Tri Nguyen","Jing Du"],"pdf_url":"https://arxiv.org/pdf/2307.03351v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2307.03338v1","updated":"2023-07-07T00:45:25Z","published":"2023-07-07T00:45:25Z","title":"Deciphering the Drivers of Smart Livestock Technology Adoption in Japan:\n  A Scoping Review, Expert Interviews, and Grounded Theory Approach","summary":"  With global demand for animal products projected to increase significantly by\n2050, understanding the factors that influence the adoption of smart livestock\ntechnologies has become increasingly crucial. Conducted within the unique\nagricultural context of Japan, our study builds upon traditional theoretical\nframeworks that often oversimplify farmers' decision-making processes. By\nemploying a scoping review, expert interviews, and a Modified Grounded Theory\nApproach, our research uncovers the intricate interplay between individual\nfarmer values, farm management policies, social relations, agricultural\npolicies, and livestock industry trends. We particularly highlight the unique\ndynamics within family-owned businesses, noting the tension between an\n\"advanced management mindset\" and \"conservatism.\" Our study underscores\ntechnology adoption's sequential and iterative nature, intricately tied to\ntechnology availability, farmers' digital literacy, technology implementation\nsupport, and observable technology impacts on animal health and productivity.\nDespite certain limitations, our findings carry profound implications for\nstakeholders, providing valuable insights to overcome adoption barriers and\nadvocating for more sustainable, efficient, and animal welfare-oriented\nlivestock production systems. This research establishes a solid foundation for\nfuture explorations into smart livestock technology adoption.\n","authors":["Takumi Ohashi","Miki Saijo","Kento Suzuki","Shinsuke Arafuka"],"pdf_url":"https://arxiv.org/pdf/2307.03338v1.pdf","comment":"56 pages, 3 figures"},{"id":"http://arxiv.org/abs/2307.02288v2","updated":"2023-07-07T00:43:00Z","published":"2023-07-05T13:40:57Z","title":"Performance Comparison of Large Language Models on VNHSGE English\n  Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard","summary":"  This paper presents a performance comparison of three large language models\n(LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard, on the\nVNHSGE English dataset. The results show that BingChat is better than ChatGPT\nand Bard. Therefore, BingChat and Bard can replace ChatGPT while ChatGPT is not\nyet officially available in Vietnam. The results also indicate that ChatGPT,\nBing Chat, and Bard outperform Vietnamese students in English language\nproficiency. The findings of this study contribute to the understanding of the\npotential of LLMs in English language education. The remarkable performance of\nChatGPT, Bing Chat, and Bard demonstrates their potential as effective tools\nfor teaching and learning English at the high school level.\n","authors":["Xuan-Quy Dao"],"pdf_url":"https://arxiv.org/pdf/2307.02288v2.pdf","comment":"11 pages, 8 figures. arxiv admin note: substantial text overlap with\n  arXiv: 2305.12199"},{"id":"http://arxiv.org/abs/2307.03336v1","updated":"2023-07-07T00:38:40Z","published":"2023-07-07T00:38:40Z","title":"DIG: The Data Interface Grammar","summary":"  Building interactive data interfaces is hard because the design of an\ninterface depends on the data processing needs for the underlying analysis\ntask, yet we do not have a good representation for analysis tasks. To fill this\ngap, this paper advocates for a Data Interface Grammar (DIG) as an intermediate\nrepresentation of analysis tasks. We show that DIG is compatible with existing\ndata engineering practices, compact to represent any analysis, simple to\ntranslate into an interface design, and amenable to offline analysis. We\nfurther illustrate the potential benefits of this abstraction, such as\nautomatic interface generation, automatic interface backend optimization,\ntutorial generation, and workload generation.\n","authors":["Yiru Chen","Jeffery Tao","Eugene Wu"],"pdf_url":"https://arxiv.org/pdf/2307.03336v1.pdf","comment":"7 pages, Workshop on Human-In-the-Loop Data Analytics(HILDA) at\n  SIGMOD 2023"},{"id":"http://arxiv.org/abs/2306.00919v2","updated":"2023-07-07T00:04:18Z","published":"2023-06-01T17:20:56Z","title":"Understanding Social Context from Smartphone Sensing: Generalization\n  Across Countries and Daily Life Moments","summary":"  Understanding and longitudinally tracking the social context of people help\nin understanding their behavior and mental well-being better. Hence, instead of\nburdensome questionnaires, some studies used passive smartphone sensors to\ninfer social context with machine learning models. However, the few studies\nthat have been done up to date have focused on unique, situated contexts (i.e.,\nwhen eating or drinking) in one or two countries, hence limiting the\nunderstanding of the inference in terms of generalization to (i) everyday life\noccasions and (ii) different countries. In this paper, we used a novel,\nlarge-scale, and multimodal smartphone sensing dataset with over 216K\nself-reports collected from over 580 participants in five countries (Mongolia,\nItaly, Denmark, UK, Paraguay), first to understand whether social context\ninference (i.e., alone or not) is feasible with sensor data, and then, to know\nhow behavioral and country-level diversity affects the inference. We found that\n(i) sensor features from modalities such as activity, location, app usage,\nBluetooth, and WiFi could be informative of social context; (ii) partially\npersonalized multi-country models (trained and tested with data from all\ncountries) and country-specific models (trained and tested within countries)\nachieved similar accuracies in the range of 80%-90%; and (iii) models do not\ngeneralize well to unseen countries regardless of geographic similarity.\n","authors":["Aurel Ruben Mader","Lakmal Meegahapola","Daniel Gatica-Perez"],"pdf_url":"https://arxiv.org/pdf/2306.00919v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03853v1","updated":"2023-07-07T21:58:28Z","published":"2023-07-07T21:58:28Z","title":"Teach Me How to Learn: A Perspective Review towards User-centered\n  Neuro-symbolic Learning for Robotic Surgical Systems","summary":"  Recent advances in machine learning models allowed robots to identify objects\non a perceptual nonsymbolic level (e.g., through sensor fusion and natural\nlanguage understanding). However, these primarily black-box learning models\nstill lack interpretation and transferability and require high data and\ncomputational demand. An alternative solution is to teach a robot on both\nperceptual nonsymbolic and conceptual symbolic levels through hybrid\nneurosymbolic learning approaches with expert feedback (i.e., human-in-the-loop\nlearning). This work proposes a concept for this user-centered hybrid learning\nparadigm that focuses on robotic surgical situations. While most recent\nresearch focused on hybrid learning for non-robotic and some generic robotic\ndomains, little work focuses on surgical robotics. We survey this related\nresearch while focusing on human-in-the-loop surgical robotic systems. This\nevaluation highlights the most prominent solutions for autonomous surgical\nrobots and the challenges surgeons face when interacting with these systems.\nFinally, we envision possible ways to address these challenges using online\napprenticeship learning based on implicit and explicit feedback from expert\nsurgeons.\n","authors":["Amr Gomaa","Bilal Mahdy","Niko Kleer","Michael Feld","Frank Kirchner","Antonio Krüger"],"pdf_url":"https://arxiv.org/pdf/2307.03853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03826v1","updated":"2023-07-07T20:41:26Z","published":"2023-07-07T20:41:26Z","title":"How does AI chat change search behaviors?","summary":"  Generative AI tools such as chatGPT are poised to change the way people\nengage with online information. Recently, Microsoft announced their \"new Bing\"\nsearch system which incorporates chat and generative AI technology from OpenAI.\nGoogle has announced plans to deploy search interfaces that incorporate similar\ntypes of technology. These new technologies will transform how people can\nsearch for information. The research presented here is an early investigation\ninto how people make use of a generative AI chat system (referred to simply as\nchat from here on) as part of a search process, and how the incorporation of\nchat systems with existing search tools may effect users search behaviors and\nstrategies.\n  We report on an exploratory user study with 10 participants who used a\ncombined Chat+Search system that utilized the OpenAI GPT-3.5 API and the Bing\nWeb Search v5 API. Participants completed three search tasks. In this pre-print\npaper of preliminary results, we report on ways that users integrated AI chat\ninto their search process, things they liked and disliked about the chat\nsystem, their trust in the chat responses, and their mental models of how the\nchat system generated responses.\n","authors":["Robert Capra","Jaime Arguello"],"pdf_url":"https://arxiv.org/pdf/2307.03826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03802v1","updated":"2023-07-07T19:08:59Z","published":"2023-07-07T19:08:59Z","title":"Student Teacher Interaction While Learning Computer Science: Early\n  Results from an Experiment on Undergraduates","summary":"  The scope of this paper was to find out how the students in Computer Science\nperceive different teaching styles and how the teaching style impacts the\nlearning desire and interest in the course. To find out, we designed and\nimplemented an experiment in which the same groups of students (86 students)\nwere exposed to different teaching styles (presented by the same teacher at a\ndifference of two weeks between lectures). We tried to minimize external\nfactors' impact by carefully selecting the dates (close ones), having the\ncourses in the same classroom and on the same day of the week, at the same\nhour, and checking the number and the complexity of the introduced items to be\ncomparable. We asked for students' feedback and we define a set of countable\nbody signs for their involvement in the course. The results were comparable by\nboth metrics (body language) and text analysis results, students prefer a more\ninteractive course, with a relaxing atmosphere, and are keener to learn in\nthese conditions.\n","authors":["Manuela Petrescu","Kuderna Bentasup"],"pdf_url":"https://arxiv.org/pdf/2307.03802v1.pdf","comment":"CSEDU 2023, 15th International Conference on Computer Supported\n  Education"},{"id":"http://arxiv.org/abs/2306.05725v2","updated":"2023-07-07T18:05:27Z","published":"2023-06-09T07:45:57Z","title":"Privacy, Security, and Usability Tradeoffs of Telehealth from\n  Practitioners' Perspectives","summary":"  The COVID-19 pandemic has significantly transformed the healthcare sector,\nwith telehealth services being among the most prominent changes. The adoption\nof telehealth services, however, has raised new challenges, particularly in the\nareas of security and privacy. To better comprehend the telehealth needs and\nconcerns of medical professionals, particularly those in private practice, we\nconducted a study comprised of 20 semi-structured interviews with telehealth\npractitioners in audiology and speech therapy. Our findings indicate that\nprivate telehealth practitioners encounter difficult choices when it comes to\nbalancing security, privacy, usability, and accessibility, particularly while\ncaring for vulnerable populations. Additionally, the study revealed that\npractitioners face challenges in ensuring HIPAA compliance due to inadequate\nresources and a lack of technological comprehension. Policymakers and\nhealthcare providers should take proactive measures to address these\nchallenges, including offering resources and training to ensure HIPAA\ncompliance and enhancing technology infrastructure to support secure and\naccessible telehealth.\n","authors":["Faiza Tazi","Archana Nandakumar","Josiah Dykstra","Prashanth Rajivan","Sanchari Das"],"pdf_url":"https://arxiv.org/pdf/2306.05725v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05518v1","updated":"2023-07-07T11:14:53Z","published":"2023-07-07T11:14:53Z","title":"Procedurally generating rules to adapt difficulty for narrative puzzle\n  games","summary":"  This paper focuses on procedurally generating rules and communicating them to\nplayers to adjust the difficulty. This is part of a larger project to collect\nand adapt games in educational games for young children using a digital puzzle\ngame designed for kindergarten. A genetic algorithm is used together with a\ndifficulty measure to find a target number of solution sets and a large\nlanguage model is used to communicate the rules in a narrative context. During\ntesting the approach was able to find rules that approximate any given target\ndifficulty within two dozen generations on average. The approach was combined\nwith a large language model to create a narrative puzzle game where players\nhave to host a dinner for animals that can't get along. Future experiments will\ntry to improve evaluation, specialize the language model on children's\nliterature, and collect multi-modal data from players to guide adaptation.\n","authors":["Thomas Volden","Djordje Grbic","Paolo Burelli"],"pdf_url":"https://arxiv.org/pdf/2307.05518v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2307.03750v1","updated":"2023-07-07T17:59:20Z","published":"2023-07-07T17:59:20Z","title":"When does the ID algorithm fail?","summary":"  The ID algorithm solves the problem of identification of interventional\ndistributions of the form p(Y | do(a)) in graphical causal models, and has been\nformulated in a number of ways [12, 9, 6]. The ID algorithm is sound (outputs\nthe correct functional of the observed data distribution whenever p(Y | do(a))\nis identified in the causal model represented by the input graph), and complete\n(explicitly flags as a failure any input p(Y | do(a)) whenever this\ndistribution is not identified in the causal model represented by the input\ngraph).\n  The reference [9] provides a result, the so called \"hedge criterion\"\n(Corollary 3), which aims to give a graphical characterization of situations\nwhen the ID algorithm fails to identify its input in terms of a structure in\nthe input graph called the hedge. While the ID algorithm is, indeed, a sound\nand complete algorithm, and the hedge structure does arise whenever the input\ndistribution is not identified, Corollary 3 presented in [9] is incorrect as\nstated. In this note, I outline the modern presentation of the ID algorithm,\ndiscuss a simple counterexample to Corollary 3, and provide a number of\ngraphical characterizations of the ID algorithm failing to identify its input\ndistribution.\n","authors":["Ilya Shpitser"],"pdf_url":"https://arxiv.org/pdf/2307.03750v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2108.06818"},{"id":"http://arxiv.org/abs/2307.02792v2","updated":"2023-07-07T17:56:39Z","published":"2023-07-06T06:07:29Z","title":"What Should Data Science Education Do with Large Language Models?","summary":"  The rapid advances of large language models (LLMs), such as ChatGPT, are\nrevolutionizing data science and statistics. These state-of-the-art tools can\nstreamline complex processes. As a result, it reshapes the role of data\nscientists. We argue that LLMs are transforming the responsibilities of data\nscientists, shifting their focus from hands-on coding, data-wrangling and\nconducting standard analyses to assessing and managing analyses performed by\nthese automated AIs. This evolution of roles is reminiscent of the transition\nfrom a software engineer to a product manager. We illustrate this transition\nwith concrete data science case studies using LLMs in this paper. These\ndevelopments necessitate a meaningful evolution in data science education.\nPedagogy must now place greater emphasis on cultivating diverse skillsets among\nstudents, such as LLM-informed creativity, critical thinking, AI-guided\nprogramming. LLMs can also play a significant role in the classroom as\ninteractive teaching and learning tools, contributing to personalized\neducation. This paper discusses the opportunities, resources and open\nchallenges for each of these directions. As with any transformative technology,\nintegrating LLMs into education calls for careful consideration. While LLMs can\nperform repetitive tasks efficiently, it's crucial to remember that their role\nis to supplement human intelligence and creativity, not to replace it.\nTherefore, the new era of data science education should balance the benefits of\nLLMs while fostering complementary human expertise and innovations. In\nconclusion, the rise of LLMs heralds a transformative period for data science\nand its education. This paper seeks to shed light on the emerging trends,\npotential opportunities, and challenges accompanying this paradigm shift,\nhoping to spark further discourse and investigation into this exciting,\nuncharted territory.\n","authors":["Xinming Tu","James Zou","Weijie J. Su","Linjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.02792v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11498v2","updated":"2023-07-07T17:20:25Z","published":"2022-12-22T06:18:41Z","title":"Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with\n  Robotic and Human Co-Workers","summary":"  We envision a warehouse in which dozens of mobile robots and human pickers\nwork together to collect and deliver items within the warehouse. The\nfundamental problem we tackle, called the order-picking problem, is how these\nworker agents must coordinate their movement and actions in the warehouse to\nmaximise performance (e.g. order throughput). Established industry methods\nusing heuristic approaches require large engineering efforts to optimise for\ninnately variable warehouse configurations. In contrast, multi-agent\nreinforcement learning (MARL) can be flexibly applied to diverse warehouse\nconfigurations (e.g. size, layout, number/types of workers, item replenishment\nfrequency), as the agents learn through experience how to optimally cooperate\nwith one another. We develop hierarchical MARL algorithms in which a manager\nassigns goals to worker agents, and the policies of the manager and workers are\nco-trained toward maximising a global objective (e.g. pick rate). Our\nhierarchical algorithms achieve significant gains in sample efficiency and\noverall pick rates over baseline MARL algorithms in diverse warehouse\nconfigurations, and substantially outperform two established industry\nheuristics for order-picking systems.\n","authors":["Aleksandar Krnjaic","Raul D. Steleac","Jonathan D. Thomas","Georgios Papoudakis","Lukas Schäfer","Andrew Wing Keung To","Kuan-Ho Lao","Murat Cubuktepe","Matthew Haley","Peter Börsting","Stefano V. Albrecht"],"pdf_url":"https://arxiv.org/pdf/2212.11498v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.09836v2","updated":"2023-07-07T17:09:00Z","published":"2021-12-18T03:45:28Z","title":"Creativity of AI: Hierarchical Planning Model Learning for Facilitating\n  Deep Reinforcement Learning","summary":"  Despite of achieving great success in real-world applications, Deep\nReinforcement Learning (DRL) is still suffering from three critical issues,\ni.e., data efficiency, lack of the interpretability and transferability. Recent\nresearch shows that embedding symbolic knowledge into DRL is promising in\naddressing those challenges. Inspired by this, we introduce a novel deep\nreinforcement learning framework with symbolic options. Our framework features\na loop training procedure, which enables guiding the improvement of policy by\nplanning with planning models (including action models and hierarchical task\nnetwork models) and symbolic options learned from interactive trajectories\nautomatically. The learned symbolic options alleviate the dense requirement of\nexpert domain knowledge and provide inherent interpretability of policies.\nMoreover, the transferability and data efficiency can be further improved by\nplanning with the symbolic planning models. To validate the effectiveness of\nour framework, we conduct experiments on two domains, Montezuma's Revenge and\nOffice World, respectively. The results demonstrate the comparable performance,\nimproved data efficiency, interpretability and transferability.\n","authors":["Hankz Hankui Zhuo","Shuting Deng","Mu Jin","Zhihao Ma","Kebing Jin","Chen Chen","Chao Yu"],"pdf_url":"https://arxiv.org/pdf/2112.09836v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03705v1","updated":"2023-07-07T16:30:50Z","published":"2023-07-07T16:30:50Z","title":"Intelligent Robotic Sonographer: Mutual Information-based Disentangled\n  Reward Learning from Few Demonstrations","summary":"  Ultrasound (US) imaging is widely used for biometric measurement and\ndiagnosis of internal organs due to the advantages of being real-time and\nradiation-free. However, due to high inter-operator variability, resulting\nimages highly depend on operators' experience. In this work, an intelligent\nrobotic sonographer is proposed to autonomously \"explore\" target anatomies and\nnavigate a US probe to a relevant 2D plane by learning from expert. The\nunderlying high-level physiological knowledge from experts is inferred by a\nneural reward function, using a ranked pairwise image comparisons approach in a\nself-supervised fashion. This process can be referred to as understanding the\n\"language of sonography\". Considering the generalization capability to overcome\ninter-patient variations, mutual information is estimated by a network to\nexplicitly extract the task-related and domain features in latent space.\nBesides, a Gaussian distribution-based filter is developed to automatically\nevaluate and take the quality of the expert's demonstrations into account. The\nrobotic localization is carried out in coarse-to-fine mode based on the\npredicted reward associated to B-mode images. To demonstrate the performance of\nthe proposed approach, representative experiments for the \"line\" target and\n\"point\" target are performed on vascular phantom and two ex-vivo animal organ\nphantoms (chicken heart and lamb kidney), respectively. The results\ndemonstrated that the proposed advanced framework can robustly work on\ndifferent kinds of known and unseen phantoms.\n","authors":["Zhongliang Jiang","Yuan Bi","Mingchuan Zhou","Ying Hu","Michael Burke","and Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2307.03705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03699v1","updated":"2023-07-07T16:15:59Z","published":"2023-07-07T16:15:59Z","title":"Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug\n  Trafficking Detection on Social Media","summary":"  Social media platforms such as Instagram and Twitter have emerged as critical\nchannels for drug marketing and illegal sale. Detecting and labeling online\nillicit drug trafficking activities becomes important in addressing this issue.\nHowever, the effectiveness of conventional supervised learning methods in\ndetecting drug trafficking heavily relies on having access to substantial\namounts of labeled data, while data annotation is time-consuming and\nresource-intensive. Furthermore, these models often face challenges in\naccurately identifying trafficking activities when drug dealers use deceptive\nlanguage and euphemisms to avoid detection. To overcome this limitation, we\nconduct the first systematic study on leveraging large language models (LLMs),\nsuch as ChatGPT, to detect illicit drug trafficking activities on social media.\nWe propose an analytical framework to compose \\emph{knowledge-informed\nprompts}, which serve as the interface that humans can interact with and use\nLLMs to perform the detection task. Additionally, we design a Monte Carlo\ndropout based prompt optimization method to further to improve performance and\ninterpretability. Our experimental findings demonstrate that the proposed\nframework outperforms other baseline language models in terms of drug\ntrafficking detection accuracy, showing a remarkable improvement of nearly\n12\\%. By integrating prior knowledge and the proposed prompts, ChatGPT can\neffectively identify and label drug trafficking activities on social networks,\neven in the presence of deceptive language and euphemisms used by drug dealers\nto evade detection. The implications of our research extend to social networks,\nemphasizing the importance of incorporating prior knowledge and scenario-based\nprompts into analytical tools to improve online security and public safety.\n","authors":["Chuanbo Hu","Bin Liu","Xin Li","Yanfang Ye"],"pdf_url":"https://arxiv.org/pdf/2307.03699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03694v1","updated":"2023-07-07T16:07:00Z","published":"2023-07-07T16:07:00Z","title":"Scalable Membership Inference Attacks via Quantile Regression","summary":"  Membership inference attacks are designed to determine, using black box\naccess to trained models, whether a particular example was used in training or\nnot. Membership inference can be formalized as a hypothesis testing problem.\nThe most effective existing attacks estimate the distribution of some test\nstatistic (usually the model's confidence on the true label) on points that\nwere (and were not) used in training by training many \\emph{shadow models} --\ni.e. models of the same architecture as the model being attacked, trained on a\nrandom subsample of data. While effective, these attacks are extremely\ncomputationally expensive, especially when the model under attack is large.\n  We introduce a new class of attacks based on performing quantile regression\non the distribution of confidence scores induced by the model under attack on\npoints that are not used in training. We show that our method is competitive\nwith state-of-the-art shadow model attacks, while requiring substantially less\ncompute because our attack requires training only a single model. Moreover,\nunlike shadow model attacks, our proposed attack does not require any knowledge\nof the architecture of the model under attack and is therefore truly\n``black-box\". We show the efficacy of this approach in an extensive series of\nexperiments on various datasets and model architectures.\n","authors":["Martin Bertran","Shuai Tang","Michael Kearns","Jamie Morgenstern","Aaron Roth","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2307.03694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06489v3","updated":"2023-07-07T15:55:35Z","published":"2022-11-11T21:58:15Z","title":"Equivariance with Learned Canonicalization Functions","summary":"  Symmetry-based neural networks often constrain the architecture in order to\nachieve invariance or equivariance to a group of transformations. In this\npaper, we propose an alternative that avoids this architectural constraint by\nlearning to produce canonical representations of the data. These\ncanonicalization functions can readily be plugged into non-equivariant backbone\narchitectures. We offer explicit ways to implement them for some groups of\ninterest. We show that this approach enjoys universality while providing\ninterpretable insights. Our main hypothesis, supported by our empirical\nresults, is that learning a small neural network to perform canonicalization is\nbetter than using predefined heuristics. Our experiments show that learning the\ncanonicalization function is competitive with existing techniques for learning\nequivariant functions across many tasks, including image classification,\n$N$-body dynamics prediction, point cloud classification and part segmentation,\nwhile being faster across the board.\n","authors":["Sékou-Oumar Kaba","Arnab Kumar Mondal","Yan Zhang","Yoshua Bengio","Siamak Ravanbakhsh"],"pdf_url":"https://arxiv.org/pdf/2211.06489v3.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2307.03659v1","updated":"2023-07-07T15:26:03Z","published":"2023-07-07T15:26:03Z","title":"Decomposing the Generalization Gap in Imitation Learning for Visual\n  Robotic Manipulation","summary":"  What makes generalization hard for imitation learning in visual robotic\nmanipulation? This question is difficult to approach at face value, but the\nenvironment from the perspective of a robot can often be decomposed into\nenumerable factors of variation, such as the lighting conditions or the\nplacement of the camera. Empirically, generalization to some of these factors\nhave presented a greater obstacle than others, but existing work sheds little\nlight on precisely how much each factor contributes to the generalization gap.\nTowards an answer to this question, we study imitation learning policies in\nsimulation and on a real robot language-conditioned manipulation task to\nquantify the difficulty of generalization to different (sets of) factors. We\nalso design a new simulated benchmark of 19 tasks with 11 factors of variation\nto facilitate more controlled evaluations of generalization. From our study, we\ndetermine an ordering of factors based on generalization difficulty, that is\nconsistent across simulation and our real robot setup.\n","authors":["Annie Xie","Lisa Lee","Ted Xiao","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2307.03659v1.pdf","comment":"Project webpage at https://sites.google.com/view/generalization-gap"},{"id":"http://arxiv.org/abs/2307.03637v1","updated":"2023-07-07T14:51:30Z","published":"2023-07-07T14:51:30Z","title":"Discovering Variable Binding Circuitry with Desiderata","summary":"  Recent work has shown that computation in language models may be\nhuman-understandable, with successful efforts to localize and intervene on both\nsingle-unit features and input-output circuits. Here, we introduce an approach\nwhich extends causal mediation experiments to automatically identify model\ncomponents responsible for performing a specific subtask by solely specifying a\nset of \\textit{desiderata}, or causal attributes of the model components\nexecuting that subtask. As a proof of concept, we apply our method to\nautomatically discover shared \\textit{variable binding circuitry} in LLaMA-13B,\nwhich retrieves variable values for multiple arithmetic tasks. Our method\nsuccessfully localizes variable binding to only 9 attention heads (of the 1.6k)\nand one MLP in the final token's residual stream.\n","authors":["Xander Davies","Max Nadeau","Nikhil Prakash","Tamar Rott Shaham","David Bau"],"pdf_url":"https://arxiv.org/pdf/2307.03637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09495v2","updated":"2023-07-07T13:44:03Z","published":"2022-08-19T18:13:27Z","title":"Topical: Learning Repository Embeddings from Source Code using Attention","summary":"  Machine learning on source code (MLOnCode) promises to transform how software\nis delivered. By mining the context and relationship between software\nartefacts, MLOnCode augments the software developers capabilities with code\nauto-generation, code recommendation, code auto-tagging and other data-driven\nenhancements. For many of these tasks a script level representation of code is\nsufficient, however, in many cases a repository level representation that takes\ninto account various dependencies and repository structure is imperative, for\nexample, auto-tagging repositories with topics or auto-documentation of\nrepository code etc. Existing methods for computing repository level\nrepresentations suffer from (a) reliance on natural language documentation of\ncode (for example, README files) (b) naive aggregation of method/script-level\nrepresentation, for example, by concatenation or averaging. This paper\nintroduces Topical a deep neural network to generate repository level\nembeddings of publicly available GitHub code repositories directly from source\ncode. Topical incorporates an attention mechanism that projects the source\ncode, the full dependency graph and the script level textual information into a\ndense repository-level representation. To compute the repository-level\nrepresentations, Topical is trained to predict the topics associated with a\nrepository, on a dataset of publicly available GitHub repositories that were\ncrawled along with their ground truth topic tags. Our experiments show that the\nembeddings computed by Topical are able to outperform multiple baselines,\nincluding baselines that naively combine the method-level representations\nthrough averaging or concatenation at the task of repository auto-tagging.\n","authors":["Agathe Lherondelle","Varun Babbar","Yash Satsangi","Fran Silavong","Shaltiel Eloul","Sean Moran"],"pdf_url":"https://arxiv.org/pdf/2208.09495v2.pdf","comment":"Pre-print, under review"},{"id":"http://arxiv.org/abs/2307.03595v1","updated":"2023-07-07T13:38:16Z","published":"2023-07-07T13:38:16Z","title":"GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series\n  Forecasting","summary":"  Encoder-decoder deep neural networks have been increasingly studied for\nmulti-horizon time series forecasting, especially in real-world applications.\nHowever, to forecast accurately, these sophisticated models typically rely on a\nlarge number of time series examples with substantial history. A rapidly\ngrowing topic of interest is forecasting time series which lack sufficient\nhistorical data -- often referred to as the ``cold start'' problem. In this\npaper, we introduce a novel yet simple method to address this problem by\nleveraging graph neural networks (GNNs) as a data augmentation for enhancing\nthe encoder used by such forecasters. These GNN-based features can capture\ncomplex inter-series relationships, and their generation process can be\noptimized end-to-end with the forecasting task. We show that our architecture\ncan use either data-driven or domain knowledge-defined graphs, scaling to\nincorporate information from multiple very large graphs with millions of nodes.\nIn our target application of demand forecasting for a large e-commerce\nretailer, we demonstrate on both a small dataset of 100K products and a large\ndataset with over 2 million products that our method improves overall\nperformance over competitive baseline models. More importantly, we show that it\nbrings substantially more gains to ``cold start'' products such as those newly\nlaunched or recently out-of-stock.\n","authors":["Sitan Yang","Malcolm Wolff","Shankar Ramasubramanian","Vincent Quenneville-Belair","Ronak Metha","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2307.03595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02427v2","updated":"2023-07-07T13:36:35Z","published":"2023-07-05T16:49:06Z","title":"FOCUS: Object-Centric World Models for Robotics Manipulation","summary":"  Understanding the world in terms of objects and the possible interplays with\nthem is an important cognition ability, especially in robotics manipulation,\nwhere many tasks require robot-object interactions. However, learning such a\nstructured world model, which specifically captures entities and relationships,\nremains a challenging and underexplored problem. To address this, we propose\nFOCUS, a model-based agent that learns an object-centric world model. Thanks to\na novel exploration bonus that stems from the object-centric representation,\nFOCUS can be deployed on robotics manipulation tasks to explore object\ninteractions more easily. Evaluating our approach on manipulation tasks across\ndifferent settings, we show that object-centric world models allow the agent to\nsolve tasks more efficiently and enable consistent exploration of robot-object\ninteractions. Using a Franka Emika robot arm, we also showcase how FOCUS could\nbe adopted in real-world settings.\n","authors":["Stefano Ferraro","Pietro Mazzaglia","Tim Verbelen","Bart Dhoedt"],"pdf_url":"https://arxiv.org/pdf/2307.02427v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03592v1","updated":"2023-07-07T13:35:48Z","published":"2023-07-07T13:35:48Z","title":"VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel\n  Synthesis","summary":"  We present a data-driven generative framework for synthesizing blood vessel\n3D geometry. This is a challenging task due to the complexity of vascular\nsystems, which are highly variating in shape, size, and structure. Existing\nmodel-based methods provide some degree of control and variation in the\nstructures produced, but fail to capture the diversity of actual anatomical\ndata. We developed VesselVAE, a recursive variational Neural Network that fully\nexploits the hierarchical organization of the vessel and learns a\nlow-dimensional manifold encoding branch connectivity along with geometry\nfeatures describing the target surface. After training, the VesselVAE latent\nspace can be sampled to generate new vessel geometries. To the best of our\nknowledge, this work is the first to utilize this technique for synthesizing\nblood vessels. We achieve similarities of synthetic and real data for radius\n(.97), length (.95), and tortuosity (.96). By leveraging the power of deep\nneural networks, we generate 3D models of blood vessels that are both accurate\nand diverse, which is crucial for medical and surgical training, hemodynamic\nsimulations, and many other purposes.\n","authors":["Paula Feldman","Miguel Fainstein","Viviana Siless","Claudio Delrieux","Emmanuel Iarussi"],"pdf_url":"https://arxiv.org/pdf/2307.03592v1.pdf","comment":"Accepted for MICCAI 2023"},{"id":"http://arxiv.org/abs/2307.03575v1","updated":"2023-07-07T13:09:07Z","published":"2023-07-07T13:09:07Z","title":"Multimodal Deep Learning for Personalized Renal Cell Carcinoma\n  Prognosis: Integrating CT Imaging and Clinical Data","summary":"  Renal cell carcinoma represents a significant global health challenge with a\nlow survival rate. This research aimed to devise a comprehensive deep-learning\nmodel capable of predicting survival probabilities in patients with renal cell\ncarcinoma by integrating CT imaging and clinical data and addressing the\nlimitations observed in prior studies. The aim is to facilitate the\nidentification of patients requiring urgent treatment. The proposed framework\ncomprises three modules: a 3D image feature extractor, clinical variable\nselection, and survival prediction. The feature extractor module, based on the\n3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumors\nlinked to mortality rates from CT images. A selection of clinical variables is\nsystematically chosen using the Spearman score and random forest importance\nscore as criteria. A deep learning-based network, trained with discrete\nLogisticHazard-based loss, performs the survival prediction. Nine distinct\nexperiments are performed, with varying numbers of clinical variables\ndetermined by different thresholds of the Spearman and importance scores. Our\nfindings demonstrate that the proposed strategy surpasses the current\nliterature on renal cancer prognosis based on CT scans and clinical factors.\nThe best-performing experiment yielded a concordance index of 0.84 and an area\nunder the curve value of 0.8 on the test cohort, which suggests strong\npredictive power. The multimodal deep-learning approach developed in this study\nshows promising results in estimating survival probabilities for renal cell\ncarcinoma patients using CT imaging and clinical data. This may have potential\nimplications in identifying patients who require urgent treatment, potentially\nimproving patient outcomes. The code created for this project is available for\nthe public on:\n\\href{https://github.com/Balasingham-AI-Group/Survival_CTplusClinical}{GitHub}\n","authors":["Maryamalsadat Mahootiha","Hemin Ali Qadir","Jacob Bergsland","Ilangko Balasingham"],"pdf_url":"https://arxiv.org/pdf/2307.03575v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.08815v2","updated":"2023-07-07T12:53:40Z","published":"2022-02-17T18:29:30Z","title":"GRAPHSHAP: Explaining Identity-Aware Graph Classifiers Through the\n  Language of Motifs","summary":"  Most methods for explaining black-box classifiers (e.g. on tabular data,\nimages, or time series) rely on measuring the impact that removing/perturbing\nfeatures has on the model output. This forces the explanation language to match\nthe classifier's feature space. However, when dealing with graph data, in which\nthe basic features correspond to the edges describing the graph structure, this\nmatching between features space and explanation language might not be\nappropriate. Decoupling the feature space (edges) from a desired high-level\nexplanation language (such as motifs) is thus a major challenge towards\ndeveloping actionable explanations for graph classification tasks. In this\npaper we introduce GRAPHSHAP, a Shapley-based approach able to provide\nmotif-based explanations for identity-aware graph classifiers, assuming no\nknowledge whatsoever about the model or its training data: the only requirement\nis that the classifier can be queried as a black-box at will. For the sake of\ncomputational efficiency we explore a progressive approximation strategy and\nshow how a simple kernel can efficiently approximate explanation scores, thus\nallowing GRAPHSHAP to scale on scenarios with a large explanation space (i.e.\nlarge number of motifs). We showcase GRAPHSHAP on a real-world brain-network\ndataset consisting of patients affected by Autism Spectrum Disorder and a\ncontrol group. Our experiments highlight how the classification provided by a\nblack-box model can be effectively explained by few connectomics patterns.\n","authors":["Alan Perotti","Paolo Bajardi","Francesco Bonchi","André Panisson"],"pdf_url":"https://arxiv.org/pdf/2202.08815v2.pdf","comment":"Accepted by International Joint Conference on Neural Networks 2023\n  (IJCNN)"},{"id":"http://arxiv.org/abs/2303.13300v2","updated":"2023-07-07T12:38:14Z","published":"2023-03-23T14:37:35Z","title":"The Innovation Paradox: Concept Space Expansion with Diminishing\n  Originality and the Promise of Creative AI","summary":"  Innovation, typically spurred by reusing, recombining, and synthesizing\nexisting concepts, is expected to result in an exponential growth of the\nconcept space over time. However, our statistical analysis of TechNet, which is\na comprehensive technology semantic network encompassing over four million\nconcepts derived from patent texts, reveals a linear rather than exponential\nexpansion of the overall technological concept space. Moreover, there is a\nnotable decline in the originality of newly created concepts. These trends can\nbe attributed to the constraints of human cognitive abilities to innovate\nbeyond an ever-growing space of prior art, among other factors. Integrating\ncreative artificial intelligence into the innovation process holds the\npotential to overcome these limitations and alter the observed trends in the\nfuture.\n","authors":["Serhad Sarica","Jianxi Luo"],"pdf_url":"https://arxiv.org/pdf/2303.13300v2.pdf","comment":"submitted to Design Science"},{"id":"http://arxiv.org/abs/2307.03539v1","updated":"2023-07-07T12:04:12Z","published":"2023-07-07T12:04:12Z","title":"Large Language Models as Batteries-Included Zero-Shot ESCO Skills\n  Matchers","summary":"  Understanding labour market dynamics requires accurately identifying the\nskills required for and possessed by the workforce. Automation techniques are\nincreasingly being developed to support this effort. However, automatically\nextracting skills from job postings is challenging due to the vast number of\nexisting skills. The ESCO (European Skills, Competences, Qualifications and\nOccupations) framework provides a useful reference, listing over 13,000\nindividual skills. However, skills extraction remains difficult and accurately\nmatching job posts to the ESCO taxonomy is an open problem. In this work, we\npropose an end-to-end zero-shot system for skills extraction from job\ndescriptions based on large language models (LLMs). We generate synthetic\ntraining data for the entirety of ESCO skills and train a classifier to extract\nskill mentions from job posts. We also employ a similarity retriever to\ngenerate skill candidates which are then re-ranked using a second LLM. Using\nsynthetic data achieves an RP@10 score 10 points higher than previous distant\nsupervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22\npoints over previous methods. We also show that Framing the task as mock\nprogramming when prompting the LLM can lead to better performance than natural\nlanguage prompts, especially with weaker LLMs. We demonstrate the potential of\nintegrating large language models at both ends of skills matching pipelines.\nOur approach requires no human annotations and achieve extremely promising\nresults on skills extraction against ESCO.\n","authors":["Benjamin Clavié","Guillaume Soulié"],"pdf_url":"https://arxiv.org/pdf/2307.03539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03512v1","updated":"2023-07-07T11:00:44Z","published":"2023-07-07T11:00:44Z","title":"Tranfer Learning of Semantic Segmentation Methods for Identifying Buried\n  Archaeological Structures on LiDAR Data","summary":"  When applying deep learning to remote sensing data in archaeological\nresearch, a notable obstacle is the limited availability of suitable datasets\nfor training models. The application of transfer learning is frequently\nemployed to mitigate this drawback. However, there is still a need to explore\nits effectiveness when applied across different archaeological datasets. This\npaper compares the performance of various transfer learning configurations\nusing two semantic segmentation deep neural networks on two LiDAR datasets. The\nexperimental results indicate that transfer learning-based approaches in\narchaeology can lead to performance improvements, although a systematic\nenhancement has not yet been observed. We provide specific insights about the\nvalidity of such techniques that can serve as a baseline for future works.\n","authors":["Paolo Soleni","Wouter B. Verschoof-van der Vaart","Žiga Kokalj","Arianna Traviglia","Marco Fiorucci"],"pdf_url":"https://arxiv.org/pdf/2307.03512v1.pdf","comment":"Accepted to IEEE International Geoscience and Remote Sensing\n  Symposium 2023 (IGARSS 2023) @IEEE copyright"},{"id":"http://arxiv.org/abs/2307.03506v1","updated":"2023-07-07T10:42:44Z","published":"2023-07-07T10:42:44Z","title":"Derivative Free Weight-space Ensembling","summary":"  Recent work suggests that interpolating between the weights of two\nspecialized language models can transfer knowledge between tasks in a way that\nmulti-task learning cannot. However, very few have explored interpolation\nbetween more than two models, where each has a distinct knowledge base. In this\npaper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new\nfew-sample task transfer approach for open-domain dialogue. Our framework\ncreates a set of diverse expert language models trained using a predefined set\nof source tasks. Next, we finetune each of the expert models on the target\ntask, approaching the target task from several distinct knowledge bases.\nFinally, we linearly interpolate between the model weights using a\ngradient-free-optimization algorithm, to efficiently find a good interpolation\nweighting. We demonstrate the effectiveness of the method on FETA-Friends\noutperforming the standard pretrain-finetune approach.\n","authors":["Dean Ninalga"],"pdf_url":"https://arxiv.org/pdf/2307.03506v1.pdf","comment":"For consideration at the 5th Workshop on NLP for Conversational AI\n  (co-located with ACL 2023)"},{"id":"http://arxiv.org/abs/2307.03505v1","updated":"2023-07-07T10:40:41Z","published":"2023-07-07T10:40:41Z","title":"RCDN -- Robust X-Corner Detection Algorithm based on Advanced CNN Model","summary":"  Accurate detection and localization of X-corner on both planar and non-planar\npatterns is a core step in robotics and machine vision. However, previous works\ncould not make a good balance between accuracy and robustness, which are both\ncrucial criteria to evaluate the detectors performance. To address this\nproblem, in this paper we present a novel detection algorithm which can\nmaintain high sub-pixel precision on inputs under multiple interference, such\nas lens distortion, extreme poses and noise. The whole algorithm, adopting a\ncoarse-to-fine strategy, contains a X-corner detection network and three\npost-processing techniques to distinguish the correct corner candidates, as\nwell as a mixed sub-pixel refinement technique and an improved region growth\nstrategy to recover the checkerboard pattern partially visible or occluded\nautomatically. Evaluations on real and synthetic images indicate that the\npresented algorithm has the higher detection rate, sub-pixel accuracy and\nrobustness than other commonly used methods. Finally, experiments of camera\ncalibration and pose estimation verify it can also get smaller re-projection\nerror in quantitative comparisons to the state-of-the-art.\n","authors":["Ben Chen","Caihua Xiong","Quanlin Li","Zhonghua Wan"],"pdf_url":"https://arxiv.org/pdf/2307.03505v1.pdf","comment":"15 pages, 8 figures and 4 tables. Unpublished further research and\n  experiments of Checkerboard corner detection network CCDN (arXiv:2302.05097)\n  and application exploration for robust camera calibration\n  (https://ieeexplore.ieee.org/abstract/document/9428389)"},{"id":"http://arxiv.org/abs/2307.03492v1","updated":"2023-07-07T10:01:08Z","published":"2023-07-07T10:01:08Z","title":"Large AI Model-Based Semantic Communications","summary":"  Semantic communication (SC) is an emerging intelligent paradigm, offering\nsolutions for various future applications like metaverse, mixed-reality, and\nthe Internet of everything. However, in current SC systems, the construction of\nthe knowledge base (KB) faces several issues, including limited knowledge\nrepresentation, frequent knowledge updates, and insecure knowledge sharing.\nFortunately, the development of the large AI model provides new solutions to\novercome above issues. Here, we propose a large AI model-based SC framework\n(LAM-SC) specifically designed for image data, where we first design the\nsegment anything model (SAM)-based KB (SKB) that can split the original image\ninto different semantic segments by universal semantic knowledge. Then, we\npresent an attention-based semantic integration (ASI) to weigh the semantic\nsegments generated by SKB without human participation and integrate them as the\nsemantic-aware image. Additionally, we propose an adaptive semantic compression\n(ASC) encoding to remove redundant information in semantic features, thereby\nreducing communication overhead. Finally, through simulations, we demonstrate\nthe effectiveness of the LAM-SC framework and the significance of the large AI\nmodel-based KB development in future SC paradigms.\n","authors":["Feibo Jiang","Yubo Peng","Li Dong","Kezhi Wang","Kun Yang","Cunhua Pan","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2307.03492v1.pdf","comment":"Plan to submit it to journal for possible publication"},{"id":"http://arxiv.org/abs/2212.09811v3","updated":"2023-07-07T09:53:20Z","published":"2022-12-19T19:29:40Z","title":"Memory-efficient NLLB-200: Language-specific Expert Pruning of a\n  Massively Multilingual Machine Translation Model","summary":"  The recently released NLLB-200 is a set of multilingual Neural Machine\nTranslation models that cover 202 languages. The largest model is based on a\nMixture of Experts architecture and achieves SoTA results across many language\npairs. It contains 54.5B parameters and requires at least four 32GB GPUs just\nfor inference. In this work, we propose a pruning method that enables the\nremoval of up to 80% of experts without further finetuning and with a\nnegligible loss in translation quality, which makes it feasible to run the\nmodel on a single 32GB GPU. Further analysis suggests that our pruning metrics\ncan identify language-specific experts.\n","authors":["Yeskendir Koishekenov","Alexandre Berard","Vassilina Nikoulina"],"pdf_url":"https://arxiv.org/pdf/2212.09811v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03486v1","updated":"2023-07-07T09:47:15Z","published":"2023-07-07T09:47:15Z","title":"Discovering Hierarchical Achievements in Reinforcement Learning via\n  Contrastive Learning","summary":"  Discovering achievements with a hierarchical structure on procedurally\ngenerated environments poses a significant challenge. This requires agents to\npossess a broad range of abilities, including generalization and long-term\nreasoning. Many prior methods are built upon model-based or hierarchical\napproaches, with the belief that an explicit module for long-term planning\nwould be beneficial for learning hierarchical achievements. However, these\nmethods require an excessive amount of environment interactions or large model\nsizes, limiting their practicality. In this work, we identify that proximal\npolicy optimization (PPO), a simple and versatile model-free algorithm,\noutperforms the prior methods with recent implementation practices. Moreover,\nwe find that the PPO agent can predict the next achievement to be unlocked to\nsome extent, though with low confidence. Based on this observation, we propose\na novel contrastive learning method, called achievement distillation, that\nstrengthens the agent's capability to predict the next achievement. Our method\nexhibits a strong capacity for discovering hierarchical achievements and shows\nstate-of-the-art performance on the challenging Crafter environment using fewer\nmodel parameters in a sample-efficient regime.\n","authors":["Seungyong Moon","Junyoung Yeom","Bumsoo Park","Hyun Oh Song"],"pdf_url":"https://arxiv.org/pdf/2307.03486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05412v2","updated":"2023-07-07T09:32:56Z","published":"2023-06-08T17:56:46Z","title":"Offline Prioritized Experience Replay","summary":"  Offline reinforcement learning (RL) is challenged by the distributional shift\nproblem. To address this problem, existing works mainly focus on designing\nsophisticated policy constraints between the learned policy and the behavior\npolicy. However, these constraints are applied equally to well-performing and\ninferior actions through uniform sampling, which might negatively affect the\nlearned policy. To alleviate this issue, we propose Offline Prioritized\nExperience Replay (OPER), featuring a class of priority functions designed to\nprioritize highly-rewarding transitions, making them more frequently visited\nduring training. Through theoretical analysis, we show that this class of\npriority functions induce an improved behavior policy, and when constrained to\nthis improved policy, a policy-constrained offline RL algorithm is likely to\nyield a better solution. We develop two practical strategies to obtain priority\nweights by estimating advantages based on a fitted value network (OPER-A) or\nutilizing trajectory returns (OPER-R) for quick computation. OPER is a\nplug-and-play component for offline RL algorithms. As case studies, we evaluate\nOPER on five different algorithms, including BC, TD3+BC, Onestep RL, CQL, and\nIQL. Extensive experiments demonstrate that both OPER-A and OPER-R\nsignificantly improve the performance for all baseline methods. Codes and\npriority weights are availiable at https://github.com/sail-sg/OPER.\n","authors":["Yang Yue","Bingyi Kang","Xiao Ma","Gao Huang","Shiji Song","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2306.05412v2.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2307.03465v1","updated":"2023-07-07T08:57:57Z","published":"2023-07-07T08:57:57Z","title":"TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task\n  Foundation Model Learning","summary":"  The AllInOne training paradigm squeezes a wide range of tasks into a unified\nmodel in a multi-task learning manner. However, optimization in multi-task\nlearning is more challenge than single-task learning, as the gradient norm from\ndifferent tasks may vary greatly, making the backbone overly biased towards one\nspecific task. To address this issue, we propose the task-level\nbackbone-oriented gradient clip paradigm, compared with the vanilla gradient\nclip method, it has two points of emphasis:1) gradient clip is performed\nindependently for each task. 2) backbone gradients generated from each task are\nrescaled to the same norm scale. Based on the experimental results, we argue\nthat the task-level backbone-oriented gradient clip paradigm can relieve the\ngradient bias problem to some extent. We also propose a novel multi-branch data\naugmentation strategy where conflict augmentations are placed in different\nbranches. Our approach has been shown to be effective and finally achieve 1st\nplace in the Leaderboard A and 2nd place in the Leaderboard B of the CVPR2023\nFoundation Model Challenge. It's worth noting that instead of evaluating all\nthree tasks(detection, segmentation and fine-grained classification) in\nLeaderboard A, the segmentation task is not evaluated in Leaderboard B, in\nwhich our team has a huge advantage.\n","authors":["Zelun Zhang","Xue Pan"],"pdf_url":"https://arxiv.org/pdf/2307.03465v1.pdf","comment":"Foundation Model Challenge@CVPR2023, Accepted by CVPR2023 Workshop"},{"id":"http://arxiv.org/abs/2306.14275v3","updated":"2023-07-07T08:38:25Z","published":"2023-06-25T15:53:31Z","title":"Enhancing Adversarial Training via Reweighting Optimization Trajectory","summary":"  Despite the fact that adversarial training has become the de facto method for\nimproving the robustness of deep neural networks, it is well-known that vanilla\nadversarial training suffers from daunting robust overfitting, resulting in\nunsatisfactory robust generalization. A number of approaches have been proposed\nto address these drawbacks such as extra regularization, adversarial weights\nperturbation, and training with more data over the last few years. However, the\nrobust generalization improvement is yet far from satisfactory. In this paper,\nwe approach this challenge with a brand new perspective -- refining historical\noptimization trajectories. We propose a new method named \\textbf{Weighted\nOptimization Trajectories (WOT)} that leverages the optimization trajectories\nof adversarial training in time. We have conducted extensive experiments to\ndemonstrate the effectiveness of WOT under various state-of-the-art adversarial\nattacks. Our results show that WOT integrates seamlessly with the existing\nadversarial training methods and consistently overcomes the robust overfitting\nissue, resulting in better adversarial robustness. For example, WOT boosts the\nrobust accuracy of AT-PGD under AA-$L_{\\infty}$ attack by 1.53\\% $\\sim$ 6.11\\%\nand meanwhile increases the clean accuracy by 0.55\\%$\\sim$5.47\\% across SVHN,\nCIFAR-10, CIFAR-100, and Tiny-ImageNet datasets.\n","authors":["Tianjin Huang","Shiwei Liu","Tianlong Chen","Meng Fang","Li Shen","Vlaod Menkovski","Lu Yin","Yulong Pei","Mykola Pechenizkiy"],"pdf_url":"https://arxiv.org/pdf/2306.14275v3.pdf","comment":"Accepted by ECML 2023"},{"id":"http://arxiv.org/abs/2302.12589v2","updated":"2023-07-07T08:22:17Z","published":"2023-02-24T11:56:57Z","title":"Revisiting Modality Imbalance In Multimodal Pedestrian Detection","summary":"  Multimodal learning, particularly for pedestrian detection, has recently\nreceived emphasis due to its capability to function equally well in several\ncritical autonomous driving scenarios such as low-light, night-time, and\nadverse weather conditions. However, in most cases, the training distribution\nlargely emphasizes the contribution of one specific input that makes the\nnetwork biased towards one modality. Hence, the generalization of such models\nbecomes a significant problem where the non-dominant input modality during\ntraining could be contributing more to the course of inference. Here, we\nintroduce a novel training setup with regularizer in the multimodal\narchitecture to resolve the problem of this disparity between the modalities.\nSpecifically, our regularizer term helps to make the feature fusion method more\nrobust by considering both the feature extractors equivalently important during\nthe training to extract the multimodal distribution which is referred to as\nremoving the imbalance problem. Furthermore, our decoupling concept of output\nstream helps the detection task by sharing the spatial sensitive information\nmutually. Extensive experiments of the proposed method on KAIST and UTokyo\ndatasets shows improvement of the respective state-of-the-art performance.\n","authors":["Arindam Das","Sudip Das","Ganesh Sistu","Jonathan Horgan","Ujjwal Bhattacharya","Edward Jones","Martin Glavin","Ciarán Eising"],"pdf_url":"https://arxiv.org/pdf/2302.12589v2.pdf","comment":"5 pages, 3 figure, 4 tables"},{"id":"http://arxiv.org/abs/2201.05745v3","updated":"2023-07-07T08:14:38Z","published":"2022-01-15T03:13:02Z","title":"Deep Optimal Transport for Domain Adaptation on SPD Manifolds","summary":"  In recent years, there has been significant interest in solving the domain\nadaptation (DA) problem on symmetric positive definite (SPD) manifolds within\nthe machine learning community. This interest stems from the fact that complex\nneurophysiological data generated by medical equipment, such as\nelectroencephalograms, magnetoencephalograms, and diffusion tensor imaging,\noften exhibit a shift in data distribution across different domains. These data\nrepresentations, represented by signal covariance matrices, possess properties\nof symmetry and positive definiteness. However, directly applying previous\nexperiences and solutions to the DA problem poses challenges due to the\nmanipulation complexities of covariance matrices.To address this, our research\nintroduces a category of deep learning-based transfer learning approaches\ncalled deep optimal transport. This category utilizes optimal transport theory\nand leverages the Log-Euclidean geometry for SPD manifolds. Additionally, we\npresent a comprehensive categorization of existing geometric methods to tackle\nthese problems effectively. This categorization provides practical solutions\nfor specific DA problems, including handling discrepancies in marginal and\nconditional distributions between the source and target domains on the SPD\nmanifold. To evaluate the effectiveness, we conduct experiments on three\npublicly available highly non-stationary cross-session brain-computer interface\nscenarios. Moreover, we provide visualization results on the SPD cone to offer\nfurther insights into the framework.\n","authors":["Ce Ju","Cuntai Guan"],"pdf_url":"https://arxiv.org/pdf/2201.05745v3.pdf","comment":"15 pages, 4 figures, and 4 tables; This work has been submitted to\n  the IEEE for possible publication. Copyright may be transferred without\n  notice, after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2307.03444v1","updated":"2023-07-07T08:02:01Z","published":"2023-07-07T08:02:01Z","title":"Towards Deep Network Steganography: From Networks to Networks","summary":"  With the widespread applications of the deep neural network (DNN), how to\ncovertly transmit the DNN models in public channels brings us the attention,\nespecially for those trained for secret-learning tasks. In this paper, we\npropose deep network steganography for the covert communication of DNN models.\nUnlike the existing steganography schemes which focus on the subtle\nmodification of the cover data to accommodate the secrets, our scheme is\nlearning task oriented, where the learning task of the secret DNN model (termed\nas secret-learning task) is disguised into another ordinary learning task\nconducted in a stego DNN model (termed as stego-learning task). To this end, we\npropose a gradient-based filter insertion scheme to insert interference filters\ninto the important positions in the secret DNN model to form a stego DNN model.\nThese positions are then embedded into the stego DNN model using a key by side\ninformation hiding. Finally, we activate the interference filters by a partial\noptimization strategy, such that the generated stego DNN model works on the\nstego-learning task. We conduct the experiments on both the intra-task\nsteganography and inter-task steganography (i.e., the secret and stego-learning\ntasks belong to the same and different categories), both of which demonstrate\nthe effectiveness of our proposed method for covert communication of DNN\nmodels.\n","authors":["Guobiao Li","Sheng Li","Meiling Li","Zhenxing Qian","Xinpeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.03444v1.pdf","comment":"8 pages. arXiv admin note: text overlap with arXiv:2302.14521"},{"id":"http://arxiv.org/abs/2305.16724v2","updated":"2023-07-07T07:51:38Z","published":"2023-05-26T08:22:35Z","title":"Code-Switched Text Synthesis in Unseen Language Pairs","summary":"  Existing efforts on text synthesis for code-switching mostly require training\non code-switched texts in the target language pairs, limiting the deployment of\nthe models to cases lacking code-switched data. In this work, we study the\nproblem of synthesizing code-switched texts for language pairs absent from the\ntraining data. We introduce GLOSS, a model built on top of a pre-trained\nmultilingual machine translation model (PMMTM) with an additional\ncode-switching module. This module, either an adapter or extra prefixes, learns\ncode-switching patterns from code-switched data during training, while the\nprimary component of GLOSS, i.e., the PMMTM, is frozen. The design of only\nadjusting the code-switching module prevents our model from overfitting to the\nconstrained training data for code-switching. Hence, GLOSS exhibits the ability\nto generalize and synthesize code-switched texts across a broader spectrum of\nlanguage pairs. Additionally, we develop a self-training algorithm on target\nlanguage pairs further to enhance the reliability of GLOSS. Automatic\nevaluations on four language pairs show that GLOSS achieves at least 55%\nrelative BLEU and METEOR scores improvements compared to strong baselines.\nHuman evaluations on two language pairs further validate the success of GLOSS.\n","authors":["I-Hung Hsu","Avik Ray","Shubham Garg","Nanyun Peng","Jing Huang"],"pdf_url":"https://arxiv.org/pdf/2305.16724v2.pdf","comment":"Paper accepted by ACL2023 as a Finding paper"},{"id":"http://arxiv.org/abs/2306.07675v2","updated":"2023-07-07T07:37:54Z","published":"2023-06-13T10:41:28Z","title":"An Interleaving Semantics of the Timed Concurrent Language for\n  Argumentation to Model Debates and Dialogue Games","summary":"  Time is a crucial factor in modelling dynamic behaviours of intelligent\nagents: activities have a determined temporal duration in a real-world\nenvironment, and previous actions influence agents' behaviour. In this paper,\nwe propose a language for modelling concurrent interaction between agents that\nalso allows the specification of temporal intervals in which particular actions\noccur. Such a language exploits a timed version of Abstract Argumentation\nFrameworks to realise a shared memory used by the agents to communicate and\nreason on the acceptability of their beliefs with respect to a given time\ninterval. An interleaving model on a single processor is used for basic\ncomputation steps, with maximum parallelism for time elapsing. Following this\napproach, only one of the enabled agents is executed at each moment. To\ndemonstrate the capabilities of language, we also show how it can be used to\nmodel interactions such as debates and dialogue games taking place between\nintelligent agents. Lastly, we present an implementation of the language that\ncan be accessed via a web interface. Under consideration in Theory and Practice\nof Logic Programming (TPLP).\n","authors":["Stefano Bistarelli","Maria Chiara Meo","Carlo Taticchi"],"pdf_url":"https://arxiv.org/pdf/2306.07675v2.pdf","comment":"Under consideration in Theory and Practice of Logic Programming\n  (TPLP)"},{"id":"http://arxiv.org/abs/2305.11814v2","updated":"2023-07-07T07:31:22Z","published":"2023-05-19T16:49:36Z","title":"Summarizing Strategy Card Game AI Competition","summary":"  This paper concludes five years of AI competitions based on Legends of Code\nand Magic (LOCM), a small Collectible Card Game (CCG), designed with the goal\nof supporting research and algorithm development. The game was used in a number\nof events, including Community Contests on the CodinGame platform, and Strategy\nCard Game AI Competition at the IEEE Congress on Evolutionary Computation and\nIEEE Conference on Games. LOCM has been used in a number of publications\nrelated to areas such as game tree search algorithms, neural networks,\nevaluation functions, and CCG deckbuilding. We present the rules of the game,\nthe history of organized competitions, and a listing of the participant and\ntheir approaches, as well as some general advice on organizing AI competitions\nfor the research community. Although the COG 2022 edition was announced to be\nthe last one, the game remains available and can be played using an online\nleaderboard arena.\n","authors":["Jakub Kowalski","Radosław Miernik"],"pdf_url":"https://arxiv.org/pdf/2305.11814v2.pdf","comment":"IEEE Conference on Games 2023"},{"id":"http://arxiv.org/abs/2212.10936v4","updated":"2023-07-07T07:19:22Z","published":"2022-12-21T11:24:32Z","title":"A Memetic Algorithm with Reinforcement Learning for Sociotechnical\n  Production Scheduling","summary":"  The following interdisciplinary article presents a memetic algorithm with\napplying deep reinforcement learning (DRL) for solving practically oriented\ndual resource constrained flexible job shop scheduling problems (DRC-FJSSP).\nFrom research projects in industry, we recognize the need to consider flexible\nmachines, flexible human workers, worker capabilities, setup and processing\noperations, material arrival times, complex job paths with parallel tasks for\nbill of material (BOM) manufacturing, sequence-dependent setup times and\n(partially) automated tasks in human-machine-collaboration. In recent years,\nthere has been extensive research on metaheuristics and DRL techniques but\nfocused on simple scheduling environments. However, there are few approaches\ncombining metaheuristics and DRL to generate schedules more reliably and\nefficiently. In this paper, we first formulate a DRC-FJSSP to map complex\nindustry requirements beyond traditional job shop models. Then we propose a\nscheduling framework integrating a discrete event simulation (DES) for schedule\nevaluation, considering parallel computing and multicriteria optimization.\nHere, a memetic algorithm is enriched with DRL to improve sequencing and\nassignment decisions. Through numerical experiments with real-world production\ndata, we confirm that the framework generates feasible schedules efficiently\nand reliably for a balanced optimization of makespan (MS) and total tardiness\n(TT). Utilizing DRL instead of random metaheuristic operations leads to better\nresults in fewer algorithm iterations and outperforms traditional approaches in\nsuch complex environments.\n","authors":["Felix Grumbach","Nour Eldin Alaa Badr","Pascal Reusch","Sebastian Trojahn"],"pdf_url":"https://arxiv.org/pdf/2212.10936v4.pdf","comment":"This article has been accepted by IEEE Access on June 30, 2023"},{"id":"http://arxiv.org/abs/2307.03421v1","updated":"2023-07-07T07:07:42Z","published":"2023-07-07T07:07:42Z","title":"Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and\n  Deformable Image Registration","summary":"  Image registration is a fundamental requirement for medical image analysis.\nDeep registration methods based on deep learning have been widely recognized\nfor their capabilities to perform fast end-to-end registration. Many deep\nregistration methods achieved state-of-the-art performance by performing\ncoarse-to-fine registration, where multiple registration steps were iterated\nwith cascaded networks. Recently, Non-Iterative Coarse-to-finE (NICE)\nregistration methods have been proposed to perform coarse-to-fine registration\nin a single network and showed advantages in both registration accuracy and\nruntime. However, existing NICE registration methods mainly focus on deformable\nregistration, while affine registration, a common prerequisite, is still\nreliant on time-consuming traditional optimization-based methods or extra\naffine registration networks. In addition, existing NICE registration methods\nare limited by the intrinsic locality of convolution operations. Transformers\nmay address this limitation for their capabilities to capture long-range\ndependency, but the benefits of using transformers for NICE registration have\nnot been explored. In this study, we propose a Non-Iterative Coarse-to-finE\nTransformer network (NICE-Trans) for image registration. Our NICE-Trans is the\nfirst deep registration method that (i) performs joint affine and deformable\ncoarse-to-fine registration within a single network, and (ii) embeds\ntransformers into a NICE registration framework to model long-range relevance\nbetween images. Extensive experiments with seven public datasets show that our\nNICE-Trans outperforms state-of-the-art registration methods on both\nregistration accuracy and runtime.\n","authors":["Mingyuan Meng","Lei Bi","Michael Fulham","Dagan Feng","Jinman Kim"],"pdf_url":"https://arxiv.org/pdf/2307.03421v1.pdf","comment":"Accepted at International Conference on Medical Image Computing and\n  Computer Assisted Intervention (MICCAI 2023)"},{"id":"http://arxiv.org/abs/2307.03419v1","updated":"2023-07-07T07:06:38Z","published":"2023-07-07T07:06:38Z","title":"QI2 -- an Interactive Tool for Data Quality Assurance","summary":"  The importance of high data quality is increasing with the growing impact and\ndistribution of ML systems and big data. Also the planned AI Act from the\nEuropean commission defines challenging legal requirements for data quality\nespecially for the market introduction of safety relevant ML systems. In this\npaper we introduce a novel approach that supports the data quality assurance\nprocess of multiple data quality aspects. This approach enables the\nverification of quantitative data quality requirements. The concept and\nbenefits are introduced and explained on small example data sets. How the\nmethod is applied is demonstrated on the well known MNIST data set based an\nhandwritten digits.\n","authors":["Simon Geerkens","Christian Sieberichs","Alexander Braun","Thomas Waschulzik"],"pdf_url":"https://arxiv.org/pdf/2307.03419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.17258v2","updated":"2023-07-07T07:00:22Z","published":"2023-06-29T18:58:01Z","title":"Suffering Toasters -- A New Self-Awareness Test for AI","summary":"  A widely accepted definition of intelligence in the context of Artificial\nIntelligence (AI) still eludes us. Due to our exceedingly rapid development of\nAI paradigms, architectures, and tools, the prospect of naturally arising AI\nconsciousness seems more likely than ever. In this paper, we claim that all\ncurrent intelligence tests are insufficient to point to the existence or lack\nof intelligence \\textbf{as humans intuitively perceive it}. We draw from ideas\nin the philosophy of science, psychology, and other areas of research to\nprovide a clearer definition of the problems of artificial intelligence,\nself-awareness, and agency. We furthermore propose a new heuristic approach to\ntest for artificial self-awareness and outline a possible implementation.\nFinally, we discuss some of the questions that arise from this new heuristic,\nbe they philosophical or implementation-oriented.\n","authors":["Ira Wolfson"],"pdf_url":"https://arxiv.org/pdf/2306.17258v2.pdf","comment":"4 double-column pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.06722v3","updated":"2023-07-07T06:59:26Z","published":"2023-06-11T16:48:03Z","title":"$E(2)$-Equivariant Vision Transformer","summary":"  Vision Transformer (ViT) has achieved remarkable performance in computer\nvision. However, positional encoding in ViT makes it substantially difficult to\nlearn the intrinsic equivariance in data. Initial attempts have been made on\ndesigning equivariant ViT but are proved defective in some cases in this paper.\nTo address this issue, we design a Group Equivariant Vision Transformer\n(GE-ViT) via a novel, effective positional encoding operator. We prove that\nGE-ViT meets all the theoretical requirements of an equivariant neural network.\nComprehensive experiments are conducted on standard benchmark datasets,\ndemonstrating that GE-ViT significantly outperforms non-equivariant\nself-attention networks. The code is available at\nhttps://github.com/ZJUCDSYangKaifan/GEVit.\n","authors":["Renjun Xu","Kaifan Yang","Ke Liu","Fengxiang He"],"pdf_url":"https://arxiv.org/pdf/2306.06722v3.pdf","comment":"Accept to UAI2023"},{"id":"http://arxiv.org/abs/2306.13264v2","updated":"2023-07-07T06:57:18Z","published":"2023-06-23T02:22:04Z","title":"FedSelect: Customized Selection of Parameters for Fine-Tuning during\n  Personalized Federated Learning","summary":"  Recent advancements in federated learning (FL) seek to increase client-level\nperformance by fine-tuning client parameters on local data or personalizing\narchitectures for the local task. Existing methods for such personalization\neither prune a global model or fine-tune a global model on a local client\ndistribution. However, these existing methods either personalize at the expense\nof retaining important global knowledge, or predetermine network layers for\nfine-tuning, resulting in suboptimal storage of global knowledge within client\nmodels. Enlightened by the lottery ticket hypothesis, we first introduce a\nhypothesis for finding optimal client subnetworks to locally fine-tune while\nleaving the rest of the parameters frozen. We then propose a novel FL\nframework, FedSelect, using this procedure that directly personalizes both\nclient subnetwork structure and parameters, via the simultaneous discovery of\noptimal parameters for personalization and the rest of parameters for global\naggregation during training. We show that this method achieves promising\nresults on CIFAR-10.\n","authors":["Rishub Tamirisa","John Won","Chengjun Lu","Ron Arel","Andy Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.13264v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2307.03406v1","updated":"2023-07-07T06:12:14Z","published":"2023-07-07T06:12:14Z","title":"Goal-Conditioned Predictive Coding as an Implicit Planner for Offline\n  Reinforcement Learning","summary":"  Recent work has demonstrated the effectiveness of formulating decision making\nas a supervised learning problem on offline-collected trajectories. However,\nthe benefits of performing sequence modeling on trajectory data is not yet\nclear. In this work we investigate if sequence modeling has the capability to\ncondense trajectories into useful representations that can contribute to policy\nlearning. To achieve this, we adopt a two-stage framework that first summarizes\ntrajectories with sequence modeling techniques, and then employs these\nrepresentations to learn a policy along with a desired goal. This design allows\nmany existing supervised offline RL methods to be considered as specific\ninstances of our framework. Within this framework, we introduce\nGoal-Conditioned Predicitve Coding (GCPC), an approach that brings powerful\ntrajectory representations and leads to performant policies. We conduct\nextensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion\nenvironments, and observe that sequence modeling has a significant impact on\nsome decision making tasks. In addition, we demonstrate that GCPC learns a\ngoal-conditioned latent representation about the future, which serves as an\n\"implicit planner\", and enables competitive performance on all three\nbenchmarks.\n","authors":["Zilai Zeng","Ce Zhang","Shijie Wang","Chen Sun"],"pdf_url":"https://arxiv.org/pdf/2307.03406v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03393v1","updated":"2023-07-07T05:31:31Z","published":"2023-07-07T05:31:31Z","title":"Exploring the Potential of Large Language Models (LLMs) in Learning on\n  Graphs","summary":"  Learning on Graphs has attracted immense attention due to its wide real-world\napplications. The most popular pipeline for learning on graphs with textual\nnode attributes primarily relies on Graph Neural Networks (GNNs), and utilizes\nshallow text embedding as initial node representations, which has limitations\nin general knowledge and profound semantic understanding. In recent years,\nLarge Language Models (LLMs) have been proven to possess extensive common\nknowledge and powerful semantic comprehension abilities that have\nrevolutionized existing workflows to handle text data. In this paper, we aim to\nexplore the potential of LLMs in graph machine learning, especially the node\nclassification task, and investigate two possible pipelines: LLMs-as-Enhancers\nand LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text\nattributes with their massive knowledge and then generate predictions through\nGNNs. The latter attempts to directly employ LLMs as standalone predictors. We\nconduct comprehensive and systematical studies on these two pipelines under\nvarious settings. From comprehensive empirical results, we make original\nobservations and find new insights that open new possibilities and suggest\npromising directions to leverage LLMs for learning on graphs.\n","authors":["Zhikai Chen","Haitao Mao","Hang Li","Wei Jin","Hongzhi Wen","Xiaochi Wei","Shuaiqiang Wang","Dawei Yin","Wenqi Fan","Hui Liu","Jiliang Tang"],"pdf_url":"https://arxiv.org/pdf/2307.03393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.03466v3","updated":"2023-07-07T05:24:12Z","published":"2022-02-07T19:09:27Z","title":"Reward-Respecting Subtasks for Model-Based Reinforcement Learning","summary":"  To achieve the ambitious goals of artificial intelligence, reinforcement\nlearning must include planning with a model of the world that is abstract in\nstate and time. Deep learning has made progress with state abstraction, but\ntemporal abstraction has rarely been used, despite extensively developed theory\nbased on the options framework. One reason for this is that the space of\npossible options is immense, and the methods previously proposed for option\ndiscovery do not take into account how the option models will be used in\nplanning. Options are typically discovered by posing subsidiary tasks, such as\nreaching a bottleneck state or maximizing the cumulative sum of a sensory\nsignal other than reward. Each subtask is solved to produce an option, and then\na model of the option is learned and made available to the planning process. In\nmost previous work, the subtasks ignore the reward on the original problem,\nwhereas we propose subtasks that use the original reward plus a bonus based on\na feature of the state at the time the option terminates. We show that option\nmodels obtained from such reward-respecting subtasks are much more likely to be\nuseful in planning than eigenoptions, shortest path options based on bottleneck\nstates, or reward-respecting options generated by the option-critic. Reward\nrespecting subtasks strongly constrain the space of options and thereby also\nprovide a partial solution to the problem of option discovery. Finally, we show\nhow values, policies, options, and models can all be learned online and\noff-policy using standard algorithms and general value functions.\n","authors":["Richard S. Sutton","Marlos C. Machado","G. Zacharias Holland","David Szepesvari","Finbarr Timbers","Brian Tanner","Adam White"],"pdf_url":"https://arxiv.org/pdf/2202.03466v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.11145v2","updated":"2023-07-07T05:16:29Z","published":"2020-04-17T14:56:29Z","title":"F2A2: Flexible Fully-decentralized Approximate Actor-critic for\n  Cooperative Multi-agent Reinforcement Learning","summary":"  Traditional centralized multi-agent reinforcement learning (MARL) algorithms\nare sometimes unpractical in complicated applications, due to non-interactivity\nbetween agents, curse of dimensionality and computation complexity. Hence,\nseveral decentralized MARL algorithms are motivated. However, existing\ndecentralized methods only handle the fully cooperative setting where massive\ninformation needs to be transmitted in training. The block coordinate gradient\ndescent scheme they used for successive independent actor and critic steps can\nsimplify the calculation, but it causes serious bias. In this paper, we propose\na flexible fully decentralized actor-critic MARL framework, which can combine\nmost of actor-critic methods, and handle large-scale general cooperative\nmulti-agent setting. A primal-dual hybrid gradient descent type algorithm\nframework is designed to learn individual agents separately for\ndecentralization. From the perspective of each agent, policy improvement and\nvalue evaluation are jointly optimized, which can stabilize multi-agent policy\nlearning. Furthermore, our framework can achieve scalability and stability for\nlarge-scale environment and reduce information transmission, by the parameter\nsharing mechanism and a novel modeling-other-agents methods based on\ntheory-of-mind and online supervised learning. Sufficient experiments in\ncooperative Multi-agent Particle Environment and StarCraft II show that our\ndecentralized MARL instantiation algorithms perform competitively against\nconventional centralized and decentralized methods.\n","authors":["Wenhao Li","Bo Jin","Xiangfeng Wang","Junchi Yan","Hongyuan Zha"],"pdf_url":"https://arxiv.org/pdf/2004.11145v2.pdf","comment":"75 pages, 10 figures, JMLR camera ready"},{"id":"http://arxiv.org/abs/2301.10886v4","updated":"2023-07-07T04:48:01Z","published":"2023-01-26T01:06:46Z","title":"Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement\n  Learning","summary":"  We present AIRS: Automatic Intrinsic Reward Shaping that intelligently and\nadaptively provides high-quality intrinsic rewards to enhance exploration in\nreinforcement learning (RL). More specifically, AIRS selects shaping function\nfrom a predefined set based on the estimated task return in real-time,\nproviding reliable exploration incentives and alleviating the biased objective\nproblem. Moreover, we develop an intrinsic reward toolkit to provide efficient\nand reliable implementations of diverse intrinsic reward approaches. We test\nAIRS on various tasks of MiniGrid, Procgen, and DeepMind Control Suite.\nExtensive simulation demonstrates that AIRS can outperform the benchmarking\nschemes and achieve superior performance with simple architecture.\n","authors":["Mingqi Yuan","Bo Li","Xin Jin","Wenjun Zeng"],"pdf_url":"https://arxiv.org/pdf/2301.10886v4.pdf","comment":"24 pages, 16 figures"},{"id":"http://arxiv.org/abs/2307.03380v1","updated":"2023-07-07T04:20:36Z","published":"2023-07-07T04:20:36Z","title":"On Formal Feature Attribution and Its Approximation","summary":"  Recent years have witnessed the widespread use of artificial intelligence\n(AI) algorithms and machine learning (ML) models. Despite their tremendous\nsuccess, a number of vital problems like ML model brittleness, their fairness,\nand the lack of interpretability warrant the need for the active developments\nin explainable artificial intelligence (XAI) and formal ML model verification.\nThe two major lines of work in XAI include feature selection methods, e.g.\nAnchors, and feature attribution techniques, e.g. LIME and SHAP. Despite their\npromise, most of the existing feature selection and attribution approaches are\nsusceptible to a range of critical issues, including explanation unsoundness\nand out-of-distribution sampling. A recent formal approach to XAI (FXAI)\nalthough serving as an alternative to the above and free of these issues\nsuffers from a few other limitations. For instance and besides the scalability\nlimitation, the formal approach is unable to tackle the feature attribution\nproblem. Additionally, a formal explanation despite being formally sound is\ntypically quite large, which hampers its applicability in practical settings.\nMotivated by the above, this paper proposes a way to apply the apparatus of\nformal XAI to the case of feature attribution based on formal explanation\nenumeration. Formal feature attribution (FFA) is argued to be advantageous over\nthe existing methods, both formal and non-formal. Given the practical\ncomplexity of the problem, the paper then proposes an efficient technique for\napproximating exact FFA. Finally, it offers experimental evidence of the\neffectiveness of the proposed approximate FFA in comparison to the existing\nfeature attribution algorithms not only in terms of feature importance and but\nalso in terms of their relative order.\n","authors":["Jinqiang Yu","Alexey Ignatiev","Peter J. Stuckey"],"pdf_url":"https://arxiv.org/pdf/2307.03380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03379v1","updated":"2023-07-07T04:20:07Z","published":"2023-07-07T04:20:07Z","title":"Efficient Ground Vehicle Path Following in Game AI","summary":"  This short paper presents an efficient path following solution for ground\nvehicles tailored to game AI. Our focus is on adapting established techniques\nto design simple solutions with parameters that are easily tunable for an\nefficient benchmark path follower. Our solution pays particular attention to\ncomputing a target speed which uses quadratic Bezier curves to estimate the\npath curvature. The performance of the proposed path follower is evaluated\nthrough a variety of test scenarios in a first-person shooter game,\ndemonstrating its effectiveness and robustness in handling different types of\npaths and vehicles. We achieved a 70% decrease in the total number of stuck\nevents compared to an existing path following solution.\n","authors":["Rodrigue de Schaetzen","Alessandro Sestini"],"pdf_url":"https://arxiv.org/pdf/2307.03379v1.pdf","comment":"4 pages, 3 figures, to be published in IEEE Conference on Games 2023"},{"id":"http://arxiv.org/abs/2304.14102v2","updated":"2023-07-07T04:00:36Z","published":"2023-04-27T11:29:02Z","title":"SocNavGym: A Reinforcement Learning Gym for Social Navigation","summary":"  It is essential for autonomous robots to be socially compliant while\nnavigating in human-populated environments. Machine Learning and, especially,\nDeep Reinforcement Learning have recently gained considerable traction in the\nfield of Social Navigation. This can be partially attributed to the resulting\npolicies not being bound by human limitations in terms of code complexity or\nthe number of variables that are handled. Unfortunately, the lack of safety\nguarantees and the large data requirements by DRL algorithms make learning in\nthe real world unfeasible. To bridge this gap, simulation environments are\nfrequently used. We propose SocNavGym, an advanced simulation environment for\nsocial navigation that can generate a wide variety of social navigation\nscenarios and facilitates the development of intelligent social agents.\nSocNavGym is light-weight, fast, easy-to-use, and can be effortlessly\nconfigured to generate different types of social navigation scenarios. It can\nalso be configured to work with different hand-crafted and data-driven social\nreward signals and to yield a variety of evaluation metrics to benchmark\nagents' performance. Further, we also provide a case study where a Dueling-DQN\nagent is trained to learn social-navigation policies using SocNavGym. The\nresults provides evidence that SocNavGym can be used to train an agent from\nscratch to navigate in simple as well as complex social scenarios. Our\nexperiments also show that the agents trained using the data-driven reward\nfunction displays more advanced social compliance in comparison to the\nheuristic-based reward function.\n","authors":["Aditya Kapoor","Sushant Swamy","Luis Manso","Pilar Bachiller"],"pdf_url":"https://arxiv.org/pdf/2304.14102v2.pdf","comment":"IEEE RO-MAN"},{"id":"http://arxiv.org/abs/2307.03373v1","updated":"2023-07-07T03:51:21Z","published":"2023-07-07T03:51:21Z","title":"All in One: Exploring Unified Vision-Language Tracking with Multi-Modal\n  Alignment","summary":"  Current mainstream vision-language (VL) tracking framework consists of three\nparts, \\ie a visual feature extractor, a language feature extractor, and a\nfusion model. To pursue better performance, a natural modus operandi for VL\ntracking is employing customized and heavier unimodal encoders, and multi-modal\nfusion models. Albeit effective, existing VL trackers separate feature\nextraction and feature integration, resulting in extracted features that lack\nsemantic guidance and have limited target-aware capability in complex\nscenarios, \\eg similar distractors and extreme illumination. In this work,\ninspired by the recent success of exploring foundation models with unified\narchitecture for both natural language and computer vision tasks, we propose an\nAll-in-One framework, which learns joint feature extraction and interaction by\nadopting a unified transformer backbone. Specifically, we mix raw vision and\nlanguage signals to generate language-injected vision tokens, which we then\nconcatenate before feeding into the unified backbone architecture. This\napproach achieves feature integration in a unified backbone, removing the need\nfor carefully-designed fusion modules and resulting in a more effective and\nefficient VL tracking framework. To further improve the learning efficiency, we\nintroduce a multi-modal alignment module based on cross-modal and intra-modal\ncontrastive objectives, providing more reasonable representations for the\nunified All-in-One transformer backbone. Extensive experiments on five\nbenchmarks, \\ie OTB99-L, TNL2K, LaSOT, LaSOT$_{\\rm Ext}$ and WebUAV-3M,\ndemonstrate the superiority of the proposed tracker against existing\nstate-of-the-arts on VL tracking. Codes will be made publicly available.\n","authors":["Chunhui Zhang","Xin Sun","Li Liu","Yiqian Yang","Qiong Liu","Xi Zhou","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2307.03373v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2307.03362v1","updated":"2023-07-07T03:05:34Z","published":"2023-07-07T03:05:34Z","title":"Adaptation and Communication in Human-Robot Teaming to Handle\n  Discrepancies in Agents' Beliefs about Plans","summary":"  When agents collaborate on a task, it is important that they have some shared\nmental model of the task routines -- the set of feasible plans towards\nachieving the goals. However, in reality, situations often arise that such a\nshared mental model cannot be guaranteed, such as in ad-hoc teams where agents\nmay follow different conventions or when contingent constraints arise that only\nsome agents are aware of. Previous work on human-robot teaming has assumed that\nthe team has a set of shared routines, which breaks down in these situations.\nIn this work, we leverage epistemic logic to enable agents to understand the\ndiscrepancy in each other's beliefs about feasible plans and dynamically plan\ntheir actions to adapt or communicate to resolve the discrepancy. We propose a\nformalism that extends conditional doxastic logic to describe knowledge bases\nin order to explicitly represent agents' nested beliefs on the feasible plans\nand state of execution. We provide an online execution algorithm based on Monte\nCarlo Tree Search for the agent to plan its action, including communication\nactions to explain the feasibility of plans, announce intent, and ask\nquestions. Finally, we evaluate the success rate and scalability of the\nalgorithm and show that our agent is better equipped to work in teams without\nthe guarantee of a shared mental model.\n","authors":["Yuening Zhang","Brian C. Williams"],"pdf_url":"https://arxiv.org/pdf/2307.03362v1.pdf","comment":"10 pages, Published at ICAPS 2023 (Main Track)"},{"id":"http://arxiv.org/abs/2307.03360v1","updated":"2023-07-07T03:01:56Z","published":"2023-07-07T03:01:56Z","title":"Evaluating Biased Attitude Associations of Language Models in an\n  Intersectional Context","summary":"  Language models are trained on large-scale corpora that embed implicit biases\ndocumented in psychology. Valence associations (pleasantness/unpleasantness) of\nsocial groups determine the biased attitudes towards groups and concepts in\nsocial cognition. Building on this established literature, we quantify how\nsocial groups are valenced in English language models using a sentence template\nthat provides an intersectional context. We study biases related to age,\neducation, gender, height, intelligence, literacy, race, religion, sex, sexual\norientation, social class, and weight. We present a concept projection approach\nto capture the valence subspace through contextualized word embeddings of\nlanguage models. Adapting the projection-based approach to embedding\nassociation tests that quantify bias, we find that language models exhibit the\nmost biased attitudes against gender identity, social class, and sexual\norientation signals in language. We find that the largest and better-performing\nmodel that we study is also more biased as it effectively captures bias\nembedded in sociocultural data. We validate the bias evaluation method by\noverperforming on an intrinsic valence evaluation task. The approach enables us\nto measure complex intersectional biases as they are known to manifest in the\noutputs and applications of language models that perpetuate historical biases.\nMoreover, our approach contributes to design justice as it studies the\nassociations of groups underrepresented in language such as transgender and\nhomosexual individuals.\n","authors":["Shiva Omrani Sabbaghi","Robert Wolfe","Aylin Caliskan"],"pdf_url":"https://arxiv.org/pdf/2307.03360v1.pdf","comment":"to be published in AIES 2023"},{"id":"http://arxiv.org/abs/2307.02484v2","updated":"2023-07-07T01:12:55Z","published":"2023-07-05T17:58:21Z","title":"Elastic Decision Transformer","summary":"  This paper introduces Elastic Decision Transformer (EDT), a significant\nadvancement over the existing Decision Transformer (DT) and its variants.\nAlthough DT purports to generate an optimal trajectory, empirical evidence\nsuggests it struggles with trajectory stitching, a process involving the\ngeneration of an optimal or near-optimal trajectory from the best parts of a\nset of sub-optimal trajectories. The proposed EDT differentiates itself by\nfacilitating trajectory stitching during action inference at test time,\nachieved by adjusting the history length maintained in DT. Further, the EDT\noptimizes the trajectory by retaining a longer history when the previous\ntrajectory is optimal and a shorter one when it is sub-optimal, enabling it to\n\"stitch\" with a more optimal trajectory. Extensive experimentation demonstrates\nEDT's ability to bridge the performance gap between DT-based and Q\nLearning-based approaches. In particular, the EDT outperforms Q Learning-based\nmethods in a multi-task regime on the D4RL locomotion benchmark and Atari\ngames. Videos are available at: https://kristery.github.io/edt/\n","authors":["Yueh-Hua Wu","Xiaolong Wang","Masashi Hamaya"],"pdf_url":"https://arxiv.org/pdf/2307.02484v2.pdf","comment":"https://kristery.github.io/edt/"},{"id":"http://arxiv.org/abs/2307.03860v1","updated":"2023-07-07T22:47:29Z","published":"2023-07-07T22:47:29Z","title":"Reinforcement and Deep Reinforcement Learning-based Solutions for\n  Machine Maintenance Planning, Scheduling Policies, and Optimization","summary":"  Systems and machines undergo various failure modes that result in machine\nhealth degradation, so maintenance actions are required to restore them back to\na state where they can perform their expected functions. Since maintenance\ntasks are inevitable, maintenance planning is essential to ensure the smooth\noperations of the production system and other industries at large. Maintenance\nplanning is a decision-making problem that aims at developing optimum\nmaintenance policies and plans that help reduces maintenance costs, extend\nasset life, maximize their availability, and ultimately ensure workplace\nsafety. Reinforcement learning is a data-driven decision-making algorithm that\nhas been increasingly applied to develop dynamic maintenance plans while\nleveraging the continuous information from condition monitoring of the system\nand machine states. By leveraging the condition monitoring data of systems and\nmachines with reinforcement learning, smart maintenance planners can be\ndeveloped, which is a precursor to achieving a smart factory. This paper\npresents a literature review on the applications of reinforcement and deep\nreinforcement learning for maintenance planning and optimization problems. To\ncapture the common ideas without losing touch with the uniqueness of each\npublication, taxonomies used to categorize the systems were developed, and\nreviewed publications were highlighted, classified, and summarized based on\nthese taxonomies. Adopted methodologies, findings, and well-defined\ninterpretations of the reviewed studies were summarized in graphical and\ntabular representations to maximize the utility of the work for both\nresearchers and practitioners. This work also highlights the research gaps, key\ninsights from the literature, and areas for future work.\n","authors":["Oluwaseyi Ogunfowora","Homayoun Najjaran"],"pdf_url":"https://arxiv.org/pdf/2307.03860v1.pdf","comment":"33 pages with references, 11 figures"},{"id":"http://arxiv.org/abs/2307.03853v1","updated":"2023-07-07T21:58:28Z","published":"2023-07-07T21:58:28Z","title":"Teach Me How to Learn: A Perspective Review towards User-centered\n  Neuro-symbolic Learning for Robotic Surgical Systems","summary":"  Recent advances in machine learning models allowed robots to identify objects\non a perceptual nonsymbolic level (e.g., through sensor fusion and natural\nlanguage understanding). However, these primarily black-box learning models\nstill lack interpretation and transferability and require high data and\ncomputational demand. An alternative solution is to teach a robot on both\nperceptual nonsymbolic and conceptual symbolic levels through hybrid\nneurosymbolic learning approaches with expert feedback (i.e., human-in-the-loop\nlearning). This work proposes a concept for this user-centered hybrid learning\nparadigm that focuses on robotic surgical situations. While most recent\nresearch focused on hybrid learning for non-robotic and some generic robotic\ndomains, little work focuses on surgical robotics. We survey this related\nresearch while focusing on human-in-the-loop surgical robotic systems. This\nevaluation highlights the most prominent solutions for autonomous surgical\nrobots and the challenges surgeons face when interacting with these systems.\nFinally, we envision possible ways to address these challenges using online\napprenticeship learning based on implicit and explicit feedback from expert\nsurgeons.\n","authors":["Amr Gomaa","Bilal Mahdy","Niko Kleer","Michael Feld","Frank Kirchner","Antonio Krüger"],"pdf_url":"https://arxiv.org/pdf/2307.03853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03848v1","updated":"2023-07-07T21:39:25Z","published":"2023-07-07T21:39:25Z","title":"Optimal Learners for Realizable Regression: PAC Learning and Online\n  Learning","summary":"  In this work, we aim to characterize the statistical complexity of realizable\nregression both in the PAC learning setting and the online learning setting.\n  Previous work had established the sufficiency of finiteness of the fat\nshattering dimension for PAC learnability and the necessity of finiteness of\nthe scaled Natarajan dimension, but little progress had been made towards a\nmore complete characterization since the work of Simon 1997 (SICOMP '97). To\nthis end, we first introduce a minimax instance optimal learner for realizable\nregression and propose a novel dimension that both qualitatively and\nquantitatively characterizes which classes of real-valued predictors are\nlearnable. We then identify a combinatorial dimension related to the Graph\ndimension that characterizes ERM learnability in the realizable setting.\nFinally, we establish a necessary condition for learnability based on a\ncombinatorial dimension related to the DS dimension, and conjecture that it may\nalso be sufficient in this context.\n  Additionally, in the context of online learning we provide a dimension that\ncharacterizes the minimax instance optimal cumulative loss up to a constant\nfactor and design an optimal online learner for realizable regression, thus\nresolving an open question raised by Daskalakis and Golowich in STOC '22.\n","authors":["Idan Attias","Steve Hanneke","Alkis Kalavasis","Amin Karbasi","Grigoris Velegkas"],"pdf_url":"https://arxiv.org/pdf/2307.03848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03838v1","updated":"2023-07-07T21:13:27Z","published":"2023-07-07T21:13:27Z","title":"RADAR: Robust AI-Text Detection via Adversarial Learning","summary":"  Recent advances in large language models (LLMs) and the intensifying\npopularity of ChatGPT-like applications have blurred the boundary of\nhigh-quality text generation between humans and machines. However, in addition\nto the anticipated revolutionary changes to our technology and society, the\ndifficulty of distinguishing LLM-generated texts (AI-text) from human-generated\ntexts poses new challenges of misuse and fairness, such as fake content\ngeneration, plagiarism, and false accusation of innocent writers. While\nexisting works show that current AI-text detectors are not robust to LLM-based\nparaphrasing, this paper aims to bridge this gap by proposing a new framework\ncalled RADAR, which jointly trains a Robust AI-text Detector via Adversarial\nleaRning. RADAR is based on adversarial training of a paraphraser and a\ndetector. The paraphraser's goal is to generate realistic contents to evade\nAI-text detection. RADAR uses the feedback from the detector to update the\nparaphraser, and vice versa. Evaluated with 8 different LLMs (Pythia, Dolly\n2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna) across 4 datasets,\nexperimental results show that RADAR significantly outperforms existing AI-text\ndetection methods, especially when paraphrasing is in place. We also identify\nthe strong transferability of RADAR from instruction-tuned LLMs to other LLMs,\nand evaluate the improved capability of RADAR via GPT-3.5.\n","authors":["Xiaomeng Hu","Pin-Yu Chen","Tsung-Yi Ho"],"pdf_url":"https://arxiv.org/pdf/2307.03838v1.pdf","comment":"Preprint. Project page and demos: https://radar.vizhub.ai"},{"id":"http://arxiv.org/abs/2307.03833v1","updated":"2023-07-07T21:03:18Z","published":"2023-07-07T21:03:18Z","title":"Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation","summary":"  Learning-based methods have dominated the 3D human pose estimation (HPE)\ntasks with significantly better performance in most benchmarks than traditional\noptimization-based methods. Nonetheless, 3D HPE in the wild is still the\nbiggest challenge of learning-based models, whether with 2D-3D lifting,\nimage-to-3D, or diffusion-based methods, since the trained networks implicitly\nlearn camera intrinsic parameters and domain-based 3D human pose distributions\nand estimate poses by statistical average. On the other hand, the\noptimization-based methods estimate results case-by-case, which can predict\nmore diverse and sophisticated human poses in the wild. By combining the\nadvantages of optimization-based and learning-based methods, we propose the\nZero-shot Diffusion-based Optimization (ZeDO) pipeline for 3D HPE to solve the\nproblem of cross-domain and in-the-wild 3D HPE. Our multi-hypothesis ZeDO\nachieves state-of-the-art (SOTA) performance on Human3.6M as minMPJPE $51.4$mm\nwithout training with any 2D-3D or image-3D pairs. Moreover, our\nsingle-hypothesis ZeDO achieves SOTA performance on 3DPW dataset with PA-MPJPE\n$42.6$mm on cross-dataset evaluation, which even outperforms learning-based\nmethods trained on 3DPW.\n","authors":["Zhongyu Jiang","Zhuoran Zhou","Lei Li","Wenhao Chai","Cheng-Yen Yang","Jenq-Neng Hwang"],"pdf_url":"https://arxiv.org/pdf/2307.03833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03827v1","updated":"2023-07-07T20:51:38Z","published":"2023-07-07T20:51:38Z","title":"Effect of Intensity Standardization on Deep Learning for WML\n  Segmentation in Multi-Centre FLAIR MRI","summary":"  Deep learning (DL) methods for white matter lesion (WML) segmentation in MRI\nsuffer a reduction in performance when applied on data from a scanner or centre\nthat is out-of-distribution (OOD) from the training data. This is critical for\ntranslation and widescale adoption, since current models cannot be readily\napplied to data from new institutions. In this work, we evaluate several\nintensity standardization methods for MRI as a preprocessing step for WML\nsegmentation in multi-centre Fluid-Attenuated Inversion Recovery (FLAIR) MRI.\nWe evaluate a method specifically developed for FLAIR MRI called IAMLAB along\nwith other popular normalization techniques such as White-strip, Nyul and\nZ-score. We proposed an Ensemble model that combines predictions from each of\nthese models. A skip-connection UNet (SC UNet) was trained on the standardized\nimages, as well as the original data and segmentation performance was evaluated\nover several dimensions. The training (in-distribution) data consists of a\nsingle study, of 60 volumes, and the test (OOD) data is 128 unseen volumes from\nthree clinical cohorts. Results show IAMLAB and Ensemble provide higher WML\nsegmentation performance compared to models from original data or other\nnormalization methods. IAMLAB & Ensemble have the highest dice similarity\ncoefficient (DSC) on the in-distribution data (0.78 & 0.80) and on clinical OOD\ndata. DSC was significantly higher for IAMLAB compared to the original data\n(p<0.05) for all lesion categories (LL>25mL: 0.77 vs. 0.71; 10mL<= LL<25mL:\n0.66 vs. 0.61; LL<10mL: 0.53 vs. 0.52). The IAMLAB and Ensemble normalization\nmethods are mitigating MRI domain shift and are optimal for DL-based WML\nsegmentation in unseen FLAIR data.\n","authors":["Abdollah Ghazvanchahi","Pejman Jahbedar Maralani","Alan R. Moody","April Khademi"],"pdf_url":"https://arxiv.org/pdf/2307.03827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03826v1","updated":"2023-07-07T20:41:26Z","published":"2023-07-07T20:41:26Z","title":"How does AI chat change search behaviors?","summary":"  Generative AI tools such as chatGPT are poised to change the way people\nengage with online information. Recently, Microsoft announced their \"new Bing\"\nsearch system which incorporates chat and generative AI technology from OpenAI.\nGoogle has announced plans to deploy search interfaces that incorporate similar\ntypes of technology. These new technologies will transform how people can\nsearch for information. The research presented here is an early investigation\ninto how people make use of a generative AI chat system (referred to simply as\nchat from here on) as part of a search process, and how the incorporation of\nchat systems with existing search tools may effect users search behaviors and\nstrategies.\n  We report on an exploratory user study with 10 participants who used a\ncombined Chat+Search system that utilized the OpenAI GPT-3.5 API and the Bing\nWeb Search v5 API. Participants completed three search tasks. In this pre-print\npaper of preliminary results, we report on ways that users integrated AI chat\ninto their search process, things they liked and disliked about the chat\nsystem, their trust in the chat responses, and their mental models of how the\nchat system generated responses.\n","authors":["Robert Capra","Jaime Arguello"],"pdf_url":"https://arxiv.org/pdf/2307.03826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01735v3","updated":"2023-07-07T20:36:16Z","published":"2022-12-04T03:45:08Z","title":"Neural Fourier Filter Bank","summary":"  We present a novel method to provide efficient and highly detailed\nreconstructions. Inspired by wavelets, we learn a neural field that decompose\nthe signal both spatially and frequency-wise. We follow the recent grid-based\nparadigm for spatial decomposition, but unlike existing work, encourage\nspecific frequencies to be stored in each grid via Fourier features encodings.\nWe then apply a multi-layer perceptron with sine activations, taking these\nFourier encoded features in at appropriate layers so that higher-frequency\ncomponents are accumulated on top of lower-frequency components sequentially,\nwhich we sum up to form the final output. We demonstrate that our method\noutperforms the state of the art regarding model compactness and convergence\nspeed on multiple tasks: 2D image fitting, 3D shape reconstruction, and neural\nradiance fields. Our code is available at https://github.com/ubc-vision/NFFB.\n","authors":["Zhijie Wu","Yuhe Jin","Kwang Moo Yi"],"pdf_url":"https://arxiv.org/pdf/2212.01735v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03817v1","updated":"2023-07-07T20:14:22Z","published":"2023-07-07T20:14:22Z","title":"Exploring and Characterizing Large Language Models For Embedded System\n  Development and Debugging","summary":"  Large language models (LLMs) have shown remarkable abilities to generate\ncode, however their ability to develop software for embedded systems, which\nrequires cross-domain knowledge of hardware and software has not been studied.\nIn this paper we systematically evaluate leading LLMs (GPT-3.5, GPT-4, PaLM 2)\nto assess their performance for embedded system development, study how human\nprogrammers interact with these tools, and develop an AI-based software\nengineering workflow for building embedded systems.\n  We develop an an end-to-end hardware-in-the-loop evaluation platform for\nverifying LLM generated programs using sensor actuator pairs. We compare all\nthree models with N=450 experiments and find surprisingly that GPT-4 especially\nshows an exceptional level of cross-domain understanding and reasoning, in some\ncases generating fully correct programs from a single prompt. In N=50 trials,\nGPT-4 produces functional I2C interfaces 66% of the time. GPT-4 also produces\nregister-level drivers, code for LoRa communication, and context-specific power\noptimizations for an nRF52 program resulting in over 740x current reduction to\n12.2 uA. We also characterize the models' limitations to develop a\ngeneralizable workflow for using LLMs in embedded system development. We\nevaluate the workflow with 15 users including novice and expert programmers. We\nfind that our workflow improves productivity for all users and increases the\nsuccess rate for building a LoRa environmental sensor from 25% to 100%,\nincluding for users with zero hardware or C/C++ experience.\n","authors":["Zachary Englhardt","Richard Li","Dilini Nissanka","Zhihan Zhang","Girish Narayanswamy","Joseph Breda","Xin Liu","Shwetak Patel","Vikram Iyer"],"pdf_url":"https://arxiv.org/pdf/2307.03817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04547v2","updated":"2023-07-07T19:40:13Z","published":"2022-09-09T22:48:35Z","title":"Defend Data Poisoning Attacks on Voice Authentication","summary":"  With the advances in deep learning, speaker verification has achieved very\nhigh accuracy and is gaining popularity as a type of biometric authentication\noption in many scenes of our daily life, especially the growing market of web\nservices. Compared to traditional passwords, \"vocal passwords\" are much more\nconvenient as they relieve people from memorizing different passwords. However,\nnew machine learning attacks are putting these voice authentication systems at\nrisk. Without a strong security guarantee, attackers could access legitimate\nusers' web accounts by fooling the deep neural network (DNN) based voice\nrecognition models. In this paper, we demonstrate an easy-to-implement data\npoisoning attack to the voice authentication system, which can hardly be\ncaptured by existing defense mechanisms. Thus, we propose a more robust defense\nmethod, called Guardian, which is a convolutional neural network-based\ndiscriminator. The Guardian discriminator integrates a series of novel\ntechniques including bias reduction, input augmentation, and ensemble learning.\nOur approach is able to distinguish about 95% of attacked accounts from normal\naccounts, which is much more effective than existing approaches with only 60%\naccuracy.\n","authors":["Ke Li","Cameron Baird","Dan Lin"],"pdf_url":"https://arxiv.org/pdf/2209.04547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03764v1","updated":"2023-07-07T19:39:15Z","published":"2023-07-07T19:39:15Z","title":"For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis\n  of a Watershed Moment in Iran's Gender Struggles","summary":"  In this paper, we present a computational analysis of the Persian language\nTwitter discourse with the aim to estimate the shift in stance toward gender\nequality following the death of Mahsa Amini in police custody. We present an\nensemble active learning pipeline to train a stance classifier. Our novelty\nlies in the involvement of Iranian women in an active role as annotators in\nbuilding this AI system. Our annotators not only provide labels, but they also\nsuggest valuable keywords for more meaningful corpus creation as well as\nprovide short example documents for a guided sampling step. Our analyses\nindicate that Mahsa Amini's death triggered polarized Persian language\ndiscourse where both fractions of negative and positive tweets toward gender\nequality increased. The increase in positive tweets was slightly greater than\nthe increase in negative tweets. We also observe that with respect to account\ncreation time, between the state-aligned Twitter accounts and pro-protest\nTwitter accounts, pro-protest accounts are more similar to baseline Persian\nTwitter activity.\n","authors":["Adel Khorramrouz","Sujan Dutta","Ashiqur R. KhudaBukhsh"],"pdf_url":"https://arxiv.org/pdf/2307.03764v1.pdf","comment":"Accepted at IJCAI 2023 (AI for good track)"},{"id":"http://arxiv.org/abs/2307.03810v1","updated":"2023-07-07T19:34:04Z","published":"2023-07-07T19:34:04Z","title":"URL: A Representation Learning Benchmark for Transferable Uncertainty\n  Estimates","summary":"  Representation learning has significantly driven the field to develop\npretrained models that can act as a valuable starting point when transferring\nto new datasets. With the rising demand for reliable machine learning and\nuncertainty quantification, there is a need for pretrained models that not only\nprovide embeddings but also transferable uncertainty estimates. To guide the\ndevelopment of such models, we propose the Uncertainty-aware Representation\nLearning (URL) benchmark. Besides the transferability of the representations,\nit also measures the zero-shot transferability of the uncertainty estimate\nusing a novel metric. We apply URL to evaluate eleven uncertainty quantifiers\nthat are pretrained on ImageNet and transferred to eight downstream datasets.\nWe find that approaches that focus on the uncertainty of the representation\nitself or estimate the prediction risk directly outperform those that are based\non the probabilities of upstream classes. Yet, achieving transferable\nuncertainty quantification remains an open challenge. Our findings indicate\nthat it is not necessarily in conflict with traditional representation learning\ngoals. Code is provided under https://github.com/mkirchhof/url .\n","authors":["Michael Kirchhof","Bálint Mucsányi","Seong Joon Oh","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2307.03810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07733v5","updated":"2023-07-07T19:08:18Z","published":"2023-01-18T19:00:50Z","title":"Learning-Rate-Free Learning by D-Adaptation","summary":"  D-Adaptation is an approach to automatically setting the learning rate which\nasymptotically achieves the optimal rate of convergence for minimizing convex\nLipschitz functions, with no back-tracking or line searches, and no additional\nfunction value or gradient evaluations per step. Our approach is the first\nhyper-parameter free method for this class without additional multiplicative\nlog factors in the convergence rate. We present extensive experiments for SGD\nand Adam variants of our method, where the method automatically matches\nhand-tuned learning rates across more than a dozen diverse machine learning\nproblems, including large-scale vision and language problems.\n  An open-source implementation is available.\n","authors":["Aaron Defazio","Konstantin Mishchenko"],"pdf_url":"https://arxiv.org/pdf/2301.07733v5.pdf","comment":null}]},"2023-07-10T00:00:00Z":{"Sound":[{"id":"http://arxiv.org/abs/2307.04760v1","updated":"2023-07-10T17:58:17Z","published":"2023-07-10T17:58:17Z","title":"Learning Spatial Features from Audio-Visual Correspondence in Egocentric\n  Videos","summary":"  We propose a self-supervised method for learning representations based on\nspatial audio-visual correspondences in egocentric videos. In particular, our\nmethod leverages a masked auto-encoding framework to synthesize masked binaural\naudio through the synergy of audio and vision, thereby learning useful spatial\nrelationships between the two modalities. We use our pretrained features to\ntackle two downstream video tasks requiring spatial understanding in social\nscenarios: active speaker detection and spatial audio denoising. We show\nthrough extensive experiments that our features are generic enough to improve\nover multiple state-of-the-art baselines on two public challenging egocentric\nvideo datasets, EgoCom and EasyCom. Project:\nhttp://vision.cs.utexas.edu/projects/ego_av_corr.\n","authors":["Sagnik Majumder","Ziad Al-Halah","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2307.04760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04702v1","updated":"2023-07-10T16:59:49Z","published":"2023-07-10T16:59:49Z","title":"Vocal Tract Area Estimation by Gradient Descent","summary":"  Articulatory features can provide interpretable and flexible controls for the\nsynthesis of human vocalizations by allowing the user to directly modify\nparameters like vocal strain or lip position. To make this manipulation through\nresynthesis possible, we need to estimate the features that result in a desired\nvocalization directly from audio recordings. In this work, we propose a\nwhite-box optimization technique for estimating glottal source parameters and\nvocal tract shapes from audio recordings of human vowels. The approach is based\non inverse filtering and optimizing the frequency response of a wave\\-guide\nmodel of the vocal tract with gradient descent, propagating error gradients\nthrough the mapping of articulatory features to the vocal tract area function.\nWe apply this method to the task of matching the sound of the Pink Trombone, an\ninteractive articulatory synthesizer, to a given vocalization. We find that our\nmethod accurately recovers control functions for audio generated by the Pink\nTrombone itself. We then compare our technique against evolutionary\noptimization algorithms and a neural network trained to predict control\nparameters from audio. A subjective evaluation finds that our approach\noutperforms these black-box optimization baselines on the task of reproducing\nhuman vocalizations.\n","authors":["David Südholt","Mateo Cámara","Zhiyuan Xu","Joshua D. Reiss"],"pdf_url":"https://arxiv.org/pdf/2307.04702v1.pdf","comment":"Accepted to DAFx 2023"},{"id":"http://arxiv.org/abs/2307.04686v1","updated":"2023-07-10T16:42:03Z","published":"2023-07-10T16:42:03Z","title":"VampNet: Music Generation via Masked Acoustic Token Modeling","summary":"  We introduce VampNet, a masked acoustic token modeling approach to music\nsynthesis, compression, inpainting, and variation. We use a variable masking\nschedule during training which allows us to sample coherent music from the\nmodel by applying a variety of masking approaches (called prompts) during\ninference. VampNet is non-autoregressive, leveraging a bidirectional\ntransformer architecture that attends to all tokens in a forward pass. With\njust 36 sampling passes, VampNet can generate coherent high-fidelity musical\nwaveforms. We show that by prompting VampNet in various ways, we can apply it\nto tasks like music compression, inpainting, outpainting, continuation, and\nlooping with variation (vamping). Appropriately prompted, VampNet is capable of\nmaintaining style, genre, instrumentation, and other high-level aspects of the\nmusic. This flexible prompting capability makes VampNet a powerful music\nco-creation tool. Code and audio samples are available online.\n","authors":["Hugo Flores Garcia","Prem Seetharaman","Rithesh Kumar","Bryan Pardo"],"pdf_url":"https://arxiv.org/pdf/2307.04686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02719v2","updated":"2023-07-10T15:15:47Z","published":"2023-03-05T17:20:10Z","title":"A Comparative Study of Self-Supervised Speech Representations in Read\n  and Spontaneous TTS","summary":"  Recent work has explored using self-supervised learning (SSL) speech\nrepresentations such as wav2vec2.0 as the representation medium in standard\ntwo-stage TTS, in place of conventionally used mel-spectrograms. It is however\nunclear which speech SSL is the better fit for TTS, and whether or not the\nperformance differs between read and spontaneous TTS, the later of which is\narguably more challenging. This study aims at addressing these questions by\ntesting several speech SSLs, including different layers of the same SSL, in\ntwo-stage TTS on both read and spontaneous corpora, while maintaining constant\nTTS model architecture and training settings. Results from listening tests show\nthat the 9th layer of 12-layer wav2vec2.0 (ASR finetuned) outperforms other\ntested SSLs and mel-spectrogram, in both read and spontaneous TTS. Our work\nsheds light on both how speech SSL can readily improve current TTS systems, and\nhow SSLs compare in the challenging generative task of TTS. Audio examples can\nbe found at https://www.speech.kth.se/tts-demos/ssr_tts\n","authors":["Siyang Wang","Gustav Eje Henter","Joakim Gustafson","Éva Székely"],"pdf_url":"https://arxiv.org/pdf/2303.02719v2.pdf","comment":"5 pages, 2 figures. ICASSP Workshop SASB (Self-Supervision in Audio,\n  Speech and Beyond)2023"},{"id":"http://arxiv.org/abs/2307.04630v1","updated":"2023-07-10T15:15:17Z","published":"2023-07-10T15:15:17Z","title":"The NPU-MSXF Speech-to-Speech Translation System for IWSLT 2023\n  Speech-to-Speech Translation Task","summary":"  This paper describes the NPU-MSXF system for the IWSLT 2023 speech-to-speech\ntranslation (S2ST) task which aims to translate from English speech of\nmulti-source to Chinese speech. The system is built in a cascaded manner\nconsisting of automatic speech recognition (ASR), machine translation (MT), and\ntext-to-speech (TTS). We make tremendous efforts to handle the challenging\nmulti-source input. Specifically, to improve the robustness to multi-source\nspeech input, we adopt various data augmentation strategies and a ROVER-based\nscore fusion on multiple ASR model outputs. To better handle the noisy ASR\ntranscripts, we introduce a three-stage fine-tuning strategy to improve\ntranslation accuracy. Finally, we build a TTS model with high naturalness and\nsound quality, which leverages a two-stage framework, using network bottleneck\nfeatures as a robust intermediate representation for speaker timbre and\nlinguistic content disentanglement. Based on the two-stage framework,\npre-trained speaker embedding is leveraged as a condition to transfer the\nspeaker timbre in the source English speech to the translated Chinese speech.\nExperimental results show that our system has high translation accuracy, speech\nnaturalness, sound quality, and speaker similarity. Moreover, it shows good\nrobustness to multi-source data.\n","authors":["Kun Song","Yi lei","Peikun Chen","Yiqing Cao","Kun Wei","Yongmao Zhang","Lei Xie","Ning Jiang","Guoqing Zhao"],"pdf_url":"https://arxiv.org/pdf/2307.04630v1.pdf","comment":"IWSLT@ACL 2023 system paper. Our submitted system ranks 1st in the\n  S2ST task of the IWSLT 2023 evaluation campaign"},{"id":"http://arxiv.org/abs/2307.04604v1","updated":"2023-07-10T14:43:32Z","published":"2023-07-10T14:43:32Z","title":"EchoVest: Real-Time Sound Classification and Depth Perception Expressed\n  through Transcutaneous Electrical Nerve Stimulation","summary":"  Over 1.5 billion people worldwide live with hearing impairment. Despite\nvarious technologies that have been created for individuals with such\ndisabilities, most of these technologies are either extremely expensive or\ninaccessible for everyday use in low-medium income countries. In order to\ncombat this issue, we have developed a new assistive device, EchoVest, for\nblind/deaf people to intuitively become more aware of their environment.\nEchoVest transmits vibrations to the user's body by utilizing transcutaneous\nelectric nerve stimulation (TENS) based on the source of the sounds. EchoVest\nalso provides various features, including sound localization, sound\nclassification, noise reduction, and depth perception. We aimed to outperform\nCNN-based machine-learning models, the most commonly used machine learning\nmodel for classification tasks, in accuracy and computational costs. To do so,\nwe developed and employed a novel audio pipeline that adapts the Audio\nSpectrogram Transformer (AST) model, an attention-based model, for our sound\nclassification purposes, and Fast Fourier Transforms for noise reduction. The\napplication of Otsu's Method helped us find the optimal thresholds for\nbackground noise sound filtering and gave us much greater accuracy. In order to\ncalculate direction and depth accurately, we applied Complex Time Difference of\nArrival algorithms and SOTA localization. Our last improvement was to use blind\nsource separation to make our algorithms applicable to multiple microphone\ninputs. The final algorithm achieved state-of-the-art results on numerous\ncheckpoints, including a 95.7\\% accuracy on the ESC-50 dataset for\nenvironmental sound classification.\n","authors":["Jesse Choe","Siddhant Sood","Ryan Park"],"pdf_url":"https://arxiv.org/pdf/2307.04604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04974v4","updated":"2023-07-10T10:30:38Z","published":"2022-08-09T18:01:50Z","title":"Mathematical Foundations of Complex Tonality","summary":"  Equal temperament, in which semitones are tuned in the irrational ratio of\n$2^{1/12} : 1$, is best seen as a serviceable compromise, sacrificing purity\nfor flexibility. Just intonation, in which intervals are given by products of\npowers of $2$, $3$, and $5$, is more natural, but of limited flexibility. We\npropose a new scheme in which ratios of Gaussian integers form the basis of an\nabstract tonal system. The tritone, so problematic in just temperament, given\nambiguously by the ratios $\\tfrac{45}{32}$, $\\tfrac{64}{45}$, $\\tfrac{36}{25}$,\n$\\tfrac{25}{18}$, none satisfactory, is in our scheme represented by the\ncomplex ratio $1 + \\rm{i} : 1$. The major and minor whole tones, given by\nintervals of $\\tfrac{9}{8}$ and $\\tfrac{10}{9}$, can each be factorized into\nproducts of complex semitones, giving us a major complex semitone\n$\\tfrac{3}{4}(1 + \\rm{i})$ and a minor complex semitone $\\tfrac{1}{3}(3 +\n\\rm{i})$. The perfect third, given by the interval $\\tfrac{5}{4}$, factorizes\ninto the product of a complex whole tone $\\tfrac{1}{2}(1 + 2\\rm{i})$ and its\ncomplex conjugate. Augmented with these supplementary tones, the resulting\nscheme of complex intervals based on products of low powers of Gaussian primes\nleads to the construction of a complete system of major and minor scales in all\nkeys.\n","authors":["Jeffrey R. Boland","Lane P. Hughston"],"pdf_url":"https://arxiv.org/pdf/2208.04974v4.pdf","comment":"35 pages, to appear in Journal of Mathematics and Music"},{"id":"http://arxiv.org/abs/2307.04460v1","updated":"2023-07-10T10:13:12Z","published":"2023-07-10T10:13:12Z","title":"Exploiting an External Microphone for Binaural RTF-Vector-Based\n  Direction of Arrival Estimation for Multiple Speakers","summary":"  In hearing aid applications, an important objective is to accurately estimate\nthe direction of arrival (DOA) of multiple speakers in noisy and reverberant\nenvironments. Recently, we proposed a binaural DOA estimation method, where the\nDOAs of the speakers are estimated by selecting the directions for which the\nso-called Hermitian angle spectrum between the estimated relative transfer\nfunction (RTF) vector and a database of prototype anechoic RTF vectors is\nmaximized. The RTF vector is estimated using the covariance whitening (CW)\nmethod, which requires a computationally complex generalized eigenvalue\ndecomposition. The spatial spectrum is obtained by only considering frequencies\nwhere it is likely that one speaker dominates over the other speakers, noise\nand reverberation. In this contribution, we exploit the availability of an\nexternal microphone that is spatially separated from the hearing aid\nmicrophones and consider a low-complexity RTF vector estimation method that\nassumes a low spatial coherence between the undesired components in the\nexternal microphone and the hearing aid microphones. Using recordings of two\nspeakers and diffuse-like babble noise in acoustic environments with mild\nreverberation and low signal-to-noise ratio, simulation results show that the\nproposed method yields a comparable DOA estimation performance as the CW method\nat a lower computational complexity.\n","authors":["Daniel Fejgin","Simon Doclo"],"pdf_url":"https://arxiv.org/pdf/2307.04460v1.pdf","comment":"Paper accepted for Forum Acusticum 2023"},{"id":"http://arxiv.org/abs/2306.03718v3","updated":"2023-07-10T09:27:17Z","published":"2023-06-06T14:28:57Z","title":"Emotion-Conditioned Melody Harmonization with Hierarchical Variational\n  Autoencoder","summary":"  Existing melody harmonization models have made great progress in improving\nthe quality of generated harmonies, but most of them ignored the emotions\nbeneath the music. Meanwhile, the variability of harmonies generated by\nprevious methods is insufficient. To solve these problems, we propose a novel\nLSTM-based Hierarchical Variational Auto-Encoder (LHVAE) to investigate the\ninfluence of emotional conditions on melody harmonization, while improving the\nquality of generated harmonies and capturing the abundant variability of chord\nprogressions. Specifically, LHVAE incorporates latent variables and emotional\nconditions at different levels (piece- and bar-level) to model the global and\nlocal music properties. Additionally, we introduce an attention-based melody\ncontext vector at each step to better learn the correspondence between melodies\nand harmonies. Objective experimental results show that our proposed model\noutperforms other LSTM-based models. Through subjective evaluation, we conclude\nthat only altering the type of chord hardly changes the overall emotion of the\nmusic. The qualitative analysis demonstrates the ability of our model to\ngenerate variable harmonies.\n","authors":["Shulei Ji","Xinyu Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03718v3.pdf","comment":"Accepted by IEEE SMC 2023"},{"id":"http://arxiv.org/abs/2307.04377v1","updated":"2023-07-10T07:22:06Z","published":"2023-07-10T07:22:06Z","title":"HCLAS-X: Hierarchical and Cascaded Lyrics Alignment System Using\n  Multimodal Cross-Correlation","summary":"  In this work, we address the challenge of lyrics alignment, which involves\naligning the lyrics and vocal components of songs. This problem requires the\nalignment of two distinct modalities, namely text and audio. To overcome this\nchallenge, we propose a model that is trained in a supervised manner, utilizing\nthe cross-correlation matrix of latent representations between vocals and\nlyrics. Our system is designed in a hierarchical and cascaded manner. It\npredicts synced time first on a sentence-level and subsequently on a\nword-level. This design enables the system to process long sequences, as the\ncross-correlation uses quadratic memory with respect to sequence length. In our\nexperiments, we demonstrate that our proposed system achieves a significant\nimprovement in mean average error, showcasing its robustness in comparison to\nthe previous state-of-the-art model. Additionally, we conduct a qualitative\nanalysis of the system after successfully deploying it in several music\nstreaming services.\n","authors":["Minsung Kang","Soochul Park","Keunwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2307.04377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04305v1","updated":"2023-07-10T02:04:43Z","published":"2023-07-10T02:04:43Z","title":"Automatic Piano Transcription with Hierarchical Frequency-Time\n  Transformer","summary":"  Taking long-term spectral and temporal dependencies into account is essential\nfor automatic piano transcription. This is especially helpful when determining\nthe precise onset and offset for each note in the polyphonic piano content. In\nthis case, we may rely on the capability of self-attention mechanism in\nTransformers to capture these long-term dependencies in the frequency and time\naxes. In this work, we propose hFT-Transformer, which is an automatic music\ntranscription method that uses a two-level hierarchical frequency-time\nTransformer architecture. The first hierarchy includes a convolutional block in\nthe time axis, a Transformer encoder in the frequency axis, and a Transformer\ndecoder that converts the dimension in the frequency axis. The output is then\nfed into the second hierarchy which consists of another Transformer encoder in\nthe time axis. We evaluated our method with the widely used MAPS and MAESTRO\nv3.0.0 datasets, and it demonstrated state-of-the-art performance on all the\nF1-scores of the metrics among Frame, Note, Note with Offset, and Note with\nOffset and Velocity estimations.\n","authors":["Keisuke Toyama","Taketo Akama","Yukara Ikemiya","Yuhta Takida","Wei-Hsiang Liao","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2307.04305v1.pdf","comment":"8 pages, 6 figures, to be published in ISMIR2023"},{"id":"http://arxiv.org/abs/2307.04298v1","updated":"2023-07-10T01:30:21Z","published":"2023-07-10T01:30:21Z","title":"Edge Storage Management Recipe with Zero-Shot Data Compression for Road\n  Anomaly Detection","summary":"  Recent studies show edge computing-based road anomaly detection systems which\nmay also conduct data collection simultaneously. However, the edge computers\nwill have small data storage but we need to store the collected audio samples\nfor a long time in order to update existing models or develop a novel method.\nTherefore, we should consider an approach for efficient storage management\nmethods while preserving high-fidelity audio. A hardware-perspective approach,\nsuch as using a low-resolution microphone, is an intuitive way to reduce file\nsize but is not recommended because it fundamentally cuts off high-frequency\ncomponents. On the other hand, a computational file compression approach that\nencodes collected high-resolution audio into a compact code should be\nrecommended because it also provides a corresponding decoding method. Motivated\nby this, we propose a way of simple yet effective pre-trained autoencoder-based\ndata compression method. The pre-trained autoencoder is trained for the purpose\nof audio super-resolution so it can be utilized to encode or decode any\narbitrary sampling rate. Moreover, it will reduce the communication cost for\ndata transmission from the edge to the central server. Via the comparative\nexperiments, we confirm that the zero-shot audio compression and decompression\nhighly preserve anomaly detection performance while enhancing storage and\ntransmission efficiency.\n","authors":["YeongHyeon Park","Uju Gim","Myung Jin Kim"],"pdf_url":"https://arxiv.org/pdf/2307.04298v1.pdf","comment":"5 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2107.00439v3","updated":"2023-07-10T18:08:42Z","published":"2021-07-01T13:32:55Z","title":"What do End-to-End Speech Models Learn about Speaker, Language and\n  Channel Information? A Layer-wise and Neuron-level Analysis","summary":"  Deep neural networks are inherently opaque and challenging to interpret.\nUnlike hand-crafted feature-based models, we struggle to comprehend the\nconcepts learned and how they interact within these models. This understanding\nis crucial not only for debugging purposes but also for ensuring fairness in\nethical decision-making. In our study, we conduct a post-hoc functional\ninterpretability analysis of pretrained speech models using the probing\nframework [1]. Specifically, we analyze utterance-level representations of\nspeech models trained for various tasks such as speaker recognition and dialect\nidentification. We conduct layer and neuron-wise analyses, probing for speaker,\nlanguage, and channel properties. Our study aims to answer the following\nquestions: i) what information is captured within the representations? ii) how\nis it represented and distributed? and iii) can we identify a minimal subset of\nthe network that possesses this information?\n  Our results reveal several novel findings, including: i) channel and gender\ninformation are distributed across the network, ii) the information is\nredundantly available in neurons with respect to a task, iii) complex\nproperties such as dialectal information are encoded only in the task-oriented\npretrained network, iv) and is localised in the upper layers, v) we can extract\na minimal subset of neurons encoding the pre-defined property, vi) salient\nneurons are sometimes shared between properties, vii) our analysis highlights\nthe presence of biases (for example gender) in the network. Our\ncross-architectural comparison indicates that: i) the pretrained models capture\nspeaker-invariant information, and ii) CNN models are competitive with\nTransformer models in encoding various understudied properties.\n","authors":["Shammur Absar Chowdhury","Nadir Durrani","Ahmed Ali"],"pdf_url":"https://arxiv.org/pdf/2107.00439v3.pdf","comment":"Accepted in CSL journal. Keywords: Speech, Neuron Analysis,\n  Interpretibility, Diagnostic Classifier, AI explainability, End-to-End\n  Architecture"},{"id":"http://arxiv.org/abs/2307.05588v1","updated":"2023-07-10T15:57:42Z","published":"2023-07-10T15:57:42Z","title":"Collaborative Song Dataset (CoSoD): An annotated dataset of multi-artist\n  collaborations in popular music","summary":"  The Collaborative Song Dataset (CoSoD) is a corpus of 331 multi-artist\ncollaborations from the 2010-2019 Billboard \"Hot 100\" year-end charts. The\ncorpus is annotated with formal sections, aspects of vocal production\n(including reverberation, layering, panning, and gender of the performers), and\nrelevant metadata. CoSoD complements other popular music datasets by focusing\nexclusively on musical collaborations between independent acts. In addition to\nfacilitating the study of song form and vocal production, CoSoD allows for the\nin-depth study of gender as it relates to various timbral, pitch, and formal\nparameters in musical collaborations. In this paper, we detail the contents of\nthe dataset and outline the annotation process. We also present an experiment\nusing CoSoD that examines how the use of reverberation, layering, and panning\nare related to the gender of the artist. In this experiment, we find that men's\nvoices are on average treated with less reverberation and occupy a more narrow\nposition in the stereo mix than women's voices.\n","authors":["Michèle Duguay","Kate Mancey","Johanna Devaney"],"pdf_url":"https://arxiv.org/pdf/2307.05588v1.pdf","comment":"To be published in the Proceedings of the 24th International Society\n  for Music Information Retrieval Conference (ISMIR)"}],"Audio and Speech Processing":[{"id":"http://arxiv.org/abs/2307.04760v1","updated":"2023-07-10T17:58:17Z","published":"2023-07-10T17:58:17Z","title":"Learning Spatial Features from Audio-Visual Correspondence in Egocentric\n  Videos","summary":"  We propose a self-supervised method for learning representations based on\nspatial audio-visual correspondences in egocentric videos. In particular, our\nmethod leverages a masked auto-encoding framework to synthesize masked binaural\naudio through the synergy of audio and vision, thereby learning useful spatial\nrelationships between the two modalities. We use our pretrained features to\ntackle two downstream video tasks requiring spatial understanding in social\nscenarios: active speaker detection and spatial audio denoising. We show\nthrough extensive experiments that our features are generic enough to improve\nover multiple state-of-the-art baselines on two public challenging egocentric\nvideo datasets, EgoCom and EasyCom. Project:\nhttp://vision.cs.utexas.edu/projects/ego_av_corr.\n","authors":["Sagnik Majumder","Ziad Al-Halah","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2307.04760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04744v1","updated":"2023-07-10T17:53:21Z","published":"2023-07-10T17:53:21Z","title":"Behavioral Analysis of Pathological Speaker Embeddings of Patients\n  During Oncological Treatment of Oral Cancer","summary":"  In this paper, we analyze the behavior of speaker embeddings of patients\nduring oral cancer treatment. First, we found that pre- and post-treatment\nspeaker embeddings differ significantly, notifying a substantial change in\nvoice characteristics. However, a partial recovery to pre-operative voice\ntraits is observed after 12 months post-operation. Secondly, the same-speaker\nsimilarity at distinct treatment stages is similar to healthy speakers,\nindicating that the embeddings can capture characterizing features of even\nseverely impaired speech. Finally, a speaker verification analysis signifies a\nstable false positive rate and variable false negative rate when combining\nspeech samples of different treatment stages. This indicates robustness of the\nembeddings towards other speakers, while still capturing the changing voice\ncharacteristics during treatment. To the best of our knowledge, this is the\nfirst analysis of speaker embeddings during oral cancer treatment of patients.\n","authors":["Jenthe Thienpondt","Kris Demuynck"],"pdf_url":"https://arxiv.org/pdf/2307.04744v1.pdf","comment":"proceedings of INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2307.04702v1","updated":"2023-07-10T16:59:49Z","published":"2023-07-10T16:59:49Z","title":"Vocal Tract Area Estimation by Gradient Descent","summary":"  Articulatory features can provide interpretable and flexible controls for the\nsynthesis of human vocalizations by allowing the user to directly modify\nparameters like vocal strain or lip position. To make this manipulation through\nresynthesis possible, we need to estimate the features that result in a desired\nvocalization directly from audio recordings. In this work, we propose a\nwhite-box optimization technique for estimating glottal source parameters and\nvocal tract shapes from audio recordings of human vowels. The approach is based\non inverse filtering and optimizing the frequency response of a wave\\-guide\nmodel of the vocal tract with gradient descent, propagating error gradients\nthrough the mapping of articulatory features to the vocal tract area function.\nWe apply this method to the task of matching the sound of the Pink Trombone, an\ninteractive articulatory synthesizer, to a given vocalization. We find that our\nmethod accurately recovers control functions for audio generated by the Pink\nTrombone itself. We then compare our technique against evolutionary\noptimization algorithms and a neural network trained to predict control\nparameters from audio. A subjective evaluation finds that our approach\noutperforms these black-box optimization baselines on the task of reproducing\nhuman vocalizations.\n","authors":["David Südholt","Mateo Cámara","Zhiyuan Xu","Joshua D. Reiss"],"pdf_url":"https://arxiv.org/pdf/2307.04702v1.pdf","comment":"Accepted to DAFx 2023"},{"id":"http://arxiv.org/abs/2307.04686v1","updated":"2023-07-10T16:42:03Z","published":"2023-07-10T16:42:03Z","title":"VampNet: Music Generation via Masked Acoustic Token Modeling","summary":"  We introduce VampNet, a masked acoustic token modeling approach to music\nsynthesis, compression, inpainting, and variation. We use a variable masking\nschedule during training which allows us to sample coherent music from the\nmodel by applying a variety of masking approaches (called prompts) during\ninference. VampNet is non-autoregressive, leveraging a bidirectional\ntransformer architecture that attends to all tokens in a forward pass. With\njust 36 sampling passes, VampNet can generate coherent high-fidelity musical\nwaveforms. We show that by prompting VampNet in various ways, we can apply it\nto tasks like music compression, inpainting, outpainting, continuation, and\nlooping with variation (vamping). Appropriately prompted, VampNet is capable of\nmaintaining style, genre, instrumentation, and other high-level aspects of the\nmusic. This flexible prompting capability makes VampNet a powerful music\nco-creation tool. Code and audio samples are available online.\n","authors":["Hugo Flores Garcia","Prem Seetharaman","Rithesh Kumar","Bryan Pardo"],"pdf_url":"https://arxiv.org/pdf/2307.04686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02719v2","updated":"2023-07-10T15:15:47Z","published":"2023-03-05T17:20:10Z","title":"A Comparative Study of Self-Supervised Speech Representations in Read\n  and Spontaneous TTS","summary":"  Recent work has explored using self-supervised learning (SSL) speech\nrepresentations such as wav2vec2.0 as the representation medium in standard\ntwo-stage TTS, in place of conventionally used mel-spectrograms. It is however\nunclear which speech SSL is the better fit for TTS, and whether or not the\nperformance differs between read and spontaneous TTS, the later of which is\narguably more challenging. This study aims at addressing these questions by\ntesting several speech SSLs, including different layers of the same SSL, in\ntwo-stage TTS on both read and spontaneous corpora, while maintaining constant\nTTS model architecture and training settings. Results from listening tests show\nthat the 9th layer of 12-layer wav2vec2.0 (ASR finetuned) outperforms other\ntested SSLs and mel-spectrogram, in both read and spontaneous TTS. Our work\nsheds light on both how speech SSL can readily improve current TTS systems, and\nhow SSLs compare in the challenging generative task of TTS. Audio examples can\nbe found at https://www.speech.kth.se/tts-demos/ssr_tts\n","authors":["Siyang Wang","Gustav Eje Henter","Joakim Gustafson","Éva Székely"],"pdf_url":"https://arxiv.org/pdf/2303.02719v2.pdf","comment":"5 pages, 2 figures. ICASSP Workshop SASB (Self-Supervision in Audio,\n  Speech and Beyond)2023"},{"id":"http://arxiv.org/abs/2307.04630v1","updated":"2023-07-10T15:15:17Z","published":"2023-07-10T15:15:17Z","title":"The NPU-MSXF Speech-to-Speech Translation System for IWSLT 2023\n  Speech-to-Speech Translation Task","summary":"  This paper describes the NPU-MSXF system for the IWSLT 2023 speech-to-speech\ntranslation (S2ST) task which aims to translate from English speech of\nmulti-source to Chinese speech. The system is built in a cascaded manner\nconsisting of automatic speech recognition (ASR), machine translation (MT), and\ntext-to-speech (TTS). We make tremendous efforts to handle the challenging\nmulti-source input. Specifically, to improve the robustness to multi-source\nspeech input, we adopt various data augmentation strategies and a ROVER-based\nscore fusion on multiple ASR model outputs. To better handle the noisy ASR\ntranscripts, we introduce a three-stage fine-tuning strategy to improve\ntranslation accuracy. Finally, we build a TTS model with high naturalness and\nsound quality, which leverages a two-stage framework, using network bottleneck\nfeatures as a robust intermediate representation for speaker timbre and\nlinguistic content disentanglement. Based on the two-stage framework,\npre-trained speaker embedding is leveraged as a condition to transfer the\nspeaker timbre in the source English speech to the translated Chinese speech.\nExperimental results show that our system has high translation accuracy, speech\nnaturalness, sound quality, and speaker similarity. Moreover, it shows good\nrobustness to multi-source data.\n","authors":["Kun Song","Yi lei","Peikun Chen","Yiqing Cao","Kun Wei","Yongmao Zhang","Lei Xie","Ning Jiang","Guoqing Zhao"],"pdf_url":"https://arxiv.org/pdf/2307.04630v1.pdf","comment":"IWSLT@ACL 2023 system paper. Our submitted system ranks 1st in the\n  S2ST task of the IWSLT 2023 evaluation campaign"},{"id":"http://arxiv.org/abs/2307.04604v1","updated":"2023-07-10T14:43:32Z","published":"2023-07-10T14:43:32Z","title":"EchoVest: Real-Time Sound Classification and Depth Perception Expressed\n  through Transcutaneous Electrical Nerve Stimulation","summary":"  Over 1.5 billion people worldwide live with hearing impairment. Despite\nvarious technologies that have been created for individuals with such\ndisabilities, most of these technologies are either extremely expensive or\ninaccessible for everyday use in low-medium income countries. In order to\ncombat this issue, we have developed a new assistive device, EchoVest, for\nblind/deaf people to intuitively become more aware of their environment.\nEchoVest transmits vibrations to the user's body by utilizing transcutaneous\nelectric nerve stimulation (TENS) based on the source of the sounds. EchoVest\nalso provides various features, including sound localization, sound\nclassification, noise reduction, and depth perception. We aimed to outperform\nCNN-based machine-learning models, the most commonly used machine learning\nmodel for classification tasks, in accuracy and computational costs. To do so,\nwe developed and employed a novel audio pipeline that adapts the Audio\nSpectrogram Transformer (AST) model, an attention-based model, for our sound\nclassification purposes, and Fast Fourier Transforms for noise reduction. The\napplication of Otsu's Method helped us find the optimal thresholds for\nbackground noise sound filtering and gave us much greater accuracy. In order to\ncalculate direction and depth accurately, we applied Complex Time Difference of\nArrival algorithms and SOTA localization. Our last improvement was to use blind\nsource separation to make our algorithms applicable to multiple microphone\ninputs. The final algorithm achieved state-of-the-art results on numerous\ncheckpoints, including a 95.7\\% accuracy on the ESC-50 dataset for\nenvironmental sound classification.\n","authors":["Jesse Choe","Siddhant Sood","Ryan Park"],"pdf_url":"https://arxiv.org/pdf/2307.04604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04586v1","updated":"2023-07-10T14:28:56Z","published":"2023-07-10T14:28:56Z","title":"Timbre transfer using image-to-image denoising diffusion models","summary":"  Timbre transfer techniques aim at converting the sound of a musical piece\ngenerated by one instrument into the same one as if it was played by another\ninstrument, while maintaining as much as possible the content in terms of\nmusical characteristics such as melody and dynamics. Following their recent\nbreakthroughs in deep learning-based generation, we apply Denoising Diffusion\nModels (DDMs) to perform timbre transfer. Specifically, we apply the recently\nproposed Denoising Diffusion Implicit Models (DDIMs) that enable to accelerate\nthe sampling procedure. Inspired by the recent application of DDMs to image\ntranslation problems we formulate the timbre transfer task similarly, by first\nconverting the audio tracks into log mel spectrograms and by conditioning the\ngeneration of the desired timbre spectrogram through the input timbre\nspectrogram. We perform both one-to-one and many-to-many timbre transfer, by\nconverting audio waveforms containing only single instruments and multiple\ninstruments, respectively. We compare the proposed technique with existing\nstate-of-the-art methods both through listening tests and objective measures in\norder to demonstrate the effectiveness of the proposed model.\n","authors":["Luca Comanducci","Fabio Antonacci","Augusto Sarti"],"pdf_url":"https://arxiv.org/pdf/2307.04586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09417v2","updated":"2023-07-10T12:53:24Z","published":"2023-06-15T18:02:49Z","title":"Diff-TTSG: Denoising probabilistic integrated speech and gesture\n  synthesis","summary":"  With read-aloud speech synthesis achieving high naturalness scores, there is\na growing research interest in synthesising spontaneous speech. However, human\nspontaneous face-to-face conversation has both spoken and non-verbal aspects\n(here, co-speech gestures). Only recently has research begun to explore the\nbenefits of jointly synthesising these two modalities in a single system. The\nprevious state of the art used non-probabilistic methods, which fail to capture\nthe variability of human speech and motion, and risk producing oversmoothing\nartefacts and sub-optimal synthesis quality. We present the first\ndiffusion-based probabilistic model, called Diff-TTSG, that jointly learns to\nsynthesise speech and gestures together. Our method can be trained on small\ndatasets from scratch. Furthermore, we describe a set of careful uni- and\nmulti-modal subjective tests for evaluating integrated speech and gesture\nsynthesis systems, and use them to validate our proposed approach. For\nsynthesised examples please see https://shivammehta25.github.io/Diff-TTSG\n","authors":["Shivam Mehta","Siyang Wang","Simon Alexanderson","Jonas Beskow","Éva Székely","Gustav Eje Henter"],"pdf_url":"https://arxiv.org/pdf/2306.09417v2.pdf","comment":"7 pages, 2 figures, Accepted at ISCA Speech Synthesis Workshop (SSW)\n  2023"},{"id":"http://arxiv.org/abs/2307.04517v1","updated":"2023-07-10T12:25:24Z","published":"2023-07-10T12:25:24Z","title":"Study on the Correlation between Objective Evaluations and Subjective\n  Speech Quality and Intelligibility","summary":"  Subjective tests are the gold standard for evaluating speech quality and\nintelligibility, but they are time-consuming and expensive. Thus, objective\nmeasures that align with human perceptions are crucial. This study evaluates\nthe correlation between commonly used objective measures and subjective speech\nquality and intelligibility using a Chinese speech dataset. Moreover, new\nobjective measures are proposed combining current objective measures using deep\nlearning techniques to predict subjective quality and intelligibility. The\nproposed deep learning model reduces the amount of training data without\nsignificantly impacting prediction performance. We interpret the deep learning\nmodel to understand how objective measures reflect subjective quality and\nintelligibility. We also explore the impact of including subjective speech\nquality ratings on speech intelligibility prediction. Our findings offer\nvaluable insights into the relationship between objective measures and human\nperceptions.\n","authors":["Hsin-Tien Chiang","Kuo-Hsuan Hung","Szu-Wei Fu","Heng-Cheng Kuo","Ming-Hsueh Tsai","Yu Tsao"],"pdf_url":"https://arxiv.org/pdf/2307.04517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04974v4","updated":"2023-07-10T10:30:38Z","published":"2022-08-09T18:01:50Z","title":"Mathematical Foundations of Complex Tonality","summary":"  Equal temperament, in which semitones are tuned in the irrational ratio of\n$2^{1/12} : 1$, is best seen as a serviceable compromise, sacrificing purity\nfor flexibility. Just intonation, in which intervals are given by products of\npowers of $2$, $3$, and $5$, is more natural, but of limited flexibility. We\npropose a new scheme in which ratios of Gaussian integers form the basis of an\nabstract tonal system. The tritone, so problematic in just temperament, given\nambiguously by the ratios $\\tfrac{45}{32}$, $\\tfrac{64}{45}$, $\\tfrac{36}{25}$,\n$\\tfrac{25}{18}$, none satisfactory, is in our scheme represented by the\ncomplex ratio $1 + \\rm{i} : 1$. The major and minor whole tones, given by\nintervals of $\\tfrac{9}{8}$ and $\\tfrac{10}{9}$, can each be factorized into\nproducts of complex semitones, giving us a major complex semitone\n$\\tfrac{3}{4}(1 + \\rm{i})$ and a minor complex semitone $\\tfrac{1}{3}(3 +\n\\rm{i})$. The perfect third, given by the interval $\\tfrac{5}{4}$, factorizes\ninto the product of a complex whole tone $\\tfrac{1}{2}(1 + 2\\rm{i})$ and its\ncomplex conjugate. Augmented with these supplementary tones, the resulting\nscheme of complex intervals based on products of low powers of Gaussian primes\nleads to the construction of a complete system of major and minor scales in all\nkeys.\n","authors":["Jeffrey R. Boland","Lane P. Hughston"],"pdf_url":"https://arxiv.org/pdf/2208.04974v4.pdf","comment":"35 pages, to appear in Journal of Mathematics and Music"},{"id":"http://arxiv.org/abs/2307.04460v1","updated":"2023-07-10T10:13:12Z","published":"2023-07-10T10:13:12Z","title":"Exploiting an External Microphone for Binaural RTF-Vector-Based\n  Direction of Arrival Estimation for Multiple Speakers","summary":"  In hearing aid applications, an important objective is to accurately estimate\nthe direction of arrival (DOA) of multiple speakers in noisy and reverberant\nenvironments. Recently, we proposed a binaural DOA estimation method, where the\nDOAs of the speakers are estimated by selecting the directions for which the\nso-called Hermitian angle spectrum between the estimated relative transfer\nfunction (RTF) vector and a database of prototype anechoic RTF vectors is\nmaximized. The RTF vector is estimated using the covariance whitening (CW)\nmethod, which requires a computationally complex generalized eigenvalue\ndecomposition. The spatial spectrum is obtained by only considering frequencies\nwhere it is likely that one speaker dominates over the other speakers, noise\nand reverberation. In this contribution, we exploit the availability of an\nexternal microphone that is spatially separated from the hearing aid\nmicrophones and consider a low-complexity RTF vector estimation method that\nassumes a low spatial coherence between the undesired components in the\nexternal microphone and the hearing aid microphones. Using recordings of two\nspeakers and diffuse-like babble noise in acoustic environments with mild\nreverberation and low signal-to-noise ratio, simulation results show that the\nproposed method yields a comparable DOA estimation performance as the CW method\nat a lower computational complexity.\n","authors":["Daniel Fejgin","Simon Doclo"],"pdf_url":"https://arxiv.org/pdf/2307.04460v1.pdf","comment":"Paper accepted for Forum Acusticum 2023"},{"id":"http://arxiv.org/abs/2306.03718v3","updated":"2023-07-10T09:27:17Z","published":"2023-06-06T14:28:57Z","title":"Emotion-Conditioned Melody Harmonization with Hierarchical Variational\n  Autoencoder","summary":"  Existing melody harmonization models have made great progress in improving\nthe quality of generated harmonies, but most of them ignored the emotions\nbeneath the music. Meanwhile, the variability of harmonies generated by\nprevious methods is insufficient. To solve these problems, we propose a novel\nLSTM-based Hierarchical Variational Auto-Encoder (LHVAE) to investigate the\ninfluence of emotional conditions on melody harmonization, while improving the\nquality of generated harmonies and capturing the abundant variability of chord\nprogressions. Specifically, LHVAE incorporates latent variables and emotional\nconditions at different levels (piece- and bar-level) to model the global and\nlocal music properties. Additionally, we introduce an attention-based melody\ncontext vector at each step to better learn the correspondence between melodies\nand harmonies. Objective experimental results show that our proposed model\noutperforms other LSTM-based models. Through subjective evaluation, we conclude\nthat only altering the type of chord hardly changes the overall emotion of the\nmusic. The qualitative analysis demonstrates the ability of our model to\ngenerate variable harmonies.\n","authors":["Shulei Ji","Xinyu Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03718v3.pdf","comment":"Accepted by IEEE SMC 2023"},{"id":"http://arxiv.org/abs/2307.04377v1","updated":"2023-07-10T07:22:06Z","published":"2023-07-10T07:22:06Z","title":"HCLAS-X: Hierarchical and Cascaded Lyrics Alignment System Using\n  Multimodal Cross-Correlation","summary":"  In this work, we address the challenge of lyrics alignment, which involves\naligning the lyrics and vocal components of songs. This problem requires the\nalignment of two distinct modalities, namely text and audio. To overcome this\nchallenge, we propose a model that is trained in a supervised manner, utilizing\nthe cross-correlation matrix of latent representations between vocals and\nlyrics. Our system is designed in a hierarchical and cascaded manner. It\npredicts synced time first on a sentence-level and subsequently on a\nword-level. This design enables the system to process long sequences, as the\ncross-correlation uses quadratic memory with respect to sequence length. In our\nexperiments, we demonstrate that our proposed system achieves a significant\nimprovement in mean average error, showcasing its robustness in comparison to\nthe previous state-of-the-art model. Additionally, we conduct a qualitative\nanalysis of the system after successfully deploying it in several music\nstreaming services.\n","authors":["Minsung Kang","Soochul Park","Keunwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2307.04377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04305v1","updated":"2023-07-10T02:04:43Z","published":"2023-07-10T02:04:43Z","title":"Automatic Piano Transcription with Hierarchical Frequency-Time\n  Transformer","summary":"  Taking long-term spectral and temporal dependencies into account is essential\nfor automatic piano transcription. This is especially helpful when determining\nthe precise onset and offset for each note in the polyphonic piano content. In\nthis case, we may rely on the capability of self-attention mechanism in\nTransformers to capture these long-term dependencies in the frequency and time\naxes. In this work, we propose hFT-Transformer, which is an automatic music\ntranscription method that uses a two-level hierarchical frequency-time\nTransformer architecture. The first hierarchy includes a convolutional block in\nthe time axis, a Transformer encoder in the frequency axis, and a Transformer\ndecoder that converts the dimension in the frequency axis. The output is then\nfed into the second hierarchy which consists of another Transformer encoder in\nthe time axis. We evaluated our method with the widely used MAPS and MAESTRO\nv3.0.0 datasets, and it demonstrated state-of-the-art performance on all the\nF1-scores of the metrics among Frame, Note, Note with Offset, and Note with\nOffset and Velocity estimations.\n","authors":["Keisuke Toyama","Taketo Akama","Yukara Ikemiya","Yuhta Takida","Wei-Hsiang Liao","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2307.04305v1.pdf","comment":"8 pages, 6 figures, to be published in ISMIR2023"},{"id":"http://arxiv.org/abs/2307.04298v1","updated":"2023-07-10T01:30:21Z","published":"2023-07-10T01:30:21Z","title":"Edge Storage Management Recipe with Zero-Shot Data Compression for Road\n  Anomaly Detection","summary":"  Recent studies show edge computing-based road anomaly detection systems which\nmay also conduct data collection simultaneously. However, the edge computers\nwill have small data storage but we need to store the collected audio samples\nfor a long time in order to update existing models or develop a novel method.\nTherefore, we should consider an approach for efficient storage management\nmethods while preserving high-fidelity audio. A hardware-perspective approach,\nsuch as using a low-resolution microphone, is an intuitive way to reduce file\nsize but is not recommended because it fundamentally cuts off high-frequency\ncomponents. On the other hand, a computational file compression approach that\nencodes collected high-resolution audio into a compact code should be\nrecommended because it also provides a corresponding decoding method. Motivated\nby this, we propose a way of simple yet effective pre-trained autoencoder-based\ndata compression method. The pre-trained autoencoder is trained for the purpose\nof audio super-resolution so it can be utilized to encode or decode any\narbitrary sampling rate. Moreover, it will reduce the communication cost for\ndata transmission from the edge to the central server. Via the comparative\nexperiments, we confirm that the zero-shot audio compression and decompression\nhighly preserve anomaly detection performance while enhancing storage and\ntransmission efficiency.\n","authors":["YeongHyeon Park","Uju Gim","Myung Jin Kim"],"pdf_url":"https://arxiv.org/pdf/2307.04298v1.pdf","comment":"5 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2307.04292v1","updated":"2023-07-10T00:58:28Z","published":"2023-07-10T00:58:28Z","title":"A Demand-Driven Perspective on Generative Audio AI","summary":"  To achieve successful deployment of AI research, it is crucial to understand\nthe demands of the industry. In this paper, we present the results of a survey\nconducted with professional audio engineers, in order to determine research\npriorities and define various research tasks. We also summarize the current\nchallenges in audio quality and controllability based on the survey. Our\nanalysis emphasizes that the availability of datasets is currently the main\nbottleneck for achieving high-quality audio generation. Finally, we suggest\npotential solutions for some revealed issues with empirical evidence.\n","authors":["Sangshin Oh","Minsung Kang","Hyeongi Moon","Keunwoo Choi","Ben Sangbae Chon"],"pdf_url":"https://arxiv.org/pdf/2307.04292v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2307.04842v1","updated":"2023-07-10T18:21:48Z","published":"2023-07-10T18:21:48Z","title":"Predicting Tuberculosis from Real-World Cough Audio Recordings and\n  Metadata","summary":"  Tuberculosis (TB) is an infectious disease caused by the bacterium\nMycobacterium tuberculosis and primarily affects the lungs, as well as other\nbody parts. TB is spread through the air when an infected person coughs,\nsneezes, or talks. Medical doctors diagnose TB in patients via clinical\nexaminations and specialized tests. However, coughing is a common symptom of\nrespiratory diseases such as TB. Literature suggests that cough sounds coming\nfrom different respiratory diseases can be distinguished by both medical\ndoctors and computer algorithms. Therefore, cough recordings associated with\npatients with and without TB seems to be a reasonable avenue of investigation.\nIn this work, we utilize a very large dataset of TB and non-TB cough audio\nrecordings obtained from the south-east of Africa, India, and the south-east of\nAsia using a fully automated phone-based application (Hyfe), without manual\nannotation. We fit statistical classifiers based on spectral and time domain\nfeatures with and without clinical metadata. A stratified grouped\ncross-validation approach shows that an average Area Under Curve (AUC) of\napproximately 0.70 $\\pm$ 0.05 both for a cough-level and a participant-level\nclassification can be achieved using cough sounds alone. The addition of\ndemographic and clinical factors increases performance, resulting in an average\nAUC of approximately 0.81 $\\pm$ 0.05. Our results suggest mobile phone-based\napplications that integrate clinical symptoms and cough sound analysis could\nhelp community health workers and, most importantly, health service programs to\nimprove TB case-finding efforts while reducing costs, which could substantially\nimprove public health.\n","authors":["George P. Kafentzis","Stephane Tetsing","Joe Brew","Lola Jover","Mindaugas Galvosas","Carlos Chaccour","Peter M. Small"],"pdf_url":"https://arxiv.org/pdf/2307.04842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.00439v3","updated":"2023-07-10T18:08:42Z","published":"2021-07-01T13:32:55Z","title":"What do End-to-End Speech Models Learn about Speaker, Language and\n  Channel Information? A Layer-wise and Neuron-level Analysis","summary":"  Deep neural networks are inherently opaque and challenging to interpret.\nUnlike hand-crafted feature-based models, we struggle to comprehend the\nconcepts learned and how they interact within these models. This understanding\nis crucial not only for debugging purposes but also for ensuring fairness in\nethical decision-making. In our study, we conduct a post-hoc functional\ninterpretability analysis of pretrained speech models using the probing\nframework [1]. Specifically, we analyze utterance-level representations of\nspeech models trained for various tasks such as speaker recognition and dialect\nidentification. We conduct layer and neuron-wise analyses, probing for speaker,\nlanguage, and channel properties. Our study aims to answer the following\nquestions: i) what information is captured within the representations? ii) how\nis it represented and distributed? and iii) can we identify a minimal subset of\nthe network that possesses this information?\n  Our results reveal several novel findings, including: i) channel and gender\ninformation are distributed across the network, ii) the information is\nredundantly available in neurons with respect to a task, iii) complex\nproperties such as dialectal information are encoded only in the task-oriented\npretrained network, iv) and is localised in the upper layers, v) we can extract\na minimal subset of neurons encoding the pre-defined property, vi) salient\nneurons are sometimes shared between properties, vii) our analysis highlights\nthe presence of biases (for example gender) in the network. Our\ncross-architectural comparison indicates that: i) the pretrained models capture\nspeaker-invariant information, and ii) CNN models are competitive with\nTransformer models in encoding various understudied properties.\n","authors":["Shammur Absar Chowdhury","Nadir Durrani","Ahmed Ali"],"pdf_url":"https://arxiv.org/pdf/2107.00439v3.pdf","comment":"Accepted in CSL journal. Keywords: Speech, Neuron Analysis,\n  Interpretibility, Diagnostic Classifier, AI explainability, End-to-End\n  Architecture"},{"id":"http://arxiv.org/abs/2307.05588v1","updated":"2023-07-10T15:57:42Z","published":"2023-07-10T15:57:42Z","title":"Collaborative Song Dataset (CoSoD): An annotated dataset of multi-artist\n  collaborations in popular music","summary":"  The Collaborative Song Dataset (CoSoD) is a corpus of 331 multi-artist\ncollaborations from the 2010-2019 Billboard \"Hot 100\" year-end charts. The\ncorpus is annotated with formal sections, aspects of vocal production\n(including reverberation, layering, panning, and gender of the performers), and\nrelevant metadata. CoSoD complements other popular music datasets by focusing\nexclusively on musical collaborations between independent acts. In addition to\nfacilitating the study of song form and vocal production, CoSoD allows for the\nin-depth study of gender as it relates to various timbral, pitch, and formal\nparameters in musical collaborations. In this paper, we detail the contents of\nthe dataset and outline the annotation process. We also present an experiment\nusing CoSoD that examines how the use of reverberation, layering, and panning\nare related to the gender of the artist. In this experiment, we find that men's\nvoices are on average treated with less reverberation and occupy a more narrow\nposition in the stereo mix than women's voices.\n","authors":["Michèle Duguay","Kate Mancey","Johanna Devaney"],"pdf_url":"https://arxiv.org/pdf/2307.05588v1.pdf","comment":"To be published in the Proceedings of the 24th International Society\n  for Music Information Retrieval Conference (ISMIR)"}],"Signal Processing":[{"id":"http://arxiv.org/abs/2307.04727v1","updated":"2023-07-10T17:37:14Z","published":"2023-07-10T17:37:14Z","title":"Deceptive Information Retrieval","summary":"  We introduce the problem of deceptive information retrieval (DIR), in which a\nuser wishes to download a required file out of multiple independent files\nstored in a system of databases while \\emph{deceiving} the databases by making\nthe databases' predictions on the user-required file index incorrect with high\nprobability. Conceptually, DIR is an extension of private information retrieval\n(PIR). In PIR, a user downloads a required file without revealing its index to\nany of the databases. The metric of deception is defined as the probability of\nerror of databases' prediction on the user-required file, minus the\ncorresponding probability of error in PIR. The problem is defined on\ntime-sensitive data that keeps updating from time to time. In the proposed\nscheme, the user deceives the databases by sending \\emph{real} queries to\ndownload the required file at the time of the requirement and \\emph{dummy}\nqueries at multiple distinct future time instances to manipulate the\nprobabilities of sending each query for each file requirement, using which the\ndatabases' make the predictions on the user-required file index. The proposed\nDIR scheme is based on a capacity achieving probabilistic PIR scheme, and\nachieves rates lower than the PIR capacity due to the additional downloads made\nto deceive the databases. When the required level of deception is zero, the\nproposed scheme achieves the PIR capacity.\n","authors":["Sajani Vithana","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2307.04727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04692v1","updated":"2023-07-10T16:44:54Z","published":"2023-07-10T16:44:54Z","title":"Spoofing-Resilient LiDAR-GPS Factor Graph Localization with Chimera\n  Authentication","summary":"  Many vehicle platforms typically use sensors such as LiDAR or camera for\nlocally-referenced navigation with GPS for globally-referenced navigation.\nHowever, due to the unencrypted nature of GPS signals, all civilian users are\nvulner-able to spoofing attacks, where a malicious spoofer broadcasts\nfabricated signals and causes the user to track a false position fix. To\nprotect against such GPS spoofing attacks, Chips-Message Robust Authentication\n(Chimera) has been developed and will be tested on the Navigation Technology\nSatellite 3 (NTS-3) satellite being launched later this year. However, Chimera\nauthentication is not continuously available and may not provide sufficient\nprotection for vehicles which rely on more frequent GPS measurements. In this\npaper, we propose a factor graph-based state estimation framework which\nintegrates LiDAR and GPS while simultaneously detecting and mitigating spoofing\nattacks experienced between consecutive Chimera authentications. Our proposed\nframework combines GPS pseudorange measurements with LiDAR odometry to provide\na robust navigation solution. A chi-squared detector, based on pseudorange\nresiduals, is used to detect and mitigate any potential GPS spoofing attacks.\nWe evaluate our method using real-world LiDAR data from the KITTI dataset and\nsimulated GPS measurements, both nominal and with spoofing. Across multiple\ntrajectories and Monte Carlo runs, our method consistently achieves position\nerrors under 5 m during nominal conditions, and successfully bounds positioning\nerror to within odometry drift levels during spoofed conditions.\n","authors":["Adam Dai","Tara Minda","Ashwin Kanhere","Grace Gao"],"pdf_url":"https://arxiv.org/pdf/2307.04692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04677v1","updated":"2023-07-10T16:21:35Z","published":"2023-07-10T16:21:35Z","title":"Practical Trustworthiness Model for DNN in Dedicated 6G Application","summary":"  Artificial intelligence (AI) is considered an efficient response to several\nchallenges facing 6G technology. However, AI still suffers from a huge trust\nissue due to its ambiguous way of making predictions. Therefore, there is a\nneed for a method to evaluate the AI's trustworthiness in practice for future\n6G applications. This paper presents a practical model to analyze the\ntrustworthiness of AI in a dedicated 6G application. In particular, we present\ntwo customized Deep Neural Networks (DNNs) to solve the Automatic Modulation\nRecognition (AMR) problem in Terahertz communications-based 6G technology.\nThen, a specific trustworthiness model and its attributes, namely data\nrobustness, parameter sensitivity, and security covering adversarial examples,\nare introduced. The evaluation results indicate that the proposed\ntrustworthiness attributes are crucial to evaluate the trustworthiness of DNN\nfor this 6G application.\n","authors":["Anouar Nechi","Ahmed Mahmoudi","Christoph Herold","Daniel Widmer","Thomas Kürner","Mladen Berekovic","Saleh Mulhem"],"pdf_url":"https://arxiv.org/pdf/2307.04677v1.pdf","comment":"PREPRINT - accepted In Proceedings of the 19th International\n  Conference on Wireless and Mobile Computing, Networking and Communications\n  2023(STWiMob 2023)"},{"id":"http://arxiv.org/abs/2307.04632v1","updated":"2023-07-10T15:19:37Z","published":"2023-07-10T15:19:37Z","title":"An End-To-End Analysis of Deep Learning-Based Remaining Useful Life\n  Algorithms for Satefy-Critical 5G-Enabled IIoT Networks","summary":"  Remaining Useful Life (RUL) prediction is a critical task that aims to\nestimate the amount of time until a system fails, where the latter is formed by\nthree main components, that is, the application, communication network, and RUL\nlogic. In this paper, we provide an end-to-end analysis of an entire RUL-based\nchain. Specifically, we consider a factory floor where Automated Guided\nVehicles (AGVs) transport dangerous liquids whose fall may cause injuries to\nworkers. Regarding the communication infrastructure, the AGVs are equipped with\n5G User Equipments (UEs) that collect real-time data of their movements and\nsend them to an application server. The RUL logic consists of a Deep Learning\n(DL)-based pipeline that assesses if there will be liquid falls by analyzing\nthe collected data, and, eventually, sending commands to the AGVs to avoid such\na danger. According to this scenario, we performed End-to-End 5G NR-compliant\nnetwork simulations to study the Round-Trip Time (RTT) as a function of the\noverall system bandwidth, subcarrier spacing, and modulation order. Then, via\nreal-world experiments, we collect data to train, test and compare 7 DL models\nand 1 baseline threshold-based algorithm in terms of cost and average advance.\nFinally, we assess whether or not the RTT provided by four different 5G NR\nnetwork architectures is compatible with the average advance provided by the\nbest-performing one-Dimensional Convolutional Neural Network (1D-CNN).\nNumerical results show under which conditions the DL-based approach for RUL\nestimation matches with the RTT performance provided by different 5G NR network\narchitectures.\n","authors":["Lorenzo Mario Amorosa","Nicolò Longhi","Giampaolo Cuozzo","Weronika Maria Bachan","Valerio Lieti","Enrico Buracchini","Roberto Verdone"],"pdf_url":"https://arxiv.org/pdf/2307.04632v1.pdf","comment":"6 pages, 4 figures. This work has been accepted for publication at\n  IEEE PIMRC 2023"},{"id":"http://arxiv.org/abs/2305.17383v2","updated":"2023-07-10T15:05:46Z","published":"2023-05-27T06:32:24Z","title":"On the convergence of the distributed proximal point algorithm","summary":"  In this work, we establish convergence results for the distributed proximal\npoint algorithm (DPPA) for distributed optimization problems. We consider the\nproblem on the whole domain Rd and find a general condition on the stepsize and\ncost functions such that the DPPA is stable. We prove that the DPPA with\nstepsize $\\eta > 0$ exponentially converges to an $O(\\eta)$-neighborhood of the\noptimizer. Our result clearly explains the advantage of the DPPA with respect\nto the convergence and stability in comparison with the distributed gradient\ndescent algorithm. We also provide numerical tests supporting the theoretical\nresults.\n","authors":["Woocheol Choi"],"pdf_url":"https://arxiv.org/pdf/2305.17383v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04607v1","updated":"2023-07-10T14:51:30Z","published":"2023-07-10T14:51:30Z","title":"A Memristor-Inspired Computation for Epileptiform Signals in Spheroids","summary":"  In this paper we present a memristor-inspired computational method for\nobtaining a type of running spectrogram or fingerprint of epileptiform activity\ngenerated by rodent hippocampal spheroids. It can be used to compute on the fly\nand with low computational cost an alert-level signal for epileptiform events\nonset. Here, we describe the computational method behind this fingerprint\ntechnique and illustrate it using epileptiform events recorded from hippocampal\nspheroids using a microelectrode array system.\n","authors":["Iván Díez de los Ríos","John Wesley Ephraim","Gemma Palazzolo","Teresa Serrano-Gotarredona","Gabriella Panuccio","Bernabé Linares-Barranco"],"pdf_url":"https://arxiv.org/pdf/2307.04607v1.pdf","comment":"published in 2023 IEEE 5th International Conference on Artificial\n  Intelligence Circuits and Systems (AICAS)"},{"id":"http://arxiv.org/abs/2307.04604v1","updated":"2023-07-10T14:43:32Z","published":"2023-07-10T14:43:32Z","title":"EchoVest: Real-Time Sound Classification and Depth Perception Expressed\n  through Transcutaneous Electrical Nerve Stimulation","summary":"  Over 1.5 billion people worldwide live with hearing impairment. Despite\nvarious technologies that have been created for individuals with such\ndisabilities, most of these technologies are either extremely expensive or\ninaccessible for everyday use in low-medium income countries. In order to\ncombat this issue, we have developed a new assistive device, EchoVest, for\nblind/deaf people to intuitively become more aware of their environment.\nEchoVest transmits vibrations to the user's body by utilizing transcutaneous\nelectric nerve stimulation (TENS) based on the source of the sounds. EchoVest\nalso provides various features, including sound localization, sound\nclassification, noise reduction, and depth perception. We aimed to outperform\nCNN-based machine-learning models, the most commonly used machine learning\nmodel for classification tasks, in accuracy and computational costs. To do so,\nwe developed and employed a novel audio pipeline that adapts the Audio\nSpectrogram Transformer (AST) model, an attention-based model, for our sound\nclassification purposes, and Fast Fourier Transforms for noise reduction. The\napplication of Otsu's Method helped us find the optimal thresholds for\nbackground noise sound filtering and gave us much greater accuracy. In order to\ncalculate direction and depth accurately, we applied Complex Time Difference of\nArrival algorithms and SOTA localization. Our last improvement was to use blind\nsource separation to make our algorithms applicable to multiple microphone\ninputs. The final algorithm achieved state-of-the-art results on numerous\ncheckpoints, including a 95.7\\% accuracy on the ESC-50 dataset for\nenvironmental sound classification.\n","authors":["Jesse Choe","Siddhant Sood","Ryan Park"],"pdf_url":"https://arxiv.org/pdf/2307.04604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04589v1","updated":"2023-07-10T14:30:40Z","published":"2023-07-10T14:30:40Z","title":"Harnessing the Power of Swarm Satellite Networks with Wideband\n  Distributed Beamforming","summary":"  The space communications industry is challenged to develop a technology that\ncan deliver broadband services to user terminals equipped with miniature\nantennas, such as handheld devices. One potential solution to establish links\nwith ground users is the deployment of massive antennas in one single\nspacecraft. However, this is not cost-effective. Aligning with recent\n\\emph{NewSpace} activities directed toward miniaturization, mass production,\nand a significant reduction in spacecraft launch costs, an alternative could be\ndistributed beamforming from multiple satellites. In this context, we propose a\ndistributed beamforming modeling technique for wideband signals. We also\nconsider the statistical behavior of the relative geometry of the swarm nodes.\nThe paper assesses the proposed technique via computer simulations, providing\ninteresting results on the beamforming gains in terms of power and the security\nof the communication against potential eavesdroppers at non-intended pointing\nangles. This approach paves the way for further exploration of wideband\ndistributed beamforming from satellite swarms in several future communication\napplications.\n","authors":["Juan Carlos Merlano Duncan","Vu Nguyen Ha","Jevgenij Krivochiza","Rakesh Palisetty","Geoffrey Eappen","Juan Andres Vasquez","Wallace Alves Martins","Symeon Chatzinotas","Björn Ottersten"],"pdf_url":"https://arxiv.org/pdf/2307.04589v1.pdf","comment":"PIMRC'23 WS MCSN-6G (accepted)"},{"id":"http://arxiv.org/abs/2307.04559v1","updated":"2023-07-10T13:47:48Z","published":"2023-07-10T13:47:48Z","title":"Thin-Film Lithium Niobate Acoustic Filter at 23.5 GHz with 2.38 dB IL\n  and 18.2% FBW","summary":"  This work reports an acoustic filter at 23.5 GHz with a low insertion loss\n(IL) of 2.38 dB and a 3-dB fractional bandwidth (FBW) of 18.2%, significantly\nsurpassing the state-of-the-art. The device leverages electrically coupled\nacoustic resonators in 100 nm 128{\\deg} Y-cut lithium niobate (LiNbO3)\npiezoelectric thin film, operating in the first-order antisymmetric (A1) mode.\nA new film stack, namely transferred thin-film LiNbO3 on silicon (Si) substrate\nwith an intermediate amorphous silicon (a-Si) layer, facilitates the\nrecord-breaking performance at millimeter-wave (mmWave). The filter features a\ncompact footprint of 0.56 mm2. In this letter, acoustic and EM consideration,\nalong with material characterization with X-ray diffraction and verified with\ncross-sectional electron microscopy are reported. Upon further development, the\nreported filter platform can enable various front-end signal-processing\nfunctions at mmWave.\n","authors":["Omar Barrera","Sinwoo Cho","Lezli Matto","Jack Kramer","Kenny Huynh","Vakhtang Chulukhadze","Yen-Wei Chang","Mark S. Goorsky","Ruochen Lu"],"pdf_url":"https://arxiv.org/pdf/2307.04559v1.pdf","comment":"4 pages, 8 figures, submitted to IEEE JMEMS"},{"id":"http://arxiv.org/abs/2307.04506v1","updated":"2023-07-10T11:57:03Z","published":"2023-07-10T11:57:03Z","title":"Distributed Decisions on Optimal Load Balancing in Loss Networks","summary":"  When multiple users share a common link in direct transmission, packet loss\nand network collision may occur due to the simultaneous arrival of traffics at\nthe source node. To tackle this problem, users may resort to an indirect path:\nthe packet flows are first relayed through a sidelink to another source node,\nthen transmitted to the destination. This behavior brings the problems of\npacket routing or load balancing: (1) how to maximize the total traffic in a\ncollaborative way; (2) how self-interested users choose routing strategies to\nminimize their individual packet loss independently. In this work, we propose a\ngeneralized mathematical framework to tackle the packet and load balancing\nissue in loss networks. In centralized scenarios with a planner, we provide a\npolynomial-time algorithm to compute the system optimum point where the total\ntraffic rate is maximized. Conversely, in decentralized settings with\nautonomous users making distributed decisions, the system converges to an\nequilibrium where no user can reduce their loss probability through unilateral\ndeviation. We thereby provide a full characterization of Nash equilibrium and\nexamine the efficiency loss stemming from selfish behaviors, both theoretically\nand empirically. In general, the performance degradation caused by selfish\nbehaviors is not catastrophic; however, this gap is not monotonic and can have\nextreme values in certain specific scenarios.\n","authors":["Qiong Liu","Chehao Wang","Ce Zheng"],"pdf_url":"https://arxiv.org/pdf/2307.04506v1.pdf","comment":"6 pages, WiOPT workshop RAWNET"},{"id":"http://arxiv.org/abs/2307.04460v1","updated":"2023-07-10T10:13:12Z","published":"2023-07-10T10:13:12Z","title":"Exploiting an External Microphone for Binaural RTF-Vector-Based\n  Direction of Arrival Estimation for Multiple Speakers","summary":"  In hearing aid applications, an important objective is to accurately estimate\nthe direction of arrival (DOA) of multiple speakers in noisy and reverberant\nenvironments. Recently, we proposed a binaural DOA estimation method, where the\nDOAs of the speakers are estimated by selecting the directions for which the\nso-called Hermitian angle spectrum between the estimated relative transfer\nfunction (RTF) vector and a database of prototype anechoic RTF vectors is\nmaximized. The RTF vector is estimated using the covariance whitening (CW)\nmethod, which requires a computationally complex generalized eigenvalue\ndecomposition. The spatial spectrum is obtained by only considering frequencies\nwhere it is likely that one speaker dominates over the other speakers, noise\nand reverberation. In this contribution, we exploit the availability of an\nexternal microphone that is spatially separated from the hearing aid\nmicrophones and consider a low-complexity RTF vector estimation method that\nassumes a low spatial coherence between the undesired components in the\nexternal microphone and the hearing aid microphones. Using recordings of two\nspeakers and diffuse-like babble noise in acoustic environments with mild\nreverberation and low signal-to-noise ratio, simulation results show that the\nproposed method yields a comparable DOA estimation performance as the CW method\nat a lower computational complexity.\n","authors":["Daniel Fejgin","Simon Doclo"],"pdf_url":"https://arxiv.org/pdf/2307.04460v1.pdf","comment":"Paper accepted for Forum Acusticum 2023"},{"id":"http://arxiv.org/abs/2307.04445v1","updated":"2023-07-10T09:53:14Z","published":"2023-07-10T09:53:14Z","title":"Learning Behavioral Representations of Routines From Large-scale\n  Unlabeled Wearable Time-series Data Streams using Hawkes Point Process","summary":"  Continuously-worn wearable sensors enable researchers to collect copious\namounts of rich bio-behavioral time series recordings of real-life activities\nof daily living, offering unprecedented opportunities to infer novel human\nbehavior patterns during daily routines. Existing approaches to routine\ndiscovery through bio-behavioral data rely either on pre-defined notions of\nactivities or use additional non-behavioral measurements as contexts, such as\nGPS location or localization within the home, presenting risks to user privacy.\nIn this work, we propose a novel wearable time-series mining framework, Hawkes\npoint process On Time series clusters for ROutine Discovery (HOT-ROD), for\nuncovering behavioral routines from completely unlabeled wearable recordings.\nWe utilize a covariance-based method to generate time-series clusters and\ndiscover routines via the Hawkes point process learning algorithm. We\nempirically validate our approach for extracting routine behaviors using a\ncompletely unlabeled time-series collected continuously from over 100\nindividuals both in and outside of the workplace during a period of ten weeks.\nFurthermore, we demonstrate this approach intuitively captures daily\ntransitional relationships between physical activity states without using prior\nknowledge. We also show that the learned behavioral patterns can assist in\nilluminating an individual's personality and affect.\n","authors":["Tiantian Feng","Brandon M Booth","Shrikanth Narayanan"],"pdf_url":"https://arxiv.org/pdf/2307.04445v1.pdf","comment":"2023 9th ACM SIGKDD International Workshop on Mining and Learning\n  From Time Series (MiLeTS 2023)"},{"id":"http://arxiv.org/abs/2307.04440v1","updated":"2023-07-10T09:41:16Z","published":"2023-07-10T09:41:16Z","title":"Time-Frequency-Space Transmit Design and Signal Processing with Dynamic\n  Subarray for Terahertz Integrated Sensing and Communication","summary":"  Terahertz (THz) integrated sensing and communication (ISAC) enables\nsimultaneous data transmission with Terabit-per-second (Tbps) rate and\nmillimeter-level accurate sensing. To realize such a blueprint, ultra-massive\nantenna arrays with directional beamforming are used to compensate for severe\npath loss in the THz band. In this paper, the time-frequency-space transmit\ndesign is investigated for THz ISAC to generate time-varying scanning sensing\nbeams and stable communication beams. Specifically, with the dynamic\narray-of-subarray (DAoSA) hybrid beamforming architecture and multi-carrier\nmodulation, two ISAC hybrid precoding algorithms are proposed, namely, a\nvectorization (VEC) based algorithm that outperforms existing ISAC hybrid\nprecoding methods and a low-complexity sensing codebook assisted (SCA)\napproach. Meanwhile, coupled with the transmit design, parameter estimation\nalgorithms are proposed to realize high-accuracy sensing, including a wideband\nDAoSA MUSIC (W-DAoSA-MUSIC) method for angle estimation and a sum-DFT-GSS\n(S-DFT-GSS) approach for range and velocity estimation. Numerical results\nindicate that the proposed algorithms can realize centi-degree-level angle\nestimation accuracy and millimeter-level range estimation accuracy, which are\none or two orders of magnitudes better than the methods in the millimeter-wave\nband. In addition, to overcome the cyclic prefix limitation and Doppler effects\nin the THz band, an inter-symbol interference- and inter-carrier\ninterference-tackled sensing algorithm is developed to refine sensing\ncapabilities for THz ISAC.\n","authors":["Yongzhi Wu","Chong Han"],"pdf_url":"https://arxiv.org/pdf/2307.04440v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04438v1","updated":"2023-07-10T09:29:26Z","published":"2023-07-10T09:29:26Z","title":"Reconfigurable Intelligent Surface Assisted Railway Communications: A\n  survey","summary":"  The number of train passengers and the demand for high data rates to handle\nnew technologies such as video streaming and IoT technologies are continuously\nincreasing. Therefore the exploration of millimeter waves (mmWave) band is a\nkey technology to meet this demand. However, the high penetration loss makes\nmmWave very sensitive to blocking, limiting its coverage area. One promising,\nefficient, and low-cost solution is the reconfigurable intelligent surface\n(RIS). This paper reviews the state of the art of RIS for railway\ncommunications in the mmWave context. First, we present the different types of\nRIS and review some optimization algorithms used in the literature to find the\nRIS phase shift. Then, we review recent works on RIS in the railway domain and\nprovide future directions.\n","authors":["Aline Habib","Ammar El Falou","Charlotte Langlais","Marion Berbineau"],"pdf_url":"https://arxiv.org/pdf/2307.04438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04421v1","updated":"2023-07-10T08:54:12Z","published":"2023-07-10T08:54:12Z","title":"Towards Enabling Cardiac Digital Twins of Myocardial Infarction Using\n  Deep Computational Models for Inverse Inference","summary":"  Myocardial infarction (MI) demands precise and swift diagnosis. Cardiac\ndigital twins (CDTs) have the potential to offer individualized evaluation of\ncardiac function in a non-invasive manner, making them a promising approach for\npersonalized diagnosis and treatment planning of MI. The inference of accurate\nmyocardial tissue properties is crucial in creating a reliable CDT platform,\nand particularly in the context of studying MI. In this work, we investigate\nthe feasibility of inferring myocardial tissue properties from the\nelectrocardiogram (ECG), focusing on the development of a comprehensive CDT\nplatform specifically designed for MI. The platform integrates multi-modal\ndata, such as cardiac MRI and ECG, to enhance the accuracy and reliability of\nthe inferred tissue properties. We perform a sensitivity analysis based on\ncomputer simulations, systematically exploring the effects of infarct location,\nsize, degree of transmurality, and electrical activity alteration on the\nsimulated QRS complex of ECG, to establish the limits of the approach. We\nsubsequently propose a deep computational model to infer infarct location and\ndistribution from the simulated QRS. The in silico experimental results show\nthat our model can effectively capture the complex relationships between the\nQRS signals and the corresponding infarct regions, with promising potential for\nclinical application in the future. The code will be released publicly once the\nmanuscript is accepted for publication.\n","authors":["Lei Li","Julia Camps","Zhinuo Wang","Abhirup Banerjee","Blanca Rodriguez","Vicente Grau"],"pdf_url":"https://arxiv.org/pdf/2307.04421v1.pdf","comment":"Cardiac digital twins; Inverse inference; Myocardial infarction"},{"id":"http://arxiv.org/abs/2301.00583v2","updated":"2023-07-10T08:35:44Z","published":"2023-01-02T10:15:54Z","title":"Spectral and Energy Efficiency Maximization of MISO STAR-RIS-assisted\n  URLLC Systems","summary":"  This paper proposes a general optimization framework to improve the spectral\nand energy efficiency (EE) of ultra-reliable low-latency communication (URLLC)\nsimultaneous-transfer-and-receive (STAR) reconfigurable intelligent surface\n(RIS)-assisted interference-limited systems with finite block length (FBL).\nThis framework can solve a large variety of optimization problems in which the\nobjective and/or constraints are linear functions of the rates and/or EE of\nusers. Additionally, the framework can be applied to any interference-limited\nsystem with treating interference as noise as the decoding strategy at\nreceivers. We consider a multi-cell broadcast channel as an example and show\nhow this framework can be specialized to solve the minimum-weighted rate,\nweighted sum rate, global EE and weighted EE of the system. We make realistic\nassumptions regarding the (STAR-)RIS by considering three different feasibility\nsets for the components of either regular RIS or STAR-RIS. Our results show\nthat RIS can substantially increase the spectral and EE of URLLC systems if the\nreflecting coefficients are properly optimized. Moreover, we consider three\ndifferent transmission strategies for STAR-RIS as energy splitting (ES), mode\nswitching (MS), and time switching (TS). We show that STAR-RIS can outperform a\nregular RIS when the regular RIS cannot cover all the users. Furthermore, it is\nshown that the ES scheme outperforms the MS and TS schemes.\n","authors":["Mohammad Soleymani","Ignacio Santamaria","Eduard Jorswieck"],"pdf_url":"https://arxiv.org/pdf/2301.00583v2.pdf","comment":"Accepted at IEEE ACCESS"},{"id":"http://arxiv.org/abs/2307.04391v1","updated":"2023-07-10T07:54:59Z","published":"2023-07-10T07:54:59Z","title":"Vehicle Detection in 6G Systems with OTFS Modulation","summary":"  The recently introduced orthogonal time frequency space modulation (OTFSM) is\nmore robust to large narrow-band Doppler frequency shift than the orthogonal\nfrequency division multiplexing (OFDM), used in the 5G standard. In this paper\nit is shown how the elecommunication OTFSM-based signal with random padding can\nbe used with success in the 6G standard for detection of high-speed vehicles.\nTwo approaches for detecting targets during the random padded OTFS based\ntransmission are compared in the paper\n","authors":["Pavel Karpovich","Tomasz P. Zielinski"],"pdf_url":"https://arxiv.org/pdf/2307.04391v1.pdf","comment":"Accepted for Konferencja Radiokomunikacji i Teleinformatyki\n  KRiT-2023, Krakow, Poland"},{"id":"http://arxiv.org/abs/2307.04376v1","updated":"2023-07-10T07:21:23Z","published":"2023-07-10T07:21:23Z","title":"Joint Communications and Sensing Hybrid Beamforming Design via Deep\n  Unfolding","summary":"  Joint communications and sensing (JCAS) is envisioned as a key feature in\nfuture wireless communications networks. In massive MIMO-JCAS systems, hybrid\nbeamforming (HBF) is typically employed to achieve satisfactory beamforming\ngains with reasonable hardware cost and power consumption. Due to the coupling\nof the analog and digital precoders in HBF and the dual objective in JCAS,\nJCAS-HBF design problems are very challenging and usually require highly\ncomplex algorithms. In this paper, we propose a fast HBF design for JCAS based\non deep unfolding to optimize a tradeoff between the communications rate and\nsensing accuracy. We first derive closed-form expressions for the gradients of\nthe communications and sensing objectives with respect to the precoders and\ndemonstrate that the magnitudes of the gradients pertaining to the analog\nprecoder are typically smaller than those associated with the digital precoder.\nBased on this observation, we propose a modified projected gradient ascent\n(PGA) method with significantly improved convergence. We then develop a deep\nunfolded PGA scheme that efficiently optimizes the communications-sensing\nperformance tradeoff with fast convergence thanks to the well-trained\nhyperparameters. In doing so, we preserve the interpretability and flexibility\nof the optimizer while leveraging data to improve performance. Finally, our\nsimulations demonstrate the potential of the proposed deep unfolded method,\nwhich achieves up to 33.5% higher communications sum rate and 2.5 dB lower\nbeampattern error compared with the conventional design based on successive\nconvex approximation and Riemannian manifold optimization. Furthermore, it\nattains up to a 65% reduction in run time and computational complexity with\nrespect to the PGA procedure without unfolding.\n","authors":["Nhan Thanh Nguyen","Ly V. Nguyen","Nir Shlezinger","Yonina C. Eldar","A. Lee Swindlehurst","Markku Juntti"],"pdf_url":"https://arxiv.org/pdf/2307.04376v1.pdf","comment":"This paper has been submitted to Journal of Selected Topics in Signal\n  Processing"},{"id":"http://arxiv.org/abs/2210.01081v3","updated":"2023-07-10T07:14:02Z","published":"2022-10-03T16:51:12Z","title":"On The Effects Of Data Normalisation For Domain Adaptation On EEG Data","summary":"  In the Machine Learning (ML) literature, a well-known problem is the Dataset\nShift problem where, differently from the ML standard hypothesis, the data in\nthe training and test sets can follow different probability distributions,\nleading ML systems toward poor generalisation performances. This problem is\nintensely felt in the Brain-Computer Interface (BCI) context, where bio-signals\nas Electroencephalographic (EEG) are often used. In fact, EEG signals are\nhighly non-stationary both over time and between different subjects. To\novercome this problem, several proposed solutions are based on recent transfer\nlearning approaches such as Domain Adaption (DA). In several cases, however,\nthe actual causes of the improvements remain ambiguous. This paper focuses on\nthe impact of data normalisation, or standardisation strategies applied\ntogether with DA methods. In particular, using \\textit{SEED}, \\textit{DEAP},\nand \\textit{BCI Competition IV 2a} EEG datasets, we experimentally evaluated\nthe impact of different normalization strategies applied with and without\nseveral well-known DA methods, comparing the obtained performances. It results\nthat the choice of the normalisation strategy plays a key role on the\nclassifier performances in DA scenarios, and interestingly, in several cases,\nthe use of only an appropriate normalisation schema outperforms the DA\ntechnique.\n","authors":["Andrea Apicella","Francesco Isgrò","Andrea Pollastro","Roberto Prevete"],"pdf_url":"https://arxiv.org/pdf/2210.01081v3.pdf","comment":"Published in its final version on Engineering Applications of\n  Artificial Intelligence (EAAI) https://doi.org/10.1016/j.engappai.2023.106205"},{"id":"http://arxiv.org/abs/2307.04326v1","updated":"2023-07-10T03:39:43Z","published":"2023-07-10T03:39:43Z","title":"Automotive Radar Mutual Interference Mitigation Based on Hough Transform\n  in Time-Frequency Domain","summary":"  With the development of autonomous driving technology, automotive radar has\nreceived unprecedented attention due to its day-and-night and all-weather\nworking capability. It is worthwhile to note that more and more vehicles are\nequipped with automotive radars, resulting in mutual interference between\nradars. The interference reduces radar target detection performance, making\nperception information unreliable. In this paper, a novel interference\nmitigation method based on power-weighted Hough transform is proposed for\nsolving the radar mutual interference and improving the safety of autonomous\ndriving systems. Firstly, the frequency modulation characteristics of\ninterference signals and target echo signals are analyzed, and differences\nbetween the two signals are introduced. Secondly, based on the straight line\ndetection technique, the power of the mutual interference signal in\ntime-frequency domain is accumulated, and the accurate position of the\ninterference is located. Finally, the target echo is recovered by\nautoregressive model. Compared with existing state-of-the-art methods, the\nproposed method has the ability to retain more useful signals after the\ninterference mitigation, and achieve better interference detection robustness\nunder low signal-to-noise ratio conditions. Simulation experiments and real\nscenario experiments verify the effectiveness of the proposed method and show\nits superiority.\n","authors":["Yanbing Li","Weichuan Zhang","Lianying Ji"],"pdf_url":"https://arxiv.org/pdf/2307.04326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08198v2","updated":"2023-07-10T01:49:15Z","published":"2022-09-16T23:48:29Z","title":"Grid-Free MIMO Beam Alignment through Site-Specific Deep Learning","summary":"  Beam alignment is a critical bottleneck in millimeter wave (mmWave)\ncommunication. An ideal beam alignment technique should achieve high\nbeamforming (BF) gain with low latency, scale well to systems with higher\ncarrier frequencies, larger antenna arrays and multiple user equipments (UEs),\nand not require hard-to-obtain context information (CI). These qualities are\ncollectively lacking in existing methods. We depart from the conventional\ncodebook-based (CB) approach where the optimal beam is chosen from quantized\ncodebooks and instead propose a grid-free (GF) beam alignment method that\ndirectly synthesizes the transmit (Tx) and receive (Rx) beams from the\ncontinuous search space using measurements from a few site-specific probing\nbeams that are found via a deep learning (DL) pipeline. In realistic settings,\nthe proposed method achieves a far superior signal-to-noise ratio (SNR)-latency\ntrade-off compared to the CB baselines: it aligns near-optimal beams 100x\nfaster or equivalently finds beams with 10-15 dB better average SNR in the same\nnumber of searches, relative to an exhaustive search over a conventional\ncodebook.\n","authors":["Yuqiang Heng","Jeffrey G. Andrews"],"pdf_url":"https://arxiv.org/pdf/2209.08198v2.pdf","comment":"to appear in IEEE Transactions on Wireless Communications,\n  10.1109/TWC.2023.3283475"},{"id":"http://arxiv.org/abs/2307.04917v1","updated":"2023-07-10T21:49:42Z","published":"2023-07-10T21:49:42Z","title":"Unlimited Sampling of Bandpass Signals: Computational Demodulation via\n  Undersampling","summary":"  Bandpass signals are an important sub-class of bandlimited signals that\nnaturally arise in a number of application areas but their high-frequency\ncontent poses an acquisition challenge. Consequently, \"Bandpass Sampling\nTheory\" has been investigated and applied in the literature. In this paper, we\nconsider the problem of modulo sampling of bandpass signals with the main goal\nof sampling and recovery of high dynamic range inputs. Our work is inspired by\nthe Unlimited Sensing Framework (USF). In the USF, the modulo operation folds\nhigh dynamic range inputs into low dynamic range, modulo samples. This\nfundamentally avoids signal clipping. Given that the output of the modulo\nnonlinearity is non-bandlimited, bandpass sampling conditions never hold true.\nYet, we show that bandpass signals can be recovered from a modulo\nrepresentation despite the inevitable aliasing. Our main contribution includes\nproof of sampling theorems for recovery of bandpass signals from an\nundersampled representation, reaching sub-Nyquist sampling rates. On the\nrecovery front, by considering both time-and frequency-domain perspectives, we\nprovide a holistic view of the modulo bandpass sampling problem. On the\nhardware front, we include ideal, non-ideal and generalized modulo folding\narchitectures that arise in the hardware implementation of modulo\nanalog-to-digital converters. Numerical simulations corroborate our theoretical\nresults. Bridging the theory-practice gap, we validate our results using\nhardware experiments, thus demonstrating the practical effectiveness of our\nmethods.\n","authors":["Gal Shtendel","Dorian Florescu","Ayush Bhandari"],"pdf_url":"https://arxiv.org/pdf/2307.04917v1.pdf","comment":"24 pages, 9 figures, revised manuscript"},{"id":"http://arxiv.org/abs/2307.04904v1","updated":"2023-07-10T21:08:27Z","published":"2023-07-10T21:08:27Z","title":"Fast dynamic time warping and clustering in C++","summary":"  We present an approach for computationally efficient dynamic time warping\n(DTW) and clustering of time-series data. The method frames the dynamic warping\nof time series datasets as an optimisation problem solved using dynamic\nprogramming, and then clusters time series data by solving a second\noptimisation problem using mixed-integer programming (MIP). There is also an\noption to use k-medoids clustering for increased speed, when a certificate for\nglobal optimality is not essential. The improved efficiency of our approach is\ndue to task-level parallelisation of the clustering alongside DTW. Our approach\nwas tested using the UCR Time Series Archive, and was found to be, on average,\n33% faster than the next fastest option when using the same clustering method.\nThis increases to 64% faster when considering only larger datasets (with more\nthan 1000 time series). The MIP clustering is most effective on small numbers\nof longer time series, because the DTW computation is faster than other\napproaches, but the clustering problem becomes increasingly computationally\nexpensive as the number of time series to be clustered increases.\n","authors":["Volkan Kumtepeli","Rebecca Perriment","David A. Howey"],"pdf_url":"https://arxiv.org/pdf/2307.04904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.06295v3","updated":"2023-07-10T19:53:21Z","published":"2021-05-12T07:06:57Z","title":"Gait Characterization in Duchenne Muscular Dystrophy (DMD) Using a\n  Single-Sensor Accelerometer: Classical Machine Learning and Deep Learning\n  Approaches","summary":"  Differences in gait patterns of children with Duchenne muscular dystrophy\n(DMD) and typically-developing (TD) peers are visible to the eye, but\nquantifications of those differences outside of the gait laboratory have been\nelusive. In this work, we measured vertical, mediolateral, and anteroposterior\nacceleration using a waist-worn iPhone accelerometer during ambulation across a\ntypical range of velocities. Fifteen TD and fifteen DMD children from 3-16\nyears of age underwent eight walking/running activities, including five 25\nmeters walk/run speed-calibration tests at a slow walk to running speeds (SC-L1\nto SC-L5), a 6-minute walk test (6MWT), a 100 meters fast-walk/jog/run\n(100MRW), and a free walk (FW). For clinical anchoring purposes, participants\ncompleted a Northstar Ambulatory Assessment (NSAA). We extracted temporospatial\ngait clinical features (CFs) and applied multiple machine learning (ML)\napproaches to differentiate between DMD and TD children using extracted\ntemporospatial gait CFs and raw data. Extracted temporospatial gait CFs showed\nreduced step length and a greater mediolateral component of total power (TP)\nconsistent with shorter strides and Trendelenberg-like gait commonly observed\nin DMD. ML approaches using temporospatial gait CFs and raw data varied in\neffectiveness at differentiating between DMD and TD controls at different\nspeeds, with an accuracy of up to 100%. We demonstrate that by using ML with\naccelerometer data from a consumer-grade smartphone, we can capture\nDMD-associated gait characteristics in toddlers to teens.\n","authors":["Albara Ah Ramli","Xin Liu","Kelly Berndt","Erica Goude","Jiahui Hou","Lynea B. Kaethler","Rex Liu","Amanda Lopez","Alina Nicorici","Corey Owens","David Rodriguez","Jane Wang","Huanle Zhang","Daniel Aranki","Craig M. McDonald","Erik K. Henricson"],"pdf_url":"https://arxiv.org/pdf/2105.06295v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04866v1","updated":"2023-07-10T19:25:45Z","published":"2023-07-10T19:25:45Z","title":"Automated Detection of Gait Events and Travel Distance Using Waist-worn\n  Accelerometers Across a Typical Range of Walking and Running Speeds","summary":"  Background: Estimation of temporospatial clinical features of gait (CFs),\nsuch as step count and length, step duration, step frequency, gait speed and\ndistance traveled is an important component of community-based mobility\nevaluation using wearable accelerometers. However, challenges arising from\ndevice complexity and availability, cost and analytical methodology have\nlimited widespread application of such tools. Research Question: Can\naccelerometer data from commercially-available smartphones be used to extract\ngait CFs across a broad range of attainable gait velocities in children with\nDuchenne muscular dystrophy (DMD) and typically developing controls (TDs) using\nmachine learning (ML)-based methods Methods: Fifteen children with DMD and 15\nTDs underwent supervised clinical testing across a range of gait speeds using\n10 or 25m run/walk (10MRW, 25MRW), 100m run/walk (100MRW), 6-minute walk (6MWT)\nand free-walk (FW) evaluations while wearing a mobile phone-based accelerometer\nat the waist near the body's center of mass. Gait CFs were extracted from the\naccelerometer data using a multi-step machine learning-based process and\nresults were compared to ground-truth observation data. Results: Model\npredictions vs. observed values for step counts, distance traveled, and step\nlength showed a strong correlation (Pearson's r = -0.9929 to 0.9986, p<0.0001).\nThe estimates demonstrated a mean (SD) percentage error of 1.49% (7.04%) for\nstep counts, 1.18% (9.91%) for distance traveled, and 0.37% (7.52%) for step\nlength compared to ground truth observations for the combined 6MWT, 100MRW, and\nFW tasks. Significance: The study findings indicate that a single accelerometer\nplaced near the body's center of mass can accurately measure CFs across\ndifferent gait speeds in both TD and DMD peers, suggesting that there is\npotential for accurately measuring CFs in the community with consumer-level\nsmartphones.\n","authors":["Albara Ah Ramli","Xin Liu","Kelly Berndt","Chen-Nee Chuah","Erica Goude","Lynea B. Kaethler","Amanda Lopez","Alina Nicorici","Corey Owens","David Rodriguez","Jane Wang","Daniel Aranki","Craig M. McDonald","Erik K. Henricson"],"pdf_url":"https://arxiv.org/pdf/2307.04866v1.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2307.04727v1","updated":"2023-07-10T17:37:14Z","published":"2023-07-10T17:37:14Z","title":"Deceptive Information Retrieval","summary":"  We introduce the problem of deceptive information retrieval (DIR), in which a\nuser wishes to download a required file out of multiple independent files\nstored in a system of databases while \\emph{deceiving} the databases by making\nthe databases' predictions on the user-required file index incorrect with high\nprobability. Conceptually, DIR is an extension of private information retrieval\n(PIR). In PIR, a user downloads a required file without revealing its index to\nany of the databases. The metric of deception is defined as the probability of\nerror of databases' prediction on the user-required file, minus the\ncorresponding probability of error in PIR. The problem is defined on\ntime-sensitive data that keeps updating from time to time. In the proposed\nscheme, the user deceives the databases by sending \\emph{real} queries to\ndownload the required file at the time of the requirement and \\emph{dummy}\nqueries at multiple distinct future time instances to manipulate the\nprobabilities of sending each query for each file requirement, using which the\ndatabases' make the predictions on the user-required file index. The proposed\nDIR scheme is based on a capacity achieving probabilistic PIR scheme, and\nachieves rates lower than the PIR capacity due to the additional downloads made\nto deceive the databases. When the required level of deception is zero, the\nproposed scheme achieves the PIR capacity.\n","authors":["Sajani Vithana","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2307.04727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04695v1","updated":"2023-07-10T16:50:58Z","published":"2023-07-10T16:50:58Z","title":"Cobalt: Optimizing Mining Rewards in Proof-of-Work Network Games","summary":"  Mining in proof-of-work blockchains has become an expensive affair requiring\nspecialized hardware capable of executing several megahashes per second at huge\nelectricity costs. Miners earn a reward each time they mine a block within the\nlongest chain, which helps offset their mining costs. It is therefore of\ninterest to miners to maximize the number of mined blocks in the blockchain and\nincrease revenue. A key factor affecting mining rewards earned is the\nconnectivity between miners in the peer-to-peer network. To maximize rewards a\nminer must choose its network connections carefully, ensuring existence of\npaths to other miners that are on average of a lower latency compared to paths\nbetween other miners. We formulate the problem of deciding whom to connect to\nfor miners as a combinatorial bandit problem. Each node picks its neighbors\nstrategically to minimize the latency to reach 90\\% of the hash power of the\nnetwork relative to the 90-th percentile latency from other nodes. A key\ncontribution of our work is the use of a network coordinates based model for\nlearning the network structure within the bandit algorithm. Experimentally we\nshow our proposed algorithm outperforming or matching baselines on diverse\nnetwork settings.\n","authors":["Arti Vedula","Abhishek Gupta","Shaileshh Bojja Venkatakrishnan"],"pdf_url":"https://arxiv.org/pdf/2307.04695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04677v1","updated":"2023-07-10T16:21:35Z","published":"2023-07-10T16:21:35Z","title":"Practical Trustworthiness Model for DNN in Dedicated 6G Application","summary":"  Artificial intelligence (AI) is considered an efficient response to several\nchallenges facing 6G technology. However, AI still suffers from a huge trust\nissue due to its ambiguous way of making predictions. Therefore, there is a\nneed for a method to evaluate the AI's trustworthiness in practice for future\n6G applications. This paper presents a practical model to analyze the\ntrustworthiness of AI in a dedicated 6G application. In particular, we present\ntwo customized Deep Neural Networks (DNNs) to solve the Automatic Modulation\nRecognition (AMR) problem in Terahertz communications-based 6G technology.\nThen, a specific trustworthiness model and its attributes, namely data\nrobustness, parameter sensitivity, and security covering adversarial examples,\nare introduced. The evaluation results indicate that the proposed\ntrustworthiness attributes are crucial to evaluate the trustworthiness of DNN\nfor this 6G application.\n","authors":["Anouar Nechi","Ahmed Mahmoudi","Christoph Herold","Daniel Widmer","Thomas Kürner","Mladen Berekovic","Saleh Mulhem"],"pdf_url":"https://arxiv.org/pdf/2307.04677v1.pdf","comment":"PREPRINT - accepted In Proceedings of the 19th International\n  Conference on Wireless and Mobile Computing, Networking and Communications\n  2023(STWiMob 2023)"},{"id":"http://arxiv.org/abs/2307.04632v1","updated":"2023-07-10T15:19:37Z","published":"2023-07-10T15:19:37Z","title":"An End-To-End Analysis of Deep Learning-Based Remaining Useful Life\n  Algorithms for Satefy-Critical 5G-Enabled IIoT Networks","summary":"  Remaining Useful Life (RUL) prediction is a critical task that aims to\nestimate the amount of time until a system fails, where the latter is formed by\nthree main components, that is, the application, communication network, and RUL\nlogic. In this paper, we provide an end-to-end analysis of an entire RUL-based\nchain. Specifically, we consider a factory floor where Automated Guided\nVehicles (AGVs) transport dangerous liquids whose fall may cause injuries to\nworkers. Regarding the communication infrastructure, the AGVs are equipped with\n5G User Equipments (UEs) that collect real-time data of their movements and\nsend them to an application server. The RUL logic consists of a Deep Learning\n(DL)-based pipeline that assesses if there will be liquid falls by analyzing\nthe collected data, and, eventually, sending commands to the AGVs to avoid such\na danger. According to this scenario, we performed End-to-End 5G NR-compliant\nnetwork simulations to study the Round-Trip Time (RTT) as a function of the\noverall system bandwidth, subcarrier spacing, and modulation order. Then, via\nreal-world experiments, we collect data to train, test and compare 7 DL models\nand 1 baseline threshold-based algorithm in terms of cost and average advance.\nFinally, we assess whether or not the RTT provided by four different 5G NR\nnetwork architectures is compatible with the average advance provided by the\nbest-performing one-Dimensional Convolutional Neural Network (1D-CNN).\nNumerical results show under which conditions the DL-based approach for RUL\nestimation matches with the RTT performance provided by different 5G NR network\narchitectures.\n","authors":["Lorenzo Mario Amorosa","Nicolò Longhi","Giampaolo Cuozzo","Weronika Maria Bachan","Valerio Lieti","Enrico Buracchini","Roberto Verdone"],"pdf_url":"https://arxiv.org/pdf/2307.04632v1.pdf","comment":"6 pages, 4 figures. This work has been accepted for publication at\n  IEEE PIMRC 2023"},{"id":"http://arxiv.org/abs/2307.02329v2","updated":"2023-07-10T14:04:52Z","published":"2023-07-05T14:39:47Z","title":"Data-driven Predictive Latency for 5G: A Theoretical and Experimental\n  Analysis Using Network Measurements","summary":"  The advent of novel 5G services and applications with binding latency\nrequirements and guaranteed Quality of Service (QoS) hastened the need to\nincorporate autonomous and proactive decision-making in network management\nprocedures. The objective of our study is to provide a thorough analysis of\npredictive latency within 5G networks by utilizing real-world network data that\nis accessible to mobile network operators (MNOs). In particular, (i) we present\nan analytical formulation of the user-plane latency as a Hypoexponential\ndistribution, which is validated by means of a comparative analysis with\nempirical measurements, and (ii) we conduct experimental results of\nprobabilistic regression, anomaly detection, and predictive forecasting\nleveraging on emerging domains in Machine Learning (ML), such as Bayesian\nLearning (BL) and Machine Learning on Graphs (GML). We test our predictive\nframework using data gathered from scenarios of vehicular mobility, dense-urban\ntraffic, and social gathering events. Our results provide valuable insights\ninto the efficacy of predictive algorithms in practical applications.\n","authors":["Marco Skocaj","Francesca Conserva","Nicol Sarcone Grande","Andrea Orsi","Davide Micheli","Giorgio Ghinamo","Simone Bizzarri","Roberto Verdone"],"pdf_url":"https://arxiv.org/pdf/2307.02329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04529v1","updated":"2023-07-10T12:56:41Z","published":"2023-07-10T12:56:41Z","title":"Cross-Layer Assisted Early Congestion Control for Cloud VR Services in\n  5G Edge Network","summary":"  Cloud virtual reality (VR) has emerged as a promising technology, offering\nusers a highly immersive and easily accessible experience. However, the current\n5G radio access network faces challenges in accommodating the bursty traffic\ngenerated by multiple cloudVR flows simultaneously, leading to congestion at\nthe 5G base station and increased delays. In this research, we present a\ncomprehensive quantitative analysis that highlights the underlying causes for\nthe poor delay performance of cloudVR flows within the existing 5G protocol\nstack and network. To address these issues, we propose a novel cross-layer\ninformationassisted congestion control mechanism deployed in the 5G edge\nnetwork. Experiment results show that our mechanism enhances the number of\nconcurrent flows meeting delay standards by 1.5x to 2.5x, while maintaining a\nsmooth network load. These findings underscore the potential of leveraging 5G\nedge nodes as a valuable resource to effectively meet the anticipated demands\nof future services.\n","authors":["Wanghong Yang","Wenji Du","Baosen Zhao","Yongmao Ren","Jianan Sun","Xu Zhou"],"pdf_url":"https://arxiv.org/pdf/2307.04529v1.pdf","comment":"this paper is under review"},{"id":"http://arxiv.org/abs/2307.04498v1","updated":"2023-07-10T11:39:18Z","published":"2023-07-10T11:39:18Z","title":"RCS-based Quasi-Deterministic Ray Tracing for Statistical Channel\n  Modeling","summary":"  This paper presents a quasi-deterministic ray tracing (QD-RT) method for\nanalyzing the propagation of electromagnetic waves in street canyons. The\nmethod uses a statistical bistatic distribution to model the Radar Cross\nSection (RCS) of various irregular objects such as cars and pedestrians,\ninstead of relying on exact values as in a deterministic propagation model. The\nperformance of the QD-RT method is evaluated by comparing its generated path\nloss distributions to those of the deterministic ray tracing (D-RT) model using\nthe Two-sample Cramer-von Mises test. The results indicate that the QD-RT\nmethod generates the same path loss distributions as the D-RT model while\noffering lower complexity. This study suggests that the QD-RT method has the\npotential to be used for analyzing complicated scenarios such as street canyon\nscenarios in mmWave wireless communication systems.\n","authors":["Javad Ebrahimizadeh","Evgenii Vinogradov","Guy A. E. Vandenbosch"],"pdf_url":"https://arxiv.org/pdf/2307.04498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04477v1","updated":"2023-07-10T10:58:02Z","published":"2023-07-10T10:58:02Z","title":"On the Bipartite Entanglement Capacity of Quantum Networks","summary":"  We consider the problem of multi-path entanglement distribution to a pair of\nnodes in a quantum network consisting of devices with non-deterministic\nentanglement swapping capabilities. Multi-path entanglement distribution\nenables a network to establish end-to-end entangled links across any number of\navailable paths with pre-established link-level entanglement. Probabilistic\nentanglement swapping, on the other hand, limits the amount of entanglement\nthat is shared between the nodes; this is especially the case when, due to\narchitectural and other practical constraints, swaps must be performed in\ntemporal proximity to each other. Limiting our focus to the case where only\nbipartite entangled states are generated across the network, we cast the\nproblem as an instance of generalized flow maximization between two quantum end\nnodes wishing to communicate. We propose a mixed-integer quadratically\nconstrained program (MIQCP) to solve this flow problem for networks with\narbitrary topology. We then compute the overall network capacity, defined as\nthe maximum number of EPR states distributed to users per time unit, by solving\nthe flow problem for all possible network states generated by probabilistic\nentangled link presence and absence, and subsequently by averaging over all\nnetwork state capacities. The MIQCP can also be applied to networks with\nmultiplexed links. While our approach for computing the overall network\ncapacity has the undesirable property that the total number of states grows\nexponentially with link multiplexing capability, it nevertheless yields an\nexact solution that serves as an upper bound comparison basis for the\nthroughput performance of easily-implementable yet non-optimal entanglement\nrouting algorithms. We apply our capacity computation method to several\nnetworks, including a topology based on SURFnet -- a backbone network used for\nresearch purposes in the Netherlands.\n","authors":["Gayane Vardoyan","Emily van Milligen","Saikat Guha","Stephanie Wehner","Don Towsley"],"pdf_url":"https://arxiv.org/pdf/2307.04477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04819v1","updated":"2023-07-10T18:04:26Z","published":"2023-07-10T18:04:26Z","title":"A Kalman Filter based Low Complexity Throughput Prediction Algorithm for\n  5G Cellular Networks","summary":"  Throughput Prediction is one of the primary preconditions for the\nuninterrupted operation of several network-aware mobile applications, namely\nvideo streaming. Recent works have advocated using Machine Learning (ML) and\nDeep Learning (DL) for cellular network throughput prediction. In contrast,\nthis work has proposed a low computationally complex simple solution which\nmodels the future throughput as a multiple linear regression of several present\nnetwork parameters and present throughput. It then feeds the variance of\nprediction error and measurement error, which is inherent in any measurement\nsetup but unaccounted for in existing works, to a Kalman filter-based\nprediction-correction approach to obtain the optimal estimates of the future\nthroughput. Extensive experiments across seven publicly available 5G throughput\ndatasets for different prediction window lengths have shown that the proposed\nmethod outperforms the baseline ML and DL algorithms by delivering more\naccurate results within a shorter timeframe for inferencing and retraining.\nFurthermore, in comparison to its ML and DL counterparts, the proposed\nthroughput prediction method is also found to deliver higher QoE to both\nstreaming and live video users when used in conjunction with popular Model\nPredictive Control (MPC) based adaptive bitrate streaming algorithms.\n","authors":["Mayukh Biswas","Ayan Chakraborty","Basabdatta Palit"],"pdf_url":"https://arxiv.org/pdf/2307.04819v1.pdf","comment":"13 pages, 14 figures"},{"id":"http://arxiv.org/abs/2307.05609v1","updated":"2023-07-10T22:37:54Z","published":"2023-07-10T22:37:54Z","title":"Virtual Network Embedding without Explicit Virtual Network Specification","summary":"  Network virtualization enables Internet service providers to run multiple\nheterogeneous and dedicated network architectures for different customers on a\nshared substrate. In existing works on virtual network embedding (VNE), each\ncustomer formulates a virtual network request (VNR) where a virtual network\n(VN) is required. Motivated by a concrete example where VN is not a proper VNR\nformulation to reflect the traffic demand of a customer, we propose a new VNR\nformulation described by the traffic demand between several access node pairs\nto complement the existing VNR formulation. Moreover, three different groups of\nVNE variants are systematically examined. Simulations demonstrate that shared\nchannel embedding, as a new embedding variant under the proposed VNR\nformulation, improves the acceptance rate and reduces cost and link utility\ncompared to traditional independent channel embedding.\n","authors":["Jiangnan Cheng","Yingjie Bi","Ao Tang"],"pdf_url":"https://arxiv.org/pdf/2307.05609v1.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2307.04684v1","updated":"2023-07-10T16:37:46Z","published":"2023-07-10T16:37:46Z","title":"FreeDrag: Point Tracking is Not You Need for Interactive Point-based\n  Image Editing","summary":"  To serve the intricate and varied demands of image editing, precise and\nflexible manipulation of image content is indispensable. Recently, DragGAN has\nachieved impressive editing results through point-based manipulation. However,\nwe have observed that DragGAN struggles with miss tracking, where DragGAN\nencounters difficulty in effectively tracking the desired handle points, and\nambiguous tracking, where the tracked points are situated within other regions\nthat bear resemblance to the handle points. To deal with the above issues, we\npropose FreeDrag, which adopts a feature-oriented approach to free the burden\non point tracking within the point-oriented methodology of DragGAN. The\nFreeDrag incorporates adaptive template features, line search, and fuzzy\nlocalization techniques to perform stable and efficient point-based image\nediting. Extensive experiments demonstrate that our method is superior to the\nDragGAN and enables stable point-based editing in challenging scenarios with\nsimilar structures, fine details, or under multi-point targets.\n","authors":["Pengyang Ling","Lin Chen","Pan Zhang","Huaian Chen","Yi Jin"],"pdf_url":"https://arxiv.org/pdf/2307.04684v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.02719v2","updated":"2023-07-10T15:15:47Z","published":"2023-03-05T17:20:10Z","title":"A Comparative Study of Self-Supervised Speech Representations in Read\n  and Spontaneous TTS","summary":"  Recent work has explored using self-supervised learning (SSL) speech\nrepresentations such as wav2vec2.0 as the representation medium in standard\ntwo-stage TTS, in place of conventionally used mel-spectrograms. It is however\nunclear which speech SSL is the better fit for TTS, and whether or not the\nperformance differs between read and spontaneous TTS, the later of which is\narguably more challenging. This study aims at addressing these questions by\ntesting several speech SSLs, including different layers of the same SSL, in\ntwo-stage TTS on both read and spontaneous corpora, while maintaining constant\nTTS model architecture and training settings. Results from listening tests show\nthat the 9th layer of 12-layer wav2vec2.0 (ASR finetuned) outperforms other\ntested SSLs and mel-spectrogram, in both read and spontaneous TTS. Our work\nsheds light on both how speech SSL can readily improve current TTS systems, and\nhow SSLs compare in the challenging generative task of TTS. Audio examples can\nbe found at https://www.speech.kth.se/tts-demos/ssr_tts\n","authors":["Siyang Wang","Gustav Eje Henter","Joakim Gustafson","Éva Székely"],"pdf_url":"https://arxiv.org/pdf/2303.02719v2.pdf","comment":"5 pages, 2 figures. ICASSP Workshop SASB (Self-Supervision in Audio,\n  Speech and Beyond)2023"},{"id":"http://arxiv.org/abs/2307.04563v1","updated":"2023-07-10T13:52:09Z","published":"2023-07-10T13:52:09Z","title":"Automatically detecting activities of daily living from in-home sensors\n  as indicators of routine behaviour in an older population","summary":"  Objective: The NEX project has developed an integrated Internet of Things\n(IoT) system coupled with data analytics to offer unobtrusive health and\nwellness monitoring supporting older adults living independently at home.\nMonitoring {currently} involves visualising a set of automatically detected\nactivities of daily living (ADLs) for each participant. The detection of ADLs\nis achieved {} to allow the incorporation of additional participants whose ADLs\nare detected without re-training the system.\n  Methods: Following an extensive User Needs and Requirements study involving\n426 participants, a pilot trial and a friendly trial of the deployment, an\nAction Research Cycle (ARC) trial was completed. This involved 23 participants\nover a 10-week period each with c.20 IoT sensors in their homes. During the ARC\ntrial, participants each took part in two data-informed briefings which\npresented visualisations of their own in-home activities. The briefings also\ngathered training data on the accuracy of detected activities. Association rule\nmining was then used on the combination of data from sensors and participant\nfeedback to improve the automatic detection of ADLs.\n  Results: Association rule mining was used to detect a range of ADLs for each\nparticipant independently of others and was then used to detect ADLs across\nparticipants using a single set of rules {for each ADL}. This allows additional\nparticipants to be added without the necessity of them providing training data.\n  Conclusions: Additional participants can be added to the NEX system without\nthe necessity to re-train the system for automatic detection of the set of\ntheir activities of daily living.\n","authors":["Claire M. Timon","Pamela Hussey","Hyowon Lee","Catriona Murphy","Harsh Vardan Rai","and Alan F. Smeaton"],"pdf_url":"https://arxiv.org/pdf/2307.04563v1.pdf","comment":"11 pages, 7 Figures, 2 tables"},{"id":"http://arxiv.org/abs/2307.04549v1","updated":"2023-07-10T13:27:13Z","published":"2023-07-10T13:27:13Z","title":"Needs, Passions and Loot Boxes -- Exploring Reasons for Problem\n  Behaviour in Relation to Loot Box Engagement","summary":"  Research on the convergence of gaming and gambling has been around since the\n1990s. The emergence of loot boxes in video games in the mid 2010s, a game\nmechanic with a chance-based outcome that shares structural and psychological\nsimilarities to gambling, caused public controversy and lead to the inception\nof a new field of study, loot box research. Since then, various studies have\nfound a relationship between loot box engagement and problem gambling as well\nas problem gaming. Due to the cross-sectional nature of this data, however,\ninferences about causality are limited. While loot box research has extensively\ninvestigated the relationship between loot box engagement and problem\nbehaviour, little research has been done to explain the underlying motivations\nof players that drive them to interact with loot boxes. The goal of this thesis\nis to provide possible explanations for the relationship between loot box\nengagement and problem gamblers or problem gamers. In doing so, it draws upon\ntwo prominent psychological theories. Self-Determination Theory and the\nDualistic Model of Passion. Self-Determination Theory's concept of\npsychological needs and their satisfaction or frustration is hereby used to\nexplain the development of harmonious or obsessive passions, which are\nintroduced in the Dualistic Model of Passion. These obsessive passions have\nbeen shown to be possible antecedents of behavioural addictions, such as\nproblem gambling or problem gaming. Thus, the interplay between needs, passions\nand loot box opening could elucidate the aforementioned correlations between\nloot box engagement and problem behaviour. However, further research,\nespecially utilising longitudinal data, is needed to better understand these\nprocesses.\n","authors":["Dylan Mercury Cooper"],"pdf_url":"https://arxiv.org/pdf/2307.04549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09417v2","updated":"2023-07-10T12:53:24Z","published":"2023-06-15T18:02:49Z","title":"Diff-TTSG: Denoising probabilistic integrated speech and gesture\n  synthesis","summary":"  With read-aloud speech synthesis achieving high naturalness scores, there is\na growing research interest in synthesising spontaneous speech. However, human\nspontaneous face-to-face conversation has both spoken and non-verbal aspects\n(here, co-speech gestures). Only recently has research begun to explore the\nbenefits of jointly synthesising these two modalities in a single system. The\nprevious state of the art used non-probabilistic methods, which fail to capture\nthe variability of human speech and motion, and risk producing oversmoothing\nartefacts and sub-optimal synthesis quality. We present the first\ndiffusion-based probabilistic model, called Diff-TTSG, that jointly learns to\nsynthesise speech and gestures together. Our method can be trained on small\ndatasets from scratch. Furthermore, we describe a set of careful uni- and\nmulti-modal subjective tests for evaluating integrated speech and gesture\nsynthesis systems, and use them to validate our proposed approach. For\nsynthesised examples please see https://shivammehta25.github.io/Diff-TTSG\n","authors":["Shivam Mehta","Siyang Wang","Simon Alexanderson","Jonas Beskow","Éva Székely","Gustav Eje Henter"],"pdf_url":"https://arxiv.org/pdf/2306.09417v2.pdf","comment":"7 pages, 2 figures, Accepted at ISCA Speech Synthesis Workshop (SSW)\n  2023"},{"id":"http://arxiv.org/abs/2307.04500v1","updated":"2023-07-10T11:41:20Z","published":"2023-07-10T11:41:20Z","title":"Algorithm- Versus Human-Generated Academic Plans: Determining Optimality\n  from Community College Articulation Agreements","summary":"  We developed a low-fidelity prototype of a report that contains an\nalgorithmically-generated optimal academic plan. Optimal is defined as the\nminimal set of community college courses that satisfy the transfer requirements\nfor multiple universities a student is preparing to apply to. We recruited 24\nCalifornia community college transfer students to participate in a research\nsession, consisting of an experiment, survey, and interview. We experimentally\ncompared the prototype to ASSIST, California's official statewide database of\narticulation agreement reports. Compared to students who used the prototype,\nstudents assigned to use ASSIST reports to manually create an optimal academic\nplan underperformed in optimality mistakes, time required, and usability\nscores. Moving to our non-experimental results, a sizable minority of students\nhad a negative assessment of counselors' ability and willingness to manually\ncreate optimal academic plans using ASSIST. Our last results revolved around\nstudents' recommendations for supplemental software features to improve the\noptimization prototype.\n","authors":["David Van Nguyen","Shayan Doroudi","Daniel A. Epstein"],"pdf_url":"https://arxiv.org/pdf/2307.04500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09170v3","updated":"2023-07-10T11:22:20Z","published":"2023-06-15T14:47:03Z","title":"Can ChatGPT pass the Vietnamese National High School Graduation\n  Examination?","summary":"  This research article highlights the potential of AI-powered chatbots in\neducation and presents the results of using ChatGPT, a large language model, to\ncomplete the Vietnamese National High School Graduation Examination (VNHSGE).\nThe study dataset included 30 essays in the literature test case and 1,700\nmultiple-choice questions designed for other subjects. The results showed that\nChatGPT was able to pass the examination with an average score of 6-7,\ndemonstrating the technology's potential to revolutionize the educational\nlandscape. The analysis of ChatGPT performance revealed its proficiency in a\nrange of subjects, including mathematics, English, physics, chemistry, biology,\nhistory, geography, civic education, and literature, which suggests its\npotential to provide effective support for learners. However, further research\nis needed to assess ChatGPT performance on more complex exam questions and its\npotential to support learners in different contexts. As technology continues to\nevolve and improve, we can expect to see the use of AI tools like ChatGPT\nbecome increasingly common in educational settings, ultimately enhancing the\neducational experience for both students and educators.\n","authors":["Xuan-Quy Dao","Ngoc-Bich Le","Xuan-Dung Phan","Bac-Bien Ngo"],"pdf_url":"https://arxiv.org/pdf/2306.09170v3.pdf","comment":"9 pages, 13 figures, 4 tables"},{"id":"http://arxiv.org/abs/2307.04481v1","updated":"2023-07-10T11:03:32Z","published":"2023-07-10T11:03:32Z","title":"Digital Modeling for Everyone: Exploring How Novices Approach\n  Voice-Based 3D Modeling","summary":"  Manufacturing tools like 3D printers have become accessible to the wider\nsociety, making the promise of digital fabrication for everyone seemingly\nreachable. While the actual manufacturing process is largely automated today,\nusers still require knowledge of complex design applications to produce\nready-designed objects and adapt them to their needs or design new objects from\nscratch. To lower the barrier to the design and customization of personalized\n3D models, we explored novice mental models in voice-based 3D modeling by\nconducting a high-fidelity Wizard of Oz study with 22 participants. We\nperformed a thematic analysis of the collected data to understand how the\nmental model of novices translates into voice-based 3D modeling. We conclude\nwith design implications for voice assistants. For example, they have to: deal\nwith vague, incomplete and wrong commands; provide a set of straightforward\ncommands to shape simple and composite objects; and offer different strategies\nto select 3D objects.\n","authors":["Giuseppe Desolda","Andrea Esposito","Florian Müller","Sebastian Feger"],"pdf_url":"https://arxiv.org/pdf/2307.04481v1.pdf","comment":"Accepted for publication at INTERACT 2023"},{"id":"http://arxiv.org/abs/2307.04462v1","updated":"2023-07-10T10:20:09Z","published":"2023-07-10T10:20:09Z","title":"Utilising Explanations to Mitigate Robot Conversational Failures","summary":"  This paper presents an overview of robot failure detection work from HRI and\nadjacent fields using failures as an opportunity to examine robot explanation\nbehaviours. As humanoid robots remain experimental tools in the early 2020s,\ninteractions with robots are situated overwhelmingly in controlled\nenvironments, typically studying various interactional phenomena. Such\ninteractions suffer from real-world and large-scale experimentation and tend to\nignore the 'imperfectness' of the everyday user. Robot explanations can be used\nto approach and mitigate failures, by expressing robot legibility and\nincapability, and within the perspective of common-ground. In this paper, I\ndiscuss how failures present opportunities for explanations in interactive\nconversational robots and what the potentials are for the intersection of HRI\nand explainability research.\n","authors":["Dimosthenis Kontogiorgos"],"pdf_url":"https://arxiv.org/pdf/2307.04462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.05527v2","updated":"2023-07-10T09:06:40Z","published":"2022-01-14T15:54:51Z","title":"Federated Continual Learning for Socially Aware Robotics","summary":"  From learning assistance to companionship, social robots promise to enhance\nmany aspects of daily life. However, social robots have not seen widespread\nadoption, in part because (1) they do not adapt their behavior to new users,\nand (2) they do not provide sufficient privacy protections. Centralized\nlearning, whereby robots develop skills by gathering data on a server,\ncontributes to these limitations by preventing online learning of new\nexperiences and requiring storage of privacy-sensitive data. In this work, we\npropose a decentralized learning alternative that improves the privacy and\npersonalization of social robots. We combine two machine learning approaches,\nFederated Learning and Continual Learning, to capture interaction dynamics\ndistributed physically across robots and temporally across repeated robot\nencounters. We define a set of criteria that should be balanced in\ndecentralized robot learning scenarios. We also develop a new algorithm --\nElastic Transfer -- that leverages importance-based regularization to preserve\nrelevant parameters across robots and interactions with multiple humans. We\nshow that decentralized learning is a viable alternative to centralized\nlearning in a proof-of-concept Socially-Aware Navigation domain, and\ndemonstrate how Elastic Transfer improves several of the proposed criteria.\n","authors":["Luke Guerdan","Hatice Gunes"],"pdf_url":"https://arxiv.org/pdf/2201.05527v2.pdf","comment":"IEEE RO-MAN 23'"},{"id":"http://arxiv.org/abs/2307.04872v1","updated":"2023-07-10T19:41:54Z","published":"2023-07-10T19:41:54Z","title":"The Synthesis Lab: Empowering Collaborative Learning in Higher Education\n  through Knowledge Synthesis","summary":"  The ability to synthesize information has emerged as a critical skill for\nsuccess across various fields. However, within the field of education, there is\na lack of systematic understanding and well-defined design infrastructures that\naddress the mechanisms and processes of knowledge synthesis in collaborative\nlearning settings. In this poster, we introduce a design innovation - The\nSynthesis Lab, which aims to support students in synthesizing ideas from their\nonline discussions in higher education classrooms. The tool offers structured\nwork-spaces for students to decompose the synthesis process into intermediate\nsynthesis products and features two key iterative processes of knowledge\nsynthesis in collaborative settings: categorizing peers' ideas into conceptual\nbuilding blocks and developing a synthesis of the discussions. Future\nimplementation and evaluation of the design will make significant contributions\nto both research and practice.\n","authors":["Xinran Zhu","Hong Shui","Bodong Chen"],"pdf_url":"https://arxiv.org/pdf/2307.04872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04858v1","updated":"2023-07-10T19:15:17Z","published":"2023-07-10T19:15:17Z","title":"AmadeusGPT: a natural language interface for interactive animal\n  behavioral analysis","summary":"  The process of quantifying and analyzing animal behavior involves translating\nthe naturally occurring descriptive language of their actions into\nmachine-readable code. Yet, codifying behavior analysis is often challenging\nwithout deep understanding of animal behavior and technical machine learning\nknowledge. To limit this gap, we introduce AmadeusGPT: a natural language\ninterface that turns natural language descriptions of behaviors into\nmachine-executable code. Large-language models (LLMs) such as GPT3.5 and GPT4\nallow for interactive language-based queries that are potentially well suited\nfor making interactive behavior analysis. However, the comprehension capability\nof these LLMs is limited by the context window size, which prevents it from\nremembering distant conversations. To overcome the context window limitation,\nwe implement a novel dual-memory mechanism to allow communication between\nshort-term and long-term memory using symbols as context pointers for retrieval\nand saving. Concretely, users directly use language-based definitions of\nbehavior and our augmented GPT develops code based on the core AmadeusGPT API,\nwhich contains machine learning, computer vision, spatio-temporal reasoning,\nand visualization modules. Users then can interactively refine results, and\nseamlessly add new behavioral modules as needed. We benchmark AmadeusGPT and\nshow we can produce state-of-the-art performance on the MABE 2022 behavior\nchallenge tasks. Note, an end-user would not need to write any code to achieve\nthis. Thus, collectively AmadeusGPT presents a novel way to merge deep\nbiological knowledge, large-language models, and core computer vision modules\ninto a more naturally intelligent system. Code and demos can be found at:\nhttps://github.com/AdaptiveMotorControlLab/AmadeusGPT.\n","authors":["Shaokai Ye","Jessy Lauer","Mu Zhou","Alexander Mathis","Mackenzie W. Mathis"],"pdf_url":"https://arxiv.org/pdf/2307.04858v1.pdf","comment":"demo available https://github.com/AdaptiveMotorControlLab/AmadeusGPT"},{"id":"http://arxiv.org/abs/2304.02819v3","updated":"2023-07-10T18:48:45Z","published":"2023-04-06T01:51:15Z","title":"GPT detectors are biased against non-native English writers","summary":"  The rapid adoption of generative language models has brought about\nsubstantial advancements in digital communication, while simultaneously raising\nconcerns regarding the potential misuse of AI-generated content. Although\nnumerous detection methods have been proposed to differentiate between AI and\nhuman-generated content, the fairness and robustness of these detectors remain\nunderexplored. In this study, we evaluate the performance of several\nwidely-used GPT detectors using writing samples from native and non-native\nEnglish writers. Our findings reveal that these detectors consistently\nmisclassify non-native English writing samples as AI-generated, whereas native\nwriting samples are accurately identified. Furthermore, we demonstrate that\nsimple prompting strategies can not only mitigate this bias but also\neffectively bypass GPT detectors, suggesting that GPT detectors may\nunintentionally penalize writers with constrained linguistic expressions. Our\nresults call for a broader conversation about the ethical implications of\ndeploying ChatGPT content detectors and caution against their use in evaluative\nor educational settings, particularly when they may inadvertently penalize or\nexclude non-native English speakers from the global discourse. The published\nversion of this study can be accessed at:\nwww.cell.com/patterns/fulltext/S2666-3899(23)00130-7\n","authors":["Weixin Liang","Mert Yuksekgonul","Yining Mao","Eric Wu","James Zou"],"pdf_url":"https://arxiv.org/pdf/2304.02819v3.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2307.04749v1","updated":"2023-07-10T17:54:57Z","published":"2023-07-10T17:54:57Z","title":"Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image\n  Alignment with Iterative VQA Feedback","summary":"  The field of text-conditioned image generation has made unparalleled progress\nwith the recent advent of latent diffusion models. While remarkable, as the\ncomplexity of given text input increases, the state-of-the-art diffusion models\nmay still fail in generating images which accurately convey the semantics of\nthe given prompt. Furthermore, it has been observed that such misalignments are\noften left undetected by pretrained multi-modal models such as CLIP. To address\nthese problems, in this paper we explore a simple yet effective decompositional\napproach towards both evaluation and improvement of text-to-image alignment. In\nparticular, we first introduce a Decompositional-Alignment-Score which given a\ncomplex prompt decomposes it into a set of disjoint assertions. The alignment\nof each assertion with generated images is then measured using a VQA model.\nFinally, alignment scores for different assertions are combined aposteriori to\ngive the final text-to-image alignment score. Experimental analysis reveals\nthat the proposed alignment metric shows significantly higher correlation with\nhuman ratings as opposed to traditional CLIP, BLIP scores. Furthermore, we also\nfind that the assertion level alignment scores provide a useful feedback which\ncan then be used in a simple iterative procedure to gradually increase the\nexpression of different assertions in the final image outputs. Human user\nstudies indicate that the proposed approach surpasses previous state-of-the-art\nby 8.7% in overall text-to-image alignment accuracy. Project page for our paper\nis available at https://1jsingh.github.io/divide-evaluate-and-refine\n","authors":["Jaskirat Singh","Liang Zheng"],"pdf_url":"https://arxiv.org/pdf/2307.04749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04738v1","updated":"2023-07-10T17:52:01Z","published":"2023-07-10T17:52:01Z","title":"RoCo: Dialectic Multi-Robot Collaboration with Large Language Models","summary":"  We propose a novel approach to multi-robot collaboration that harnesses the\npower of pre-trained large language models (LLMs) for both high-level\ncommunication and low-level path planning. Robots are equipped with LLMs to\ndiscuss and collectively reason task strategies. They then generate sub-task\nplans and task space waypoint paths, which are used by a multi-arm motion\nplanner to accelerate trajectory planning. We also provide feedback from the\nenvironment, such as collision checking, and prompt the LLM agents to improve\ntheir plan and waypoints in-context. For evaluation, we introduce RoCoBench, a\n6-task benchmark covering a wide range of multi-robot collaboration scenarios,\naccompanied by a text-only dataset for agent representation and reasoning. We\nexperimentally demonstrate the effectiveness of our approach -- it achieves\nhigh success rates across all tasks in RoCoBench and adapts to variations in\ntask semantics. Our dialog setup offers high interpretability and flexibility\n-- in real world experiments, we show RoCo easily incorporates\nhuman-in-the-loop, where a user can communicate and collaborate with a robot\nagent to complete tasks together. See project website\nhttps://project-roco.github.io for videos and code.\n","authors":["Zhao Mandi","Shreeya Jain","Shuran Song"],"pdf_url":"https://arxiv.org/pdf/2307.04738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04726v1","updated":"2023-07-10T17:34:23Z","published":"2023-07-10T17:34:23Z","title":"Diffusion Policies for Out-of-Distribution Generalization in Offline\n  Reinforcement Learning","summary":"  Offline Reinforcement Learning (RL) methods leverage previous experiences to\nlearn better policies than the behavior policy used for experience collection.\nIn contrast to behavior cloning, which assumes the data is collected from\nexpert demonstrations, offline RL can work with non-expert data and multimodal\nbehavior policies. However, offline RL algorithms face challenges in handling\ndistribution shifts and effectively representing policies due to the lack of\nonline interaction during training. Prior work on offline RL uses conditional\ndiffusion models to obtain expressive policies to represent multimodal behavior\nin the dataset. Nevertheless, they are not tailored toward alleviating the\nout-of-distribution state generalization. We introduce a novel method\nincorporating state reconstruction feature learning in the recent class of\ndiffusion policies to address the out-of-distribution generalization problem.\nState reconstruction loss promotes more descriptive representation learning of\nstates to alleviate the distribution shift incurred by the out-of-distribution\nstates. We design a 2D Multimodal Contextual Bandit environment to demonstrate\nand evaluate our proposed model. We assess the performance of our model not\nonly in this new environment but also on several D4RL benchmark tasks,\nachieving state-of-the-art results.\n","authors":["Suzan Ece Ada","Erhan Oztop","Emre Ugur"],"pdf_url":"https://arxiv.org/pdf/2307.04726v1.pdf","comment":"14 pages, 4 figures"},{"id":"http://arxiv.org/abs/2307.04721v1","updated":"2023-07-10T17:32:13Z","published":"2023-07-10T17:32:13Z","title":"Large Language Models as General Pattern Machines","summary":"  We observe that pre-trained large language models (LLMs) are capable of\nautoregressively completing complex token sequences -- from arbitrary ones\nprocedurally generated by probabilistic context-free grammars (PCFG), to more\nrich spatial patterns found in the Abstract Reasoning Corpus (ARC), a general\nAI benchmark, prompted in the style of ASCII art. Surprisingly, pattern\ncompletion proficiency can be partially retained even when the sequences are\nexpressed using tokens randomly sampled from the vocabulary. These results\nsuggest that without any additional training, LLMs can serve as general\nsequence modelers, driven by in-context learning. In this work, we investigate\nhow these zero-shot capabilities may be applied to problems in robotics -- from\nextrapolating sequences of numbers that represent states over time to complete\nsimple motions, to least-to-most prompting of reward-conditioned trajectories\nthat can discover and represent closed-loop policies (e.g., a stabilizing\ncontroller for CartPole). While difficult to deploy today for real systems due\nto latency, context size limitations, and compute costs, the approach of using\nLLMs to drive low-level control may provide an exciting glimpse into how the\npatterns among words could be transferred to actions.\n","authors":["Suvir Mirchandani","Fei Xia","Pete Florence","Brian Ichter","Danny Driess","Montserrat Gonzalez Arenas","Kanishka Rao","Dorsa Sadigh","Andy Zeng"],"pdf_url":"https://arxiv.org/pdf/2307.04721v1.pdf","comment":"18 pages, 23 figures"},{"id":"http://arxiv.org/abs/2307.04701v1","updated":"2023-07-10T16:58:37Z","published":"2023-07-10T16:58:37Z","title":"Understanding Real-World AI Planning Domains: A Conceptual Framework","summary":"  Planning is a pivotal ability of any intelligent system being developed for\nreal-world applications. AI planning is concerned with researching and\ndeveloping planning systems that automatically compute plans that satisfy some\nuser objective. Identifying and understanding the relevant and realistic\naspects that characterise real-world application domains are crucial to the\ndevelopment of AI planning systems. This provides guidance to knowledge\nengineers and software engineers in the process of designing, identifying, and\ncategorising resources required for the development process. To the best of our\nknowledge, such support does not exist. We address this research gap by\ndeveloping a conceptual framework that identifies and categorises the aspects\nof real-world planning domains in varying levels of granularity. Our framework\nprovides not only a common terminology but also a comprehensive overview of a\nbroad range of planning aspects exemplified using the domain of sustainable\nbuildings as a prominent application domain of AI planning. The framework has\nthe potential to impact the design, development, and applicability of AI\nplanning systems in real-world application domains.\n","authors":["Ebaa Alnazer","Ilche Georgievski"],"pdf_url":"https://arxiv.org/pdf/2307.04701v1.pdf","comment":"21 pages, 3 figures, 17th Symposium and Summer School (SummerSOC)\n  2023"},{"id":"http://arxiv.org/abs/2208.12306v3","updated":"2023-07-10T16:51:34Z","published":"2022-08-25T19:04:28Z","title":"Multimedia Generative Script Learning for Task Planning","summary":"  Goal-oriented generative script learning aims to generate subsequent steps to\nreach a particular goal, which is an essential task to assist robots or humans\nin performing stereotypical activities. An important aspect of this process is\nthe ability to capture historical states visually, which provides detailed\ninformation that is not covered by text and will guide subsequent steps.\nTherefore, we propose a new task, Multimedia Generative Script Learning, to\ngenerate subsequent steps by tracking historical states in both text and vision\nmodalities, as well as presenting the first benchmark containing 5,652 tasks\nand 79,089 multimedia steps. This task is challenging in three aspects: the\nmultimedia challenge of capturing the visual states in images, the induction\nchallenge of performing unseen tasks, and the diversity challenge of covering\ndifferent information in individual steps. We propose to encode visual state\nchanges through a selective multimedia encoder to address the multimedia\nchallenge, transfer knowledge from previously observed tasks using a\nretrieval-augmented decoder to overcome the induction challenge, and further\npresent distinct information at each step by optimizing a diversity-oriented\ncontrastive learning objective. We define metrics to evaluate both generation\nand inductive quality. Experiment results demonstrate that our approach\nsignificantly outperforms strong baselines.\n","authors":["Qingyun Wang","Manling Li","Hou Pong Chan","Lifu Huang","Julia Hockenmaier","Girish Chowdhary","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2208.12306v3.pdf","comment":"21 pages, Accepted by Findings of the Association for Computational\n  Linguistics: ACL 2023, Code and Resources at\n  https://github.com/EagleW/Multimedia-Generative-Script-Learning"},{"id":"http://arxiv.org/abs/2307.04693v1","updated":"2023-07-10T16:46:34Z","published":"2023-07-10T16:46:34Z","title":"COMEX: A Tool for Generating Customized Source Code Representations","summary":"  Learning effective representations of source code is critical for any Machine\nLearning for Software Engineering (ML4SE) system. Inspired by natural language\nprocessing, large language models (LLMs) like Codex and CodeGen treat code as\ngeneric sequences of text and are trained on huge corpora of code data,\nachieving state of the art performance on several software engineering (SE)\ntasks. However, valid source code, unlike natural language, follows a strict\nstructure and pattern governed by the underlying grammar of the programming\nlanguage. Current LLMs do not exploit this property of the source code as they\ntreat code like a sequence of tokens and overlook key structural and semantic\nproperties of code that can be extracted from code-views like the Control Flow\nGraph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc.\nUnfortunately, the process of generating and integrating code-views for every\nprogramming language is cumbersome and time consuming. To overcome this\nbarrier, we propose our tool COMEX - a framework that allows researchers and\ndevelopers to create and combine multiple code-views which can be used by\nmachine learning (ML) models for various SE tasks. Some salient features of our\ntool are: (i) it works directly on source code (which need not be compilable),\n(ii) it currently supports Java and C#, (iii) it can analyze both method-level\nsnippets and program-level snippets by using both intra-procedural and\ninter-procedural analysis, and (iv) it is easily extendable to other languages\nas it is built on tree-sitter - a widely used incremental parser that supports\nover 40 languages. We believe this easy-to-use code-view generation and\ncustomization tool will give impetus to research in source code representation\nlearning methods and ML4SE.\n  Tool: https://pypi.org/project/comex - GitHub:\nhttps://github.com/IBM/tree-sitter-codeviews - Demo:\nhttps://youtu.be/GER6U87FVbU\n","authors":["Debeshee Das","Noble Saji Mathews","Alex Mathai","Srikanth Tamilselvam","Kranthi Sedamaki","Sridhar Chimalakonda","Atul Kumar"],"pdf_url":"https://arxiv.org/pdf/2307.04693v1.pdf","comment":"The paper has been accepted for publication at ASE 2023 (Tool\n  Demonstrations Track)"},{"id":"http://arxiv.org/abs/2307.04686v1","updated":"2023-07-10T16:42:03Z","published":"2023-07-10T16:42:03Z","title":"VampNet: Music Generation via Masked Acoustic Token Modeling","summary":"  We introduce VampNet, a masked acoustic token modeling approach to music\nsynthesis, compression, inpainting, and variation. We use a variable masking\nschedule during training which allows us to sample coherent music from the\nmodel by applying a variety of masking approaches (called prompts) during\ninference. VampNet is non-autoregressive, leveraging a bidirectional\ntransformer architecture that attends to all tokens in a forward pass. With\njust 36 sampling passes, VampNet can generate coherent high-fidelity musical\nwaveforms. We show that by prompting VampNet in various ways, we can apply it\nto tasks like music compression, inpainting, outpainting, continuation, and\nlooping with variation (vamping). Appropriately prompted, VampNet is capable of\nmaintaining style, genre, instrumentation, and other high-level aspects of the\nmusic. This flexible prompting capability makes VampNet a powerful music\nco-creation tool. Code and audio samples are available online.\n","authors":["Hugo Flores Garcia","Prem Seetharaman","Rithesh Kumar","Bryan Pardo"],"pdf_url":"https://arxiv.org/pdf/2307.04686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15666v2","updated":"2023-07-10T16:14:33Z","published":"2023-06-21T16:29:44Z","title":"Testing of Detection Tools for AI-Generated Text","summary":"  Recent advances in generative pre-trained transformer large language models\nhave emphasised the potential risks of unfair use of artificial intelligence\n(AI) generated content in an academic environment and intensified efforts in\nsearching for solutions to detect such content. The paper examines the general\nfunctionality of detection tools for artificial intelligence generated text and\nevaluates them based on accuracy and error type analysis. Specifically, the\nstudy seeks to answer research questions about whether existing detection tools\ncan reliably differentiate between human-written text and ChatGPT-generated\ntext, and whether machine translation and content obfuscation techniques affect\nthe detection of AI-generated text. The research covers 12 publicly available\ntools and two commercial systems (Turnitin and PlagiarismCheck) that are widely\nused in the academic setting. The researchers conclude that the available\ndetection tools are neither accurate nor reliable and have a main bias towards\nclassifying the output as human-written rather than detecting AI-generated\ntext. Furthermore, content obfuscation techniques significantly worsen the\nperformance of tools. The study makes several significant contributions. First,\nit summarises up-to-date similar scientific and non-scientific efforts in the\nfield. Second, it presents the result of one of the most comprehensive tests\nconducted so far, based on a rigorous research methodology, an original\ndocument set, and a broad coverage of tools. Third, it discusses the\nimplications and drawbacks of using detection tools for AI-generated text in\nacademic settings.\n","authors":["Debora Weber-Wulff","Alla Anohina-Naumeca","Sonja Bjelobaba","Tomáš Foltýnek","Jean Guerrero-Dib","Olumide Popoola","Petr Šigut","Lorna Waddington"],"pdf_url":"https://arxiv.org/pdf/2306.15666v2.pdf","comment":"38 pages, 13 figures and 10 tables, and an appendix with 18 figures.\n  Submitted to the International Journal for Educational Integrity"},{"id":"http://arxiv.org/abs/2307.04668v1","updated":"2023-07-10T16:11:33Z","published":"2023-07-10T16:11:33Z","title":"Quantifying the Echo Chamber Effect: An Embedding Distance-based\n  Approach","summary":"  The rise of social media platforms has facilitated the formation of echo\nchambers, which are online spaces where users predominantly encounter\nviewpoints that reinforce their existing beliefs while excluding dissenting\nperspectives. This phenomenon significantly hinders information dissemination\nacross communities and fuels societal polarization. Therefore, it is crucial to\ndevelop methods for quantifying echo chambers. In this paper, we present the\nEcho Chamber Score (ECS), a novel metric that assesses the cohesion and\nseparation of user communities by measuring distances between users in the\nembedding space. In contrast to existing approaches, ECS is able to function\nwithout labels for user ideologies and makes no assumptions about the structure\nof the interaction graph. To facilitate measuring distances between users, we\npropose EchoGAE, a self-supervised graph autoencoder-based user embedding model\nthat leverages users' posts and the interaction graph to embed them in a manner\nthat reflects their ideological similarity. To assess the effectiveness of ECS,\nwe use a Twitter dataset consisting of four topics - two polarizing and two\nnon-polarizing. Our results showcase ECS's effectiveness as a tool for\nquantifying echo chambers and shedding light on the dynamics of online\ndiscourse.\n","authors":["Faisal Alatawi","Paras Sheth","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2307.04668v1.pdf","comment":"9 Pages, 3 Figures"},{"id":"http://arxiv.org/abs/2111.09266v4","updated":"2023-07-10T15:45:11Z","published":"2021-11-17T17:59:54Z","title":"GFlowNet Foundations","summary":"  Generative Flow Networks (GFlowNets) have been introduced as a method to\nsample a diverse set of candidates in an active learning context, with a\ntraining objective that makes them approximately sample in proportion to a\ngiven reward function. In this paper, we show a number of additional\ntheoretical properties of GFlowNets. They can be used to estimate joint\nprobability distributions and the corresponding marginal distributions where\nsome variables are unspecified and, of particular interest, can represent\ndistributions over composite objects like sets and graphs. GFlowNets amortize\nthe work typically done by computationally expensive MCMC methods in a single\nbut trained generative pass. They could also be used to estimate partition\nfunctions and free energies, conditional probabilities of supersets\n(supergraphs) given a subset (subgraph), as well as marginal distributions over\nall supersets (supergraphs) of a given set (graph). We introduce variations\nenabling the estimation of entropy and mutual information, sampling from a\nPareto frontier, connections to reward-maximizing policies, and extensions to\nstochastic environments, continuous actions and modular energy functions.\n","authors":["Yoshua Bengio","Salem Lahlou","Tristan Deleu","Edward J. Hu","Mo Tiwari","Emmanuel Bengio"],"pdf_url":"https://arxiv.org/pdf/2111.09266v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04530v4","updated":"2023-07-10T15:42:34Z","published":"2022-06-09T14:25:14Z","title":"DORA: Exploring Outlier Representations in Deep Neural Networks","summary":"  Deep Neural Networks (DNNs) excel at learning complex abstractions within\ntheir internal representations. However, the concepts they learn remain opaque,\na problem that becomes particularly acute when models unintentionally learn\nspurious correlations. In this work, we present DORA (Data-agnOstic\nRepresentation Analysis), the first data-agnostic framework for analyzing the\nrepresentational space of DNNs. Central to our framework is the proposed\nExtreme-Activation (EA) distance measure, which assesses similarities between\nrepresentations by analyzing their activation patterns on data points that\ncause the highest level of activation. As spurious correlations often manifest\nin features of data that are anomalous to the desired task, such as watermarks\nor artifacts, we demonstrate that internal representations capable of detecting\nsuch artifactual concepts can be found by analyzing relationships within neural\nrepresentations. We validate the EA metric quantitatively, demonstrating its\neffectiveness both in controlled scenarios and real-world applications.\nFinally, we provide practical examples from popular Computer Vision models to\nillustrate that representations identified as outliers using the EA metric\noften correspond to undesired and spurious concepts.\n","authors":["Kirill Bykov","Mayukh Deb","Dennis Grinwald","Klaus-Robert Müller","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2206.04530v4.pdf","comment":"24 pages, 18 figures"},{"id":"http://arxiv.org/abs/2304.14251v2","updated":"2023-07-10T15:13:02Z","published":"2023-04-27T15:10:16Z","title":"Variational Bayes Made Easy","summary":"  Variational Bayes is a popular method for approximate inference but its\nderivation can be cumbersome. To simplify the process, we give a 3-step recipe\nto identify the posterior form by explicitly looking for linearity with respect\nto expectations of well-known distributions. We can then directly write the\nupdate by simply ``reading-off'' the terms in front of those expectations. The\nrecipe makes the derivation easier, faster, shorter, and more general.\n","authors":["Mohammad Emtiyaz Khan"],"pdf_url":"https://arxiv.org/pdf/2304.14251v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18703v3","updated":"2023-07-10T15:06:21Z","published":"2023-05-30T03:00:30Z","title":"Large Language Models, Natural Language Processing, Domain\n  Specialization","summary":"  Large language models (LLMs) have significantly advanced the field of natural\nlanguage processing (NLP), providing a highly useful, task-agnostic foundation\nfor a wide range of applications. However, directly applying LLMs to solve\nsophisticated problems in specific domains meets many hurdles, caused by the\nheterogeneity of domain data, the sophistication of domain knowledge, the\nuniqueness of domain objectives, and the diversity of the constraints (e.g.,\nvarious social norms, cultural conformity, religious beliefs, and ethical\nstandards in the domain applications). Domain specification techniques are key\nto make large language models disruptive in many applications. Specifically, to\nsolve these hurdles, there has been a notable increase in research and\npractices conducted in recent years on the domain specialization of LLMs. This\nemerging field of study, with its substantial potential for impact,\nnecessitates a comprehensive and systematic review to better summarize and\nguide ongoing work in this area. In this article, we present a comprehensive\nsurvey on domain specification techniques for large language models, an\nemerging direction critical for large language model applications. First, we\npropose a systematic taxonomy that categorizes the LLM domain-specialization\ntechniques based on the accessibility to LLMs and summarizes the framework for\nall the subcategories as well as their relations and differences to each other.\nSecond, we present an extensive taxonomy of critical application domains that\ncan benefit dramatically from specialized LLMs, discussing their practical\nsignificance and open challenges. Last, we offer our insights into the current\nresearch status and future trends in this area.\n","authors":["Chen Ling","Xujiang Zhao","Jiaying Lu","Chengyuan Deng","Can Zheng","Junxiang Wang","Tanmoy Chowdhury","Yun Li","Hejie Cui","Xuchao Zhang","Tianjiao Zhao","Amit Panalkar","Wei Cheng","Haoyu Wang","Yanchi Liu","Zhengzhang Chen","Haifeng Chen","Chris White","Quanquan Gu","Jian Pei","Carl Yang","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2305.18703v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04617v1","updated":"2023-07-10T15:02:13Z","published":"2023-07-10T15:02:13Z","title":"Weakly-supervised positional contrastive learning: application to\n  cirrhosis classification","summary":"  Large medical imaging datasets can be cheaply and quickly annotated with\nlow-confidence, weak labels (e.g., radiological scores). Access to\nhigh-confidence labels, such as histology-based diagnoses, is rare and costly.\nPretraining strategies, like contrastive learning (CL) methods, can leverage\nunlabeled or weakly-annotated datasets. These methods typically require large\nbatch sizes, which poses a difficulty in the case of large 3D images at full\nresolution, due to limited GPU memory. Nevertheless, volumetric positional\ninformation about the spatial context of each 2D slice can be very important\nfor some medical applications. In this work, we propose an efficient\nweakly-supervised positional (WSP) contrastive learning strategy where we\nintegrate both the spatial context of each 2D slice and a weak label via a\ngeneric kernel-based loss function. We illustrate our method on cirrhosis\nprediction using a large volume of weakly-labeled images, namely radiological\nlow-confidence annotations, and small strongly-labeled (i.e., high-confidence)\ndatasets. The proposed model improves the classification AUC by 5% with respect\nto a baseline model on our internal dataset, and by 26% on the public LIHC\ndataset from the Cancer Genome Atlas. The code is available at:\nhttps://github.com/Guerbet-AI/wsp-contrastive.\n","authors":["Emma Sarfati","Alexandre Bône","Marc-Michel Rohé","Pietro Gori","Isabelle Bloch"],"pdf_url":"https://arxiv.org/pdf/2307.04617v1.pdf","comment":"MICCAI 2023"},{"id":"http://arxiv.org/abs/2307.04616v1","updated":"2023-07-10T14:58:10Z","published":"2023-07-10T14:58:10Z","title":"MiVOLO: Multi-input Transformer for Age and Gender Estimation","summary":"  Age and gender recognition in the wild is a highly challenging task: apart\nfrom the variability of conditions, pose complexities, and varying image\nquality, there are cases where the face is partially or completely occluded. We\npresent MiVOLO (Multi Input VOLO), a straightforward approach for age and\ngender estimation using the latest vision transformer. Our method integrates\nboth tasks into a unified dual input/output model, leveraging not only facial\ninformation but also person image data. This improves the generalization\nability of our model and enables it to deliver satisfactory results even when\nthe face is not visible in the image. To evaluate our proposed model, we\nconduct experiments on four popular benchmarks and achieve state-of-the-art\nperformance, while demonstrating real-time processing capabilities.\nAdditionally, we introduce a novel benchmark based on images from the Open\nImages Dataset. The ground truth annotations for this benchmark have been\nmeticulously generated by human annotators, resulting in high accuracy answers\ndue to the smart aggregation of votes. Furthermore, we compare our model's age\nrecognition performance with human-level accuracy and demonstrate that it\nsignificantly outperforms humans across a majority of age ranges. Finally, we\ngrant public access to our models, along with the code for validation and\ninference. In addition, we provide extra annotations for used datasets and\nintroduce our new benchmark.\n","authors":["Maksim Kuprashevich","Irina Tolstykh"],"pdf_url":"https://arxiv.org/pdf/2307.04616v1.pdf","comment":"For the project repository, please visit:\n  https://github.com/WildChlamydia/MiVOLO"},{"id":"http://arxiv.org/abs/2307.04608v1","updated":"2023-07-10T14:52:14Z","published":"2023-07-10T14:52:14Z","title":"Learning Interpretable Heuristics for WalkSAT","summary":"  Local search algorithms are well-known methods for solving large, hard\ninstances of the satisfiability problem (SAT). The performance of these\nalgorithms crucially depends on heuristics for setting noise parameters and\nscoring variables. The optimal setting for these heuristics varies for\ndifferent instance distributions. In this paper, we present an approach for\nlearning effective variable scoring functions and noise parameters by using\nreinforcement learning. We consider satisfiability problems from different\ninstance distributions and learn specialized heuristics for each of them. Our\nexperimental results show improvements with respect to both a WalkSAT baseline\nand another local search learned heuristic.\n","authors":["Yannet Interian","Sara Bernardini"],"pdf_url":"https://arxiv.org/pdf/2307.04608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04607v1","updated":"2023-07-10T14:51:30Z","published":"2023-07-10T14:51:30Z","title":"A Memristor-Inspired Computation for Epileptiform Signals in Spheroids","summary":"  In this paper we present a memristor-inspired computational method for\nobtaining a type of running spectrogram or fingerprint of epileptiform activity\ngenerated by rodent hippocampal spheroids. It can be used to compute on the fly\nand with low computational cost an alert-level signal for epileptiform events\nonset. Here, we describe the computational method behind this fingerprint\ntechnique and illustrate it using epileptiform events recorded from hippocampal\nspheroids using a microelectrode array system.\n","authors":["Iván Díez de los Ríos","John Wesley Ephraim","Gemma Palazzolo","Teresa Serrano-Gotarredona","Gabriella Panuccio","Bernabé Linares-Barranco"],"pdf_url":"https://arxiv.org/pdf/2307.04607v1.pdf","comment":"published in 2023 IEEE 5th International Conference on Artificial\n  Intelligence Circuits and Systems (AICAS)"},{"id":"http://arxiv.org/abs/2307.04599v1","updated":"2023-07-10T14:38:38Z","published":"2023-07-10T14:38:38Z","title":"Model-Driven Engineering for Artificial Intelligence -- A Systematic\n  Literature Review","summary":"  Objective: This study aims to investigate the existing body of knowledge in\nthe field of Model-Driven Engineering MDE in support of AI (MDE4AI) to sharpen\nfuture research further and define the current state of the art.\n  Method: We conducted a Systemic Literature Review (SLR), collecting papers\nfrom five major databases resulting in 703 candidate studies, eventually\nretaining 15 primary studies. Each primary study will be evaluated and\ndiscussed with respect to the adoption of (1) MDE principles and practices and\n(2) the phases of AI development support aligned with the stages of the\nCRISP-DM methodology.\n  Results: The study's findings show that the pillar concepts of MDE\n(metamodel, concrete syntax and model transformation), are leveraged to define\ndomain-specific languages (DSL) explicitly addressing AI concerns. Different\nMDE technologies are used, leveraging different language workbenches. The most\nprominent AI-related concerns are training and modeling of the AI algorithm,\nwhile minor emphasis is given to the time-consuming preparation of the data\nsets. Early project phases that support interdisciplinary communication of\nrequirements, such as the CRISP-DM \\textit{Business Understanding} phase, are\nrarely reflected.\n  Conclusion: The study found that the use of MDE for AI is still in its early\nstages, and there is no single tool or method that is widely used.\nAdditionally, current approaches tend to focus on specific stages of\ndevelopment rather than providing support for the entire development process.\nAs a result, the study suggests several research directions to further improve\nthe use of MDE for AI and to guide future research in this area.\n","authors":["Simon Raedler","Luca Berardinelli","Karolin Winter","Abbas Rahimi","Stefanie Rinderle-Ma"],"pdf_url":"https://arxiv.org/pdf/2307.04599v1.pdf","comment":"42 pages, 1 figure, 8 tables"},{"id":"http://arxiv.org/abs/2305.16044v4","updated":"2023-07-10T14:37:55Z","published":"2023-05-25T13:21:26Z","title":"Exploiting Noise as a Resource for Computation and Learning in Spiking\n  Neural Networks","summary":"  -- A theoretical framework that subsumes conventional deterministic spiking\nneural networks and surrogate gradients, facilitating more efficient and\neffective employment of various neuromorphic hardware developments in\nreal-world applications.\n  -- Scalable spiking neural models that incorporate noisy neuronal dynamics\nfor implicit regularization, improved robustness, and computational accounts of\nbiological neural computation, revealing that unreliable neural substrates\nyield reliable computation and learning.\n  Networks of spiking neurons underpin the extraordinary information-processing\ncapabilities of the brain and have emerged as pillar models in neuromorphic\nintelligence. Despite extensive research on spiking neural networks (SNNs),\nmost are established on deterministic models. Integrating noise into SNNs leads\nto biophysically more realistic neural dynamics and may benefit model\nperformance. This work presents the noisy spiking neural network (NSNN) and the\nnoise-driven learning rule (NDL) by introducing a spiking neuron model\nincorporating noisy neuronal dynamics. Our approach shows how noise may serve\nas a resource for computation and learning and theoretically provides a\nframework for general SNNs. We show that our method exhibits competitive\nperformance and improved robustness against challenging perturbations than\ndeterministic SNNs and better reproduces probabilistic neural computation in\nneural coding. This study offers a powerful and easy-to-use tool for machine\nlearning, neuromorphic intelligence practitioners, and computational\nneuroscience researchers.\n","authors":["Gehua Ma","Rui Yan","Huajin Tang"],"pdf_url":"https://arxiv.org/pdf/2305.16044v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04573v1","updated":"2023-07-10T14:07:28Z","published":"2023-07-10T14:07:28Z","title":"A Semi-Automated Solution Approach Selection Tool for Any Use Case via\n  Scopus and OpenAI: a Case Study for AI/ML in Oncology","summary":"  In today's vast literature landscape, a manual review is very time-consuming.\nTo address this challenge, this paper proposes a semi-automated tool for\nsolution method review and selection. It caters to researchers, practitioners,\nand decision-makers while serving as a benchmark for future work. The tool\ncomprises three modules: (1) paper selection and scoring, using a keyword\nselection scheme to query Scopus API and compute relevancy; (2) solution method\nextraction in papers utilizing OpenAI API; (3) sensitivity analysis and\npost-analyzes. It reveals trends, relevant papers, and methods. AI in the\noncology case study and several use cases are presented with promising results,\ncomparing the tool to manual ground truth.\n","authors":["Deniz Kenan Kılıç","Alex Elkjær Vasegaard","Aurélien Desoeuvres","Peter Nielsen"],"pdf_url":"https://arxiv.org/pdf/2307.04573v1.pdf","comment":"The paper is under review in Expert Systems with Applications,\n  Elsevier"},{"id":"http://arxiv.org/abs/2012.12556v6","updated":"2023-07-10T13:54:04Z","published":"2020-12-23T09:37:54Z","title":"A Survey on Visual Transformer","summary":"  Transformer, first applied to the field of natural language processing, is a\ntype of deep neural network mainly based on the self-attention mechanism.\nThanks to its strong representation capabilities, researchers are looking at\nways to apply transformer to computer vision tasks. In a variety of visual\nbenchmarks, transformer-based models perform similar to or better than other\ntypes of networks such as convolutional and recurrent neural networks. Given\nits high performance and less need for vision-specific inductive bias,\ntransformer is receiving more and more attention from the computer vision\ncommunity. In this paper, we review these vision transformer models by\ncategorizing them in different tasks and analyzing their advantages and\ndisadvantages. The main categories we explore include the backbone network,\nhigh/mid-level vision, low-level vision, and video processing. We also include\nefficient transformer methods for pushing transformer into real device-based\napplications. Furthermore, we also take a brief look at the self-attention\nmechanism in computer vision, as it is the base component in transformer.\nToward the end of this paper, we discuss the challenges and provide several\nfurther research directions for vision transformers.\n","authors":["Kai Han","Yunhe Wang","Hanting Chen","Xinghao Chen","Jianyuan Guo","Zhenhua Liu","Yehui Tang","An Xiao","Chunjing Xu","Yixing Xu","Zhaohui Yang","Yiman Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2012.12556v6.pdf","comment":"Accepted by TPAMI 2022"},{"id":"http://arxiv.org/abs/2307.03039v2","updated":"2023-07-10T13:49:24Z","published":"2023-07-06T15:04:18Z","title":"Art Authentication with Vision Transformers","summary":"  In recent years, Transformers, initially developed for language, have been\nsuccessfully applied to visual tasks. Vision Transformers have been shown to\npush the state-of-the-art in a wide range of tasks, including image\nclassification, object detection, and semantic segmentation. While ample\nresearch has shown promising results in art attribution and art authentication\ntasks using Convolutional Neural Networks, this paper examines if the\nsuperiority of Vision Transformers extends to art authentication, improving,\nthus, the reliability of computer-based authentication of artworks. Using a\ncarefully compiled dataset of authentic paintings by Vincent van Gogh and two\ncontrast datasets, we compare the art authentication performances of Swin\nTransformers with those of EfficientNet. Using a standard contrast set\ncontaining imitations and proxies (works by painters with styles closely\nrelated to van Gogh), we find that EfficientNet achieves the best performance\noverall. With a contrast set that only consists of imitations, we find the Swin\nTransformer to be superior to EfficientNet by achieving an authentication\naccuracy of over 85%. These results lead us to conclude that Vision\nTransformers represent a strong and promising contender in art authentication,\nparticularly in enhancing the computer-based ability to detect artistic\nimitations.\n","authors":["Ludovica Schaerf","Carina Popovici","Eric Postma"],"pdf_url":"https://arxiv.org/pdf/2307.03039v2.pdf","comment":"Accepted for publication in Neural Computing and Applications"},{"id":"http://arxiv.org/abs/2306.02312v2","updated":"2023-07-10T13:42:44Z","published":"2023-06-04T09:34:41Z","title":"(Un)reasonable Allure of Ante-hoc Interpretability for High-stakes\n  Domains: Transparency Is Necessary but Insufficient for Comprehensibility","summary":"  Ante-hoc interpretability has become the holy grail of explainable artificial\nintelligence for high-stakes domains such as healthcare; however, this notion\nis elusive, lacks a widely-accepted definition and depends on the operational\ncontext. It can refer to predictive models whose structure adheres to\ndomain-specific constraints, or ones that are inherently transparent. The\nlatter conceptualisation assumes observers who judge this quality, whereas the\nformer presupposes them to have technical and domain expertise (thus alienating\nother groups of explainees). Additionally, the distinction between ante-hoc\ninterpretability and the less desirable post-hoc explainability, which refers\nto methods that construct a separate explanatory model, is vague given that\ntransparent predictive models may still require (post-)processing to yield\nsuitable explanatory insights. Ante-hoc interpretability is thus an overloaded\nconcept that comprises a range of implicit properties, which we unpack in this\npaper to better understand what is needed for its safe adoption across\nhigh-stakes domains. To this end, we outline modelling and explaining\ndesiderata that allow us to navigate its distinct realisations in view of the\nenvisaged application and audience.\n","authors":["Kacper Sokol","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2306.02312v2.pdf","comment":"Workshop on Interpretable ML in Healthcare at 2023 International\n  Conference on Machine Learning (ICML)"},{"id":"http://arxiv.org/abs/2307.04550v1","updated":"2023-07-10T13:29:23Z","published":"2023-07-10T13:29:23Z","title":"Gradient Surgery for One-shot Unlearning on Generative Model","summary":"  Recent regulation on right-to-be-forgotten emerges tons of interest in\nunlearning pre-trained machine learning models. While approximating a\nstraightforward yet expensive approach of retrain-from-scratch, recent machine\nunlearning methods unlearn a sample by updating weights to remove its influence\non the weight parameters. In this paper, we introduce a simple yet effective\napproach to remove a data influence on the deep generative model. Inspired by\nworks in multi-task learning, we propose to manipulate gradients to regularize\nthe interplay of influence among samples by projecting gradients onto the\nnormal plane of the gradients to be retained. Our work is agnostic to\nstatistics of the removal samples, outperforming existing baselines while\nproviding theoretical analysis for the first time in unlearning a generative\nmodel.\n","authors":["Seohui Bae","Seoyoon Kim","Hyemin Jung","Woohyung Lim"],"pdf_url":"https://arxiv.org/pdf/2307.04550v1.pdf","comment":"To appear in GenLaw Workshop @ ICML 2023"},{"id":"http://arxiv.org/abs/2307.04541v1","updated":"2023-07-10T13:09:42Z","published":"2023-07-10T13:09:42Z","title":"Learning Large Margin Sparse Embeddings for Open Set Medical Diagnosis","summary":"  Fueled by deep learning, computer-aided diagnosis achieves huge advances.\nHowever, out of controlled lab environments, algorithms could face multiple\nchallenges. Open set recognition (OSR), as an important one, states that\ncategories unseen in training could appear in testing. In medical fields, it\ncould derive from incompletely collected training datasets and the constantly\nemerging new or rare diseases. OSR requires an algorithm to not only correctly\nclassify known classes, but also recognize unknown classes and forward them to\nexperts for further diagnosis. To tackle OSR, we assume that known classes\ncould densely occupy small parts of the embedding space and the remaining\nsparse regions could be recognized as unknowns. Following it, we propose Open\nMargin Cosine Loss (OMCL) unifying two mechanisms. The former, called Margin\nLoss with Adaptive Scale (MLAS), introduces angular margin for reinforcing\nintra-class compactness and inter-class separability, together with an adaptive\nscaling factor to strengthen the generalization capacity. The latter, called\nOpen-Space Suppression (OSS), opens the classifier by recognizing sparse\nembedding space as unknowns using proposed feature space descriptors. Besides,\nsince medical OSR is still a nascent field, two publicly available benchmark\ndatasets are proposed for comparison. Extensive ablation studies and feature\nvisualization demonstrate the effectiveness of each design. Compared with\nstate-of-the-art methods, MLAS achieves superior performances, measured by ACC,\nAUROC, and OSCR.\n","authors":["Mingyuan Liu","Lu Xu","Jicong Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.04541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04537v1","updated":"2023-07-10T13:02:46Z","published":"2023-07-10T13:02:46Z","title":"Q-YOLOP: Quantization-aware You Only Look Once for Panoptic Driving\n  Perception","summary":"  In this work, we present an efficient and quantization-aware panoptic driving\nperception model (Q- YOLOP) for object detection, drivable area segmentation,\nand lane line segmentation, in the context of autonomous driving. Our model\nemploys the Efficient Layer Aggregation Network (ELAN) as its backbone and\ntask-specific heads for each task. We employ a four-stage training process that\nincludes pretraining on the BDD100K dataset, finetuning on both the BDD100K and\niVS datasets, and quantization-aware training (QAT) on BDD100K. During the\ntraining process, we use powerful data augmentation techniques, such as random\nperspective and mosaic, and train the model on a combination of the BDD100K and\niVS datasets. Both strategies enhance the model's generalization capabilities.\nThe proposed model achieves state-of-the-art performance with an mAP@0.5 of\n0.622 for object detection and an mIoU of 0.612 for segmentation, while\nmaintaining low computational and memory requirements.\n","authors":["Chi-Chih Chang","Wei-Cheng Lin","Pei-Shuo Wang","Sheng-Feng Yu","Yu-Chen Lu","Kuan-Cheng Lin","Kai-Chiang Wu"],"pdf_url":"https://arxiv.org/pdf/2307.04537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04535v1","updated":"2023-07-10T13:01:08Z","published":"2023-07-10T13:01:08Z","title":"QBitOpt: Fast and Accurate Bitwidth Reallocation during Training","summary":"  Quantizing neural networks is one of the most effective methods for achieving\nefficient inference on mobile and embedded devices. In particular, mixed\nprecision quantized (MPQ) networks, whose layers can be quantized to different\nbitwidths, achieve better task performance for the same resource constraint\ncompared to networks with homogeneous bitwidths. However, finding the optimal\nbitwidth allocation is a challenging problem as the search space grows\nexponentially with the number of layers in the network. In this paper, we\npropose QBitOpt, a novel algorithm for updating bitwidths during\nquantization-aware training (QAT). We formulate the bitwidth allocation problem\nas a constraint optimization problem. By combining fast-to-compute\nsensitivities with efficient solvers during QAT, QBitOpt can produce\nmixed-precision networks with high task performance guaranteed to satisfy\nstrict resource constraints. This contrasts with existing mixed-precision\nmethods that learn bitwidths using gradients and cannot provide such\nguarantees. We evaluate QBitOpt on ImageNet and confirm that we outperform\nexisting fixed and mixed-precision methods under average bitwidth constraints\ncommonly found in the literature.\n","authors":["Jorn Peters","Marios Fournarakis","Markus Nagel","Mart van Baalen","Tijmen Blankevoort"],"pdf_url":"https://arxiv.org/pdf/2307.04535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04533v1","updated":"2023-07-10T12:59:30Z","published":"2023-07-10T12:59:30Z","title":"Preventing Errors in Person Detection: A Part-Based Self-Monitoring\n  Framework","summary":"  The ability to detect learned objects regardless of their appearance is\ncrucial for autonomous systems in real-world applications. Especially for\ndetecting humans, which is often a fundamental task in safety-critical\napplications, it is vital to prevent errors. To address this challenge, we\npropose a self-monitoring framework that allows for the perception system to\nperform plausibility checks at runtime. We show that by incorporating an\nadditional component for detecting human body parts, we are able to\nsignificantly reduce the number of missed human detections by factors of up to\n9 when compared to a baseline setup, which was trained only on holistic person\nobjects. Additionally, we found that training a model jointly on humans and\ntheir body parts leads to a substantial reduction in false positive detections\nby up to 50% compared to training on humans alone. We performed comprehensive\nexperiments on the publicly available datasets DensePose and Pascal VOC in\norder to demonstrate the effectiveness of our framework. Code is available at\nhttps://github.com/ FraunhoferIKS/smf-object-detection.\n","authors":["Franziska Schwaiger","Andrea Matic","Karsten Roscher","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2307.04533v1.pdf","comment":"Accepted for the 35th IEEE Intelligent Vehicles Symposium (IV 2023),\n  9 pages"},{"id":"http://arxiv.org/abs/2306.09417v2","updated":"2023-07-10T12:53:24Z","published":"2023-06-15T18:02:49Z","title":"Diff-TTSG: Denoising probabilistic integrated speech and gesture\n  synthesis","summary":"  With read-aloud speech synthesis achieving high naturalness scores, there is\na growing research interest in synthesising spontaneous speech. However, human\nspontaneous face-to-face conversation has both spoken and non-verbal aspects\n(here, co-speech gestures). Only recently has research begun to explore the\nbenefits of jointly synthesising these two modalities in a single system. The\nprevious state of the art used non-probabilistic methods, which fail to capture\nthe variability of human speech and motion, and risk producing oversmoothing\nartefacts and sub-optimal synthesis quality. We present the first\ndiffusion-based probabilistic model, called Diff-TTSG, that jointly learns to\nsynthesise speech and gestures together. Our method can be trained on small\ndatasets from scratch. Furthermore, we describe a set of careful uni- and\nmulti-modal subjective tests for evaluating integrated speech and gesture\nsynthesis systems, and use them to validate our proposed approach. For\nsynthesised examples please see https://shivammehta25.github.io/Diff-TTSG\n","authors":["Shivam Mehta","Siyang Wang","Simon Alexanderson","Jonas Beskow","Éva Székely","Gustav Eje Henter"],"pdf_url":"https://arxiv.org/pdf/2306.09417v2.pdf","comment":"7 pages, 2 figures, Accepted at ISCA Speech Synthesis Workshop (SSW)\n  2023"},{"id":"http://arxiv.org/abs/2303.07308v2","updated":"2023-07-10T12:33:04Z","published":"2023-03-13T17:30:43Z","title":"NeuSE: Neural SE(3)-Equivariant Embedding for Consistent Spatial\n  Understanding with Objects","summary":"  We present NeuSE, a novel Neural SE(3)-Equivariant Embedding for objects, and\nillustrate how it supports object SLAM for consistent spatial understanding\nwith long-term scene changes. NeuSE is a set of latent object embeddings\ncreated from partial object observations. It serves as a compact point cloud\nsurrogate for complete object models, encoding full shape information while\ntransforming SE(3)-equivariantly in tandem with the object in the physical\nworld. With NeuSE, relative frame transforms can be directly derived from\ninferred latent codes. Our proposed SLAM paradigm, using NeuSE for object shape\nand pose characterization, can operate independently or in conjunction with\ntypical SLAM systems. It directly infers SE(3) camera pose constraints that are\ncompatible with general SLAM pose graph optimization, while also maintaining a\nlightweight object-centric map that adapts to real-world changes. Our approach\nis evaluated on synthetic and real-world sequences featuring changed objects\nand shows improved localization accuracy and change-aware mapping capability,\nwhen working either standalone or jointly with a common SLAM pipeline.\n","authors":["Jiahui Fu","Yilun Du","Kurran Singh","Joshua B. Tenenbaum","John J. Leonard"],"pdf_url":"https://arxiv.org/pdf/2303.07308v2.pdf","comment":"15 Pages and 12 figures. Accepted to RSS 2023. Project webpage:\n  https://neuse-slam.github.io/neuse/"},{"id":"http://arxiv.org/abs/2307.04515v1","updated":"2023-07-10T12:22:08Z","published":"2023-07-10T12:22:08Z","title":"SAGC-A68: a space access graph dataset for the classification of spaces\n  and space elements in apartment buildings","summary":"  The analysis of building models for usable area, building safety, and energy\nuse requires accurate classification data of spaces and space elements. To\nreduce input model preparation effort and errors, automated classification of\nspaces and space elements is desirable. A barrier hindering the utilization of\nGraph Deep Learning (GDL) methods to space function and space element\nclassification is a lack of suitable datasets. To bridge this gap, we introduce\na dataset, SAGC-A68, which comprises access graphs automatically generated from\n68 digital 3D models of space layouts of apartment buildings. This graph-based\ndataset is well-suited for developing GDL models for space function and space\nelement classification. To demonstrate the potential of the dataset, we employ\nit to train and evaluate a graph attention network (GAT) that predicts 22 space\nfunction and 6 space element classes. The dataset and code used in the\nexperiment are available online. https://doi.org/10.5281/zenodo.7805872,\nhttps://github.com/A2Amir/SAGC-A68.\n","authors":["Amir Ziaee","Georg Suter"],"pdf_url":"https://arxiv.org/pdf/2307.04515v1.pdf","comment":"Published in proceedings of the 30th International Workshop on\n  Intelligent Computing in Engineering, EG-ICE 2023, London, England.\n  https://www.ucl.ac.uk/bartlett/construction/sites/bartlett_construction/files/sagc-a68_a_space_access_graph_dataset_for_the_classification_of_spaces_and_space_elements_in_apartment_buildings.pdf"},{"id":"http://arxiv.org/abs/2307.04514v1","updated":"2023-07-10T12:20:50Z","published":"2023-07-10T12:20:50Z","title":"Improving Heterogeneous Graph Learning with Weighted Mixed-Curvature\n  Product Manifold","summary":"  In graph representation learning, it is important that the complex geometric\nstructure of the input graph, e.g. hidden relations among nodes, is well\ncaptured in embedding space. However, standard Euclidean embedding spaces have\na limited capacity in representing graphs of varying structures. A promising\ncandidate for the faithful embedding of data with varying structure is product\nmanifolds of component spaces of different geometries (spherical, hyperbolic,\nor euclidean). In this paper, we take a closer look at the structure of product\nmanifold embedding spaces and argue that each component space in a product\ncontributes differently to expressing structures in the input graph, hence\nshould be weighted accordingly. This is different from previous works which\nconsider the roles of different components equally. We then propose\nWEIGHTED-PM, a data-driven method for learning embedding of heterogeneous\ngraphs in weighted product manifolds. Our method utilizes the topological\ninformation of the input graph to automatically determine the weight of each\ncomponent in product spaces. Extensive experiments on synthetic and real-world\ngraph datasets demonstrate that WEIGHTED-PM is capable of learning better graph\nrepresentations with lower geometric distortion from input data, and performs\nbetter on multiple downstream tasks, such as word similarity learning, top-$k$\nrecommendation, and knowledge graph embedding.\n","authors":["Tuc Nguyen-Van","Dung D. Le","The-Anh Ta"],"pdf_url":"https://arxiv.org/pdf/2307.04514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04507v1","updated":"2023-07-10T12:01:18Z","published":"2023-07-10T12:01:18Z","title":"Improving Factuality of Abstractive Summarization via Contrastive Reward\n  Learning","summary":"  Modern abstractive summarization models often generate summaries that contain\nhallucinated or contradictory information. In this paper, we propose a simple\nbut effective contrastive learning framework that incorporates recent\ndevelopments in reward learning and factuality metrics. Empirical studies\ndemonstrate that the proposed framework enables summarization models to learn\nfrom feedback of factuality metrics using contrastive reward learning, leading\nto more factual summaries by human evaluations. This suggests that further\nadvances in learning and evaluation algorithms can feed directly into providing\nmore factual summaries.\n","authors":["I-Chun Chern","Zhiruo Wang","Sanjan Das","Bhavuk Sharma","Pengfei Liu","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2307.04507v1.pdf","comment":"TrustNLP @ ACL 2023"},{"id":"http://arxiv.org/abs/2307.04503v1","updated":"2023-07-10T11:55:44Z","published":"2023-07-10T11:55:44Z","title":"Deductive Controller Synthesis for Probabilistic Hyperproperties","summary":"  Probabilistic hyperproperties specify quantitative relations between the\nprobabilities of reaching different target sets of states from different\ninitial sets of states. This class of behavioral properties is suitable for\ncapturing important security, privacy, and system-level requirements. We\npropose a new approach to solve the controller synthesis problem for Markov\ndecision processes (MDPs) and probabilistic hyperproperties. Our specification\nlanguage builds on top of the logic HyperPCTL and enhances it with structural\nconstraints over the synthesized controllers. Our approach starts from a family\nof controllers represented symbolically and defined over the same copy of an\nMDP. We then introduce an abstraction refinement strategy that can relate\nmultiple computation trees and that we employ to prune the search space\ndeductively. The experimental evaluation demonstrates that the proposed\napproach considerably outperforms HyperProb, a state-of-the-art SMT-based model\nchecking tool for HyperPCTL. Moreover, our approach is the first one that is\nable to effectively combine probabilistic hyperproperties with additional\nintra-controller constraints (e.g. partial observability) as well as\ninter-controller constraints (e.g. agreements on a common action).\n","authors":["Roman Andriushchenko","Ezio Bartocci","Milan Ceska","Francesco Pontiggia","Sarah Sallinger"],"pdf_url":"https://arxiv.org/pdf/2307.04503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04495v1","updated":"2023-07-10T11:33:46Z","published":"2023-07-10T11:33:46Z","title":"Model-Driven Engineering Method to Support the Formalization of Machine\n  Learning using SysML","summary":"  Methods: This work introduces a method supporting the collaborative\ndefinition of machine learning tasks by leveraging model-based engineering in\nthe formalization of the systems modeling language SysML. The method supports\nthe identification and integration of various data sources, the required\ndefinition of semantic connections between data attributes, and the definition\nof data processing steps within the machine learning support.\n  Results: By consolidating the knowledge of domain and machine learning\nexperts, a powerful tool to describe machine learning tasks by formalizing\nknowledge using the systems modeling language SysML is introduced. The method\nis evaluated based on two use cases, i.e., a smart weather system that allows\nto predict weather forecasts based on sensor data, and a waste prevention case\nfor 3D printer filament that cancels the printing if the intended result cannot\nbe achieved (image processing). Further, a user study is conducted to gather\ninsights of potential users regarding perceived workload and usability of the\nelaborated method.\n  Conclusion: Integrating machine learning-specific properties in systems\nengineering techniques allows non-data scientists to understand formalized\nknowledge and define specific aspects of a machine learning problem, document\nknowledge on the data, and to further support data scientists to use the\nformalized knowledge as input for an implementation using (semi-) automatic\ncode generation. In this respect, this work contributes by consolidating\nknowledge from various domains and therefore, fosters the integration of\nmachine learning in industry by involving several stakeholders.\n","authors":["Simon Raedler","Juergen Mangler","Stefanie Rinderle-Ma"],"pdf_url":"https://arxiv.org/pdf/2307.04495v1.pdf","comment":"43 pages, 24 figure, 3 tables"},{"id":"http://arxiv.org/abs/2307.01689v2","updated":"2023-07-10T11:16:54Z","published":"2023-07-04T12:51:21Z","title":"Online Learning and Solving Infinite Games with an ERM Oracle","summary":"  While ERM suffices to attain near-optimal generalization error in the\nstochastic learning setting, this is not known to be the case in the online\nlearning setting, where algorithms for general concept classes rely on\ncomputationally inefficient oracles such as the Standard Optimal Algorithm\n(SOA). In this work, we propose an algorithm for online binary classification\nsetting that relies solely on ERM oracle calls, and show that it has finite\nregret in the realizable setting and sublinearly growing regret in the agnostic\nsetting. We bound the regret in terms of the Littlestone and threshold\ndimensions of the underlying concept class.\n  We obtain similar results for nonparametric games, where the ERM oracle can\nbe interpreted as a best response oracle, finding the best response of a player\nto a given history of play of the other players. In this setting, we provide\nlearning algorithms that only rely on best response oracles and converge to\napproximate-minimax equilibria in two-player zero-sum games and approximate\ncoarse correlated equilibria in multi-player general-sum games, as long as the\ngame has a bounded fat-threshold dimension. Our algorithms apply to both\nbinary-valued and real-valued games and can be viewed as providing\njustification for the wide use of double oracle and multiple oracle algorithms\nin the practice of solving large games.\n","authors":["Angelos Assos","Idan Attias","Yuval Dagan","Constantinos Daskalakis","Maxwell Fishelson"],"pdf_url":"https://arxiv.org/pdf/2307.01689v2.pdf","comment":"In COLT2023"},{"id":"http://arxiv.org/abs/2307.04481v1","updated":"2023-07-10T11:03:32Z","published":"2023-07-10T11:03:32Z","title":"Digital Modeling for Everyone: Exploring How Novices Approach\n  Voice-Based 3D Modeling","summary":"  Manufacturing tools like 3D printers have become accessible to the wider\nsociety, making the promise of digital fabrication for everyone seemingly\nreachable. While the actual manufacturing process is largely automated today,\nusers still require knowledge of complex design applications to produce\nready-designed objects and adapt them to their needs or design new objects from\nscratch. To lower the barrier to the design and customization of personalized\n3D models, we explored novice mental models in voice-based 3D modeling by\nconducting a high-fidelity Wizard of Oz study with 22 participants. We\nperformed a thematic analysis of the collected data to understand how the\nmental model of novices translates into voice-based 3D modeling. We conclude\nwith design implications for voice assistants. For example, they have to: deal\nwith vague, incomplete and wrong commands; provide a set of straightforward\ncommands to shape simple and composite objects; and offer different strategies\nto select 3D objects.\n","authors":["Giuseppe Desolda","Andrea Esposito","Florian Müller","Sebastian Feger"],"pdf_url":"https://arxiv.org/pdf/2307.04481v1.pdf","comment":"Accepted for publication at INTERACT 2023"},{"id":"http://arxiv.org/abs/2305.10292v2","updated":"2023-07-10T10:40:41Z","published":"2023-05-17T15:27:33Z","title":"Linear Query Approximation Algorithms for Non-monotone Submodular\n  Maximization under Knapsack Constraint","summary":"  This work, for the first time, introduces two constant factor approximation\nalgorithms with linear query complexity for non-monotone submodular\nmaximization over a ground set of size $n$ subject to a knapsack constraint,\n$\\mathsf{DLA}$ and $\\mathsf{RLA}$. $\\mathsf{DLA}$ is a deterministic algorithm\nthat provides an approximation factor of $6+\\epsilon$ while $\\mathsf{RLA}$ is a\nrandomized algorithm with an approximation factor of $4+\\epsilon$. Both run in\n$O(n \\log(1/\\epsilon)/\\epsilon)$ query complexity. The key idea to obtain a\nconstant approximation ratio with linear query lies in: (1) dividing the ground\nset into two appropriate subsets to find the near-optimal solution over these\nsubsets with linear queries, and (2) combining a threshold greedy with\nproperties of two disjoint sets or a random selection process to improve\nsolution quality. In addition to the theoretical analysis, we have evaluated\nour proposed solutions with three applications: Revenue Maximization, Image\nSummarization, and Maximum Weighted Cut, showing that our algorithms not only\nreturn comparative results to state-of-the-art algorithms but also require\nsignificantly fewer queries.\n","authors":["Canh V. Pham","Tan D. Tran","Dung T. K. Ha","My T. Thai"],"pdf_url":"https://arxiv.org/pdf/2305.10292v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.00215v3","updated":"2023-07-10T10:27:06Z","published":"2023-04-01T03:49:47Z","title":"Inductive Relation Prediction from Relational Paths and Context with\n  Hierarchical Transformers","summary":"  Relation prediction on knowledge graphs (KGs) is a key research topic.\nDominant embedding-based methods mainly focus on the transductive setting and\nlack the inductive ability to generalize to new entities for inference.\nExisting methods for inductive reasoning mostly mine the connections between\nentities, i.e., relational paths, without considering the nature of head and\ntail entities contained in the relational context. This paper proposes a novel\nmethod that captures both connections between entities and the intrinsic nature\nof entities, by simultaneously aggregating RElational Paths and cOntext with a\nunified hieRarchical Transformer framework, namely REPORT. REPORT relies solely\non relation semantics and can naturally generalize to the fully-inductive\nsetting, where KGs for training and inference have no common entities. In the\nexperiments, REPORT performs consistently better than all baselines on almost\nall the eight version subsets of two fully-inductive datasets. Moreover. REPORT\nis interpretable by providing each element's contribution to the prediction\nresults.\n","authors":["Jiaang Li","Quan Wang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2304.00215v3.pdf","comment":"Accepted by ICASSP 2023 (Oral). The code is available at:\n  https://github.com/JiaangL/REPORT"},{"id":"http://arxiv.org/abs/2208.10967v4","updated":"2023-07-10T09:15:22Z","published":"2022-08-23T13:41:01Z","title":"The Value of Out-of-Distribution Data","summary":"  We expect the generalization error to improve with more samples from a\nsimilar task, and to deteriorate with more samples from an out-of-distribution\n(OOD) task. In this work, we show a counter-intuitive phenomenon: the\ngeneralization error of a task can be a non-monotonic function of the number of\nOOD samples. As the number of OOD samples increases, the generalization error\non the target task improves before deteriorating beyond a threshold. In other\nwords, there is value in training on small amounts of OOD data. We use Fisher's\nLinear Discriminant on synthetic datasets and deep networks on computer vision\nbenchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet to demonstrate\nand analyze this phenomenon. In the idealistic setting where we know which\nsamples are OOD, we show that these non-monotonic trends can be exploited using\nan appropriately weighted objective of the target and OOD empirical risk. While\nits practical utility is limited, this does suggest that if we can detect OOD\nsamples, then there may be ways to benefit from them. When we do not know which\nsamples are OOD, we show how a number of go-to strategies such as\ndata-augmentation, hyper-parameter optimization, and pre-training are not\nenough to ensure that the target generalization error does not deteriorate with\nthe number of OOD samples in the dataset.\n","authors":["Ashwin De Silva","Rahul Ramesh","Carey E. Priebe","Pratik Chaudhari","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2208.10967v4.pdf","comment":"Previous versions of this work have been presented at the\n  Out-of-Distribution Generalization in Computer Vision (OOD-CV) Workshop (ECCV\n  2022) and the Workshop on Distribution Shifts (NeurIPS 2022)"},{"id":"http://arxiv.org/abs/2307.04429v1","updated":"2023-07-10T09:09:26Z","published":"2023-07-10T09:09:26Z","title":"Designing Novel Cognitive Diagnosis Models via Evolutionary\n  Multi-Objective Neural Architecture Search","summary":"  Cognitive diagnosis plays a vital role in modern intelligent education\nplatforms to reveal students' proficiency in knowledge concepts for subsequent\nadaptive tasks. However, due to the requirement of high model interpretability,\nexisting manually designed cognitive diagnosis models hold too simple\narchitectures to meet the demand of current intelligent education systems,\nwhere the bias of human design also limits the emergence of effective cognitive\ndiagnosis models. In this paper, we propose to automatically design novel\ncognitive diagnosis models by evolutionary multi-objective neural architecture\nsearch (NAS). Specifically, we observe existing models can be represented by a\ngeneral model handling three given types of inputs and thus first design an\nexpressive search space for the NAS task in cognitive diagnosis. Then, we\npropose multi-objective genetic programming (MOGP) to explore the NAS task's\nsearch space by maximizing model performance and interpretability. In the MOGP\ndesign, each architecture is transformed into a tree architecture and encoded\nby a tree for easy optimization, and a tailored genetic operation based on four\nsub-genetic operations is devised to generate offspring effectively. Besides,\nan initialization strategy is also suggested to accelerate the convergence by\nevolving half of the population from existing models' variants. Experiments on\ntwo real-world datasets demonstrate that the cognitive diagnosis models\nsearched by the proposed approach exhibit significantly better performance than\nexisting models and also hold as good interpretability as human-designed\nmodels.\n","authors":["Shangshang Yang","Haiping Ma","Cheng Zhen","Ye Tian","Limiao Zhang","Yaochu Jin","Xingyi Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.04429v1.pdf","comment":"15 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2307.04420v1","updated":"2023-07-10T08:54:07Z","published":"2023-07-10T08:54:07Z","title":"FedDCT: A Dynamic Cross-Tier Federated Learning Scheme in Wireless\n  Communication Networks","summary":"  With the rapid proliferation of Internet of Things (IoT) devices and the\ngrowing concern for data privacy among the public, Federated Learning (FL) has\ngained significant attention as a privacy-preserving machine learning paradigm.\nFL enables the training of a global model among clients without exposing local\ndata. However, when a federated learning system runs on wireless communication\nnetworks, limited wireless resources, heterogeneity of clients, and network\ntransmission failures affect its performance and accuracy. In this study, we\npropose a novel dynamic cross-tier FL scheme, named FedDCT to increase training\naccuracy and performance in wireless communication networks. We utilize a\ntiering algorithm that dynamically divides clients into different tiers\naccording to specific indicators and assigns specific timeout thresholds to\neach tier to reduce the training time required. To improve the accuracy of the\nmodel without increasing the training time, we introduce a cross-tier client\nselection algorithm that can effectively select the tiers and participants.\nSimulation experiments show that our scheme can make the model converge faster\nand achieve a higher accuracy in wireless communication networks.\n","authors":["Peng Liu","Youquan Xian","Chuanjian Yao","Xiaoyun Gan","Lianghaojie Zhou","Jianyong Jiang","Dongcheng Li"],"pdf_url":"https://arxiv.org/pdf/2307.04420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04401v1","updated":"2023-07-10T08:03:41Z","published":"2023-07-10T08:03:41Z","title":"Ethicist: Targeted Training Data Extraction Through Loss Smoothed Soft\n  Prompting and Calibrated Confidence Estimation","summary":"  Large pre-trained language models achieve impressive results across many\ntasks. However, recent works point out that pre-trained language models may\nmemorize a considerable fraction of their training data, leading to the privacy\nrisk of information leakage. In this paper, we propose a method named Ethicist\nfor targeted training data extraction through loss smoothed soft prompting and\ncalibrated confidence estimation, investigating how to recover the suffix in\nthe training data when given a prefix. To elicit memorization in the attacked\nmodel, we tune soft prompt embeddings while keeping the model fixed. We further\npropose a smoothing loss that smooths the loss distribution of the suffix\ntokens to make it easier to sample the correct suffix. In order to select the\nmost probable suffix from a collection of sampled suffixes and estimate the\nprediction confidence, we propose a calibrated confidence estimation method,\nwhich normalizes the confidence of the generated suffixes with a local\nestimation. We show that Ethicist significantly improves the extraction\nperformance on a recently proposed public benchmark. We also investigate\nseveral factors influencing the data extraction performance, including decoding\nstrategy, model scale, prefix length, and suffix length. Our code is available\nat https://github.com/thu-coai/Targeted-Data-Extraction.\n","authors":["Zhexin Zhang","Jiaxin Wen","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2307.04401v1.pdf","comment":"ACL 2023 Long Paper (Main Conference)"},{"id":"http://arxiv.org/abs/2207.06154v2","updated":"2023-07-10T07:29:59Z","published":"2022-07-13T12:27:38Z","title":"On the Robustness of Bayesian Neural Networks to Adversarial Attacks","summary":"  Vulnerability to adversarial attacks is one of the principal hurdles to the\nadoption of deep learning in safety-critical applications. Despite significant\nefforts, both practical and theoretical, training deep learning models robust\nto adversarial attacks is still an open problem. In this paper, we analyse the\ngeometry of adversarial attacks in the large-data, overparameterized limit for\nBayesian Neural Networks (BNNs). We show that, in the limit, vulnerability to\ngradient-based attacks arises as a result of degeneracy in the data\ndistribution, i.e., when the data lies on a lower-dimensional submanifold of\nthe ambient space. As a direct consequence, we demonstrate that in this limit\nBNN posteriors are robust to gradient-based adversarial attacks. Crucially, we\nprove that the expected gradient of the loss with respect to the BNN posterior\ndistribution is vanishing, even when each neural network sampled from the\nposterior is vulnerable to gradient-based attacks. Experimental results on the\nMNIST, Fashion MNIST, and half moons datasets, representing the finite data\nregime, with BNNs trained with Hamiltonian Monte Carlo and Variational\nInference, support this line of arguments, showing that BNNs can display both\nhigh accuracy on clean data and robustness to both gradient-based and\ngradient-free based adversarial attacks.\n","authors":["Luca Bortolussi","Ginevra Carbone","Luca Laurenti","Andrea Patane","Guido Sanguinetti","Matthew Wicker"],"pdf_url":"https://arxiv.org/pdf/2207.06154v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2002.04359"},{"id":"http://arxiv.org/abs/2211.15657v4","updated":"2023-07-10T07:25:26Z","published":"2022-11-28T18:59:02Z","title":"Is Conditional Generative Modeling all you need for Decision-Making?","summary":"  Recent improvements in conditional generative modeling have made it possible\nto generate high-quality images from language descriptions alone. We\ninvestigate whether these methods can directly address the problem of\nsequential decision-making. We view decision-making not through the lens of\nreinforcement learning (RL), but rather through conditional generative\nmodeling. To our surprise, we find that our formulation leads to policies that\ncan outperform existing offline RL approaches across standard benchmarks. By\nmodeling a policy as a return-conditional diffusion model, we illustrate how we\nmay circumvent the need for dynamic programming and subsequently eliminate many\nof the complexities that come with traditional offline RL. We further\ndemonstrate the advantages of modeling policies as conditional diffusion models\nby considering two other conditioning variables: constraints and skills.\nConditioning on a single constraint or skill during training leads to behaviors\nat test-time that can satisfy several constraints together or demonstrate a\ncomposition of skills. Our results illustrate that conditional generative\nmodeling is a powerful tool for decision-making.\n","authors":["Anurag Ajay","Yilun Du","Abhi Gupta","Joshua Tenenbaum","Tommi Jaakkola","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2211.15657v4.pdf","comment":"Website: https://anuragajay.github.io/decision-diffuser/"},{"id":"http://arxiv.org/abs/2307.04370v1","updated":"2023-07-10T07:00:06Z","published":"2023-07-10T07:00:06Z","title":"Recent Advancements in End-to-End Autonomous Driving using Deep\n  Learning: A Survey","summary":"  End-to-End driving is a promising paradigm as it circumvents the drawbacks\nassociated with modular systems, such as their overwhelming complexity and\npropensity for error propagation. Autonomous driving transcends conventional\ntraffic patterns by proactively recognizing critical events in advance,\nensuring passengers' safety and providing them with comfortable transportation,\nparticularly in highly stochastic and variable traffic settings. This paper\npresents a comprehensive review of the End-to-End autonomous driving stack. It\nprovides a taxonomy of automated driving tasks wherein neural networks have\nbeen employed in an End-to-End manner, encompassing the entire driving process\nfrom perception to control, while addressing key challenges encountered in\nreal-world applications. Recent developments in End-to-End autonomous driving\nare analyzed, and research is categorized based on underlying principles,\nmethodologies, and core functionality. These categories encompass sensorial\ninput, main and auxiliary output, learning approaches ranging from imitation to\nreinforcement learning, and model evaluation techniques. The survey\nincorporates a detailed discussion of the explainability and safety aspects.\nFurthermore, it assesses the state-of-the-art, identifies challenges, and\nexplores future possibilities. We maintained the latest advancements and their\ncorresponding open-source implementations at\nhttps://github.com/Pranav-chib/Recent-Advancements-in-End-to-End-Autonomous-Driving-using-Deep-Learning.\n","authors":["Pranav Singh Chib","Pravendra Singh"],"pdf_url":"https://arxiv.org/pdf/2307.04370v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2307.04368v1","updated":"2023-07-10T06:49:18Z","published":"2023-07-10T06:49:18Z","title":"ECS -- an Interactive Tool for Data Quality Assurance","summary":"  With the increasing capabilities of machine learning systems and their\npotential use in safety-critical systems, ensuring high-quality data is\nbecoming increasingly important. In this paper we present a novel approach for\nthe assurance of data quality. For this purpose, the mathematical basics are\nfirst discussed and the approach is presented using multiple examples. This\nresults in the detection of data points with potentially harmful properties for\nthe use in safety-critical systems.\n","authors":["Christian Sieberichs","Simon Geerkens","Alexander Braun","Thomas Waschulzik"],"pdf_url":"https://arxiv.org/pdf/2307.04368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.03774v3","updated":"2023-07-10T06:38:22Z","published":"2020-11-27T04:57:40Z","title":"Learning to extrapolate using continued fractions: Predicting the\n  critical temperature of superconductor materials","summary":"  In the field of Artificial Intelligence (AI) and Machine Learning (ML), the\napproximation of unknown target functions $y=f(\\mathbf{x})$ using limited\ninstances $S={(\\mathbf{x^{(i)}},y^{(i)})}$, where $\\mathbf{x^{(i)}} \\in D$ and\n$D$ represents the domain of interest, is a common objective. We refer to $S$\nas the training set and aim to identify a low-complexity mathematical model\nthat can effectively approximate this target function for new instances\n$\\mathbf{x}$. Consequently, the model's generalization ability is evaluated on\na separate set $T=\\{\\mathbf{x^{(j)}}\\} \\subset D$, where $T \\neq S$, frequently\nwith $T \\cap S = \\emptyset$, to assess its performance beyond the training set.\nHowever, certain applications require accurate approximation not only within\nthe original domain $D$ but also in an extended domain $D'$ that encompasses\n$D$. This becomes particularly relevant in scenarios involving the design of\nnew structures, where minimizing errors in approximations is crucial. For\nexample, when developing new materials through data-driven approaches, the\nAI/ML system can provide valuable insights to guide the design process by\nserving as a surrogate function. Consequently, the learned model can be\nemployed to facilitate the design of new laboratory experiments. In this paper,\nwe propose a method for multivariate regression based on iterative fitting of a\ncontinued fraction, incorporating additive spline models. We compare the\nperformance of our method with established techniques, including AdaBoost,\nKernel Ridge, Linear Regression, Lasso Lars, Linear Support Vector Regression,\nMulti-Layer Perceptrons, Random Forests, Stochastic Gradient Descent, and\nXGBoost. To evaluate these methods, we focus on an important problem in the\nfield: predicting the critical temperature of superconductors based on\nphysical-chemical characteristics.\n","authors":["Pablo Moscato","Mohammad Nazmul Haque","Kevin Huang","Julia Sloan","Jon C. de Oliveira"],"pdf_url":"https://arxiv.org/pdf/2012.03774v3.pdf","comment":"Submitted to Algorithms ( ISSN: 1999-4893 )"},{"id":"http://arxiv.org/abs/2307.03393v2","updated":"2023-07-10T06:06:04Z","published":"2023-07-07T05:31:31Z","title":"Exploring the Potential of Large Language Models (LLMs) in Learning on\n  Graphs","summary":"  Learning on Graphs has attracted immense attention due to its wide real-world\napplications. The most popular pipeline for learning on graphs with textual\nnode attributes primarily relies on Graph Neural Networks (GNNs), and utilizes\nshallow text embedding as initial node representations, which has limitations\nin general knowledge and profound semantic understanding. In recent years,\nLarge Language Models (LLMs) have been proven to possess extensive common\nknowledge and powerful semantic comprehension abilities that have\nrevolutionized existing workflows to handle text data. In this paper, we aim to\nexplore the potential of LLMs in graph machine learning, especially the node\nclassification task, and investigate two possible pipelines: LLMs-as-Enhancers\nand LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text\nattributes with their massive knowledge and then generate predictions through\nGNNs. The latter attempts to directly employ LLMs as standalone predictors. We\nconduct comprehensive and systematical studies on these two pipelines under\nvarious settings. From comprehensive empirical results, we make original\nobservations and find new insights that open new possibilities and suggest\npromising directions to leverage LLMs for learning on graphs.\n","authors":["Zhikai Chen","Haitao Mao","Hang Li","Wei Jin","Hongzhi Wen","Xiaochi Wei","Shuaiqiang Wang","Dawei Yin","Wenqi Fan","Hui Liu","Jiliang Tang"],"pdf_url":"https://arxiv.org/pdf/2307.03393v2.pdf","comment":"fix some minor typos and errors"},{"id":"http://arxiv.org/abs/2307.03419v2","updated":"2023-07-10T05:51:07Z","published":"2023-07-07T07:06:38Z","title":"QI2 -- an Interactive Tool for Data Quality Assurance","summary":"  The importance of high data quality is increasing with the growing impact and\ndistribution of ML systems and big data. Also the planned AI Act from the\nEuropean commission defines challenging legal requirements for data quality\nespecially for the market introduction of safety relevant ML systems. In this\npaper we introduce a novel approach that supports the data quality assurance\nprocess of multiple data quality aspects. This approach enables the\nverification of quantitative data quality requirements. The concept and\nbenefits are introduced and explained on small example data sets. How the\nmethod is applied is demonstrated on the well known MNIST data set based an\nhandwritten digits.\n","authors":["Simon Geerkens","Christian Sieberichs","Alexander Braun","Thomas Waschulzik"],"pdf_url":"https://arxiv.org/pdf/2307.03419v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01473v2","updated":"2023-07-10T05:34:34Z","published":"2023-07-04T04:46:44Z","title":"Mitigating Bias: Enhancing Image Classification by Improving Model\n  Explanations","summary":"  Deep learning models have demonstrated remarkable capabilities in learning\ncomplex patterns and concepts from training data. However, recent findings\nindicate that these models tend to rely heavily on simple and easily\ndiscernible features present in the background of images rather than the main\nconcepts or objects they are intended to classify. This phenomenon poses a\nchallenge to image classifiers as the crucial elements of interest in images\nmay be overshadowed. In this paper, we propose a novel approach to address this\nissue and improve the learning of main concepts by image classifiers. Our\ncentral idea revolves around concurrently guiding the model's attention toward\nthe foreground during the classification task. By emphasizing the foreground,\nwhich encapsulates the primary objects of interest, we aim to shift the focus\nof the model away from the dominant influence of the background. To accomplish\nthis, we introduce a mechanism that encourages the model to allocate sufficient\nattention to the foreground. We investigate various strategies, including\nmodifying the loss function or incorporating additional architectural\ncomponents, to enable the classifier to effectively capture the primary concept\nwithin an image. Additionally, we explore the impact of different foreground\nattention mechanisms on model performance and provide insights into their\neffectiveness. Through extensive experimentation on benchmark datasets, we\ndemonstrate the efficacy of our proposed approach in improving the\nclassification accuracy of image classifiers. Our findings highlight the\nimportance of foreground attention in enhancing model understanding and\nrepresentation of the main concepts within images. The results of this study\ncontribute to advancing the field of image classification and provide valuable\ninsights for developing more robust and accurate deep-learning models.\n","authors":["Raha Ahmadi","Mohammad Javad Rajabi","Mohammad Khalooie","Mohammad Sabokrou"],"pdf_url":"https://arxiv.org/pdf/2307.01473v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04349v1","updated":"2023-07-10T05:18:18Z","published":"2023-07-10T05:18:18Z","title":"RLTF: Reinforcement Learning from Unit Test Feedback","summary":"  The goal of program synthesis, or code generation, is to generate executable\ncode based on given descriptions. Recently, there has been an increasing number\nof studies employing reinforcement learning (RL) to improve the performance of\nlarge language models (LLMs) for code. However, these RL methods have only used\noffline frameworks, limiting their exploration of new sample spaces.\nAdditionally, current approaches that utilize unit test signals are rather\nsimple, not accounting for specific error locations within the code. To address\nthese issues, we proposed RLTF, i.e., Reinforcement Learning from Unit Test\nFeedback, a novel online RL framework with unit test feedback of\nmulti-granularity for refining code LLMs. Our approach generates data in\nreal-time during training and simultaneously utilizes fine-grained feedback\nsignals to guide the model towards producing higher-quality code. Extensive\nexperiments show that RLTF achieves state-of-the-art performance on the APPS\nand the MBPP benchmarks. Our code can be found at:\nhttps://github.com/Zyq-scut/RLTF.\n","authors":["Jiate Liu","Yiqin Zhu","Kaiwen Xiao","Qiang Fu","Xiao Han","Wei Yang","Deheng Ye"],"pdf_url":"https://arxiv.org/pdf/2307.04349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04347v1","updated":"2023-07-10T05:12:05Z","published":"2023-07-10T05:12:05Z","title":"Injecting Logical Constraints into Neural Networks via Straight-Through\n  Estimators","summary":"  Injecting discrete logical constraints into neural network learning is one of\nthe main challenges in neuro-symbolic AI. We find that a\nstraight-through-estimator, a method introduced to train binary neural\nnetworks, could effectively be applied to incorporate logical constraints into\nneural network learning. More specifically, we design a systematic way to\nrepresent discrete logical constraints as a loss function; minimizing this loss\nusing gradient descent via a straight-through-estimator updates the neural\nnetwork's weights in the direction that the binarized outputs satisfy the\nlogical constraints. The experimental results show that by leveraging GPUs and\nbatch training, this method scales significantly better than existing\nneuro-symbolic methods that require heavy symbolic computation for computing\ngradients. Also, we demonstrate that our method applies to different types of\nneural networks, such as MLP, CNN, and GNN, making them learn with no or fewer\nlabeled data by learning directly from known constraints.\n","authors":["Zhun Yang","Joohyung Lee","Chiyoun Park"],"pdf_url":"https://arxiv.org/pdf/2307.04347v1.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2307.04345v1","updated":"2023-07-10T05:06:41Z","published":"2023-07-10T05:06:41Z","title":"Continual Learning as Computationally Constrained Reinforcement Learning","summary":"  An agent that efficiently accumulates knowledge to develop increasingly\nsophisticated skills over a long lifetime could advance the frontier of\nartificial intelligence capabilities. The design of such agents, which remains\na long-standing challenge of artificial intelligence, is addressed by the\nsubject of continual learning. This monograph clarifies and formalizes concepts\nof continual learning, introducing a framework and set of tools to stimulate\nfurther research.\n","authors":["Saurabh Kumar","Henrik Marklund","Ashish Rao","Yifan Zhu","Hong Jun Jeon","Yueyang Liu","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2307.04345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04341v1","updated":"2023-07-10T04:50:17Z","published":"2023-07-10T04:50:17Z","title":"Stroke Extraction of Chinese Character Based on Deep Structure\n  Deformable Image Registration","summary":"  Stroke extraction of Chinese characters plays an important role in the field\nof character recognition and generation. The most existing character stroke\nextraction methods focus on image morphological features. These methods usually\nlead to errors of cross strokes extraction and stroke matching due to rarely\nusing stroke semantics and prior information. In this paper, we propose a deep\nlearning-based character stroke extraction method that takes semantic features\nand prior information of strokes into consideration. This method consists of\nthree parts: image registration-based stroke registration that establishes the\nrough registration of the reference strokes and the target as prior\ninformation; image semantic segmentation-based stroke segmentation that\npreliminarily separates target strokes into seven categories; and\nhigh-precision extraction of single strokes. In the stroke registration, we\npropose a structure deformable image registration network to achieve\nstructure-deformable transformation while maintaining the stable morphology of\nsingle strokes for character images with complex structures. In order to verify\nthe effectiveness of the method, we construct two datasets respectively for\ncalligraphy characters and regular handwriting characters. The experimental\nresults show that our method strongly outperforms the baselines. Code is\navailable at https://github.com/MengLi-l1/StrokeExtraction.\n","authors":["Meng Li","Yahan Yu","Yi Yang","Guanghao Ren","Jian Wang"],"pdf_url":"https://arxiv.org/pdf/2307.04341v1.pdf","comment":"10 pages, 8 figures, published to AAAI-23 (oral)"},{"id":"http://arxiv.org/abs/2307.04339v1","updated":"2023-07-10T04:30:44Z","published":"2023-07-10T04:30:44Z","title":"Miriam: Exploiting Elastic Kernels for Real-time Multi-DNN Inference on\n  Edge GPU","summary":"  Many applications such as autonomous driving and augmented reality, require\nthe concurrent running of multiple deep neural networks (DNN) that poses\ndifferent levels of real-time performance requirements. However, coordinating\nmultiple DNN tasks with varying levels of criticality on edge GPUs remains an\narea of limited study. Unlike server-level GPUs, edge GPUs are resource-limited\nand lack hardware-level resource management mechanisms for avoiding resource\ncontention. Therefore, we propose Miriam, a contention-aware task coordination\nframework for multi-DNN inference on edge GPU. Miriam consolidates two main\ncomponents, an elastic-kernel generator, and a runtime dynamic kernel\ncoordinator, to support mixed critical DNN inference. To evaluate Miriam, we\nbuild a new DNN inference benchmark based on CUDA with diverse representative\nDNN workloads. Experiments on two edge GPU platforms show that Miriam can\nincrease system throughput by 92% while only incurring less than 10\\% latency\noverhead for critical tasks, compared to state of art baselines.\n","authors":["Zhihe Zhao","Neiwen Ling","Nan Guan","Guoliang Xing"],"pdf_url":"https://arxiv.org/pdf/2307.04339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04336v1","updated":"2023-07-10T04:22:49Z","published":"2023-07-10T04:22:49Z","title":"Source-Aware Embedding Training on Heterogeneous Information Networks","summary":"  Heterogeneous information networks (HINs) have been extensively applied to\nreal-world tasks, such as recommendation systems, social networks, and citation\nnetworks. While existing HIN representation learning methods can effectively\nlearn the semantic and structural features in the network, little awareness was\ngiven to the distribution discrepancy of subgraphs within a single HIN.\nHowever, we find that ignoring such distribution discrepancy among subgraphs\nfrom multiple sources would hinder the effectiveness of graph embedding\nlearning algorithms. This motivates us to propose SUMSHINE (Scalable\nUnsupervised Multi-Source Heterogeneous Information Network Embedding) -- a\nscalable unsupervised framework to align the embedding distributions among\nmultiple sources of an HIN. Experimental results on real-world datasets in a\nvariety of downstream tasks validate the performance of our method over the\nstate-of-the-art heterogeneous information network embedding algorithms.\n","authors":["Tsai Hor Chan","Chi Ho Wong","Jiajun Shen","Guosheng Yin"],"pdf_url":"https://arxiv.org/pdf/2307.04336v1.pdf","comment":"Published in Data Intelligence 2023"},{"id":"http://arxiv.org/abs/2307.04333v1","updated":"2023-07-10T03:59:42Z","published":"2023-07-10T03:59:42Z","title":"Enhancing Adversarial Robustness via Score-Based Optimization","summary":"  Adversarial attacks have the potential to mislead deep neural network\nclassifiers by introducing slight perturbations. Developing algorithms that can\nmitigate the effects of these attacks is crucial for ensuring the safe use of\nartificial intelligence. Recent studies have suggested that score-based\ndiffusion models are effective in adversarial defenses. However, existing\ndiffusion-based defenses rely on the sequential simulation of the reversed\nstochastic differential equations of diffusion models, which are\ncomputationally inefficient and yield suboptimal results. In this paper, we\nintroduce a novel adversarial defense scheme named ScoreOpt, which optimizes\nadversarial samples at test-time, towards original clean data in the direction\nguided by score-based priors. We conduct comprehensive experiments on multiple\ndatasets, including CIFAR10, CIFAR100 and ImageNet. Our experimental results\ndemonstrate that our approach outperforms existing adversarial defenses in\nterms of both robustness performance and inference speed.\n","authors":["Boya Zhang","Weijian Luo","Zhihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.04333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13359v2","updated":"2023-07-10T02:21:41Z","published":"2023-01-31T01:24:45Z","title":"IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing","summary":"  Image anomaly detection (IAD) is an emerging and vital computer vision task\nin industrial manufacturing (IM). Recently many advanced algorithms have been\npublished, but their performance deviates greatly. We realize that the lack of\nactual IM settings most probably hinders the development and usage of these\nmethods in real-world applications. As far as we know, IAD methods are not\nevaluated systematically. As a result, this makes it difficult for researchers\nto analyze them because they are designed for different or special cases. To\nsolve this problem, we first propose a uniform IM setting to assess how well\nthese algorithms perform, which includes several aspects, i.e., various levels\nof supervision (unsupervised vs. semi-supervised), few-shot learning, continual\nlearning, noisy labels, memory usage, and inference speed. Moreover, we\nskillfully build a comprehensive image anomaly detection benchmark (IM-IAD)\nthat includes 16 algorithms on 7 mainstream datasets with uniform settings. Our\nextensive experiments (17,017 in total) provide in-depth insights for IAD\nalgorithm redesign or selection under the IM setting. Next, the proposed\nbenchmark IM-IAD gives challenges as well as directions for the future. To\nfoster reproducibility and accessibility, the source code of IM-IAD is uploaded\non the website, https://github.com/M-3LAB/IM-IAD.\n","authors":["Guoyang Xie","Jinbao Wang","Jiaqi Liu","Jiayi Lyu","Yong Liu","Chengjie Wang","Feng Zheng","Yaochu Jin"],"pdf_url":"https://arxiv.org/pdf/2301.13359v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04303v1","updated":"2023-07-10T01:44:13Z","published":"2023-07-10T01:44:13Z","title":"Learning to Generate Equitable Text in Dialogue from Biased Training\n  Data","summary":"  The ingrained principles of fairness in a dialogue system's decision-making\nprocess and generated responses are crucial for user engagement, satisfaction,\nand task achievement. Absence of equitable and inclusive principles can hinder\nthe formation of common ground, which in turn negatively impacts the overall\nperformance of the system. For example, misusing pronouns in a user interaction\nmay cause ambiguity about the intended subject. Yet, there is no comprehensive\nstudy of equitable text generation in dialogue. Aptly, in this work, we use\ntheories of computational learning to study this problem. We provide formal\ndefinitions of equity in text generation, and further, prove formal connections\nbetween learning human-likeness and learning equity: algorithms for improving\nequity ultimately reduce to algorithms for improving human-likeness (on\naugmented data). With this insight, we also formulate reasonable conditions\nunder which text generation algorithms can learn to generate equitable text\nwithout any modifications to the biased training data on which they learn. To\nexemplify our theory in practice, we look at a group of algorithms for the\nGuessWhat?! visual dialogue game and, using this example, test our theory\nempirically. Our theory accurately predicts relative-performance of multiple\nalgorithms in generating equitable text as measured by both human and automated\nevaluation.\n","authors":["Anthony Sicilia","Malihe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2307.04303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04292v1","updated":"2023-07-10T00:58:28Z","published":"2023-07-10T00:58:28Z","title":"A Demand-Driven Perspective on Generative Audio AI","summary":"  To achieve successful deployment of AI research, it is crucial to understand\nthe demands of the industry. In this paper, we present the results of a survey\nconducted with professional audio engineers, in order to determine research\npriorities and define various research tasks. We also summarize the current\nchallenges in audio quality and controllability based on the survey. Our\nanalysis emphasizes that the availability of datasets is currently the main\nbottleneck for achieving high-quality audio generation. Finally, we suggest\npotential solutions for some revealed issues with empirical evidence.\n","authors":["Sangshin Oh","Minsung Kang","Hyeongi Moon","Keunwoo Choi","Ben Sangbae Chon"],"pdf_url":"https://arxiv.org/pdf/2307.04292v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2307.04287v1","updated":"2023-07-10T00:29:25Z","published":"2023-07-10T00:29:25Z","title":"Generalizing Graph ODE for Learning Complex System Dynamics across\n  Environments","summary":"  Learning multi-agent system dynamics has been extensively studied for various\nreal-world applications, such as molecular dynamics in biology. Most of the\nexisting models are built to learn single system dynamics from observed\nhistorical data and predict the future trajectory. In practice, however, we\nmight observe multiple systems that are generated across different\nenvironments, which differ in latent exogenous factors such as temperature and\ngravity. One simple solution is to learn multiple environment-specific models,\nbut it fails to exploit the potential commonalities among the dynamics across\nenvironments and offers poor prediction results where per-environment data is\nsparse or limited. Here, we present GG-ODE (Generalized Graph Ordinary\nDifferential Equations), a machine learning framework for learning continuous\nmulti-agent system dynamics across environments. Our model learns system\ndynamics using neural ordinary differential equations (ODE) parameterized by\nGraph Neural Networks (GNNs) to capture the continuous interaction among\nagents. We achieve the model generalization by assuming the dynamics across\ndifferent environments are governed by common physics laws that can be captured\nvia learning a shared ODE function. The distinct latent exogenous factors\nlearned for each environment are incorporated into the ODE function to account\nfor their differences. To improve model performance, we additionally design two\nregularization losses to (1) enforce the orthogonality between the learned\ninitial states and exogenous factors via mutual information minimization; and\n(2) reduce the temporal variance of learned exogenous factors within the same\nsystem via contrastive learning. Experiments over various physical simulations\nshow that our model can accurately predict system dynamics, especially in the\nlong range, and can generalize well to new systems with few observations.\n","authors":["Zijie Huang","Yizhou Sun","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2307.04287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03017v2","updated":"2023-07-10T22:15:31Z","published":"2023-05-04T17:43:19Z","title":"Improving Code Example Recommendations on Informal Documentation Using\n  BERT and Query-Aware LSH: A Comparative Study","summary":"  Our research investigates the recommendation of code examples to aid software\ndevelopers, a practice that saves developers significant time by providing\nready-to-use code snippets. The focus of our study is Stack Overflow, a\ncommonly used resource for coding discussions and solutions, particularly in\nthe context of the Java programming language.\n  We applied BERT, a powerful Large Language Model (LLM) that enables us to\ntransform code examples into numerical vectors by extracting their semantic\ninformation. Once these numerical representations are prepared, we identify\nApproximate Nearest Neighbors (ANN) using Locality-Sensitive Hashing (LSH). Our\nresearch employed two variants of LSH: Random Hyperplane-based LSH and\nQuery-Aware LSH. We rigorously compared these two approaches across four\nparameters: HitRate, Mean Reciprocal Rank (MRR), Average Execution Time, and\nRelevance.\n  Our study revealed that the Query-Aware (QA) approach showed superior\nperformance over the Random Hyperplane-based (RH) method. Specifically, it\nexhibited a notable improvement of 20% to 35% in HitRate for query pairs\ncompared to the RH approach. Furthermore, the QA approach proved significantly\nmore time-efficient, with its speed in creating hashing tables and assigning\ndata samples to buckets being at least four times faster. It can return code\nexamples within milliseconds, whereas the RH approach typically requires\nseveral seconds to recommend code examples. Due to the superior performance of\nthe QA approach, we tested it against PostFinder and FaCoY, the\nstate-of-the-art baselines. Our QA method showed comparable efficiency proving\nits potential for effective code recommendation.\n","authors":["Sajjad Rahmani","AmirHossein Naghshzan","Latifa Guerrouj"],"pdf_url":"https://arxiv.org/pdf/2305.03017v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.16015v2","updated":"2023-07-10T22:00:41Z","published":"2023-06-28T08:41:49Z","title":"BayesFlow: Amortized Bayesian Workflows With Neural Networks","summary":"  Modern Bayesian inference involves a mixture of computational techniques for\nestimating, validating, and drawing conclusions from probabilistic models as\npart of principled workflows for data analysis. Typical problems in Bayesian\nworkflows are the approximation of intractable posterior distributions for\ndiverse model types and the comparison of competing models of the same process\nin terms of their complexity and predictive performance. This manuscript\nintroduces the Python library BayesFlow for simulation-based training of\nestablished neural network architectures for amortized data compression and\ninference. Amortized Bayesian inference, as implemented in BayesFlow, enables\nusers to train custom neural networks on model simulations and re-use these\nnetworks for any subsequent application of the models. Since the trained\nnetworks can perform inference almost instantaneously, the upfront neural\nnetwork training is quickly amortized.\n","authors":["Stefan T Radev","Marvin Schmitt","Lukas Schumacher","Lasse Elsemüller","Valentin Pratz","Yannik Schälte","Ullrich Köthe","Paul-Christian Bürkner"],"pdf_url":"https://arxiv.org/pdf/2306.16015v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05995v2","updated":"2023-07-10T21:51:34Z","published":"2023-01-15T01:36:46Z","title":"Collective Privacy Recovery: Data-sharing Coordination via Decentralized\n  Artificial Intelligence","summary":"  Collective privacy loss becomes a colossal problem, an emergency for personal\nfreedoms and democracy. But, are we prepared to handle personal data as scarce\nresource and collectively share data under the doctrine: as little as possible,\nas much as necessary? We hypothesize a significant privacy recovery if a\npopulation of individuals, the data collective, coordinates to share minimum\ndata for running online services with the required quality. Here we show how to\nautomate and scale-up complex collective arrangements for privacy recovery\nusing decentralized artificial intelligence. For this, we compare for first\ntime attitudinal, intrinsic, rewarded and coordinated data sharing in a\nrigorous living-lab experiment of high realism involving >27,000 real data\ndisclosures. Using causal inference and cluster analysis, we differentiate\ncriteria predicting privacy and five key data-sharing behaviors. Strikingly,\ndata-sharing coordination proves to be a win-win for all: remarkable privacy\nrecovery for people with evident costs reduction for service providers.\n","authors":["Evangelos Pournaras","Mark Christopher Ballandies","Stefano Bennati","Chien-fei Chen"],"pdf_url":"https://arxiv.org/pdf/2301.05995v2.pdf","comment":"Contains Supplementary Information"},{"id":"http://arxiv.org/abs/2207.06960v2","updated":"2023-07-10T21:02:05Z","published":"2022-07-14T14:39:30Z","title":"Forming Trees with Treeformers","summary":"  Human language is known to exhibit a nested, hierarchical structure, allowing\nus to form complex sentences out of smaller pieces. However, many\nstate-of-the-art neural networks models such as Transformers have no explicit\nhierarchical structure in its architecture -- that is, they don't have an\ninductive bias toward hierarchical structure. Additionally, Transformers are\nknown to perform poorly on compositional generalization tasks which require\nsuch structures. In this paper, we introduce Treeformer, a general-purpose\nencoder module inspired by the CKY algorithm which learns a composition\noperator and pooling function to construct hierarchical encodings for phrases\nand sentences. Our extensive experiments demonstrate the benefits of\nincorporating hierarchical structure into the Transformer and show significant\nimprovements in compositional generalization as well as in downstream tasks\nsuch as machine translation, abstractive summarization, and various natural\nlanguage understanding tasks.\n","authors":["Nilay Patel","Jeffrey Flanigan"],"pdf_url":"https://arxiv.org/pdf/2207.06960v2.pdf","comment":"Accepted to RANLP 2023"},{"id":"http://arxiv.org/abs/2304.02168v2","updated":"2023-07-10T20:41:34Z","published":"2023-04-04T23:51:48Z","title":"I2I: Initializing Adapters with Improvised Knowledge","summary":"  Adapters present a promising solution to the catastrophic forgetting problem\nin continual learning. However, training independent Adapter modules for every\nnew task misses an opportunity for cross-task knowledge transfer. We propose\nImprovise to Initialize (I2I), a continual learning algorithm that initializes\nAdapters for incoming tasks by distilling knowledge from previously-learned\ntasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learning\nbenchmark, by conducting experiments on sequences of visual question answering\ntasks. Adapters trained with I2I consistently achieve better task accuracy than\nindependently-trained Adapters, demonstrating that our algorithm facilitates\nknowledge transfer between task Adapters. I2I also results in better cross-task\nknowledge transfer than the state-of-the-art AdapterFusion without incurring\nthe associated parametric cost.\n","authors":["Tejas Srinivasan","Furong Jia","Mohammad Rostami","Jesse Thomason"],"pdf_url":"https://arxiv.org/pdf/2304.02168v2.pdf","comment":"Accepted at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023"},{"id":"http://arxiv.org/abs/2307.04895v1","updated":"2023-07-10T20:35:22Z","published":"2023-07-10T20:35:22Z","title":"Learning to Solve Constraint Satisfaction Problems with Recurrent\n  Transformer","summary":"  Constraint satisfaction problems (CSPs) are about finding values of variables\nthat satisfy the given constraints. We show that Transformer extended with\nrecurrence is a viable approach to learning to solve CSPs in an end-to-end\nmanner, having clear advantages over state-of-the-art methods such as Graph\nNeural Networks, SATNet, and some neuro-symbolic models. With the ability of\nTransformer to handle visual input, the proposed Recurrent Transformer can\nstraightforwardly be applied to visual constraint reasoning problems while\nsuccessfully addressing the symbol grounding problem. We also show how to\nleverage deductive knowledge of discrete constraints in the Transformer's\ninductive learning to achieve sample-efficient learning and semi-supervised\nlearning for CSPs.\n","authors":["Zhun Yang","Adam Ishay","Joohyung Lee"],"pdf_url":"https://arxiv.org/pdf/2307.04895v1.pdf","comment":"22 pages. The Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2307.04893v1","updated":"2023-07-10T20:31:23Z","published":"2023-07-10T20:31:23Z","title":"Choosing Well Your Opponents: How to Guide the Synthesis of Programmatic\n  Strategies","summary":"  This paper introduces Local Learner (2L), an algorithm for providing a set of\nreference strategies to guide the search for programmatic strategies in\ntwo-player zero-sum games. Previous learning algorithms, such as Iterated Best\nResponse (IBR), Fictitious Play (FP), and Double-Oracle (DO), can be\ncomputationally expensive or miss important information for guiding search\nalgorithms. 2L actively selects a set of reference strategies to improve the\nsearch signal. We empirically demonstrate the advantages of our approach while\nguiding a local search algorithm for synthesizing strategies in three games,\nincluding MicroRTS, a challenging real-time strategy game. Results show that 2L\nlearns reference strategies that provide a stronger search signal than IBR, FP,\nand DO. We also simulate a tournament of MicroRTS, where a synthesizer using 2L\noutperformed the winners of the two latest MicroRTS competitions, which were\nprogrammatic strategies written by human programmers.\n","authors":["Rubens O. Moraes","David S. Aleixo","Lucas N. Ferreira","Levi H. S. Lelis"],"pdf_url":"https://arxiv.org/pdf/2307.04893v1.pdf","comment":"International Joint Conference on Artificial Intelligence (IJCAI)\n  2023"},{"id":"http://arxiv.org/abs/2307.04887v1","updated":"2023-07-10T20:20:20Z","published":"2023-07-10T20:20:20Z","title":"Measuring and Mitigating Interference in Reinforcement Learning","summary":"  Catastrophic interference is common in many network-based learning systems,\nand many proposals exist for mitigating it. Before overcoming interference we\nmust understand it better. In this work, we provide a definition and novel\nmeasure of interference for value-based reinforcement learning methods such as\nFitted Q-Iteration and DQN. We systematically evaluate our measure of\ninterference, showing that it correlates with instability in control\nperformance, across a variety of network architectures. Our new interference\nmeasure allows us to ask novel scientific questions about commonly used deep\nlearning architectures and study learning algorithms which mitigate\ninterference. Lastly, we outline a class of algorithms which we call\nonline-aware that are designed to mitigate interference, and show they do\nreduce interference according to our measure and that they improve stability\nand performance in several classic control environments.\n","authors":["Vincent Liu","Han Wang","Ruo Yu Tao","Khurram Javed","Adam White","Martha White"],"pdf_url":"https://arxiv.org/pdf/2307.04887v1.pdf","comment":"Published at Conference on Lifelong Learning Agents (CoLLAs) 2023"},{"id":"http://arxiv.org/abs/2307.02738v2","updated":"2023-07-10T20:17:53Z","published":"2023-07-06T02:51:54Z","title":"RecallM: An Architecture for Temporal Context Understanding and Question\n  Answering","summary":"  The ideal long-term memory mechanism for Large Language Model (LLM) based\nchatbots, would lay the foundation for continual learning, complex reasoning\nand allow sequential and temporal dependencies to be learnt. Creating this type\nof memory mechanism is an extremely challenging problem. In this paper we\nexplore different methods of achieving the effect of long-term memory. We\npropose a new architecture focused on creating adaptable and updatable\nlong-term memory for AGI systems. We demonstrate through various experiments\nthe benefits of the RecallM architecture, particularly the improved temporal\nunderstanding of knowledge it provides.\n","authors":["Brandon Kynoch","Hugo Latapie"],"pdf_url":"https://arxiv.org/pdf/2307.02738v2.pdf","comment":"12 pages, 6 figures, Our code is publicly available online at:\n  https://github.com/cisco-open/DeepVision/tree/main/recallm"},{"id":"http://arxiv.org/abs/2307.04869v1","updated":"2023-07-10T19:32:53Z","published":"2023-07-10T19:32:53Z","title":"Fed-CPrompt: Contrastive Prompt for Rehearsal-Free Federated Continual\n  Learning","summary":"  Federated continual learning (FCL) learns incremental tasks over time from\nconfidential datasets distributed across clients. This paper focuses on\nrehearsal-free FCL, which has severe forgetting issues when learning new tasks\ndue to the lack of access to historical task data. To address this issue, we\npropose Fed-CPrompt based on prompt learning techniques to obtain task-specific\nprompts in a communication-efficient way. Fed-CPrompt introduces two key\ncomponents, asynchronous prompt learning, and contrastive continual loss, to\nhandle asynchronous task arrival and heterogeneous data distributions in FCL,\nrespectively. Extensive experiments demonstrate the effectiveness of\nFed-CPrompt in achieving SOTA rehearsal-free FCL performance.\n","authors":["Gaurav Bagwe","Xiaoyong Yuan","Miao Pan","Lan Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.04869v1.pdf","comment":"Accepted by FL-ICML 2023"},{"id":"http://arxiv.org/abs/2307.04866v1","updated":"2023-07-10T19:25:45Z","published":"2023-07-10T19:25:45Z","title":"Automated Detection of Gait Events and Travel Distance Using Waist-worn\n  Accelerometers Across a Typical Range of Walking and Running Speeds","summary":"  Background: Estimation of temporospatial clinical features of gait (CFs),\nsuch as step count and length, step duration, step frequency, gait speed and\ndistance traveled is an important component of community-based mobility\nevaluation using wearable accelerometers. However, challenges arising from\ndevice complexity and availability, cost and analytical methodology have\nlimited widespread application of such tools. Research Question: Can\naccelerometer data from commercially-available smartphones be used to extract\ngait CFs across a broad range of attainable gait velocities in children with\nDuchenne muscular dystrophy (DMD) and typically developing controls (TDs) using\nmachine learning (ML)-based methods Methods: Fifteen children with DMD and 15\nTDs underwent supervised clinical testing across a range of gait speeds using\n10 or 25m run/walk (10MRW, 25MRW), 100m run/walk (100MRW), 6-minute walk (6MWT)\nand free-walk (FW) evaluations while wearing a mobile phone-based accelerometer\nat the waist near the body's center of mass. Gait CFs were extracted from the\naccelerometer data using a multi-step machine learning-based process and\nresults were compared to ground-truth observation data. Results: Model\npredictions vs. observed values for step counts, distance traveled, and step\nlength showed a strong correlation (Pearson's r = -0.9929 to 0.9986, p<0.0001).\nThe estimates demonstrated a mean (SD) percentage error of 1.49% (7.04%) for\nstep counts, 1.18% (9.91%) for distance traveled, and 0.37% (7.52%) for step\nlength compared to ground truth observations for the combined 6MWT, 100MRW, and\nFW tasks. Significance: The study findings indicate that a single accelerometer\nplaced near the body's center of mass can accurately measure CFs across\ndifferent gait speeds in both TD and DMD peers, suggesting that there is\npotential for accurately measuring CFs in the community with consumer-level\nsmartphones.\n","authors":["Albara Ah Ramli","Xin Liu","Kelly Berndt","Chen-Nee Chuah","Erica Goude","Lynea B. Kaethler","Amanda Lopez","Alina Nicorici","Corey Owens","David Rodriguez","Jane Wang","Daniel Aranki","Craig M. McDonald","Erik K. Henricson"],"pdf_url":"https://arxiv.org/pdf/2307.04866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10343v3","updated":"2023-07-10T18:48:33Z","published":"2023-01-24T23:19:01Z","title":"ClimaX: A foundation model for weather and climate","summary":"  Most state-of-the-art approaches for weather and climate modeling are based\non physics-informed numerical models of the atmosphere. These approaches aim to\nmodel the non-linear dynamics and complex interactions between multiple\nvariables, which are challenging to approximate. Additionally, many such\nnumerical models are computationally intensive, especially when modeling the\natmospheric phenomenon at a fine-grained spatial and temporal resolution.\nRecent data-driven approaches based on machine learning instead aim to directly\nsolve a downstream forecasting or projection task by learning a data-driven\nfunctional mapping using deep neural networks. However, these networks are\ntrained using curated and homogeneous climate datasets for specific\nspatiotemporal tasks, and thus lack the generality of numerical models. We\ndevelop and demonstrate ClimaX, a flexible and generalizable deep learning\nmodel for weather and climate science that can be trained using heterogeneous\ndatasets spanning different variables, spatio-temporal coverage, and physical\ngroundings. ClimaX extends the Transformer architecture with novel encoding and\naggregation blocks that allow effective use of available compute while\nmaintaining general utility. ClimaX is pre-trained with a self-supervised\nlearning objective on climate datasets derived from CMIP6. The pre-trained\nClimaX can then be fine-tuned to address a breadth of climate and weather\ntasks, including those that involve atmospheric variables and spatio-temporal\nscales unseen during pretraining. Compared to existing data-driven baselines,\nwe show that this generality in ClimaX results in superior performance on\nbenchmarks for weather forecasting and climate projections, even when\npretrained at lower resolutions and compute budgets. The source code is\navailable at https://github.com/microsoft/ClimaX.\n","authors":["Tung Nguyen","Johannes Brandstetter","Ashish Kapoor","Jayesh K. Gupta","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2301.10343v3.pdf","comment":"International Conference on Machine Learning 2023"},{"id":"http://arxiv.org/abs/2301.12636v2","updated":"2023-07-10T18:46:55Z","published":"2023-01-30T03:42:02Z","title":"Exploring Image Augmentations for Siamese Representation Learning with\n  Chest X-Rays","summary":"  Image augmentations are quintessential for effective visual representation\nlearning across self-supervised learning techniques. While augmentation\nstrategies for natural imaging have been studied extensively, medical images\nare vastly different from their natural counterparts. Thus, it is unknown\nwhether common augmentation strategies employed in Siamese representation\nlearning generalize to medical images and to what extent. To address this\nchallenge, in this study, we systematically assess the effect of various\naugmentations on the quality and robustness of the learned representations. We\ntrain and evaluate Siamese Networks for abnormality detection on chest X-Rays\nacross three large datasets (MIMIC-CXR, CheXpert and VinDR-CXR). We investigate\nthe efficacy of the learned representations through experiments involving\nlinear probing, fine-tuning, zero-shot transfer, and data efficiency. Finally,\nwe identify a set of augmentations that yield robust representations that\ngeneralize well to both out-of-distribution data and diseases, while\noutperforming supervised baselines using just zero-shot transfer and linear\nprobes by up to 20%. Our code is available at\nhttps://github.com/StanfordMIMI/siaug.\n","authors":["Rogier van der Sluijs","Nandita Bhaskhar","Daniel Rubin","Curtis Langlotz","Akshay Chaudhari"],"pdf_url":"https://arxiv.org/pdf/2301.12636v2.pdf","comment":"Equal contributions. Oral paper at MIDL 2023. Additional experiments\n  in appendix in V2. Keywords: Data Augmentations, Self-Supervised Learning,\n  Medical Imaging, Chest X-rays, Siamese Representation Learning"},{"id":"http://arxiv.org/abs/2307.04850v1","updated":"2023-07-10T18:42:45Z","published":"2023-07-10T18:42:45Z","title":"SHAP@k:Efficient and Probably Approximately Correct (PAC) Identification\n  of Top-k Features","summary":"  The SHAP framework provides a principled method to explain the predictions of\na model by computing feature importance. Motivated by applications in finance,\nwe introduce the Top-k Identification Problem (TkIP), where the objective is to\nidentify the k features with the highest SHAP values. While any method to\ncompute SHAP values with uncertainty estimates (such as KernelSHAP and\nSamplingSHAP) can be trivially adapted to solve TkIP, doing so is highly sample\ninefficient. The goal of our work is to improve the sample efficiency of\nexisting methods in the context of solving TkIP. Our key insight is that TkIP\ncan be framed as an Explore-m problem--a well-studied problem related to\nmulti-armed bandits (MAB). This connection enables us to improve sample\nefficiency by leveraging two techniques from the MAB literature: (1) a better\nstopping-condition (to stop sampling) that identifies when PAC (Probably\nApproximately Correct) guarantees have been met and (2) a greedy sampling\nscheme that judiciously allocates samples between different features. By\nadopting these methods we develop KernelSHAP@k and SamplingSHAP@k to\nefficiently solve TkIP, offering an average improvement of $5\\times$ in\nsample-efficiency and runtime across most common credit related datasets.\n","authors":["Sanjay Kariyappa","Leonidas Tsepenekas","Freddy Lécué","Daniele Magazzeni"],"pdf_url":"https://arxiv.org/pdf/2307.04850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04849v1","updated":"2023-07-10T18:40:25Z","published":"2023-07-10T18:40:25Z","title":"SigOpt Mulch: An Intelligent System for AutoML of Gradient Boosted Trees","summary":"  Gradient boosted trees (GBTs) are ubiquitous models used by researchers,\nmachine learning (ML) practitioners, and data scientists because of their\nrobust performance, interpretable behavior, and ease-of-use. One critical\nchallenge in training GBTs is the tuning of their hyperparameters. In practice,\nselecting these hyperparameters is often done manually. Recently, the ML\ncommunity has advocated for tuning hyperparameters through black-box\noptimization and developed state-of-the-art systems to do so. However, applying\nsuch systems to tune GBTs suffers from two drawbacks. First, these systems are\nnot \\textit{model-aware}, rather they are designed to apply to a\n\\textit{generic} model; this leaves significant optimization performance on the\ntable. Second, using these systems requires \\textit{domain knowledge} such as\nthe choice of hyperparameter search space, which is an antithesis to the\nautomatic experimentation that black-box optimization aims to provide. In this\npaper, we present SigOpt Mulch, a model-aware hyperparameter tuning system\nspecifically designed for automated tuning of GBTs that provides two\nimprovements over existing systems. First, Mulch leverages powerful techniques\nin metalearning and multifidelity optimization to perform model-aware\nhyperparameter optimization. Second, it automates the process of learning\nperformant hyperparameters by making intelligent decisions about the\noptimization search space, thus reducing the need for user domain knowledge.\nThese innovations allow Mulch to identify good GBT hyperparameters far more\nefficiently -- and in a more seamless and user-friendly way -- than existing\nblack-box hyperparameter tuning systems.\n","authors":["Aleksei Sorokin","Xinran Zhu","Eric Hans Lee","Bolong Cheng"],"pdf_url":"https://arxiv.org/pdf/2307.04849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04841v1","updated":"2023-07-10T18:17:50Z","published":"2023-07-10T18:17:50Z","title":"Dynamics of Temporal Difference Reinforcement Learning","summary":"  Reinforcement learning has been successful across several applications in\nwhich agents have to learn to act in environments with sparse feedback.\nHowever, despite this empirical success there is still a lack of theoretical\nunderstanding of how the parameters of reinforcement learning models and the\nfeatures used to represent states interact to control the dynamics of learning.\nIn this work, we use concepts from statistical physics, to study the typical\ncase learning curves for temporal difference learning of a value function with\nlinear function approximators. Our theory is derived under a Gaussian\nequivalence hypothesis where averages over the random trajectories are replaced\nwith temporally correlated Gaussian feature averages and we validate our\nassumptions on small scale Markov Decision Processes. We find that the\nstochastic semi-gradient noise due to subsampling the space of possible\nepisodes leads to significant plateaus in the value error, unlike in\ntraditional gradient descent dynamics. We study how learning dynamics and\nplateaus depend on feature structure, learning rate, discount factor, and\nreward function. We then analyze how strategies like learning rate annealing\nand reward shaping can favorably alter learning dynamics and plateaus. To\nconclude, our work introduces new tools to open a new direction towards\ndeveloping a theory of learning dynamics in reinforcement learning.\n","authors":["Blake Bordelon","Paul Masset","Henry Kuo","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2307.04841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12689v2","updated":"2023-07-10T10:21:58Z","published":"2020-12-23T14:19:49Z","title":"The Less Intelligent the Elements, the More Intelligent the Whole. Or,\n  Possibly Not?","summary":"  We explore a Leviathan analogy between neurons in a brain and human beings in\nsociety, asking ourselves whether individual intelligence is necessary for\ncollective intelligence to emerge and, most importantly, what sort of\nindividual intelligence is conducive of greater collective intelligence. We\nfirst review disparate insights from connectionist cognitive science,\nagent-based modeling, group psychology, economics and physics. Subsequently, we\napply these insights to the sort and degrees of intelligence that in the\nLotka-Volterra model lead to either co-existence or global extinction of\npredators and preys.\n  We find several individual behaviors -- particularly of predators -- that are\nconducive to co-existence, eventually with oscillations around an equilibrium.\nHowever, we also find that if both preys and predators are sufficiently\nintelligent to extrapolate one other's behavior, co-existence comes along with\nindefinite growth of both populations. Since the Lotka-Volterra model is also\ninterpreted to represent the business cycle, we understand this finding as a\ncondition for economic growth around oscillations. Specifically, we hypothesize\nthat pre-modern societies may not have exhibited limitless growth also because\ncapitalistic future-oriented thinking based on saving and investing concerned\nat most a fraction of the population.\n","authors":["Guido Fioretti","Andrea Policarpi"],"pdf_url":"https://arxiv.org/pdf/2012.12689v2.pdf","comment":"22 pages, 4 figures"},{"id":"http://arxiv.org/abs/2307.05360v1","updated":"2023-07-10T08:20:34Z","published":"2023-07-10T08:20:34Z","title":"Unmasking the giant: A comprehensive evaluation of ChatGPT's proficiency\n  in coding algorithms and data structures","summary":"  The transformative influence of Large Language Models (LLMs) is profoundly\nreshaping the Artificial Intelligence (AI) technology domain. Notably, ChatGPT\ndistinguishes itself within these models, demonstrating remarkable performance\nin multi-turn conversations and exhibiting code proficiency across an array of\nlanguages. In this paper, we carry out a comprehensive evaluation of ChatGPT's\ncoding capabilities based on what is to date the largest catalog of coding\nchallenges. Our focus is on the python programming language and problems\ncentered on data structures and algorithms, two topics at the very foundations\nof Computer Science. We evaluate ChatGPT for its ability to generate correct\nsolutions to the problems fed to it, its code quality, and nature of run-time\nerrors thrown by its code. Where ChatGPT code successfully executes, but fails\nto solve the problem at hand, we look into patterns in the test cases passed in\norder to gain some insights into how wrong ChatGPT code is in these kinds of\nsituations. To infer whether ChatGPT might have directly memorized some of the\ndata that was used to train it, we methodically design an experiment to\ninvestigate this phenomena. Making comparisons with human performance whenever\nfeasible, we investigate all the above questions from the context of both its\nunderlying learning models (GPT-3.5 and GPT-4), on a vast array sub-topics\nwithin the main topics, and on problems having varying degrees of difficulty.\n","authors":["Sayed Erfan Arefin","Tasnia Ashrafi Heya","Hasan Al-Qudah","Ynes Ineza","Abdul Serwadda"],"pdf_url":"https://arxiv.org/pdf/2307.05360v1.pdf","comment":null}]},"2023-07-09T00:00:00Z":{"Sound":[{"id":"http://arxiv.org/abs/2307.04172v1","updated":"2023-07-09T13:38:25Z","published":"2023-07-09T13:38:25Z","title":"Can Generative Large Language Models Perform ASR Error Correction?","summary":"  ASR error correction continues to serve as an important part of\npost-processing for speech recognition systems. Traditionally, these models are\ntrained with supervised training using the decoding results of the underlying\nASR system and the reference text. This approach is computationally intensive\nand the model needs to be re-trained when switching the underlying ASR model.\nRecent years have seen the development of large language models and their\nability to perform natural language processing tasks in a zero-shot manner. In\nthis paper, we take ChatGPT as an example to examine its ability to perform ASR\nerror correction in the zero-shot or 1-shot settings. We use the ASR N-best\nlist as model input and propose unconstrained error correction and N-best\nconstrained error correction methods. Results on a Conformer-Transducer model\nand the pre-trained Whisper model show that we can largely improve the ASR\nsystem performance with error correction using the powerful ChatGPT model.\n","authors":["Rao Ma","Mengjie Qian","Potsawee Manakul","Mark Gales","Kate Knill"],"pdf_url":"https://arxiv.org/pdf/2307.04172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01385v2","updated":"2023-07-09T06:31:46Z","published":"2023-06-02T09:11:06Z","title":"Task-Agnostic Structured Pruning of Speech Representation Models","summary":"  Self-supervised pre-trained models such as Wav2vec2, Hubert, and WavLM have\nbeen shown to significantly improve many speech tasks. However, their large\nmemory and strong computational requirements hinder their industrial\napplicability. Structured pruning is a hardware-friendly model compression\ntechnique but usually results in a larger loss of accuracy. In this paper, we\npropose a fine-grained attention head pruning method to compensate for the\nperformance degradation. In addition, we also introduce the straight through\nestimator into the L0 regularization to further accelerate the pruned model.\nExperiments on the SUPERB benchmark show that our model can achieve comparable\nperformance to the dense model in multiple tasks and outperforms the Wav2vec\n2.0 base model on average, with 72% fewer parameters and 2 times faster\ninference speed.\n","authors":["Haoyu Wang","Siyuan Wang","Wei-Qiang Zhang","Hongbin Suo","Yulong Wan"],"pdf_url":"https://arxiv.org/pdf/2306.01385v2.pdf","comment":"Accepted by INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.07848v3","updated":"2023-07-09T04:21:54Z","published":"2023-06-13T15:28:10Z","title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Speech Emotion Recognition","summary":"  Contrastive learning based pretraining methods have recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced contrastive language-audio\npretraining (CLAP) model for speech emotion recognition. To be specific, we\nfirst build an effective emotion CLAP model Emo-CLAP for emotion recognition,\nutilizing various self-supervised learning based pre-trained models. Then,\nconsidering the importance of the gender attribute in speech emotion modeling,\ntwo GEmo-CLAP approaches are further proposed to integrate the emotion and\ngender information of speech signals, forming more reasonable objectives.\nExtensive experiments on the IEMOCAP corpus demonstrate that our proposed two\nGEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with\ndifferent pre-trained models, while also achieving superior recognition\nperformance compared with other state-of-the-art methods.\n","authors":["Yu Pan","Yanni Hu","Yuguang Yang","Jixun Yao","Wen Fei","Lei Ma","Heng Lu"],"pdf_url":"https://arxiv.org/pdf/2306.07848v3.pdf","comment":"5 pages"}],"Audio and Speech Processing":[{"id":"http://arxiv.org/abs/2307.04179v1","updated":"2023-07-09T14:04:58Z","published":"2023-07-09T14:04:58Z","title":"IANS: Intelligibility-aware Null-steering Beamforming for\n  Dual-Microphone Arrays","summary":"  Beamforming techniques are popular in speech-related applications due to\ntheir effective spatial filtering capabilities. Nonetheless, conventional\nbeamforming techniques generally depend heavily on either the target's\ndirection-of-arrival (DOA), relative transfer function (RTF) or covariance\nmatrix. This paper presents a new approach, the intelligibility-aware\nnull-steering (IANS) beamforming framework, which uses the STOI-Net\nintelligibility prediction model to improve speech intelligibility without\nprior knowledge of the speech signal parameters mentioned earlier. The IANS\nframework combines a null-steering beamformer (NSBF) to generate a set of\nbeamformed outputs, and STOI-Net, to determine the optimal result. Experimental\nresults indicate that IANS can produce intelligibility-enhanced signals using a\nsmall dual-microphone array. The results are comparable to those obtained by\nnull-steering beamformers with given knowledge of DOAs.\n","authors":["Wen-Yuan Ting","Syu-Siang Wang","Yu Tsao","Borching Su"],"pdf_url":"https://arxiv.org/pdf/2307.04179v1.pdf","comment":"Preprint submitted to IEEE MLSP 2023"},{"id":"http://arxiv.org/abs/2307.04172v1","updated":"2023-07-09T13:38:25Z","published":"2023-07-09T13:38:25Z","title":"Can Generative Large Language Models Perform ASR Error Correction?","summary":"  ASR error correction continues to serve as an important part of\npost-processing for speech recognition systems. Traditionally, these models are\ntrained with supervised training using the decoding results of the underlying\nASR system and the reference text. This approach is computationally intensive\nand the model needs to be re-trained when switching the underlying ASR model.\nRecent years have seen the development of large language models and their\nability to perform natural language processing tasks in a zero-shot manner. In\nthis paper, we take ChatGPT as an example to examine its ability to perform ASR\nerror correction in the zero-shot or 1-shot settings. We use the ASR N-best\nlist as model input and propose unconstrained error correction and N-best\nconstrained error correction methods. Results on a Conformer-Transducer model\nand the pre-trained Whisper model show that we can largely improve the ASR\nsystem performance with error correction using the powerful ChatGPT model.\n","authors":["Rao Ma","Mengjie Qian","Potsawee Manakul","Mark Gales","Kate Knill"],"pdf_url":"https://arxiv.org/pdf/2307.04172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01385v2","updated":"2023-07-09T06:31:46Z","published":"2023-06-02T09:11:06Z","title":"Task-Agnostic Structured Pruning of Speech Representation Models","summary":"  Self-supervised pre-trained models such as Wav2vec2, Hubert, and WavLM have\nbeen shown to significantly improve many speech tasks. However, their large\nmemory and strong computational requirements hinder their industrial\napplicability. Structured pruning is a hardware-friendly model compression\ntechnique but usually results in a larger loss of accuracy. In this paper, we\npropose a fine-grained attention head pruning method to compensate for the\nperformance degradation. In addition, we also introduce the straight through\nestimator into the L0 regularization to further accelerate the pruned model.\nExperiments on the SUPERB benchmark show that our model can achieve comparable\nperformance to the dense model in multiple tasks and outperforms the Wav2vec\n2.0 base model on average, with 72% fewer parameters and 2 times faster\ninference speed.\n","authors":["Haoyu Wang","Siyuan Wang","Wei-Qiang Zhang","Hongbin Suo","Yulong Wan"],"pdf_url":"https://arxiv.org/pdf/2306.01385v2.pdf","comment":"Accepted by INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.07848v3","updated":"2023-07-09T04:21:54Z","published":"2023-06-13T15:28:10Z","title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Speech Emotion Recognition","summary":"  Contrastive learning based pretraining methods have recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced contrastive language-audio\npretraining (CLAP) model for speech emotion recognition. To be specific, we\nfirst build an effective emotion CLAP model Emo-CLAP for emotion recognition,\nutilizing various self-supervised learning based pre-trained models. Then,\nconsidering the importance of the gender attribute in speech emotion modeling,\ntwo GEmo-CLAP approaches are further proposed to integrate the emotion and\ngender information of speech signals, forming more reasonable objectives.\nExtensive experiments on the IEMOCAP corpus demonstrate that our proposed two\nGEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with\ndifferent pre-trained models, while also achieving superior recognition\nperformance compared with other state-of-the-art methods.\n","authors":["Yu Pan","Yanni Hu","Yuguang Yang","Jixun Yao","Wen Fei","Lei Ma","Heng Lu"],"pdf_url":"https://arxiv.org/pdf/2306.07848v3.pdf","comment":"5 pages"}],"Signal Processing":[{"id":"http://arxiv.org/abs/2307.02900v2","updated":"2023-07-09T21:31:19Z","published":"2023-07-06T10:21:14Z","title":"Meta Federated Reinforcement Learning for Distributed Resource\n  Allocation","summary":"  In cellular networks, resource allocation is usually performed in a\ncentralized way, which brings huge computation complexity to the base station\n(BS) and high transmission overhead. This paper explores a distributed resource\nallocation method that aims to maximize energy efficiency (EE) while ensuring\nthe quality of service (QoS) for users. Specifically, in order to address\nwireless channel conditions, we propose a robust meta federated reinforcement\nlearning (\\textit{MFRL}) framework that allows local users to optimize transmit\npower and assign channels using locally trained neural network models, so as to\noffload computational burden from the cloud server to the local users, reducing\ntransmission overhead associated with local channel state information. The BS\nperforms the meta learning procedure to initialize a general global model,\nenabling rapid adaptation to different environments with improved EE\nperformance. The federated learning technique, based on decentralized\nreinforcement learning, promotes collaboration and mutual benefits among users.\nAnalysis and numerical results demonstrate that the proposed \\textit{MFRL}\nframework accelerates the reinforcement learning process, decreases\ntransmission overhead, and offloads computation, while outperforming the\nconventional decentralized reinforcement learning algorithm in terms of\nconvergence speed and EE performance across various scenarios.\n","authors":["Zelin Ji","Zhijin Qin","Xiaoming Tao"],"pdf_url":"https://arxiv.org/pdf/2307.02900v2.pdf","comment":"Submitted to TWC"},{"id":"http://arxiv.org/abs/2306.09432v2","updated":"2023-07-09T20:00:54Z","published":"2023-06-15T18:23:55Z","title":"Stable Tomography for Structured Quantum States","summary":"  The reconstruction of quantum states from experimental measurements, often\nachieved using quantum state tomography (QST), is crucial for the verification\nand benchmarking of quantum devices. However, performing QST for a generic\nunstructured quantum state requires an enormous number of state copies that\ngrows \\emph{exponentially} with the number of individual quanta in the system,\neven for the most optimal measurement settings. Fortunately, many physical\nquantum states, such as states generated by noisy, intermediate-scale quantum\ncomputers, are usually structured. In one dimension, such states are expected\nto be well approximated by matrix product operators (MPOs) with a finite\nmatrix/bond dimension independent of the number of qubits, therefore enabling\nefficient state representation. Nevertheless, it is still unclear whether\nefficient QST can be performed for these states in general.\n  In this paper, we attempt to bridge this gap and establish theoretical\nguarantees for the stable recovery of MPOs using tools from compressive sensing\nand the theory of empirical processes. We begin by studying two types of random\nmeasurement settings: Gaussian measurements and Haar random rank-one Positive\nOperator Valued Measures (POVMs). We show that the information contained in an\nMPO with a finite bond dimension can be preserved using a number of random\nmeasurements that depends only \\emph{linearly} on the number of qubits,\nassuming no statistical error of the measurements. We then study MPO-based QST\nwith physical quantum measurements through Haar random rank-one POVMs that can\nbe implemented on quantum computers. We prove that only a \\emph{polynomial}\nnumber of state copies in the number of qubits is required to guarantee bounded\nrecovery error of an MPO state.\n","authors":["Zhen Qin","Casey Jameson","Zhexuan Gong","Michael B. Wakin","Zhihui Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.09432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04179v1","updated":"2023-07-09T14:04:58Z","published":"2023-07-09T14:04:58Z","title":"IANS: Intelligibility-aware Null-steering Beamforming for\n  Dual-Microphone Arrays","summary":"  Beamforming techniques are popular in speech-related applications due to\ntheir effective spatial filtering capabilities. Nonetheless, conventional\nbeamforming techniques generally depend heavily on either the target's\ndirection-of-arrival (DOA), relative transfer function (RTF) or covariance\nmatrix. This paper presents a new approach, the intelligibility-aware\nnull-steering (IANS) beamforming framework, which uses the STOI-Net\nintelligibility prediction model to improve speech intelligibility without\nprior knowledge of the speech signal parameters mentioned earlier. The IANS\nframework combines a null-steering beamformer (NSBF) to generate a set of\nbeamformed outputs, and STOI-Net, to determine the optimal result. Experimental\nresults indicate that IANS can produce intelligibility-enhanced signals using a\nsmall dual-microphone array. The results are comparable to those obtained by\nnull-steering beamformers with given knowledge of DOAs.\n","authors":["Wen-Yuan Ting","Syu-Siang Wang","Yu Tsao","Borching Su"],"pdf_url":"https://arxiv.org/pdf/2307.04179v1.pdf","comment":"Preprint submitted to IEEE MLSP 2023"},{"id":"http://arxiv.org/abs/2304.01661v3","updated":"2023-07-09T13:09:18Z","published":"2023-04-04T09:33:01Z","title":"Energy-Saving Precoder Design for Narrowband and Wideband Massive MIMO","summary":"  In this work, we study massive multiple-input multiple-output (MIMO)\nprecoders optimizing power consumption while achieving the users' rate\nrequirements. We first characterize analytically the solutions for narrowband\nand wideband systems minimizing the power amplifiers (PAs) consumption in low\nsystem load, where the per-antenna power constraints are not binding. After, we\nfocus on the asymptotic wideband regime. The power consumed by the whole base\nstation (BS) and the high-load scenario are then also investigated. We obtain\nsimple solutions, and the optimal strategy in the asymptotic case reduces to\nfinding the optimal number of active antennas, relying on known precoders among\nthe active antennas. Numerical results show that large savings in power\nconsumption are achievable in the narrowband system by employing antenna\nselection, while all antennas need to be activated in the wideband system when\nconsidering only the PAs consumption, and this implies lower savings. When\nconsidering the overall BS power consumption and a large number of subcarriers,\nwe show that significant savings are achievable in the low-load regime by using\na subset of the BS antennas. While optimization based on transmit power pushes\nto activate all antennas, optimization based on consumed power activates a\nnumber of antennas proportional to the load.\n","authors":["Emanuele Peschiera","François Rottenberg"],"pdf_url":"https://arxiv.org/pdf/2304.01661v3.pdf","comment":"To appear in IEEE Transactions on Green Communications and Networking"},{"id":"http://arxiv.org/abs/2305.06858v2","updated":"2023-07-09T12:49:08Z","published":"2023-05-11T14:53:30Z","title":"Low-Complexity Multi-Antenna Coded Caching Using Location-Aware\n  Placement Delivery Arrays","summary":"  A location-aware multi-antenna coded caching scheme is proposed for\napplications with location-dependent data requests, such as wireless immersive\nexperience, where users are immersed in a three-dimensional virtual world. The\nwireless connectivity conditions vary as the users move within the application\narea motivating the use of a non-uniform cache memory allocation process to\navoid excessive delivery time for users located in wireless bottleneck areas.\nTo this end, a location-aware placement and delivery array (LAPDA) is designed\nfor cache-aided multiantenna data delivery with a fast converging, iterative\nlinear beamforming process. The underlying weighted max-min transmit precoder\ndesign enables the proposed scheme to serve users in poor connectivity areas\nwith smaller amounts of data while simultaneously delivering larger amounts to\nother users. Our new scheme is suitable for large networks due to its linear\ntransceiver structure and it is not constrained by the number of users, cache\nsize, or the number of antennas at the transmitter, unlike the existing\nschemes. Despite non-uniform cache placement, the proposed scheme still\nachieves a significant degree of coded caching gain that is additive to the\nmultiplexing gain and greatly outperforms the conventional symmetric CC schemes\nin terms of both average and 95-percentile delivery time.\n","authors":["Hamidreza Bakhshzad Mahmoodi","MohammadJavad Salehi","Antti Tolli"],"pdf_url":"https://arxiv.org/pdf/2305.06858v2.pdf","comment":"13 pages and 8 figures"},{"id":"http://arxiv.org/abs/2307.04155v1","updated":"2023-07-09T11:56:26Z","published":"2023-07-09T11:56:26Z","title":"The WQN algorithm for EEG artifact removal in the absence of scale\n  invariance","summary":"  Electroencephalogram (EEG) signals reflect brain activity across different\nbrain states, characterized by distinct frequency distributions. Through\nmultifractal analysis tools, we investigate the scaling behaviour of different\nclasses of EEG signals and artifacts. We show that brain states associated to\nsleep and general anaesthesia are not in general characterized by scale\ninvariance. The lack of scale invariance motivates the development of artifact\nremoval algorithms capable of operating independently at each scale. We examine\nhere the properties of the wavelet quantile normalization algorithm, a recently\nintroduced adaptive method for real-time correction of transient artifacts in\nEEG signals. We establish general results regarding the regularization\nproperties of the WQN algorithm, showing how it can eliminate singularities\nintroduced by artefacts, and we compare it to traditional thresholding\nalgorithms. Furthermore, we show that the algorithm performance is independent\nof the wavelet basis. We finally examine its continuity and boundedness\nproperties and illustrate its distinctive non-local action on the wavelet\ncoefficients through pathological examples.\n","authors":["Matteo Dora","Stéphane Jaffard","David Holcman"],"pdf_url":"https://arxiv.org/pdf/2307.04155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04111v1","updated":"2023-07-09T07:08:31Z","published":"2023-07-09T07:08:31Z","title":"Model-Based End-to-End Learning for Multi-Target Integrated Sensing and\n  Communication","summary":"  We study model-based end-to-end learning in the context of integrated sensing\nand communication (ISAC) under hardware impairments. A monostatic orthogonal\nfrequency-division multiplexing (OFDM) sensing and multiple-input single-output\n(MISO) communication scenario is considered, incorporating hardware\nimperfections at the ISAC transceiver antenna array. To enable end-to-end\nlearning of the ISAC transmitter and sensing receiver, we propose a novel\ndifferentiable version of the orthogonal matching pursuit (OMP) algorithm that\nis suitable for multi-target sensing. Based on the differentiable OMP, we\ndevise two model-based parameterization strategies to account for hardware\nimpairments: (i) learning a dictionary of steering vectors for different\nangles, and (ii) learning the parameterized hardware impairments. For the\nsingle-target case, we carry out a comprehensive performance analysis of the\nproposed model-based learning approaches, a neural-network-based learning\napproach and a strong baseline consisting of least-squares beamforming,\nconventional OMP, and maximum-likelihood symbol detection for communication.\nResults show that learning the parameterized hardware impairments offers higher\ndetection probability, better angle and range estimation accuracy, lower\ncommunication symbol error rate (SER), and exhibits the lowest complexity among\nall learning methods. Lastly, we demonstrate that learning the parameterized\nhardware impairments is scalable also to multiple targets, revealing\nsignificant improvements in terms of ISAC performance over the baseline.\n","authors":["José Miguel Mateos-Ramos","Christian Häger","Musa Furkan Keskin","Luc Le Magoarou","Henk Wymeersch"],"pdf_url":"https://arxiv.org/pdf/2307.04111v1.pdf","comment":"13 pages, 10 figures, submitted to JSTSP"},{"id":"http://arxiv.org/abs/2307.05375v1","updated":"2023-07-09T09:50:34Z","published":"2023-07-09T09:50:34Z","title":"Emotion Analysis on EEG Signal Using Machine Learning and Neural Network","summary":"  Emotion has a significant influence on how one thinks and interacts with\nothers. It serves as a link between how a person feels and the actions one\ntakes, or it could be said that it influences one's life decisions on occasion.\nSince the patterns of emotions and their reflections vary from person to\nperson, their inquiry must be based on approaches that are effective over a\nwide range of population regions. To extract features and enhance accuracy,\nemotion recognition using brain waves or EEG signals requires the\nimplementation of efficient signal processing techniques. Various approaches to\nhuman-machine interaction technologies have been ongoing for a long time, and\nin recent years, researchers have had great success in automatically\nunderstanding emotion using brain signals. In our research, several emotional\nstates were classified and tested on EEG signals collected from a well-known\npublicly available dataset, the DEAP Dataset, using SVM (Support Vector\nMachine), KNN (K-Nearest Neighbor), and an advanced neural network model, RNN\n(Recurrent Neural Network), trained with LSTM (Long Short Term Memory). The\nmain purpose of this study is to improve ways to improve emotion recognition\nperformance using brain signals. Emotions, on the other hand, can change with\ntime. As a result, the changes in emotion over time are also examined in our\nresearch.\n","authors":["S. M. Masrur Ahmed","Eshaan Tanzim Sabur"],"pdf_url":"https://arxiv.org/pdf/2307.05375v1.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2307.04184v1","updated":"2023-07-09T14:18:04Z","published":"2023-07-09T14:18:04Z","title":"Intrusion Resilience Systems for Modern Vehicles","summary":"  Current vehicular Intrusion Detection and Prevention Systems either incur\nhigh false-positive rates or do not capture zero-day vulnerabilities, leading\nto safety-critical risks. In addition, prevention is limited to few primitive\noptions like dropping network packets or extreme options, e.g., ECU Bus-off\nstate. To fill this gap, we introduce the concept of vehicular Intrusion\nResilience Systems (IRS) that ensures the resilience of critical applications\ndespite assumed faults or zero-day attacks, as long as threat assumptions are\nmet. IRS enables running a vehicular application in a replicated way, i.e., as\na Replicated State Machine, over several ECUs, and then requiring the\nreplicated processes to reach a form of Byzantine agreement before changing\ntheir local state. Our study rides the mutation of modern vehicular\nenvironments, which are closing the gap between simple and resource-constrained\n\"real-time and embedded systems\", and complex and powerful \"information\ntechnology\" ones. It shows that current vehicle (e.g., Zonal) architectures and\nnetworks are becoming plausible for such modular fault and intrusion tolerance\nsolutions,deemed too heavy in the past. Our evaluation on a simulated\nAutomotive Ethernet network running two state-of-the-art agreement protocols\n(Damysus and Hotstuff) shows that the achieved latency and throughout are\nfeasible for many Automotive applications.\n","authors":["Ali Shoker","Vincent Rahli","Jeremie Decouchant","Paulo Esteves-Verissimo"],"pdf_url":"https://arxiv.org/pdf/2307.04184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05551v1","updated":"2023-07-09T09:08:38Z","published":"2023-07-09T09:08:38Z","title":"Graph Neural Network-enabled Terahertz-based Flow-guided Nanoscale\n  Localization","summary":"  Scientific advancements in nanotechnology and advanced materials are paving\nthe way toward nanoscale devices for in-body precision medicine; comprising\nintegrated sensing, computing, communication, data and energy storage\ncapabilities. In the human cardiovascular system, such devices are envisioned\nto be passively flowing and continuously sensing for detecting events of\ndiagnostic interest. The diagnostic value of detecting such events can be\nenhanced by assigning to them their physical locations (e.g., body region),\nwhich is the main proposition of flow-guided localization. Current flow-guided\nlocalization approaches suffer from low localization accuracy and they are\nby-design unable to localize events within the entire cardiovascular system.\nToward addressing this issue, we propose the utilization of Graph Neural\nNetworks (GNNs) for this purpose, and demonstrate localization accuracy and\ncoverage enhancements of our proposal over the existing State of the Art (SotA)\napproaches. Based on our evaluation, we provide several design guidelines for\nGNN-enabled flow-guided localization.\n","authors":["Gerard Calvo Bartra","Filip Lemic","Sergi Abadal","Xavier Costa Perez"],"pdf_url":"https://arxiv.org/pdf/2307.05551v1.pdf","comment":"6 pages, 5 figures, 1 table, 15 references. arXiv admin note: text\n  overlap with arXiv:2305.18493"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2307.04280v1","updated":"2023-07-09T23:12:08Z","published":"2023-07-09T23:12:08Z","title":"Shaping the Emerging Norms of Using Large Language Models in Social\n  Computing Research","summary":"  The emergence of Large Language Models (LLMs) has brought both excitement and\nconcerns to social computing research. On the one hand, LLMs offer\nunprecedented capabilities in analyzing vast amounts of textual data and\ngenerating human-like responses, enabling researchers to delve into complex\nsocial phenomena. On the other hand, concerns are emerging regarding the\nvalidity, privacy, and ethics of the research when LLMs are involved. This SIG\naims at offering an open space for social computing researchers who are\ninterested in understanding the impacts of LLMs to discuss their current\npractices, perspectives, challenges when engaging with LLMs in their everyday\nwork and collectively shaping the emerging norms of using LLMs in social\ncomputing research.\n","authors":["Hong Shen","Tianshi Li","Toby Jia-Jun Li","Joon Sung Park","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2307.04280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04247v1","updated":"2023-07-09T18:53:38Z","published":"2023-07-09T18:53:38Z","title":"VR Job Interview Using a Gender-Swapped Avatar","summary":"  Virtual Reality (VR) has emerged as a potential solution for mitigating bias\nin a job interview by hiding the applicants' demographic features. The current\nstudy examines the use of a gender-swapped avatar in a virtual job interview\nthat affects the applicants' perceptions and their performance evaluated by\nrecruiters. With a mixed-method approach, we first conducted a lab experiment\n(N=8) exploring how using a gender-swapped avatar in a virtual job interview\nimpacts perceived anxiety, confidence, competence, and ability to perform.\nThen, a semi-structured interview investigated the participants' VR interview\nexperiences using an avatar. Our findings suggest that using gender-swapped\navatars may reduce the anxiety that job applicants will experience during the\ninterview. Also, the affinity diagram produced seven key themes highlighting\nthe advantages and limitations of VR as an interview platform. These findings\ncontribute to the emerging field of VR-based recruitment and have practical\nimplications for promoting diversity and inclusion in the hiring process.\n","authors":["Jieun Kim","Hauke Sandhaus","Susan R. Fussell"],"pdf_url":"https://arxiv.org/pdf/2307.04247v1.pdf","comment":"CSCW 2022 Posters"},{"id":"http://arxiv.org/abs/2307.04195v1","updated":"2023-07-09T15:02:34Z","published":"2023-07-09T15:02:34Z","title":"Natural Language Instructions for Intuitive Human Interaction with\n  Robotic Assistants in Field Construction Work","summary":"  The introduction of robots is widely considered to have significant potential\nof alleviating the issues of worker shortage and stagnant productivity that\nafflict the construction industry. However, it is challenging to use fully\nautomated robots in complex and unstructured construction sites. Human-Robot\nCollaboration (HRC) has shown promise of combining human workers' flexibility\nand robot assistants' physical abilities to jointly address the uncertainties\ninherent in construction work. When introducing HRC in construction, it is\ncritical to recognize the importance of teamwork and supervision in field\nconstruction and establish a natural and intuitive communication system for the\nhuman workers and robotic assistants. Natural language-based interaction can\nenable intuitive and familiar communication with robots for human workers who\nare non-experts in robot programming. However, limited research has been\nconducted on this topic in construction. This paper proposes a framework to\nallow human workers to interact with construction robots based on natural\nlanguage instructions. The proposed method consists of three stages: Natural\nLanguage Understanding (NLU), Information Mapping (IM), and Robot Control (RC).\nNatural language instructions are input to a language model to predict a tag\nfor each word in the NLU module. The IM module uses the result of the NLU\nmodule and building component information to generate the final instructional\noutput essential for a robot to acknowledge and perform the construction task.\nA case study for drywall installation is conducted to evaluate the proposed\napproach. The obtained results highlight the potential of using natural\nlanguage-based interaction to replicate the communication that occurs between\nhuman workers within the context of human-robot teams.\n","authors":["Somin Park","Xi Wang","Carol C. Menassa","Vineet R. Kamat","Joyce Y. Chai"],"pdf_url":"https://arxiv.org/pdf/2307.04195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.07013v3","updated":"2023-07-09T13:51:56Z","published":"2023-04-14T09:17:27Z","title":"Smart Dimming Sunglasses for Photophobia Using Spatial Light Modulator","summary":"  We introduce a smart dimming sunglasses system designed for photophobia\nsufferers, particularly those highly sensitive to light intensity. The system\nincorporates a spatial light modulator (SLM) to filter light based on\ncamera-detected scenes, controlling pixel transmittance via a modulation\nfunction for automated non-linear field of view dimming, thus offering flexible\nlight modulation to meet the visual needs of photophobic users. However, a\nconventional occlusion mask on the SLM, aimed at blocking incoming light,\nappears blurred and insufficient due to a misaligned focal plane. Previous\nattempts to remedy this with an aperture-based expanded mask led to\nover-blocking (occlusion leak), due to an excessively large expansion radius.\nOur work, therefore, focuses on developing an optimization model that simulates\na defocused occlusion mask and determines the degraded pixels' effective\ncontribution by studying pixel transmittance occlusion efficiency. This\noptimized mask successfully attenuates bright areas to appropriate brightness\nlevels without unnecessary attenuation of areas that do not require modulation,\novercoming the limitations of both the unprocessed and aperture-based expanded\nmasks.\n","authors":["Xiaodan Hu","Yan Zhang","Naoya Isoyama","Hideaki Uchiyama","Nobuchika Sakata","Kiyoshi Kiyokawa"],"pdf_url":"https://arxiv.org/pdf/2304.07013v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13374v2","updated":"2023-07-09T11:01:01Z","published":"2023-06-23T08:53:41Z","title":"Human Activity Behavioural Pattern Recognition in Smarthome with\n  Long-hour Data Collection","summary":"  The research on human activity recognition has provided novel solutions to\nmany applications like healthcare, sports, and user profiling. Considering the\ncomplex nature of human activities, it is still challenging even after\neffective and efficient sensors are available. The existing works on human\nactivity recognition using smartphone sensors focus on recognizing basic human\nactivities like sitting, sleeping, standing, stair up and down and running.\nHowever, more than these basic activities is needed to analyze human\nbehavioural pattern. The proposed framework recognizes basic human activities\nusing deep learning models. Also, ambient sensors like PIR, pressure sensors,\nand smartphone-based sensors like accelerometers and gyroscopes are combined to\nmake it hybrid-sensor-based human activity recognition. The hybrid approach\nhelped derive more activities than the basic ones, which also helped derive\nhuman activity patterns or user profiling. User profiling provides sufficient\ninformation to identify daily living activity patterns and predict whether any\nanomaly exists. The framework provides the base for applications such as\nelderly monitoring when they are alone at home. The GRU model's accuracy of\n95\\% is observed to recognize the basic activities. Finally, Human activity\npatterns over time are recognized based on the duration and frequency of the\nactivities. It is observed that human activity pattern, like, morning walking\nduration, varies depending on the day of the week.\n","authors":["Ranjit Kolkar","Geetha V"],"pdf_url":"https://arxiv.org/pdf/2306.13374v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05375v1","updated":"2023-07-09T09:50:34Z","published":"2023-07-09T09:50:34Z","title":"Emotion Analysis on EEG Signal Using Machine Learning and Neural Network","summary":"  Emotion has a significant influence on how one thinks and interacts with\nothers. It serves as a link between how a person feels and the actions one\ntakes, or it could be said that it influences one's life decisions on occasion.\nSince the patterns of emotions and their reflections vary from person to\nperson, their inquiry must be based on approaches that are effective over a\nwide range of population regions. To extract features and enhance accuracy,\nemotion recognition using brain waves or EEG signals requires the\nimplementation of efficient signal processing techniques. Various approaches to\nhuman-machine interaction technologies have been ongoing for a long time, and\nin recent years, researchers have had great success in automatically\nunderstanding emotion using brain signals. In our research, several emotional\nstates were classified and tested on EEG signals collected from a well-known\npublicly available dataset, the DEAP Dataset, using SVM (Support Vector\nMachine), KNN (K-Nearest Neighbor), and an advanced neural network model, RNN\n(Recurrent Neural Network), trained with LSTM (Long Short Term Memory). The\nmain purpose of this study is to improve ways to improve emotion recognition\nperformance using brain signals. Emotions, on the other hand, can change with\ntime. As a result, the changes in emotion over time are also examined in our\nresearch.\n","authors":["S. M. Masrur Ahmed","Eshaan Tanzim Sabur"],"pdf_url":"https://arxiv.org/pdf/2307.05375v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2305.18451v2","updated":"2023-07-09T23:33:19Z","published":"2023-05-29T04:02:10Z","title":"Shift-Robust Molecular Relational Learning with Causal Substructure","summary":"  Recently, molecular relational learning, whose goal is to predict the\ninteraction behavior between molecular pairs, got a surge of interest in\nmolecular sciences due to its wide range of applications. In this work, we\npropose CMRL that is robust to the distributional shift in molecular relational\nlearning by detecting the core substructure that is causally related to\nchemical reactions. To do so, we first assume a causal relationship based on\nthe domain knowledge of molecular sciences and construct a structural causal\nmodel (SCM) that reveals the relationship between variables. Based on the SCM,\nwe introduce a novel conditional intervention framework whose intervention is\nconditioned on the paired molecule. With the conditional intervention\nframework, our model successfully learns from the causal substructure and\nalleviates the confounding effect of shortcut substructures that are spuriously\ncorrelated to chemical reactions. Extensive experiments on various tasks with\nreal-world and synthetic datasets demonstrate the superiority of CMRL over\nstate-of-the-art baseline models. Our code is available at\nhttps://github.com/Namkyeong/CMRL.\n","authors":["Namkyeong Lee","Kanghoon Yoon","Gyoung S. Na","Sein Kim","Chanyoung Park"],"pdf_url":"https://arxiv.org/pdf/2305.18451v2.pdf","comment":"KDD 2023"},{"id":"http://arxiv.org/abs/2306.01505v2","updated":"2023-07-09T23:27:27Z","published":"2023-06-02T12:52:38Z","title":"Supervised Adversarial Contrastive Learning for Emotion Recognition in\n  Conversations","summary":"  Extracting generalized and robust representations is a major challenge in\nemotion recognition in conversations (ERC). To address this, we propose a\nsupervised adversarial contrastive learning (SACL) framework for learning\nclass-spread structured representations in a supervised manner. SACL applies\ncontrast-aware adversarial training to generate worst-case samples and uses\njoint class-spread contrastive learning to extract structured representations.\nIt can effectively utilize label-level feature consistency and retain\nfine-grained intra-class features. To avoid the negative impact of adversarial\nperturbations on context-dependent data, we design a contextual adversarial\ntraining (CAT) strategy to learn more diverse features from context and enhance\nthe model's context robustness. Under the framework with CAT, we develop a\nsequence-based SACL-LSTM to learn label-consistent and context-robust features\nfor ERC. Experiments on three datasets show that SACL-LSTM achieves\nstate-of-the-art performance on ERC. Extended experiments prove the\neffectiveness of SACL and CAT.\n","authors":["Dou Hu","Yinan Bao","Lingwei Wei","Wei Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2306.01505v2.pdf","comment":"16 pages, accepted by ACL 2023"},{"id":"http://arxiv.org/abs/2306.08861v2","updated":"2023-07-09T22:01:26Z","published":"2023-06-15T05:12:54Z","title":"Motion Capture Dataset for Practical Use of AI-based Motion Editing and\n  Stylization","summary":"  In this work, we proposed a new style-diverse dataset for the domain of\nmotion style transfer. The motion dataset uses an industrial-standard human\nbone structure and thus is industry-ready to be plugged into 3D characters for\nmany projects. We claim the challenges in motion style transfer and encourage\nfuture work in this domain by releasing the proposed motion dataset both to the\npublic and the market. We conduct a comprehensive study on motion style\ntransfer in the experiment using the state-of-the-art method, and the results\nshow the proposed dataset's validity for the motion style transfer task.\n","authors":["Makito Kobayashi","Chen-Chieh Liao","Keito Inoue","Sentaro Yojima","Masafumi Takahashi"],"pdf_url":"https://arxiv.org/pdf/2306.08861v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04251v1","updated":"2023-07-09T19:28:46Z","published":"2023-07-09T19:28:46Z","title":"ChatGPT in the Age of Generative AI and Large Language Models: A Concise\n  Survey","summary":"  ChatGPT is a large language model (LLM) created by OpenAI that has been\ncarefully trained on a large amount of data. It has revolutionized the field of\nnatural language processing (NLP) and has pushed the boundaries of LLM\ncapabilities. ChatGPT has played a pivotal role in enabling widespread public\ninteraction with generative artificial intelligence (GAI) on a large scale. It\nhas also sparked research interest in developing similar technologies and\ninvestigating their applications and implications. In this paper, our primary\ngoal is to provide a concise survey on the current lines of research on ChatGPT\nand its evolution. We considered both the glass box and black box views of\nChatGPT, encompassing the components and foundational elements of the\ntechnology, as well as its applications, impacts, and implications. The glass\nbox approach focuses on understanding the inner workings of the technology, and\nthe black box approach embraces it as a complex system, and thus examines its\ninputs, outputs, and effects. This paves the way for a comprehensive\nexploration of the technology and provides a road map for further research and\nexperimentation. We also lay out essential foundational literature on LLMs and\nGAI in general and their connection with ChatGPT. This overview sheds light on\nexisting and missing research lines in the emerging field of LLMs, benefiting\nboth public users and developers. Furthermore, the paper delves into the broad\nspectrum of applications and significant concerns in fields such as education,\nresearch, healthcare, finance, etc.\n","authors":["Salman Mohamadi","Ghulam Mujtaba","Ngan Le","Gianfranco Doretto","Donald A. Adjeroh"],"pdf_url":"https://arxiv.org/pdf/2307.04251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01828v2","updated":"2023-07-09T18:57:45Z","published":"2023-01-04T21:33:13Z","title":"On Sequential Bayesian Inference for Continual Learning","summary":"  Sequential Bayesian inference can be used for continual learning to prevent\ncatastrophic forgetting of past tasks and provide an informative prior when\nlearning new tasks. We revisit sequential Bayesian inference and test whether\nhaving access to the true posterior is guaranteed to prevent catastrophic\nforgetting in Bayesian neural networks. To do this we perform sequential\nBayesian inference using Hamiltonian Monte Carlo. We propagate the posterior as\na prior for new tasks by fitting a density estimator on Hamiltonian Monte Carlo\nsamples. We find that this approach fails to prevent catastrophic forgetting\ndemonstrating the difficulty in performing sequential Bayesian inference in\nneural networks. From there we study simple analytical examples of sequential\nBayesian inference and CL and highlight the issue of model misspecification\nwhich can lead to sub-optimal continual learning performance despite exact\ninference. Furthermore, we discuss how task data imbalances can cause\nforgetting. From these limitations, we argue that we need probabilistic models\nof the continual learning generative process rather than relying on sequential\nBayesian inference over Bayesian neural network weights. In this vein, we also\npropose a simple baseline called Prototypical Bayesian Continual Learning,\nwhich is competitive with state-of-the-art Bayesian continual learning methods\non class incremental continual learning vision benchmarks.\n","authors":["Samuel Kessler","Adam Cobb","Tim G. J. Rudner","Stefan Zohren","Stephen J. Roberts"],"pdf_url":"https://arxiv.org/pdf/2301.01828v2.pdf","comment":"Published in Entropy, 24 pages, 14 figures"},{"id":"http://arxiv.org/abs/2306.15079v2","updated":"2023-07-09T18:54:14Z","published":"2023-06-26T21:39:14Z","title":"From $O(\\sqrt{n})$ to $O(\\log(n))$ in Quadratic Programming","summary":"  A \"dark cloud\" hangs over numerical optimization theory for decades, namely,\nwhether an optimization algorithm $O(\\log(n))$ iteration complexity exists.\n\"Yes\", this paper answers, with a new optimization algorithm and strict theory\nproof. It starts with box-constrained quadratic programming (Box-QP), and many\npractical optimization problems fall into Box-QP. General smooth quadratic\nprogramming (QP), nonsmooth Lasso, and support vector machine (or regression)\ncan be reformulated as Box-QP via duality theory. It is the first time to\npresent an $O(\\log(n))$ iteration complexity QP algorithm, in particular, which\nbehaves like a \"direct\" method: the required number of iterations is\ndeterministic with exact value\n$\\left\\lceil\\log\\left(\\frac{3.125n}{\\epsilon}\\right)/\\log(1.5625)\\right\\rceil$.\nThis significant breakthrough enables us to transition from the $O(\\sqrt{n})$\nto the $O(\\log(n))$ optimization algorithm, whose amazing scalability is\nparticularly relevant in today's era of big data and artificial intelligence.\n","authors":["Liang Wu"],"pdf_url":"https://arxiv.org/pdf/2306.15079v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04245v1","updated":"2023-07-09T18:51:17Z","published":"2023-07-09T18:51:17Z","title":"A Novel Pipeline for Improving Optical Character Recognition through\n  Post-processing Using Natural Language Processing","summary":"  Optical Character Recognition (OCR) technology finds applications in\ndigitizing books and unstructured documents, along with applications in other\ndomains such as mobility statistics, law enforcement, traffic, security\nsystems, etc. The state-of-the-art methods work well with the OCR with printed\ntext on license plates, shop names, etc. However, applications such as printed\ntextbooks and handwritten texts have limited accuracy with existing techniques.\nThe reason may be attributed to similar-looking characters and variations in\nhandwritten characters. Since these issues are challenging to address with OCR\ntechnologies exclusively, we propose a post-processing approach using Natural\nLanguage Processing (NLP) tools. This work presents an end-to-end pipeline that\nfirst performs OCR on the handwritten or printed text and then improves its\naccuracy using NLP.\n","authors":["Aishik Rakshit","Samyak Mehta","Anirban Dasgupta"],"pdf_url":"https://arxiv.org/pdf/2307.04245v1.pdf","comment":"Accepted in IEEE GCON (IEEE Guwahati Subsection Conference) 2023"},{"id":"http://arxiv.org/abs/2111.11089v2","updated":"2023-07-09T18:38:07Z","published":"2021-11-22T10:03:41Z","title":"Monocular Road Planar Parallax Estimation","summary":"  Estimating the 3D structure of the drivable surface and surrounding\nenvironment is a crucial task for assisted and autonomous driving. It is\ncommonly solved either by using 3D sensors such as LiDAR or directly predicting\nthe depth of points via deep learning. However, the former is expensive, and\nthe latter lacks the use of geometry information for the scene. In this paper,\ninstead of following existing methodologies, we propose Road Planar Parallax\nAttention Network (RPANet), a new deep neural network for 3D sensing from\nmonocular image sequences based on planar parallax, which takes full advantage\nof the omnipresent road plane geometry in driving scenes. RPANet takes a pair\nof images aligned by the homography of the road plane as input and outputs a\n$\\gamma$ map (the ratio of height to depth) for 3D reconstruction. The $\\gamma$\nmap has the potential to construct a two-dimensional transformation between two\nconsecutive frames. It implies planar parallax and can be combined with the\nroad plane serving as a reference to estimate the 3D structure by warping the\nconsecutive frames. Furthermore, we introduce a novel cross-attention module to\nmake the network better perceive the displacements caused by planar parallax.\nTo verify the effectiveness of our method, we sample data from the Waymo Open\nDataset and construct annotations related to planar parallax. Comprehensive\nexperiments are conducted on the sampled dataset to demonstrate the 3D\nreconstruction accuracy of our approach in challenging scenarios.\n","authors":["Haobo Yuan","Teng Chen","Wei Sui","Jiafeng Xie","Lefei Zhang","Yuan Li","Qian Zhang"],"pdf_url":"https://arxiv.org/pdf/2111.11089v2.pdf","comment":"Accepted by IEEE TIP"},{"id":"http://arxiv.org/abs/2208.10264v5","updated":"2023-07-09T18:27:27Z","published":"2022-08-18T17:54:49Z","title":"Using Large Language Models to Simulate Multiple Humans and Replicate\n  Human Subject Studies","summary":"  We introduce a new type of test, called a Turing Experiment (TE), for\nevaluating to what extent a given language model, such as GPT models, can\nsimulate different aspects of human behavior. A TE can also reveal consistent\ndistortions in a language model's simulation of a specific human behavior.\nUnlike the Turing Test, which involves simulating a single arbitrary\nindividual, a TE requires simulating a representative sample of participants in\nhuman subject research. We carry out TEs that attempt to replicate\nwell-established findings from prior studies. We design a methodology for\nsimulating TEs and illustrate its use to compare how well different language\nmodels are able to reproduce classic economic, psycholinguistic, and social\npsychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock\nExperiment, and Wisdom of Crowds. In the first three TEs, the existing findings\nwere replicated using recent models, while the last TE reveals a\n\"hyper-accuracy distortion\" present in some language models (including ChatGPT\nand GPT-4), which could affect downstream applications in education and the\narts.\n","authors":["Gati Aher","Rosa I. Arriaga","Adam Tauman Kalai"],"pdf_url":"https://arxiv.org/pdf/2208.10264v5.pdf","comment":"Accepted for oral presentation at International Conference on Machine\n  Learning (ICML) 2023"},{"id":"http://arxiv.org/abs/2304.00008v3","updated":"2023-07-09T18:00:02Z","published":"2023-03-27T18:00:01Z","title":"On the Creativity of Large Language Models","summary":"  Large Language Models (LLMs) are revolutionizing several areas of Artificial\nIntelligence. One of the most remarkable applications is creative writing,\ne.g., poetry or storytelling: the generated outputs are often of astonishing\nquality. However, a natural question arises: can LLMs be really considered\ncreative? In this article we firstly analyze the development of LLMs under the\nlens of creativity theories, investigating the key open questions and\nchallenges. In particular, we focus our discussion around the dimensions of\nvalue, novelty and surprise as proposed by Margaret Boden in her work. Then, we\nconsider different classic perspectives, namely product, process, press and\nperson. We discuss a set of ``easy'' and ``hard'' problems in machine\ncreativity, presenting them in relation to LLMs. Finally, we examine the\nsocietal impact of these technologies with a particular focus on the creative\nindustries, analyzing the opportunities offered by them, the challenges arising\nby them and the potential associated risks, from both legal and ethical points\nof view.\n","authors":["Giorgio Franceschelli","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2304.00008v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16575v3","updated":"2023-07-09T16:42:37Z","published":"2022-10-29T11:34:17Z","title":"Self-Improving Safety Performance of Reinforcement Learning Based\n  Driving with Black-Box Verification Algorithms","summary":"  In this work, we propose a self-improving artificial intelligence system to\nenhance the safety performance of reinforcement learning (RL)-based autonomous\ndriving (AD) agents using black-box verification methods. RL algorithms have\nbecome popular in AD applications in recent years. However, the performance of\nexisting RL algorithms heavily depends on the diversity of training scenarios.\nA lack of safety-critical scenarios during the training phase could result in\npoor generalization performance in real-world driving applications. We propose\na novel framework in which the weaknesses of the training set are explored\nthrough black-box verification methods. After discovering AD failure scenarios,\nthe RL agent's training is re-initiated via transfer learning to improve the\nperformance of previously unsafe scenarios. Simulation results demonstrate that\nour approach efficiently discovers safety failures of action decisions in\nRL-based adaptive cruise control (ACC) applications and significantly reduces\nthe number of vehicle collisions through iterative applications of our method.\nThe source code is publicly available at\nhttps://github.com/data-and-decision-lab/self-improving-RL.\n","authors":["Resul Dagdanov","Halil Durmus","Nazim Kemal Ure"],"pdf_url":"https://arxiv.org/pdf/2210.16575v3.pdf","comment":"7 pages, 7 figures, 2 tables, published in IEEE International\n  Conference on Robotics and Automation (ICRA), June 2, 2023, London, UK"},{"id":"http://arxiv.org/abs/2307.04223v1","updated":"2023-07-09T16:28:57Z","published":"2023-07-09T16:28:57Z","title":"Real-time Human Detection in Fire Scenarios using Infrared and Thermal\n  Imaging Fusion","summary":"  Fire is considered one of the most serious threats to human lives which\nresults in a high probability of fatalities. Those severe consequences stem\nfrom the heavy smoke emitted from a fire that mostly restricts the visibility\nof escaping victims and rescuing squad. In such hazardous circumstances, the\nuse of a vision-based human detection system is able to improve the ability to\nsave more lives. To this end, a thermal and infrared imaging fusion strategy\nbased on multiple cameras for human detection in low-visibility scenarios\ncaused by smoke is proposed in this paper. By processing with multiple cameras,\nvital information can be gathered to generate more useful features for human\ndetection. Firstly, the cameras are calibrated using a Light Heating\nChessboard. Afterward, the features extracted from the input images are merged\nprior to being passed through a lightweight deep neural network to perform the\nhuman detection task. The experiments conducted on an NVIDIA Jetson Nano\ncomputer demonstrated that the proposed method can process with reasonable\nspeed and can achieve favorable performance with a mAP@0.5 of 95%.\n","authors":["Truong-Dong Do","Nghe-Nhan Truong","My-Ha Le"],"pdf_url":"https://arxiv.org/pdf/2307.04223v1.pdf","comment":"5 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2307.04217v1","updated":"2023-07-09T16:16:11Z","published":"2023-07-09T16:16:11Z","title":"LakeBench: Benchmarks for Data Discovery over Data Lakes","summary":"  Within enterprises, there is a growing need to intelligently navigate data\nlakes, specifically focusing on data discovery. Of particular importance to\nenterprises is the ability to find related tables in data repositories. These\ntables can be unionable, joinable, or subsets of each other. There is a dearth\nof benchmarks for these tasks in the public domain, with related work targeting\nprivate datasets. In LakeBench, we develop multiple benchmarks for these tasks\nby using the tables that are drawn from a diverse set of data sources such as\ngovernment data from CKAN, Socrata, and the European Central Bank. We compare\nthe performance of 4 publicly available tabular foundational models on these\ntasks. None of the existing models had been trained on the data discovery tasks\nthat we developed for this benchmark; not surprisingly, their performance shows\nsignificant room for improvement. The results suggest that the establishment of\nsuch benchmarks may be useful to the community to build tabular models usable\nfor data discovery in data lakes.\n","authors":["Kavitha Srinivas","Julian Dolby","Ibrahim Abdelaziz","Oktie Hassanzadeh","Harsha Kokel","Aamod Khatiwada","Tejaswini Pedapati","Subhajit Chaudhury","Horst Samulowitz"],"pdf_url":"https://arxiv.org/pdf/2307.04217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04216v1","updated":"2023-07-09T16:11:02Z","published":"2023-07-09T16:11:02Z","title":"Hierarchical Autoencoder-based Lossy Compression for Large-scale\n  High-resolution Scientific Data","summary":"  Lossy compression has become an important technique to reduce data size in\nmany domains. This type of compression is especially valuable for large-scale\nscientific data, whose size ranges up to several petabytes. Although\nAutoencoder-based models have been successfully leveraged to compress images\nand videos, such neural networks have not widely gained attention in the\nscientific data domain. Our work presents a neural network that not only\nsignificantly compresses large-scale scientific data but also maintains high\nreconstruction quality. The proposed model is tested with scientific benchmark\ndata available publicly and applied to a large-scale high-resolution climate\nmodeling data set. Our model achieves a compression ratio of 140 on several\nbenchmark data sets without compromising the reconstruction quality. Simulation\ndata from the High-Resolution Community Earth System Model (CESM) Version 1.3\nover 500 years are also being compressed with a compression ratio of 200 while\nthe reconstruction error is negligible for scientific analysis.\n","authors":["Hieu Le","Hernan Santos","Jian Tao"],"pdf_url":"https://arxiv.org/pdf/2307.04216v1.pdf","comment":"15 pages, 15 figures"},{"id":"http://arxiv.org/abs/2307.04208v1","updated":"2023-07-09T15:42:22Z","published":"2023-07-09T15:42:22Z","title":"On the Challenges of Deploying Privacy-Preserving Synthetic Data in the\n  Enterprise","summary":"  Generative AI technologies are gaining unprecedented popularity, causing a\nmix of excitement and apprehension through their remarkable capabilities. In\nthis paper, we study the challenges associated with deploying synthetic data, a\nsubfield of Generative AI. Our focus centers on enterprise deployment, with an\nemphasis on privacy concerns caused by the vast amount of personal and highly\nsensitive data. We identify 40+ challenges and systematize them into five main\ngroups -- i) generation, ii) infrastructure & architecture, iii) governance,\niv) compliance & regulation, and v) adoption. Additionally, we discuss a\nstrategic and systematic approach that enterprises can employ to effectively\naddress the challenges and achieve their goals by establishing trust in the\nimplemented solutions.\n","authors":["Lauren Arthur","Jason Costello","Jonathan Hardy","Will O'Brien","James Rea","Gareth Rees","Georgi Ganev"],"pdf_url":"https://arxiv.org/pdf/2307.04208v1.pdf","comment":"Accepted to the 1st Workshop on Challenges in Deployable Generative\n  AI, part of ICML 2023"},{"id":"http://arxiv.org/abs/2307.04195v1","updated":"2023-07-09T15:02:34Z","published":"2023-07-09T15:02:34Z","title":"Natural Language Instructions for Intuitive Human Interaction with\n  Robotic Assistants in Field Construction Work","summary":"  The introduction of robots is widely considered to have significant potential\nof alleviating the issues of worker shortage and stagnant productivity that\nafflict the construction industry. However, it is challenging to use fully\nautomated robots in complex and unstructured construction sites. Human-Robot\nCollaboration (HRC) has shown promise of combining human workers' flexibility\nand robot assistants' physical abilities to jointly address the uncertainties\ninherent in construction work. When introducing HRC in construction, it is\ncritical to recognize the importance of teamwork and supervision in field\nconstruction and establish a natural and intuitive communication system for the\nhuman workers and robotic assistants. Natural language-based interaction can\nenable intuitive and familiar communication with robots for human workers who\nare non-experts in robot programming. However, limited research has been\nconducted on this topic in construction. This paper proposes a framework to\nallow human workers to interact with construction robots based on natural\nlanguage instructions. The proposed method consists of three stages: Natural\nLanguage Understanding (NLU), Information Mapping (IM), and Robot Control (RC).\nNatural language instructions are input to a language model to predict a tag\nfor each word in the NLU module. The IM module uses the result of the NLU\nmodule and building component information to generate the final instructional\noutput essential for a robot to acknowledge and perform the construction task.\nA case study for drywall installation is conducted to evaluate the proposed\napproach. The obtained results highlight the potential of using natural\nlanguage-based interaction to replicate the communication that occurs between\nhuman workers within the context of human-robot teams.\n","authors":["Somin Park","Xi Wang","Carol C. Menassa","Vineet R. Kamat","Joyce Y. Chai"],"pdf_url":"https://arxiv.org/pdf/2307.04195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04192v1","updated":"2023-07-09T14:54:30Z","published":"2023-07-09T14:54:30Z","title":"SAS Video-QA: Self-Adaptive Sampling for Efficient Video\n  Question-Answering","summary":"  Video question--answering is a fundamental task in the field of video\nunderstanding. Although current vision--language models (VLMs) equipped with\nVideo Transformers have enabled temporal modeling and yielded superior results,\nthey are at the cost of huge computational power and thus too expensive to\ndeploy in real-time application scenarios. An economical workaround only\nsamples a small portion of frames to represent the main content of that video\nand tune an image--text model on these sampled frames. Recent video\nunderstanding models usually randomly sample a set of frames or clips,\nregardless of internal correlations between their visual contents, nor their\nrelevance to the problem. We argue that such kinds of aimless sampling may omit\nthe key frames from which the correct answer can be deduced, and the situation\ngets worse when the sampling sparsity increases, which always happens as the\nvideo lengths increase. To mitigate this issue, we propose two frame sampling\nstrategies, namely the most domain frames (MDF) and most implied frames (MIF),\nto maximally preserve those frames that are most likely vital to the given\nquestions. MDF passively minimizes the risk of key frame omission in a\nbootstrap manner, while MIS actively searches key frames customized for each\nvideo--question pair with the assistance of auxiliary models. The experimental\nresults on three public datasets from three advanced VLMs (CLIP, GIT and\nAll-in-one) demonstrate that our proposed strategies can boost the performance\nfor image--text pretrained models. The source codes pertaining to the method\nproposed in this paper are publicly available at\nhttps://github.com/declare-lab/sas-vqa.\n","authors":["Wei Han","Hui Chen","Min-Yen Kan","Soujanya Poria"],"pdf_url":"https://arxiv.org/pdf/2307.04192v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.13485v2","updated":"2023-07-09T12:36:50Z","published":"2023-02-27T02:49:06Z","title":"FedCLIP: Fast Generalization and Personalization for CLIP in Federated\n  Learning","summary":"  Federated learning (FL) has emerged as a new paradigm for privacy-preserving\ncomputation in recent years. Unfortunately, FL faces two critical challenges\nthat hinder its actual performance: data distribution heterogeneity and high\nresource costs brought by large foundation models. Specifically, the non-IID\ndata in different clients make existing FL algorithms hard to converge while\nthe high resource costs, including computational and communication costs that\nincrease the deployment difficulty in real-world scenarios. In this paper, we\npropose an effective yet simple method, named FedCLIP, to achieve fast\ngeneralization and personalization for CLIP in federated learning. Concretely,\nwe design an attention-based adapter for the large model, CLIP, and the rest\noperations merely depend on adapters. Lightweight adapters can make the most\nuse of pretrained model information and ensure models be adaptive for clients\nin specific tasks. Simultaneously, small-scale operations can mitigate the\ncomputational burden and communication burden caused by large models. Extensive\nexperiments are conducted on three datasets with distribution shifts.\nQualitative and quantitative results demonstrate that FedCLIP significantly\noutperforms other baselines (9% overall improvements on PACS) and effectively\nreduces computational and communication costs (283x faster than FedAVG). Our\ncode will be available at: https://github.com/microsoft/PersonalizedFL.\n","authors":["Wang Lu","Xixu Hu","Jindong Wang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2302.13485v2.pdf","comment":"Accepted by IEEE Data Engineering Bulletin; code is at:\n  https://github.com/microsoft/PersonalizedFL"},{"id":"http://arxiv.org/abs/2112.08581v5","updated":"2023-07-09T12:19:54Z","published":"2021-12-16T03:00:20Z","title":"Mathematical Runtime Analysis for the Non-Dominated Sorting Genetic\n  Algorithm II (NSGA-II)","summary":"  The non-dominated sorting genetic algorithm II (NSGA-II) is the most\nintensively used multi-objective evolutionary algorithm (MOEA) in real-world\napplications. However, in contrast to several simple MOEAs analyzed also via\nmathematical means, no such study exists for the NSGA-II so far. In this work,\nwe show that mathematical runtime analyses are feasible also for the NSGA-II.\nAs particular results, we prove that with a population size four times larger\nthan the size of the Pareto front, the NSGA-II with two classic mutation\noperators and four different ways to select the parents satisfies the same\nasymptotic runtime guarantees as the SEMO and GSEMO algorithms on the basic\nOneMinMax and LeadingOnesTrailingZeros benchmarks. However, if the population\nsize is only equal to the size of the Pareto front, then the NSGA-II cannot\nefficiently compute the full Pareto front: for an exponential number of\niterations, the population will always miss a constant fraction of the Pareto\nfront. Our experiments confirm the above findings.\n","authors":["Weijie Zheng","Benjamin Doerr"],"pdf_url":"https://arxiv.org/pdf/2112.08581v5.pdf","comment":"This is the journal version of the paper \"Weijie Zheng, Yufei Liu,\n  Benjamin Doerr: A First Mathematical Runtime Analysis of the Non-Dominated\n  Sorting Genetic Algorithm II (NSGA-II). AAAI 2022. arXiv:2112.08581v3\""},{"id":"http://arxiv.org/abs/2307.04149v1","updated":"2023-07-09T10:56:44Z","published":"2023-07-09T10:56:44Z","title":"Latent Graph Attention for Enhanced Spatial Context","summary":"  Global contexts in images are quite valuable in image-to-image translation\nproblems. Conventional attention-based and graph-based models capture the\nglobal context to a large extent, however, these are computationally expensive.\nMoreover, the existing approaches are limited to only learning the pairwise\nsemantic relation between any two points on the image. In this paper, we\npresent Latent Graph Attention (LGA) a computationally inexpensive (linear to\nthe number of nodes) and stable, modular framework for incorporating the global\ncontext in the existing architectures, especially empowering small-scale\narchitectures to give performance closer to large size architectures, thus\nmaking the light-weight architectures more useful for edge devices with lower\ncompute power and lower energy needs. LGA propagates information spatially\nusing a network of locally connected graphs, thereby facilitating to construct\na semantically coherent relation between any two spatially distant points that\nalso takes into account the influence of the intermediate pixels. Moreover, the\ndepth of the graph network can be used to adapt the extent of contextual spread\nto the target dataset, thereby being able to explicitly control the added\ncomputational cost. To enhance the learning mechanism of LGA, we also introduce\na novel contrastive loss term that helps our LGA module to couple well with the\noriginal architecture at the expense of minimal additional computational load.\nWe show that incorporating LGA improves the performance on three challenging\napplications, namely transparent object segmentation, image restoration for\ndehazing and optical flow estimation.\n","authors":["Ayush Singh","Yash Bhambhu","Himanshu Buckchash","Deepak K. Gupta","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2307.04149v1.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2307.04147v1","updated":"2023-07-09T10:35:19Z","published":"2023-07-09T10:35:19Z","title":"A Survey and Approach to Chart Classification","summary":"  Charts represent an essential source of visual information in documents and\nfacilitate a deep understanding and interpretation of information typically\nconveyed numerically. In the scientific literature, there are many charts, each\nwith its stylistic differences. Recently the document understanding community\nhas begun to address the problem of automatic chart understanding, which begins\nwith chart classification. In this paper, we present a survey of the current\nstate-of-the-art techniques for chart classification and discuss the available\ndatasets and their supported chart types. We broadly classify these\ncontributions as traditional approaches based on ML, CNN, and Transformers.\nFurthermore, we carry out an extensive comparative performance analysis of\nCNN-based and transformer-based approaches on the recently published CHARTINFO\nUB-UNITECH PMC dataset for the CHART-Infographics competition at ICPR 2022. The\ndata set includes 15 different chart categories, including 22,923 training\nimages and 13,260 test images. We have implemented a vision-based transformer\nmodel that produces state-of-the-art results in chart classification.\n","authors":["Anurag Dhote","Mohammed Javed","David S Doermann"],"pdf_url":"https://arxiv.org/pdf/2307.04147v1.pdf","comment":"Accepted in 15th IAPR Workshop on Graphics Recognition (GREC) 2023 in\n  conjunction with 17th International Conference on Document Analysis and\n  Recognition (ICDAR) 2023, August 21-26, 2023 San Jose, USA"},{"id":"http://arxiv.org/abs/2110.12468v2","updated":"2023-07-09T10:16:44Z","published":"2021-10-24T15:34:03Z","title":"SCORE: Spurious COrrelation REduction for Offline Reinforcement Learning","summary":"  Offline reinforcement learning (RL) harnesses the power of massive datasets\nfor resolving sequential decision problems. Most existing papers only discuss\ndefending against out-of-distribution (OOD) actions while we investigate a\nbroader issue, the spurious correlations between epistemic uncertainty and\ndecision-making, an essential factor that causes suboptimality. In this paper,\nwe propose Spurious COrrelation REduction (SCORE) for offline RL, a practically\neffective and theoretically provable algorithm. We empirically show that SCORE\nachieves the SoTA performance with 3.1x acceleration on various tasks in a\nstandard benchmark (D4RL). The proposed algorithm introduces an annealing\nbehavior cloning regularizer to help produce a high-quality estimation of\nuncertainty which is critical for eliminating spurious correlations from\nsuboptimality. Theoretically, we justify the rationality of the proposed method\nand prove its convergence to the optimal policy with a sublinear rate under\nmild assumptions.\n","authors":["Zhihong Deng","Zuyue Fu","Lingxiao Wang","Zhuoran Yang","Chenjia Bai","Tianyi Zhou","Zhaoran Wang","Jing Jiang"],"pdf_url":"https://arxiv.org/pdf/2110.12468v2.pdf","comment":"16 pages, 14 figures"},{"id":"http://arxiv.org/abs/2209.02370v3","updated":"2023-07-09T10:02:41Z","published":"2022-09-06T10:48:45Z","title":"Continual Learning, Fast and Slow","summary":"  According to the Complementary Learning Systems (CLS)\ntheory~\\cite{mcclelland1995there} in neuroscience, humans do effective\n\\emph{continual learning} through two complementary systems: a fast learning\nsystem centered on the hippocampus for rapid learning of the specifics,\nindividual experiences; and a slow learning system located in the neocortex for\nthe gradual acquisition of structured knowledge about the environment.\nMotivated by this theory, we propose \\emph{DualNets} (for Dual Networks), a\ngeneral continual learning framework comprising a fast learning system for\nsupervised learning of pattern-separated representation from specific tasks and\na slow learning system for representation learning of task-agnostic general\nrepresentation via Self-Supervised Learning (SSL). DualNets can seamlessly\nincorporate both representation types into a holistic framework to facilitate\nbetter continual learning in deep neural networks. Via extensive experiments,\nwe demonstrate the promising results of DualNets on a wide range of continual\nlearning protocols, ranging from the standard offline, task-aware setting to\nthe challenging online, task-free scenario. Notably, on the\nCTrL~\\cite{veniat2020efficient} benchmark that has unrelated tasks with vastly\ndifferent visual images, DualNets can achieve competitive performance with\nexisting state-of-the-art dynamic architecture\nstrategies~\\cite{ostapenko2021continual}. Furthermore, we conduct comprehensive\nablation studies to validate DualNets efficacy, robustness, and scalability.\nCode will be made available at \\url{https://github.com/phquang/DualNet}.\n","authors":["Quang Pham","Chenghao Liu","Steven C. H. Hoi"],"pdf_url":"https://arxiv.org/pdf/2209.02370v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2110.00175"},{"id":"http://arxiv.org/abs/2307.04137v1","updated":"2023-07-09T09:33:05Z","published":"2023-07-09T09:33:05Z","title":"A Novel Explainable Artificial Intelligence Model in Image\n  Classification problem","summary":"  In recent years, artificial intelligence is increasingly being applied widely\nin many different fields and has a profound and direct impact on human life.\nFollowing this is the need to understand the principles of the model making\npredictions. Since most of the current high-precision models are black boxes,\nneither the AI scientist nor the end-user deeply understands what's going on\ninside these models. Therefore, many algorithms are studied for the purpose of\nexplaining AI models, especially those in the problem of image classification\nin the field of computer vision such as LIME, CAM, GradCAM. However, these\nalgorithms still have limitations such as LIME's long execution time and CAM's\nconfusing interpretation of concreteness and clarity. Therefore, in this paper,\nwe propose a new method called Segmentation - Class Activation Mapping (SeCAM)\nthat combines the advantages of these algorithms above, while at the same time\novercoming their disadvantages. We tested this algorithm with various models,\nincluding ResNet50, Inception-v3, VGG16 from ImageNet Large Scale Visual\nRecognition Challenge (ILSVRC) data set. Outstanding results when the algorithm\nhas met all the requirements for a specific explanation in a remarkably concise\ntime.\n","authors":["Quoc Hung Cao","Truong Thanh Hung Nguyen","Vo Thanh Khang Nguyen","Xuan Phong Nguyen"],"pdf_url":"https://arxiv.org/pdf/2307.04137v1.pdf","comment":"Published in the Proceedings of FAIC 2021"},{"id":"http://arxiv.org/abs/2307.04132v1","updated":"2023-07-09T09:04:26Z","published":"2023-07-09T09:04:26Z","title":"Reasoning over the Behaviour of Objects in Video-Clips for Adverb-Type\n  Recognition","summary":"  In this work, following the intuition that adverbs describing scene-sequences\nare best identified by reasoning over high-level concepts of object-behavior,\nwe propose the design of a new framework that reasons over object-behaviours\nextracted from raw-video-clips to recognize the clip's corresponding\nadverb-types. Importantly, while previous works for general scene\nadverb-recognition assume knowledge of the clips underlying action-types, our\nmethod is directly applicable in the more general problem setting where the\naction-type of a video-clip is unknown. Specifically, we propose a novel\npipeline that extracts human-interpretable object-behaviour-facts from raw\nvideo clips and propose novel symbolic and transformer based reasoning methods\nthat operate over these extracted facts to identify adverb-types. Experiment\nresults demonstrate that our proposed methods perform favourably against the\nprevious state-of-the-art. Additionally, to support efforts in symbolic\nvideo-processing, we release two new datasets of object-behaviour-facts\nextracted from raw video clips - the MSR-VTT-ASP and ActivityNet-ASP datasets.\n","authors":["Amrit Diggavi Seshadri","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2307.04132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04131v1","updated":"2023-07-09T09:03:10Z","published":"2023-07-09T09:03:10Z","title":"Carbon-Efficient Neural Architecture Search","summary":"  This work presents a novel approach to neural architecture search (NAS) that\naims to reduce energy costs and increase carbon efficiency during the model\ndesign process. The proposed framework, called carbon-efficient NAS (CE-NAS),\nconsists of NAS evaluation algorithms with different energy requirements, a\nmulti-objective optimizer, and a heuristic GPU allocation strategy. CE-NAS\ndynamically balances energy-efficient sampling and energy-consuming evaluation\ntasks based on current carbon emissions. Using a recent NAS benchmark dataset\nand two carbon traces, our trace-driven simulations demonstrate that CE-NAS\nachieves better carbon and search efficiency than the three baselines.\n","authors":["Yiyang Zhao","Tian Guo"],"pdf_url":"https://arxiv.org/pdf/2307.04131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.17170v2","updated":"2023-07-09T08:56:08Z","published":"2023-06-02T06:24:15Z","title":"An Overview on Generative AI at Scale with Edge-Cloud Computing","summary":"  As a specific category of artificial intelligence (AI), generative artificial\nintelligence (GenAI) generates new content that resembles what is created by\nhumans. The rapid development of GenAI systems has created a huge amount of new\ndata on the Internet, posing new challenges to current computing and\ncommunication frameworks. Currently, GenAI services rely on the traditional\ncloud computing framework due to the need for large computation resources.\nHowever, such services will encounter high latency because of data transmission\nand a high volume of requests. On the other hand, edge-cloud computing can\nprovide adequate computation power and low latency at the same time through the\ncollaboration between edges and the cloud. Thus, it is attractive to build\nGenAI systems at scale by leveraging the edge-cloud computing paradigm. In this\noverview paper, we review recent developments in GenAI and edge-cloud\ncomputing, respectively. Then, we use two exemplary GenAI applications to\ndiscuss technical challenges in scaling up their solutions using edge-cloud\ncollaborative systems. Finally, we list design considerations for training and\ndeploying GenAI systems at scale and point out future research directions.\n","authors":["Yun-Cheng Wang","Jintang Xue","Chengwei Wei","C. -C. Jay Kuo"],"pdf_url":"https://arxiv.org/pdf/2306.17170v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01657v2","updated":"2023-07-09T08:09:49Z","published":"2023-06-02T16:26:21Z","title":"DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control\n  for Empathetic Response Generation","summary":"  Empathy is a crucial factor in open-domain conversations, which naturally\nshows one's caring and understanding to others. Though several methods have\nbeen proposed to generate empathetic responses, existing works often lead to\nmonotonous empathy that refers to generic and safe expressions. In this paper,\nwe propose to use explicit control to guide the empathy expression and design a\nframework DiffusEmp based on conditional diffusion language model to unify the\nutilization of dialogue context and attribute-oriented control signals.\nSpecifically, communication mechanism, intent, and semantic frame are imported\nas multi-grained signals that control the empathy realization from coarse to\nfine levels. We then design a specific masking strategy to reflect the\nrelationship between multi-grained signals and response tokens, and integrate\nit into the diffusion model to influence the generative process. Experimental\nresults on a benchmark dataset EmpatheticDialogue show that our framework\noutperforms competitive baselines in terms of controllability, informativeness,\nand diversity without the loss of context-relatedness.\n","authors":["Guanqun Bi","Lei Shen","Yanan Cao","Meng Chen","Yuqiang Xie","Zheng Lin","Xiaodong He"],"pdf_url":"https://arxiv.org/pdf/2306.01657v2.pdf","comment":"accepted by ACL 2023 main conference (Oral)"},{"id":"http://arxiv.org/abs/2307.04114v1","updated":"2023-07-09T08:07:43Z","published":"2023-07-09T08:07:43Z","title":"FILM: How can Few-Shot Image Classification Benefit from Pre-Trained\n  Language Models?","summary":"  Few-shot learning aims to train models that can be generalized to novel\nclasses with only a few samples. Recently, a line of works are proposed to\nenhance few-shot learning with accessible semantic information from class\nnames. However, these works focus on improving existing modules such as visual\nprototypes and feature extractors of the standard few-shot learning framework.\nThis limits the full potential use of semantic information. In this paper, we\npropose a novel few-shot learning framework that uses pre-trained language\nmodels based on contrastive learning. To address the challenge of alignment\nbetween visual features and textual embeddings obtained from text-based\npre-trained language model, we carefully design the textual branch of our\nframework and introduce a metric module to generalize the cosine similarity.\nFor better transferability, we let the metric module adapt to different\nfew-shot tasks and adopt MAML to train the model via bi-level optimization.\nMoreover, we conduct extensive experiments on multiple benchmarks to\ndemonstrate the effectiveness of our method.\n","authors":["Zihao Jiang","Yunkai Dang","Dong Pang","Huishuai Zhang","Weiran Huang"],"pdf_url":"https://arxiv.org/pdf/2307.04114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04098v1","updated":"2023-07-09T05:12:42Z","published":"2023-07-09T05:12:42Z","title":"A User Study on Explainable Online Reinforcement Learning for Adaptive\n  Systems","summary":"  Online reinforcement learning (RL) is increasingly used for realizing\nadaptive systems in the presence of design time uncertainty. Online RL\nfacilitates learning from actual operational data and thereby leverages\nfeedback only available at runtime. However, Online RL requires the definition\nof an effective and correct reward function, which quantifies the feedback to\nthe RL algorithm and thereby guides learning. With Deep RL gaining interest,\nthe learned knowledge is no longer explicitly represented, but is represented\nas a neural network. For a human, it becomes practically impossible to relate\nthe parametrization of the neural network to concrete RL decisions. Deep RL\nthus essentially appears as a black box, which severely limits the debugging of\nadaptive systems. We previously introduced the explainable RL technique\nXRL-DINE, which provides visual insights into why certain decisions were made\nat important time points. Here, we introduce an empirical user study involving\n54 software engineers from academia and industry to assess (1) the performance\nof software engineers when performing different tasks using XRL-DINE and (2)\nthe perceived usefulness and ease of use of XRL-DINE.\n","authors":["Andreas Metzger","Jan Laufer","Felix Feit","Klaus Pohl"],"pdf_url":"https://arxiv.org/pdf/2307.04098v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2210.05931"},{"id":"http://arxiv.org/abs/2303.02401v2","updated":"2023-07-09T04:56:10Z","published":"2023-03-04T12:26:47Z","title":"Open-Vocabulary Affordance Detection in 3D Point Clouds","summary":"  Affordance detection is a challenging problem with a wide variety of robotic\napplications. Traditional affordance detection methods are limited to a\npredefined set of affordance labels, hence potentially restricting the\nadaptability of intelligent robots in complex and dynamic environments. In this\npaper, we present the Open-Vocabulary Affordance Detection (OpenAD) method,\nwhich is capable of detecting an unbounded number of affordances in 3D point\nclouds. By simultaneously learning the affordance text and the point feature,\nOpenAD successfully exploits the semantic relationships between affordances.\nTherefore, our proposed method enables zero-shot detection and can be able to\ndetect previously unseen affordances without a single annotation example.\nIntensive experimental results show that OpenAD works effectively on a wide\nrange of affordance detection setups and outperforms other baselines by a large\nmargin. Additionally, we demonstrate the practicality of the proposed OpenAD in\nreal-world robotic applications with a fast inference speed (~100ms). Our\nproject is available at https://openad2023.github.io.\n","authors":["Toan Nguyen","Minh Nhat Vu","An Vuong","Dzung Nguyen","Thieu Vo","Ngan Le","Anh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2303.02401v2.pdf","comment":"Accepted to The 2023 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2023)"},{"id":"http://arxiv.org/abs/2307.04090v1","updated":"2023-07-09T04:19:19Z","published":"2023-07-09T04:19:19Z","title":"DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge\n  Graphs","summary":"  Recent work within the Argument Mining community has shown the applicability\nof Natural Language Processing systems for solving problems found within\ncompetitive debate. One of the most important tasks within competitive debate\nis for debaters to create high quality debate cases. We show that effective\ndebate cases can be constructed using constrained shortest path traversals on\nArgumentative Semantic Knowledge Graphs. We study this potential in the context\nof a type of American Competitive Debate, called Policy Debate, which already\nhas a large scale dataset targeting it called DebateSum. We significantly\nimprove upon DebateSum by introducing 53180 new examples, as well as further\nuseful metadata for every example, to the dataset. We leverage the txtai\nsemantic search and knowledge graph toolchain to produce and contribute 9\nsemantic knowledge graphs built on this dataset. We create a unique method for\nevaluating which knowledge graphs are better in the context of producing policy\ndebate cases. A demo which automatically generates debate cases, along with all\nother code and the Knowledge Graphs, are open-sourced and made available to the\npublic here: https://github.com/Hellisotherpeople/DebateKG\n","authors":["Allen Roush"],"pdf_url":"https://arxiv.org/pdf/2307.04090v1.pdf","comment":"8 pages, knife-edge reject from EACL 2023 and workshops, System\n  Demonstration paper"},{"id":"http://arxiv.org/abs/2206.12252v2","updated":"2023-07-09T02:15:50Z","published":"2022-06-23T12:33:20Z","title":"Indecision Trees: Learning Argument-Based Reasoning under Quantified\n  Uncertainty","summary":"  Using Machine Learning systems in the real world can often be problematic,\nwith inexplicable black-box models, the assumed certainty of imperfect\nmeasurements, or providing a single classification instead of a probability\ndistribution.\n  This paper introduces Indecision Trees, a modification to Decision Trees\nwhich learn under uncertainty, can perform inference under uncertainty, provide\na robust distribution over the possible labels, and can be disassembled into a\nset of logical arguments for use in other reasoning systems.\n","authors":["Jonathan S. Kent","David H. Menager"],"pdf_url":"https://arxiv.org/pdf/2206.12252v2.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2208.01307v2","updated":"2023-07-09T02:06:43Z","published":"2022-08-02T08:27:00Z","title":"Multilingual Coreference Resolution in Multiparty Dialogue","summary":"  Existing multiparty dialogue datasets for entity coreference resolution are\nnascent, and many challenges are still unaddressed. We create a large-scale\ndataset, Multilingual Multiparty Coref (MMC), for this task based on TV\ntranscripts. Due to the availability of gold-quality subtitles in multiple\nlanguages, we propose reusing the annotations to create silver coreference\nresolution data in other languages (Chinese and Farsi) via annotation\nprojection. On the gold (English) data, off-the-shelf models perform relatively\npoorly on MMC, suggesting that MMC has broader coverage of multiparty\ncoreference than prior datasets. On the silver data, we find success both using\nit for data augmentation and training from scratch, which effectively simulates\nthe zero-shot cross-lingual setting.\n","authors":["Boyuan Zheng","Patrick Xia","Mahsa Yarmohammadi","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2208.01307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04075v1","updated":"2023-07-09T00:53:23Z","published":"2023-07-09T00:53:23Z","title":"Multi-Head Attention Mechanism Learning for Cancer New Subtypes and\n  Treatment Based on Cancer Multi-Omics Data","summary":"  Due to the high heterogeneity and clinical characteristics of cancer, there\nare significant differences in multi-omics data and clinical features among\nsubtypes of different cancers. Therefore, the identification and discovery of\ncancer subtypes are crucial for the diagnosis, treatment, and prognosis of\ncancer. In this study, we proposed a generalization framework based on\nattention mechanisms for unsupervised contrastive learning (AMUCL) to analyze\ncancer multi-omics data for the identification and characterization of cancer\nsubtypes. AMUCL framework includes a unsupervised multi-head attention\nmechanism, which deeply extracts multi-omics data features. Importantly, a\ndecoupled contrastive learning model (DMACL) based on a multi-head attention\nmechanism is proposed to learn multi-omics data features and clusters and\nidentify new cancer subtypes. This unsupervised contrastive learning method\nclusters subtypes by calculating the similarity between samples in the feature\nspace and sample space of multi-omics data. Compared to 11 other deep learning\nmodels, the DMACL model achieved a C-index of 0.002, a Silhouette score of\n0.801, and a Davies Bouldin Score of 0.38 on a single-cell multi-omics dataset.\nOn a cancer multi-omics dataset, the DMACL model obtained a C-index of 0.016, a\nSilhouette score of 0.688, and a Davies Bouldin Score of 0.46, and obtained the\nmost reliable cancer subtype clustering results for each type of cancer.\nFinally, we used the DMACL model in the AMUCL framework to reveal six cancer\nsubtypes of AML. By analyzing the GO functional enrichment, subtype-specific\nbiological functions, and GSEA of AML, we further enhanced the interpretability\nof cancer subtype analysis based on the generalizable AMUCL framework.\n","authors":["Liangrui Pan","Dazhen Liu","Yutao Dou","Lian Wang","Zhichao Feng","Pengfei Rong","Liwen Xu","Shaoliang Peng"],"pdf_url":"https://arxiv.org/pdf/2307.04075v1.pdf","comment":null}]},"2023-07-08T00:00:00Z":{"Sound":[{"id":"http://arxiv.org/abs/2307.04015v1","updated":"2023-07-08T16:47:31Z","published":"2023-07-08T16:47:31Z","title":"Emotion-Guided Music Accompaniment Generation Based on Variational\n  Autoencoder","summary":"  Music accompaniment generation is a crucial aspect in the composition\nprocess. Deep neural networks have made significant strides in this field, but\nit remains a challenge for AI to effectively incorporate human emotions to\ncreate beautiful accompaniments. Existing models struggle to effectively\ncharacterize human emotions within neural network models while composing music.\nTo address this issue, we propose the use of an easy-to-represent emotion flow\nmodel, the Valence/Arousal Curve, which allows for the compatibility of\nemotional information within the model through data transformation and enhances\ninterpretability of emotional factors by utilizing a Variational Autoencoder as\nthe model structure. Further, we used relative self-attention to maintain the\nstructure of the music at music phrase level and to generate a richer\naccompaniment when combined with the rules of music theory.\n","authors":["Qi Wang","Shubing Zhang","Li Zhou"],"pdf_url":"https://arxiv.org/pdf/2307.04015v1.pdf","comment":"Accepted By International Joint Conference on Neural Networks\n  2023(IJCNN2023)"},{"id":"http://arxiv.org/abs/2303.16897v3","updated":"2023-07-08T07:12:28Z","published":"2023-03-29T17:59:53Z","title":"Physics-Driven Diffusion Models for Impact Sound Synthesis from Videos","summary":"  Modeling sounds emitted from physical object interactions is critical for\nimmersive perceptual experiences in real and virtual worlds. Traditional\nmethods of impact sound synthesis use physics simulation to obtain a set of\nphysics parameters that could represent and synthesize the sound. However, they\nrequire fine details of both the object geometries and impact locations, which\nare rarely available in the real world and can not be applied to synthesize\nimpact sounds from common videos. On the other hand, existing video-driven deep\nlearning-based approaches could only capture the weak correspondence between\nvisual content and impact sounds since they lack of physics knowledge. In this\nwork, we propose a physics-driven diffusion model that can synthesize\nhigh-fidelity impact sound for a silent video clip. In addition to the video\ncontent, we propose to use additional physics priors to guide the impact sound\nsynthesis procedure. The physics priors include both physics parameters that\nare directly estimated from noisy real-world impact sound examples without\nsophisticated setup and learned residual parameters that interpret the sound\nenvironment via neural networks. We further implement a novel diffusion model\nwith specific training and inference strategies to combine physics priors and\nvisual information for impact sound synthesis. Experimental results show that\nour model outperforms several existing systems in generating realistic impact\nsounds. More importantly, the physics-based representations are fully\ninterpretable and transparent, thus enabling us to perform sound editing\nflexibly.\n","authors":["Kun Su","Kaizhi Qian","Eli Shlizerman","Antonio Torralba","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2303.16897v3.pdf","comment":"CVPR 2023. Project page:\n  https://sukun1045.github.io/video-physics-sound-diffusion/"},{"id":"http://arxiv.org/abs/2307.03917v1","updated":"2023-07-08T06:47:58Z","published":"2023-07-08T06:47:58Z","title":"On decoder-only architecture for speech-to-text and large language model\n  integration","summary":"  Large language models (LLMs) have achieved remarkable success in the field of\nnatural language processing, enabling better human-computer interaction using\nnatural language. However, the seamless integration of speech signals into LLMs\nhas not been explored well. The \"decoder-only\" architecture has also not been\nwell studied for speech processing tasks. In this research, we introduce\nSpeech-LLaMA, a novel approach that effectively incorporates acoustic\ninformation into text-based large language models. Our method leverages\nConnectionist Temporal Classification and a simple audio encoder to map the\ncompressed acoustic features to the continuous semantic space of the LLM. In\naddition, we further probe the decoder-only architecture for speech-to-text\ntasks by training a smaller scale randomly initialized speech-LLaMA model from\nspeech-text paired data alone. We conduct experiments on multilingual\nspeech-to-text translation tasks and demonstrate a significant improvement over\nstrong baselines, highlighting the potential advantages of decoder-only models\nfor speech-to-text conversion.\n","authors":["Jian Wu","Yashesh Gaur","Zhuo Chen","Long Zhou","Yimeng Zhu","Tianrui Wang","Jinyu Li","Shujie Liu","Bo Ren","Linquan Liu","Yu Wu"],"pdf_url":"https://arxiv.org/pdf/2307.03917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05533v1","updated":"2023-07-08T07:39:23Z","published":"2023-07-08T07:39:23Z","title":"Anti-noise window: Subjective perception of active noise reduction and\n  effect of informational masking","summary":"  Reviving natural ventilation (NV) for urban sustainability presents\nchallenges for indoor acoustic comfort. Active control and interference-based\nnoise mitigation strategies, such as the use of loudspeakers, offer potential\nsolutions to achieve acoustic comfort while maintaining NV. However, these\napproaches are not commonly integrated or evaluated from a perceptual\nstandpoint. This study examines the perceptual and objective aspects of an\nactive-noise-control (ANC)-based \"anti-noise\" window (ANW) and its integration\nwith informational masking (IM) in a model bedroom. Forty participants assessed\nthe ANW in a three-way interaction involving noise types (traffic, train, and\naircraft), maskers (bird, water), and ANC (on, off). The evaluation focused on\nperceived annoyance (PAY; ISO/TS 15666), perceived affective quality (ISO/TS\n12913-2), loudness (PLN), and included an open-ended qualitative assessment.\nDespite minimal objective reduction in decibel-based indicators and a slight\nincrease in psychoacoustic sharpness, the ANW alone demonstrated significant\nreductions in PAY and PLN, as well as an improvement in ISO pleasantness across\nall noise types. The addition of maskers generally enhanced overall acoustic\ncomfort, although water masking led to increased PLN. Furthermore, the\ncombination of ANC with maskers showed interaction effects, with both maskers\nsignificantly reducing PAY compared to ANC alone.\n","authors":["Bhan Lam","Kelvin Chee Quan Lim","Kenneth Ooi","Zhen-Ting Ong","Dongyuan Shi","Woon-Seng Gan"],"pdf_url":"https://arxiv.org/pdf/2307.05533v1.pdf","comment":"Accepted manuscript submitted to Sustainable Cities and Society"}],"Audio and Speech Processing":[{"id":"http://arxiv.org/abs/2307.04015v1","updated":"2023-07-08T16:47:31Z","published":"2023-07-08T16:47:31Z","title":"Emotion-Guided Music Accompaniment Generation Based on Variational\n  Autoencoder","summary":"  Music accompaniment generation is a crucial aspect in the composition\nprocess. Deep neural networks have made significant strides in this field, but\nit remains a challenge for AI to effectively incorporate human emotions to\ncreate beautiful accompaniments. Existing models struggle to effectively\ncharacterize human emotions within neural network models while composing music.\nTo address this issue, we propose the use of an easy-to-represent emotion flow\nmodel, the Valence/Arousal Curve, which allows for the compatibility of\nemotional information within the model through data transformation and enhances\ninterpretability of emotional factors by utilizing a Variational Autoencoder as\nthe model structure. Further, we used relative self-attention to maintain the\nstructure of the music at music phrase level and to generate a richer\naccompaniment when combined with the rules of music theory.\n","authors":["Qi Wang","Shubing Zhang","Li Zhou"],"pdf_url":"https://arxiv.org/pdf/2307.04015v1.pdf","comment":"Accepted By International Joint Conference on Neural Networks\n  2023(IJCNN2023)"},{"id":"http://arxiv.org/abs/2305.18096v2","updated":"2023-07-08T07:25:14Z","published":"2023-05-29T14:00:24Z","title":"Improving Textless Spoken Language Understanding with Discrete Units as\n  Intermediate Target","summary":"  Spoken Language Understanding (SLU) is a task that aims to extract semantic\ninformation from spoken utterances. Previous research has made progress in\nend-to-end SLU by using paired speech-text data, such as pre-trained Automatic\nSpeech Recognition (ASR) models or paired text as intermediate targets.\nHowever, acquiring paired transcripts is expensive and impractical for\nunwritten languages. On the other hand, Textless SLU extracts semantic\ninformation from speech without utilizing paired transcripts. However, the\nabsence of intermediate targets and training guidance for textless SLU often\nresults in suboptimal performance. In this work, inspired by the\ncontent-disentangled discrete units from self-supervised speech models, we\nproposed to use discrete units as intermediate guidance to improve textless SLU\nperformance. Our method surpasses the baseline method on five SLU benchmark\ncorpora. Additionally, we find that unit guidance facilitates few-shot learning\nand enhances the model's ability to handle noise.\n","authors":["Guan-Wei Wu","Guan-Ting Lin","Shang-Wen Li","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2305.18096v2.pdf","comment":"Accepted by Interspeech 2023. *Equal contribution"},{"id":"http://arxiv.org/abs/2303.16897v3","updated":"2023-07-08T07:12:28Z","published":"2023-03-29T17:59:53Z","title":"Physics-Driven Diffusion Models for Impact Sound Synthesis from Videos","summary":"  Modeling sounds emitted from physical object interactions is critical for\nimmersive perceptual experiences in real and virtual worlds. Traditional\nmethods of impact sound synthesis use physics simulation to obtain a set of\nphysics parameters that could represent and synthesize the sound. However, they\nrequire fine details of both the object geometries and impact locations, which\nare rarely available in the real world and can not be applied to synthesize\nimpact sounds from common videos. On the other hand, existing video-driven deep\nlearning-based approaches could only capture the weak correspondence between\nvisual content and impact sounds since they lack of physics knowledge. In this\nwork, we propose a physics-driven diffusion model that can synthesize\nhigh-fidelity impact sound for a silent video clip. In addition to the video\ncontent, we propose to use additional physics priors to guide the impact sound\nsynthesis procedure. The physics priors include both physics parameters that\nare directly estimated from noisy real-world impact sound examples without\nsophisticated setup and learned residual parameters that interpret the sound\nenvironment via neural networks. We further implement a novel diffusion model\nwith specific training and inference strategies to combine physics priors and\nvisual information for impact sound synthesis. Experimental results show that\nour model outperforms several existing systems in generating realistic impact\nsounds. More importantly, the physics-based representations are fully\ninterpretable and transparent, thus enabling us to perform sound editing\nflexibly.\n","authors":["Kun Su","Kaizhi Qian","Eli Shlizerman","Antonio Torralba","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2303.16897v3.pdf","comment":"CVPR 2023. Project page:\n  https://sukun1045.github.io/video-physics-sound-diffusion/"},{"id":"http://arxiv.org/abs/2307.03917v1","updated":"2023-07-08T06:47:58Z","published":"2023-07-08T06:47:58Z","title":"On decoder-only architecture for speech-to-text and large language model\n  integration","summary":"  Large language models (LLMs) have achieved remarkable success in the field of\nnatural language processing, enabling better human-computer interaction using\nnatural language. However, the seamless integration of speech signals into LLMs\nhas not been explored well. The \"decoder-only\" architecture has also not been\nwell studied for speech processing tasks. In this research, we introduce\nSpeech-LLaMA, a novel approach that effectively incorporates acoustic\ninformation into text-based large language models. Our method leverages\nConnectionist Temporal Classification and a simple audio encoder to map the\ncompressed acoustic features to the continuous semantic space of the LLM. In\naddition, we further probe the decoder-only architecture for speech-to-text\ntasks by training a smaller scale randomly initialized speech-LLaMA model from\nspeech-text paired data alone. We conduct experiments on multilingual\nspeech-to-text translation tasks and demonstrate a significant improvement over\nstrong baselines, highlighting the potential advantages of decoder-only models\nfor speech-to-text conversion.\n","authors":["Jian Wu","Yashesh Gaur","Zhuo Chen","Long Zhou","Yimeng Zhu","Tianrui Wang","Jinyu Li","Shujie Liu","Bo Ren","Linquan Liu","Yu Wu"],"pdf_url":"https://arxiv.org/pdf/2307.03917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05533v1","updated":"2023-07-08T07:39:23Z","published":"2023-07-08T07:39:23Z","title":"Anti-noise window: Subjective perception of active noise reduction and\n  effect of informational masking","summary":"  Reviving natural ventilation (NV) for urban sustainability presents\nchallenges for indoor acoustic comfort. Active control and interference-based\nnoise mitigation strategies, such as the use of loudspeakers, offer potential\nsolutions to achieve acoustic comfort while maintaining NV. However, these\napproaches are not commonly integrated or evaluated from a perceptual\nstandpoint. This study examines the perceptual and objective aspects of an\nactive-noise-control (ANC)-based \"anti-noise\" window (ANW) and its integration\nwith informational masking (IM) in a model bedroom. Forty participants assessed\nthe ANW in a three-way interaction involving noise types (traffic, train, and\naircraft), maskers (bird, water), and ANC (on, off). The evaluation focused on\nperceived annoyance (PAY; ISO/TS 15666), perceived affective quality (ISO/TS\n12913-2), loudness (PLN), and included an open-ended qualitative assessment.\nDespite minimal objective reduction in decibel-based indicators and a slight\nincrease in psychoacoustic sharpness, the ANW alone demonstrated significant\nreductions in PAY and PLN, as well as an improvement in ISO pleasantness across\nall noise types. The addition of maskers generally enhanced overall acoustic\ncomfort, although water masking led to increased PLN. Furthermore, the\ncombination of ANC with maskers showed interaction effects, with both maskers\nsignificantly reducing PAY compared to ANC alone.\n","authors":["Bhan Lam","Kelvin Chee Quan Lim","Kenneth Ooi","Zhen-Ting Ong","Dongyuan Shi","Woon-Seng Gan"],"pdf_url":"https://arxiv.org/pdf/2307.05533v1.pdf","comment":"Accepted manuscript submitted to Sustainable Cities and Society"}],"Signal Processing":[{"id":"http://arxiv.org/abs/2307.02391v2","updated":"2023-07-08T23:21:33Z","published":"2023-07-05T16:02:05Z","title":"Physical Layer Secret Key Agreement Using One-Bit Quantization and\n  Low-Density Parity-Check Codes","summary":"  Physical layer approaches for generating secret encryption keys for wireless\nsystems using channel information have attracted increased interest from\nresearchers in recent years. This paper presents a new approach for calculating\nlog-likelihood ratios (LLRs) for secret key generation that is based on one-bit\nquantization of channel measurements and the difference between channel\nestimates at legitimate reciprocal nodes. The studied secret key agreement\napproach, which implements advantage distillation along with information\nreconciliation using Slepian-Wolf low-density parity-check (LDPC) codes, is\ndiscussed and illustrated with numerical results obtained from simulations.\nThese results show the probability of bit disagreement for keys generated using\nthe proposed LLR calculations compared with alternative LLR calculation methods\nfor key generation based on channel state information. The proposed LLR\ncalculations are shown to be an improvement to the studied approach of physical\nlayer secret key agreement.\n","authors":["John A. Snoap"],"pdf_url":"https://arxiv.org/pdf/2307.02391v2.pdf","comment":"Officially Published on ODU Digital Commons at\n  https://digitalcommons.odu.edu/ece_etds/13"},{"id":"http://arxiv.org/abs/2307.04056v1","updated":"2023-07-08T23:19:53Z","published":"2023-07-08T23:19:53Z","title":"Manifold Filter-Combine Networks","summary":"  We introduce a large class of manifold neural networks (MNNs) which we call\nManifold Filter-Combine Networks. This class includes as special cases, the\nMNNs considered in previous work by Wang, Ruiz, and Ribeiro, the manifold\nscattering transform (a wavelet-based model of neural networks), and other\ninteresting examples not previously considered in the literature such as the\nmanifold equivalent of Kipf and Welling's graph convolutional network. We then\nconsider a method, based on building a data-driven graph, for implementing such\nnetworks when one does not have global knowledge of the manifold, but merely\nhas access to finitely many sample points. We provide sufficient conditions for\nthe network to provably converge to its continuum limit as the number of sample\npoints tends to infinity. Unlike previous work (which focused on specific MNN\narchitectures and graph constructions), our rate of convergence does not\nexplicitly depend on the number of filters used. Moreover, it exhibits linear\ndependence on the depth of the network rather than the exponential dependence\nobtained previously.\n","authors":["Joyce Chew","Edward De Brouwer","Smita Krishnaswamy","Deanna Needell","Michael Perlmutter"],"pdf_url":"https://arxiv.org/pdf/2307.04056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04002v1","updated":"2023-07-08T16:03:53Z","published":"2023-07-08T16:03:53Z","title":"Energy-Efficient Beamforming Design for Integrated Sensing and\n  Communications Systems","summary":"  In this paper, we investigate the design of energy-efficient beamforming for\nan ISAC system, where the transmitted waveform is optimized for joint\nmulti-user communication and target estimation simultaneously. We aim to\nmaximize the system energy efficiency (EE), taking into account the constraints\nof a maximum transmit power budget, a minimum required\nsignal-to-interference-plus-noise ratio (SINR) for communication, and a maximum\ntolerable Cramer-Rao bound (CRB) for target estimation. We first consider\ncommunication-centric EE maximization. To handle the non-convex fractional\nobjective function, we propose an iterative quadratic-transform-Dinkelbach\nmethod, where Schur complement and semi-definite relaxation (SDR) techniques\nare leveraged to solve the subproblem in each iteration. For the scenarios\nwhere sensing is critical, we propose a novel performance metric for\ncharacterizing the sensing-centric EE and optimize the metric adopted in the\nscenario of sensing a point-like target and an extended target. To handle the\nnonconvexity, we employ the successive convex approximation (SCA) technique to\ndevelop an efficient algorithm for approximating the nonconvex problem as a\nsequence of convex ones. Furthermore, we adopt a Pareto optimization mechanism\nto articulate the tradeoff between the communication-centric EE and\nsensing-centric EE. We formulate the search of the Pareto boundary as a\nconstrained optimization problem and propose a computationally efficient\nalgorithm to handle it. Numerical results validate the effectiveness of our\nproposed algorithms compared with the baseline schemes and the obtained\napproximate Pareto boundary shows that there is a non-trivial tradeoff between\ncommunication-centric EE and sensing-centric EE, where the number of\ncommunication users and EE requirements have serious effects on the achievable\ntradeoff.\n","authors":["Jiaqi Zou","Songlin Sun","Christos Masouros","Yuanhao Cui","Yafeng Liu","Derrick Wing Kwan Ng"],"pdf_url":"https://arxiv.org/pdf/2307.04002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03945v1","updated":"2023-07-08T09:59:19Z","published":"2023-07-08T09:59:19Z","title":"Fault Monitoring in Passive Optical Networks using Machine Learning\n  Techniques","summary":"  Passive optical network (PON) systems are vulnerable to a variety of\nfailures, including fiber cuts and optical network unit (ONU)\ntransmitter/receiver failures. Any service interruption caused by a fiber cut\ncan result in huge financial losses for service providers or operators.\nIdentifying the faulty ONU becomes difficult in the case of nearly equidistant\nbranch terminations because the reflections from the branches overlap, making\nit difficult to distinguish the faulty branch given the global backscattering\nsignal. With increasing network size, the complexity of fault monitoring in PON\nsystems increases, resulting in less reliable monitoring. To address these\nchallenges, we propose in this paper various machine learning (ML) approaches\nfor fault monitoring in PON systems, and we validate them using experimental\noptical time domain reflectometry (OTDR) data.\n","authors":["Khouloud Abdelli","Carsten Tropschug","Helmut Griesser","Stephan Pachnicke"],"pdf_url":"https://arxiv.org/pdf/2307.03945v1.pdf","comment":"ICTON 2023"},{"id":"http://arxiv.org/abs/2307.03923v1","updated":"2023-07-08T07:37:17Z","published":"2023-07-08T07:37:17Z","title":"New Methods for MLE of Toeplitz Structured Covariance Matrices with\n  Applications to RADAR Problems","summary":"  This work considers Maximum Likelihood Estimation (MLE) of a Toeplitz\nstructured covariance matrix. In this regard, an equivalent reformulation of\nthe MLE problem is introduced and two iterative algorithms are proposed for the\noptimization of the equivalent statistical learning framework. Both the\nstrategies are based on the Majorization Minimization (MM) paradigm and hence\nenjoy nice properties such as monotonicity and ensured convergence to a\nstationary point of the equivalent MLE problem. The proposed framework is also\nextended to deal with MLE of other practically relevant covariance structures,\nnamely, the banded Toeplitz, block Toeplitz, and Toeplitz-block-Toeplitz.\nThrough numerical simulations, it is shown that the new methods provide\nexcellent performance levels in terms of both mean square estimation error\n(which is very close to the benchmark Cram\\'er-Rao Bound (CRB)) and\nsignal-to-interference-plus-noise ratio, especially in comparison with state of\nthe art strategies.\n","authors":["Augusto Aubry","Prabhu Babu","Antonio De Maio","Massimo Rosamilia"],"pdf_url":"https://arxiv.org/pdf/2307.03923v1.pdf","comment":"submitted to IEEE Transactions on Signal Processing. arXiv admin\n  note: substantial text overlap with arXiv:2110.12176"},{"id":"http://arxiv.org/abs/2307.03921v1","updated":"2023-07-08T07:26:24Z","published":"2023-07-08T07:26:24Z","title":"Social-Mobility-Aware Joint Communication and Computation Resource\n  Management in NOMA-Enabled Vehicular Networks","summary":"  The existing computation and communication (2C) optimization schemes for\nvehicular edge computing (VEC) networks mainly focus on the physical domain\nwithout considering the influence from the social domain. This may greatly\nlimit the potential of task offloading, making it difficult to fully boom the\ntask offloading rate with given power, resulting in low energy efficiency (EE).\nTo address the issue, this letter devotes itself to investigate\nsocial-mobility-aware VEC framework and proposes a novel EE-oriented 2C\nassignment scheme. In doing so, we assume that the task vehicular user (T-VU)\ncan offload computation tasks to the service vehicular user (S-VU) and the road\nside unit (RSU) by non-orthogonal multiple access (NOMA). An optimization\nproblem is formulated to jointly assign the 2C resources to maximize the system\nEE, which turns out to be a mixed integer non-convex objective function. To\nsolve the problem, we transform it into separated computation and communication\nresource allocation subproblems. Dealing with the first subproblem, we propose\na social-mobility-aware edge server selection and task splitting algorithm\n(SM-SSTSA) to achieve edge server selection and task splitting. Then, by\nsolving the second subproblem, the power allocation and spectrum assignment\nsolutions are obtained utilizing a tightening lower bound method and a\nKuhn-Munkres algorithm. Finally, we solve the original problem through an\niterative method. Simulation results demonstrate the superior EE performance of\nthe proposed scheme.\n","authors":["Tong Xue","Haixia Zhang","Hui Ding","Dongfeng Yuan"],"pdf_url":"https://arxiv.org/pdf/2307.03921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05361v1","updated":"2023-07-08T23:01:12Z","published":"2023-07-08T23:01:12Z","title":"A Physics-Informed Low-Shot Learning For sEMG-Based Estimation of Muscle\n  Force and Joint Kinematics","summary":"  Muscle force and joint kinematics estimation from surface electromyography\n(sEMG) are essential for real-time biomechanical analysis of the dynamic\ninterplay among neural muscle stimulation, muscle dynamics, and kinetics.\nRecent advances in deep neural networks (DNNs) have shown the potential to\nimprove biomechanical analysis in a fully automated and reproducible manner.\nHowever, the small sample nature and physical interpretability of biomechanical\nanalysis limit the applications of DNNs. This paper presents a novel\nphysics-informed low-shot learning method for sEMG-based estimation of muscle\nforce and joint kinematics. This method seamlessly integrates Lagrange's\nequation of motion and inverse dynamic muscle model into the generative\nadversarial network (GAN) framework for structured feature decoding and\nextrapolated estimation from the small sample data. Specifically, Lagrange's\nequation of motion is introduced into the generative model to restrain the\nstructured decoding of the high-level features following the laws of physics.\nAnd a physics-informed policy gradient is designed to improve the adversarial\nlearning efficiency by rewarding the consistent physical representation of the\nextrapolated estimations and the physical references. Experimental validations\nare conducted on two scenarios (i.e. the walking trials and wrist motion\ntrials). Results indicate that the estimations of the muscle forces and joint\nkinematics are unbiased compared to the physics-based inverse dynamics, which\noutperforms the selected benchmark methods, including physics-informed\nconvolution neural network (PI-CNN), vallina generative adversarial network\n(GAN), and multi-layer extreme learning machine (ML-ELM).\n","authors":["Yue Shi","Shuhao Ma","Yihui Zhao","Zhiqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.05361v1.pdf","comment":"17 pages, 8 Figures"},{"id":"http://arxiv.org/abs/2307.05535v1","updated":"2023-07-08T14:50:51Z","published":"2023-07-08T14:50:51Z","title":"UAV Trajectory Optimization for Directional THz Links Using Deep\n  Reinforcement Learning","summary":"  As an alternative solution for quick disaster recovery of backhaul/fronthaul\nlinks, in this paper, a dynamic unmanned aerial vehicles (UAV)-assisted\nheterogeneous (HetNet) network equipped with directional terahertz (THz)\nantennas is studied to solve the problem of transferring traffic of distributed\nsmall cells. To this end, we first characterize a detailed three-dimensional\nmodeling of the dynamic UAV-assisted HetNet, and then, we formulate the problem\nfor UAV trajectory to minimize the maximum outage probability of directional\nTHz links. Then, using deep reinforcement learning (DRL) method, we propose an\nefficient algorithm to learn the optimal trajectory. Finally, using\nsimulations, we investigate the performance of the proposed DRL-based\ntrajectory method.\n","authors":["Mohammad Taghi Dabiri","Mazen Hasn"],"pdf_url":"https://arxiv.org/pdf/2307.05535v1.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2307.04023v1","updated":"2023-07-08T18:00:31Z","published":"2023-07-08T18:00:31Z","title":"SDT: A Low-cost and Topology-reconfigurable Testbed for Network Research","summary":"  Network experiments are essential to network-related scientific research\n(e.g., congestion control, QoS, network topology design, and traffic\nengineering). However, (re)configuring various topologies on a real testbed is\nexpensive, time-consuming, and error-prone. In this paper, we propose\n\\emph{Software Defined Topology Testbed (SDT)}, a method for constructing a\nuser-defined network topology using a few commodity switches. SDT is low-cost,\ndeployment-friendly, and reconfigurable, which can run multiple sets of\nexperiments under different topologies by simply using different topology\nconfiguration files at the controller we designed. We implement a prototype of\nSDT and conduct numerous experiments. Evaluations show that SDT only introduces\nat most 2\\% extra overhead than full testbeds on multi-hop latency and is far\nmore efficient than software simulators (reducing the evaluation time by up to\n2899x). SDT is more cost-effective and scalable than existing Topology\nProjection (TP) solutions. Further experiments show that SDT can support\nvarious network research experiments at a low cost on topics including but not\nlimited to topology design, congestion control, and traffic engineering.\n","authors":["Zixuan Chen","Zhigao Zhao","Zijian Li","Jiang Shao","Sen Liu","Yang Xu"],"pdf_url":"https://arxiv.org/pdf/2307.04023v1.pdf","comment":"This paper will be published in IEEE CLUSTER 2023. Preview version\n  only"},{"id":"http://arxiv.org/abs/2307.04016v1","updated":"2023-07-08T17:11:22Z","published":"2023-07-08T17:11:22Z","title":"Cellular LTE and Solar Energy Harvesting for Long-Term, Reliable Urban\n  Sensor Networks: Challenges and Opportunities","summary":"  In a world driven by data, cities are increasingly interested in deploying\nnetworks of smart city devices for urban and environmental monitoring. To be\nsuccessful, these networks must be reliable, scalable, real-time, low-cost, and\neasy to install and maintain -- criteria that are all significantly affected by\nthe design choices around connectivity and power. LTE networks and solar energy\ncan seemingly both satisfy the necessary criteria and are often used in\nreal-world sensor network deployments. However, there have not been extensive\nreal-world studies to examine how well such networks perform and the challenges\nthey encounter in urban settings over long periods. In this work, we analyze\nthe performance of a stationary 118-node LTE-connected, solar-powered sensor\nnetwork over one year in Chicago. Results show the promise of LTE networks and\nsolar panels for city-wide IoT deployments, but also reveal areas for\nimprovement. Notably, we find 11 sites with inadequate RSS to support sensing\nnodes and over 33,000 hours of data loss due to solar energy availability\nissues between October and March. Furthermore, we discover that the\nneighborhoods most affected by connectivity and charging issues are\nsocioeconomically disadvantaged areas with a majority Black and Latine\nresidents. This work presents observations from a networking and powering\nperspective of the urban sensor network to help drive reliable, scalable future\nsmart city deployments. The work also analyzes the impact of land use, adaptive\nenergy harvesting management strategies, and shortcomings of open data, to\nsupport the need for increased real-world deployments that ensure the design of\nequitable smart city networks.\n","authors":["Alex Cabral","Vaishnavi Ranganathan","Jim Waldo"],"pdf_url":"https://arxiv.org/pdf/2307.04016v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04009v1","updated":"2023-07-08T16:39:49Z","published":"2023-07-08T16:39:49Z","title":"Internet Localization of Multi-Party Relay Users: Inherent Friction\n  Between Internet Services and User Privacy","summary":"  Internet privacy is increasingly important on the modern Internet. Users are\nlooking to control the trail of data that they leave behind on the systems that\nthey interact with. Multi-Party Relay (MPR) architectures lower the traditional\nbarriers to adoption of privacy enhancing technologies on the Internet. MPRs\nare unique from legacy architectures in that they are able to offer privacy\nguarantees without paying significant performance penalties. Apple's iCloud\nPrivate Relay is a recently deployed MPR service, creating the potential for\nwidespread consumer adoption of the architecture. However, many current\nInternet-scale systems are designed based on assumptions that may no longer\nhold for users of privacy enhancing systems like Private Relay. There are\ninherent tensions between systems that rely on data about users -- estimated\nlocation of a user based on their IP address, for example -- and the trend\ntowards a more private Internet.\n  This work studies a core function that is widely used to control network and\napplication behavior, IP geolocation, in the context of iCloud Private Relay\nusage. We study the location accuracy of popular IP geolocation services\ncompared against the published location dataset that Apple publicly releases to\nexplicitly aid in geolocating PR users. We characterize geolocation service\nperformance across a number of dimensions, including different countries, IP\nversion, infrastructure provider, and time. Our findings lead us to conclude\nthat existing approaches to IP geolocation (e.g., frequently updated databases)\nperform inadequately for users of the MPR architecture. For example, we find\nmedian location errors >1,000 miles in some countries for IPv4 addresses using\nIP2Location. Our findings lead us to conclude that new, privacy-focused,\ntechniques for inferring user location may be required as privacy becomes a\ndefault user expectation on the Internet.\n","authors":["Sean Flynn","Francesco Bronzino","Paul Schmitt"],"pdf_url":"https://arxiv.org/pdf/2307.04009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03981v1","updated":"2023-07-08T14:09:54Z","published":"2023-07-08T14:09:54Z","title":"BER Analysis of Full Duplex Relay assisted BPSK-SIM based VLC System for\n  Indoor Applications","summary":"  This paper contemplates a relay-assisted visible light communication (VLC)\nsystem, where the light source (Table lamp) acts as a relay node and cooperates\nwith the main light source. Following the IEEE 802.15.7r1 VLC reference channel\nmodel, we assume that there are two different light sources present in an\noffice room. The first one is the source terminal present on the ceiling and\nanother one is the desk lamp that serves as the relay station which works in\nfull-duplex method. Because of the loop interference channel, we model VLC\nrelay terminal using ray tracing simulations. We have analyzed bit error rate\n(BER) performance of the relay-assisted VLC system using binary phase shift\nkeying-subcarrier intensity modulation (BPSK-SIM) technique. The proposed\nmethod outperforms existing phase shift keying (PSK) and square M-quadrature\namplitude modulation (M-QAM) techniques. The proposed VLC system using BPSK-SIM\ntechnique achieves a BER performance of for an SNR of 20 dB. The results of\nproposed full duplex and half duplex relayed VLC system are evaluated using\nequal power allocation (EPA) and optimum power allocations (OPA) techniques\nover three different modulation schemes which are 2-PSK, square M-QAM,\nBPSK-SIM.\n","authors":["L Bhargava Kumar","Ramavath Prasad Naik","Datta Choudhari","Prabu Krishnan","Goutham Simha G D","Jagadeesh V K"],"pdf_url":"https://arxiv.org/pdf/2307.03981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03958v1","updated":"2023-07-08T11:48:51Z","published":"2023-07-08T11:48:51Z","title":"Secrets Revealed in Container Images: An Internet-wide Study on\n  Occurrence and Impact","summary":"  Containerization allows bundling applications and their dependencies into a\nsingle image. The containerization framework Docker eases the use of this\nconcept and enables sharing images publicly, gaining high momentum. However, it\ncan lead to users creating and sharing images that include private keys or API\nsecrets-either by mistake or out of negligence. This leakage impairs the\ncreator's security and that of everyone using the image. Yet, the extent of\nthis practice and how to counteract it remains unclear.\n  In this paper, we analyze 337,171 images from Docker Hub and 8,076 other\nprivate registries unveiling that 8.5% of images indeed include secrets.\nSpecifically, we find 52,107 private keys and 3,158 leaked API secrets, both\nopening a large attack surface, i.e., putting authentication and\nconfidentiality of privacy-sensitive data at stake and even allow active\nattacks. We further document that those leaked keys are used in the wild: While\nwe discovered 1,060 certificates relying on compromised keys being issued by\npublic certificate authorities, based on further active Internet measurements,\nwe find 275,269 TLS and SSH hosts using leaked private keys for authentication.\nTo counteract this issue, we discuss how our methodology can be used to prevent\nsecret leakage and reuse.\n","authors":["Markus Dahlmanns","Constantin Sander","Robin Decker","Klaus Wehrle"],"pdf_url":"https://arxiv.org/pdf/2307.03958v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2307.03945v1","updated":"2023-07-08T09:59:19Z","published":"2023-07-08T09:59:19Z","title":"Fault Monitoring in Passive Optical Networks using Machine Learning\n  Techniques","summary":"  Passive optical network (PON) systems are vulnerable to a variety of\nfailures, including fiber cuts and optical network unit (ONU)\ntransmitter/receiver failures. Any service interruption caused by a fiber cut\ncan result in huge financial losses for service providers or operators.\nIdentifying the faulty ONU becomes difficult in the case of nearly equidistant\nbranch terminations because the reflections from the branches overlap, making\nit difficult to distinguish the faulty branch given the global backscattering\nsignal. With increasing network size, the complexity of fault monitoring in PON\nsystems increases, resulting in less reliable monitoring. To address these\nchallenges, we propose in this paper various machine learning (ML) approaches\nfor fault monitoring in PON systems, and we validate them using experimental\noptical time domain reflectometry (OTDR) data.\n","authors":["Khouloud Abdelli","Carsten Tropschug","Helmut Griesser","Stephan Pachnicke"],"pdf_url":"https://arxiv.org/pdf/2307.03945v1.pdf","comment":"ICTON 2023"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2307.04036v1","updated":"2023-07-08T19:51:01Z","published":"2023-07-08T19:51:01Z","title":"Designing a Direct Feedback Loop between Humans and Convolutional Neural\n  Networks through Local Explanations","summary":"  The local explanation provides heatmaps on images to explain how\nConvolutional Neural Networks (CNNs) derive their output. Due to its visual\nstraightforwardness, the method has been one of the most popular explainable AI\n(XAI) methods for diagnosing CNNs. Through our formative study (S1), however,\nwe captured ML engineers' ambivalent perspective about the local explanation as\na valuable and indispensable envision in building CNNs versus the process that\nexhausts them due to the heuristic nature of detecting vulnerability. Moreover,\nsteering the CNNs based on the vulnerability learned from the diagnosis seemed\nhighly challenging. To mitigate the gap, we designed DeepFuse, the first\ninteractive design that realizes the direct feedback loop between a user and\nCNNs in diagnosing and revising CNN's vulnerability using local explanations.\nDeepFuse helps CNN engineers to systemically search \"unreasonable\" local\nexplanations and annotate the new boundaries for those identified as\nunreasonable in a labor-efficient manner. Next, it steers the model based on\nthe given annotation such that the model doesn't introduce similar mistakes. We\nconducted a two-day study (S2) with 12 experienced CNN engineers. Using\nDeepFuse, participants made a more accurate and \"reasonable\" model than the\ncurrent state-of-the-art. Also, participants found the way DeepFuse guides\ncase-based reasoning can practically improve their current practice. We provide\nimplications for design that explain how future HCI-driven design can move our\npractice forward to make XAI-driven insights more actionable.\n","authors":["Tong Steven Sun","Yuyang Gao","Shubham Khaladkar","Sijia Liu","Liang Zhao","Young-Ho Kim","Sungsoo Ray Hong"],"pdf_url":"https://arxiv.org/pdf/2307.04036v1.pdf","comment":"32 pages, 6 figures, 5 tables. Accepted for publication in the\n  Proceedings of the ACM on Human-Computer Interaction (PACM HCI), CSCW 2023"},{"id":"http://arxiv.org/abs/2108.04136v3","updated":"2023-07-08T16:39:38Z","published":"2021-08-09T16:06:44Z","title":"A computational medical XR discipline","summary":"  Computational medical XR (extended reality) brings together life sciences and\nneuroscience with mathematics, engineering, and computer science. It unifies\ncomputational science (scientific computing) with intelligent extended reality\nand spatial computing for the medical field. It significantly extends previous\nClinical XR, by integrating computational methods from neural simulation to\ncomputational geometry, computational vision and computer graphics up to\ntheoretical computer science to solve hard problems in medicine and\nneuroscience: from low-code/no-code authoring medical XR platforms to deep\nlearning systems for diagnostics, therapeutics, rehabilitation and from\nsurgical planning to real-time operative navigation in XR.\n","authors":["George Papagiannakis"],"pdf_url":"https://arxiv.org/pdf/2108.04136v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03926v1","updated":"2023-07-08T07:51:22Z","published":"2023-07-08T07:51:22Z","title":"Enhancing Room Security and Automating Class Attendance Using ID Cards","summary":"  With the rapid advancements in technology, automation has emerged as the\nfuture of human endeavors. From simple tasks like attendance management to\ncomplex security systems, automation has the potential to revolutionize various\naspects of our lives. This research paper explores the implementation of a\nmethod aimed at enhancing room security in hostels and automating class\nattendance using ID cards. In this study, we propose a system that utilizes the\nunique identity information stored in ID cards for various security and\ncheck-in tasks. By integrating RFID (Radio-Frequency Identification) reader\ntechnology, GSM modules, Node MCU, and Arduino, we create a comprehensive\nsolution. The RFID reader scans the ID card, extracting the relevant\ninformation and verifying the user's identity. The data is then transmitted via\nthe GSM module to a central database, ensuring real-time monitoring and\nsecurity measures. Moreover, the system also enables the automation of class\nattendance. By utilizing the same ID cards, students can simply tap their cards\non a reader placed in the classroom. This information is recorded\nautomatically, eliminating the need for manual attendance taking and reducing\nerrors and time consumption. This research project highlights the practical\nimplementation of ID card technology to enhance room security in hostels and\nautomate class attendance processes. By leveraging the power of automation, we\naim to streamline administrative tasks, improve security measures, and optimize\nefficiency in educational institutions and other relevant settings.\n","authors":["Shravan Bhat","Nithin R","Pranav S"],"pdf_url":"https://arxiv.org/pdf/2307.03926v1.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2307.03913v1","updated":"2023-07-08T06:26:38Z","published":"2023-07-08T06:26:38Z","title":"Applying human-centered AI in developing effective human-AI teaming: A\n  perspective of human-AI joint cognitive systems","summary":"  Research and application have used human-AI teaming (HAT) as a new paradigm\nto develop AI systems. HAT recognizes that AI will function as a teammate\ninstead of simply a tool in collaboration with humans. Effective human-AI teams\nneed to be capable of taking advantage of the unique abilities of both humans\nand AI while overcoming the known challenges and limitations of each member,\naugmenting human capabilities, and raising joint performance beyond that of\neither entity. The National AI Research and Strategic Plan 2023 update has\nrecognized that research programs focusing primarily on the independent\nperformance of AI systems generally fail to consider the functionality that AI\nmust provide within the context of dynamic, adaptive, and collaborative teams\nand calls for further research on human-AI teaming and collaboration. However,\nthere has been debate about whether AI can work as a teammate with humans. The\nprimary concern is that adopting the \"teaming\" paradigm contradicts the\nhuman-centered AI (HCAI) approach, resulting in humans losing control of AI\nsystems. This article further analyzes the HAT paradigm and the debates.\nSpecifically, we elaborate on our proposed conceptual framework of human-AI\njoint cognitive systems (HAIJCS) and apply it to represent HAT under the HCAI\numbrella. We believe that HAIJCS may help adopt HAI while enabling HCAI. The\nimplications and future work for HAIJCS are also discussed.\n  Insights: AI has led to the emergence of a new form of human-machine\nrelationship: human-AI teaming (HAT), a paradigmatic shift in human-AI systems;\nWe must follow a human-centered AI (HCAI) approach when applying HAT as a new\ndesign paradigm; We propose a conceptual framework of human-AI joint cognitive\nsystems (HAIJCS) to represent and implement HAT for developing effective\nhuman-AI teaming\n","authors":["Wei Xu","Zaifeng Gao"],"pdf_url":"https://arxiv.org/pdf/2307.03913v1.pdf","comment":"8"},{"id":"http://arxiv.org/abs/2307.03887v1","updated":"2023-07-08T03:42:54Z","published":"2023-07-08T03:42:54Z","title":"Improving Prototypical Part Networks with Reward Reweighing,\n  Reselection, and Retraining","summary":"  In recent years, work has gone into developing deep interpretable methods for\nimage classification that clearly attributes a model's output to specific\nfeatures of the data. One such of these methods is the prototypical part\nnetwork (ProtoPNet), which attempts to classify images based on meaningful\nparts of the input. While this method results in interpretable classifications,\nthis method often learns to classify from spurious or inconsistent parts of the\nimage. Hoping to remedy this, we take inspiration from the recent developments\nin Reinforcement Learning with Human Feedback (RLHF) to fine-tune these\nprototypes. By collecting human annotations of prototypes quality via a 1-5\nscale on the CUB-200-2011 dataset, we construct a reward model that learns to\nidentify non-spurious prototypes. In place of a full RL update, we propose the\nreweighted, reselected, and retrained prototypical part network (R3-ProtoPNet),\nwhich adds an additional three steps to the ProtoPNet training loop. The first\ntwo steps are reward-based reweighting and reselection, which align prototypes\nwith human feedback. The final step is retraining to realign the model's\nfeatures with the updated prototypes. We find that R3-ProtoPNet improves the\noverall consistency and meaningfulness of the prototypes, but lower the test\npredictive accuracy when used independently. When multiple R3-ProtoPNets are\nincorporated into an ensemble, we find an increase in test predictive\nperformance while maintaining interpretability.\n","authors":["Robin Netzorg","Jiaxun Li","Bin Yu"],"pdf_url":"https://arxiv.org/pdf/2307.03887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03877v1","updated":"2023-07-08T01:45:25Z","published":"2023-07-08T01:45:25Z","title":"Designing Mixed-Initiative Video Games","summary":"  The development of Artificial Intelligence (AI) enables humans to co-create\ncontent with machines. The unexpectedness of AI-generated content can bring\ninspiration and entertainment to users. However, the co-creation interactions\nare always designed for content creators and have poor accessibility. To\nexplore gamification of mixed-initiative co-creation and make human-AI\ninteractions accessible and fun for players, I prototyped Snake Story, a\nmixed-initiative game where players can select AI-generated texts to write a\nstory of a snake by playing a \"Snake\" like game. A controlled experiment was\nconducted to investigate the dynamics of player-AI interactions with and\nwithout the game component in the designed interface. As a result of a study\nwith 11 players (n=11), I found that players utilized different strategies when\nplaying with the two versions, game mechanics significantly affected the output\nstories, players' creative process, as well as role perceptions, and players\nwith different backgrounds showed different preferences for the two versions.\nBased on these results, I further discussed considerations for mixed-initiative\ngame design. This work aims to inspire the design of engaging co-creation\nexperiences.\n","authors":["Daijin Yang"],"pdf_url":"https://arxiv.org/pdf/2307.03877v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2303.04865v2","updated":"2023-07-08T23:39:34Z","published":"2023-03-08T20:09:58Z","title":"Convergence Rates for Localized Actor-Critic in Networked Markov\n  Potential Games","summary":"  We introduce a class of networked Markov potential games in which agents are\nassociated with nodes in a network. Each agent has its own local potential\nfunction, and the reward of each agent depends only on the states and actions\nof the agents within a neighborhood. In this context, we propose a localized\nactor-critic algorithm. The algorithm is scalable since each agent uses only\nlocal information and does not need access to the global state. Further, the\nalgorithm overcomes the curse of dimensionality through the use of function\napproximation. Our main results provide finite-sample guarantees up to a\nlocalization error and a function approximation error. Specifically, we achieve\nan $\\tilde{\\mathcal{O}}(\\tilde{\\epsilon}^{-4})$ sample complexity measured by\nthe averaged Nash regret. This is the first finite-sample bound for multi-agent\ncompetitive games that does not depend on the number of agents.\n","authors":["Zhaoyi Zhou","Zaiwei Chen","Yiheng Lin","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2303.04865v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04055v1","updated":"2023-07-08T23:06:42Z","published":"2023-07-08T23:06:42Z","title":"Contextual Dynamic Pricing with Strategic Buyers","summary":"  Personalized pricing, which involves tailoring prices based on individual\ncharacteristics, is commonly used by firms to implement a consumer-specific\npricing policy. In this process, buyers can also strategically manipulate their\nfeature data to obtain a lower price, incurring certain manipulation costs.\nSuch strategic behavior can hinder firms from maximizing their profits. In this\npaper, we study the contextual dynamic pricing problem with strategic buyers.\nThe seller does not observe the buyer's true feature, but a manipulated feature\naccording to buyers' strategic behavior. In addition, the seller does not\nobserve the buyers' valuation of the product, but only a binary response\nindicating whether a sale happens or not. Recognizing these challenges, we\npropose a strategic dynamic pricing policy that incorporates the buyers'\nstrategic behavior into the online learning to maximize the seller's cumulative\nrevenue. We first prove that existing non-strategic pricing policies that\nneglect the buyers' strategic behavior result in a linear $\\Omega(T)$ regret\nwith $T$ the total time horizon, indicating that these policies are not better\nthan a random pricing policy. We then establish that our proposed policy\nachieves a sublinear regret upper bound of $O(\\sqrt{T})$. Importantly, our\npolicy is not a mere amalgamation of existing dynamic pricing policies and\nstrategic behavior handling algorithms. Our policy can also accommodate the\nscenario when the marginal cost of manipulation is unknown in advance. To\naccount for it, we simultaneously estimate the valuation parameter and the cost\nparameter in the online pricing policy, which is shown to also achieve an\n$O(\\sqrt{T})$ regret bound. Extensive experiments support our theoretical\ndevelopments and demonstrate the superior performance of our policy compared to\nother pricing policies that are unaware of the strategic behaviors.\n","authors":["Pangpang Liu","Zhuoran Yang","Zhaoran Wang","Will Wei Sun"],"pdf_url":"https://arxiv.org/pdf/2307.04055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04050v1","updated":"2023-07-08T21:28:20Z","published":"2023-07-08T21:28:20Z","title":"Optimization-based Learning for Dynamic Load Planning in Trucking\n  Service Networks","summary":"  The load planning problem is a critical challenge in service network design\nfor parcel carriers: it decides how many trailers (or loads) to assign for\ndispatch over time between pairs of terminals. Another key challenge is to\ndetermine a flow plan, which specifies how parcel volumes are assigned to\nplanned loads. This paper considers the Dynamic Load Planning Problem (DLPP)\nthat considers both flow and load planning challenges jointly to adjust loads\nand flows as the demand forecast changes over time before the day of\noperations. The paper aims at developing a decision-support tool to inform\nplanners making these decisions at terminals across the network. The paper\nformulates the DLPP as a MIP and shows that it admits a large number of\nsymmetries in a network where each commodity can be routed through primary and\nalternate paths. As a result, an optimization solver may return fundamentally\ndifferent solutions to closely related problems, confusing planners and\nreducing trust in optimization. To remedy this limitation, the paper proposes a\nGoal-Directed Optimization that eliminates those symmetries by generating\noptimal solutions staying close to a reference plan. The paper also proposes an\noptimization proxy to address the computational challenges of the optimization\nmodels. The proxy combines a machine learning model and a feasibility\nrestoration model and finds solutions that satisfy real-time constraints\nimposed by planners-in-the-loop. An extensive computational study on industrial\ninstances shows that the optimization proxy is around 10 times faster than the\ncommercial solver in obtaining the same quality solutions and orders of\nmagnitude faster for generating solutions that are consistent with each other.\nThe proposed approach also demonstrates the benefits of the DLPP for load\nconsolidation, and the significant savings obtained from combining machine\nlearning and optimization.\n","authors":["Ritesh Ojha","Wenbo Chen","Hanyu Zhang","Reem Khir","Alan Erera","Pascal Van Hentenryck"],"pdf_url":"https://arxiv.org/pdf/2307.04050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.14452v8","updated":"2023-07-08T20:20:03Z","published":"2021-05-30T07:49:56Z","title":"A unified logical framework for explanations in classifier systems","summary":"  Recent years have witnessed a renewed interest in Boolean function in\nexplaining binary classifiers in the field of explainable AI (XAI). The\nstandard approach of Boolean function is propositional logic. We present a\nmodal language of a ceteris paribus nature which supports reasoning about\nbinary input classifiers and their properties. We study a family of classifier\nmodels, axiomatize it as two proof systems regarding the cardinality of the\nlanguage and show completeness of our axiomatics. Moreover, we prove that\nsatisfiability checking problem for our modal language is NEXPTIME-complete in\nthe infinite-variable case, while it becomes polynomial in the finite-variable\ncase. We furthermore identify an interesting NP fragment of our language in the\ninfinite-variable case. We leverage the language to formalize counterfactual\nconditional as well as a variety of notions of explanation including abductive,\ncontrastive and counterfactual explanations, and biases. Finally, we present\ntwo extensions of our language: a dynamic extension by the notion of assignment\nenabling classifier change and an epistemic extension in which the classifier's\nuncertainty about the actual input can be represented.\n","authors":["Xinghan Liu","Emiliano Lorini"],"pdf_url":"https://arxiv.org/pdf/2105.14452v8.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2307.04036v1","updated":"2023-07-08T19:51:01Z","published":"2023-07-08T19:51:01Z","title":"Designing a Direct Feedback Loop between Humans and Convolutional Neural\n  Networks through Local Explanations","summary":"  The local explanation provides heatmaps on images to explain how\nConvolutional Neural Networks (CNNs) derive their output. Due to its visual\nstraightforwardness, the method has been one of the most popular explainable AI\n(XAI) methods for diagnosing CNNs. Through our formative study (S1), however,\nwe captured ML engineers' ambivalent perspective about the local explanation as\na valuable and indispensable envision in building CNNs versus the process that\nexhausts them due to the heuristic nature of detecting vulnerability. Moreover,\nsteering the CNNs based on the vulnerability learned from the diagnosis seemed\nhighly challenging. To mitigate the gap, we designed DeepFuse, the first\ninteractive design that realizes the direct feedback loop between a user and\nCNNs in diagnosing and revising CNN's vulnerability using local explanations.\nDeepFuse helps CNN engineers to systemically search \"unreasonable\" local\nexplanations and annotate the new boundaries for those identified as\nunreasonable in a labor-efficient manner. Next, it steers the model based on\nthe given annotation such that the model doesn't introduce similar mistakes. We\nconducted a two-day study (S2) with 12 experienced CNN engineers. Using\nDeepFuse, participants made a more accurate and \"reasonable\" model than the\ncurrent state-of-the-art. Also, participants found the way DeepFuse guides\ncase-based reasoning can practically improve their current practice. We provide\nimplications for design that explain how future HCI-driven design can move our\npractice forward to make XAI-driven insights more actionable.\n","authors":["Tong Steven Sun","Yuyang Gao","Shubham Khaladkar","Sijia Liu","Liang Zhao","Young-Ho Kim","Sungsoo Ray Hong"],"pdf_url":"https://arxiv.org/pdf/2307.04036v1.pdf","comment":"32 pages, 6 figures, 5 tables. Accepted for publication in the\n  Proceedings of the ACM on Human-Computer Interaction (PACM HCI), CSCW 2023"},{"id":"http://arxiv.org/abs/2307.04033v1","updated":"2023-07-08T18:58:08Z","published":"2023-07-08T18:58:08Z","title":"Learning Variational Neighbor Labels for Test-Time Domain Generalization","summary":"  This paper strives for domain generalization, where models are trained\nexclusively on source domains before being deployed at unseen target domains.\nWe follow the strict separation of source training and target testing but\nexploit the value of the unlabeled target data itself during inference. We make\nthree contributions. First, we propose probabilistic pseudo-labeling of target\nsamples to generalize the source-trained model to the target domain at test\ntime. We formulate the generalization at test time as a variational inference\nproblem by modeling pseudo labels as distributions to consider the uncertainty\nduring generalization and alleviate the misleading signal of inaccurate pseudo\nlabels. Second, we learn variational neighbor labels that incorporate the\ninformation of neighboring target samples to generate more robust pseudo\nlabels. Third, to learn the ability to incorporate more representative target\ninformation and generate more precise and robust variational neighbor labels,\nwe introduce a meta-generalization stage during training to simulate the\ngeneralization procedure. Experiments on six widely-used datasets demonstrate\nthe benefits, abilities, and effectiveness of our proposal.\n","authors":["Sameer Ambekar","Zehao Xiao","Jiayi Shen","Xiantong Zhen","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2307.04033v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2305.06569v4","updated":"2023-07-08T18:57:21Z","published":"2023-05-11T05:02:37Z","title":"How to Index Item IDs for Recommendation Foundation Models","summary":"  Recommendation foundation model utilizes large language models (LLM) for\nrecommendation by converting recommendation tasks into natural language tasks.\nIt enables generative recommendation which directly generates the item(s) to\nrecommend rather than calculating a ranking score for each and every candidate\nitem in traditional recommendation models, simplifying the recommendation\npipeline from multi-stage filtering to single-stage filtering. To avoid\ngenerating excessively long text when deciding which item(s) to recommend,\ncreating LLM-compatible item IDs is essential for recommendation foundation\nmodels. In this study, we systematically examine the item indexing problem for\nrecommendation foundation models, using P5 as the representative backbone model\nand replicating its results with various indexing methods. To emphasize the\nimportance of item indexing, we first discuss the issues of several trivial\nitem indexing methods, such as independent indexing, title indexing, and random\nindexing. We then propose four simple yet effective solutions, including\nsequential indexing, collaborative indexing, semantic (content-based) indexing,\nand hybrid indexing. Our reproducibility study of P5 highlights the significant\ninfluence of item indexing methods on the model performance, and our results on\nreal-world datasets validate the effectiveness of our proposed solutions.\n","authors":["Wenyue Hua","Shuyuan Xu","Yingqiang Ge","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.06569v4.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2307.04029v1","updated":"2023-07-08T18:38:56Z","published":"2023-07-08T18:38:56Z","title":"On \"Indifference\" and Backward Induction in Games with Perfect\n  Information","summary":"  Indifference of a player with respect to two distinct outcomes of a game\ncannot be handled by small perturbations, because the actual choice may have\nsignificant impact on other players, and cause them to act in a way that has\nsignificant impact of the indifferent player. It is argued that ties among\nrational choices can be resolved by refinements of the concept of rationality\nbased on the utilities of other players. One such refinement is the concept of\nTit-for-Tat.\n","authors":["Nimrod Megiddo"],"pdf_url":"https://arxiv.org/pdf/2307.04029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04028v1","updated":"2023-07-08T18:31:25Z","published":"2023-07-08T18:31:25Z","title":"Measuring the Success of Diffusion Models at Imitating Human Artists","summary":"  Modern diffusion models have set the state-of-the-art in AI image generation.\nTheir success is due, in part, to training on Internet-scale data which often\nincludes copyrighted work. This prompts questions about the extent to which\nthese models learn from, imitate, or copy the work of human artists. This work\nsuggests that tying copyright liability to the capabilities of the model may be\nuseful given the evolving ecosystem of generative models. Specifically, much of\nthe legal analysis of copyright and generative systems focuses on the use of\nprotected data for training. As a result, the connections between data,\ntraining, and the system are often obscured. In our approach, we consider\nsimple image classification techniques to measure a model's ability to imitate\nspecific artists. Specifically, we use Contrastive Language-Image Pretrained\n(CLIP) encoders to classify images in a zero-shot fashion. Our process first\nprompts a model to imitate a specific artist. Then, we test whether CLIP can be\nused to reclassify the artist (or the artist's work) from the imitation. If\nthese tests match the imitation back to the original artist, this suggests the\nmodel can imitate that artist's expression. Our approach is simple and\nquantitative. Furthermore, it uses standard techniques and does not require\nadditional training. We demonstrate our approach with an audit of Stable\nDiffusion's capacity to imitate 70 professional digital artists with\ncopyrighted work online. When Stable Diffusion is prompted to imitate an artist\nfrom this set, we find that the artist can be identified from the imitation\nwith an average accuracy of 81.0%. Finally, we also show that a sample of the\nartist's work can be matched to these imitation images with a high degree of\nstatistical reliability. Overall, these results suggest that Stable Diffusion\nis broadly successful at imitating individual human artists.\n","authors":["Stephen Casper","Zifan Guo","Shreya Mogulothu","Zachary Marinov","Chinmay Deshpande","Rui-Jie Yew","Zheng Dai","Dylan Hadfield-Menell"],"pdf_url":"https://arxiv.org/pdf/2307.04028v1.pdf","comment":"Accepted to the 1 st Workshop on Generative AI and Law"},{"id":"http://arxiv.org/abs/2306.04139v2","updated":"2023-07-08T18:08:01Z","published":"2023-06-07T04:26:41Z","title":"A Comprehensive Survey on Generative Diffusion Models for Structured\n  Data","summary":"  In recent years, generative diffusion models have achieved a rapid paradigm\nshift in deep generative models by showing groundbreaking performance across\nvarious applications. Meanwhile, structured data, encompassing tabular and time\nseries data, has been received comparatively limited attention from the deep\nlearning research community, despite its omnipresence and extensive\napplications. Thus, there is still a lack of literature and its reviews on\nstructured data modelling via diffusion models, compared to other data\nmodalities such as visual and textual data. To address this gap, we present a\ncomprehensive review of recently proposed diffusion models in the field of\nstructured data. First, this survey provides a concise overview of the\nscore-based diffusion model theory, subsequently proceeding to the technical\ndescriptions of the majority of pioneering works that used structured data in\nboth data-driven general tasks and domain-specific applications. Thereafter, we\nanalyse and discuss the limitations and challenges shown in existing works and\nsuggest potential research directions. We hope this review serves as a catalyst\nfor the research community, promoting developments in generative diffusion\nmodels for structured data.\n","authors":["Heejoon Koo","To Eun Kim"],"pdf_url":"https://arxiv.org/pdf/2306.04139v2.pdf","comment":"20 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2212.14106v3","updated":"2023-07-08T17:57:36Z","published":"2022-12-28T22:05:32Z","title":"Provable Robust Saliency-based Explanations","summary":"  Robust explanations of machine learning models are critical to establishing\nhuman trust in the models. The top-$k$ intersection is widely used to evaluate\nthe robustness of explanations. However, most existing attacking and defense\nstrategies are based on $\\ell_p$ norms, thus creating a mismatch between the\nevaluation and optimization objectives. To this end, we define explanation\nthickness for measuring top-$k$ salient features ranking stability, and design\nthe \\textit{R2ET} algorithm based on a novel tractable surrogate to maximize\nthe thickness and stabilize the top salient features efficiently.\nTheoretically, we prove a connection between R2ET and adversarial training;\nusing a novel multi-objective optimization formulation and a generalization\nerror bound, we further prove that the surrogate objective can improve both the\nnumerical and statistical stability of the explanations. Experiments with a\nwide spectrum of network architectures and data modalities demonstrate that\nR2ET attains higher explanation robustness under stealthy attacks while\nretaining model accuracy.\n","authors":["Chao Chen","Chenghua Guo","Guixiang Ma","Ming Zeng","Xi Zhang","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2212.14106v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04019v1","updated":"2023-07-08T17:33:20Z","published":"2023-07-08T17:33:20Z","title":"GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered\n  Environments","summary":"  Robotic navigation in unknown, cluttered environments with limited sensing\ncapabilities poses significant challenges in robotics. Local trajectory\noptimization methods, such as Model Predictive Path Intergal (MPPI), are a\npromising solution to this challenge. However, global guidance is required to\nensure effective navigation, especially when encountering challenging\nenvironmental conditions or navigating beyond the planning horizon. This study\npresents the GP-MPPI, an online learning-based control strategy that integrates\nMPPI with a local perception model based on Sparse Gaussian Process (SGP). The\nkey idea is to leverage the learning capability of SGP to construct a variance\n(uncertainty) surface, which enables the robot to learn about the navigable\nspace surrounding it, identify a set of suggested subgoals, and ultimately\nrecommend the optimal subgoal that minimizes a predefined cost function to the\nlocal MPPI planner. Afterward, MPPI computes the optimal control sequence that\nsatisfies the robot and collision avoidance constraints. Such an approach\neliminates the necessity of a global map of the environment or an offline\ntraining process. We validate the efficiency and robustness of our proposed\ncontrol strategy through both simulated and real-world experiments of 2D\nautonomous navigation tasks in complex unknown environments, demonstrating its\nsuperiority in guiding the robot safely towards its desired goal while avoiding\nobstacles and escaping entrapment in local minima. The GPU implementation of\nGP-MPPI, including the supplementary video, is available at\nhttps://github.com/IhabMohamed/GP-MPPI.\n","authors":["Ihab S. Mohamed","Mahmoud Ali","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2307.04019v1.pdf","comment":"This paper has 8 pages, 6 figures, 2 tables. It has been accepted for\n  publication at the IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS), Detroit, Michigan, USA, 2023"},{"id":"http://arxiv.org/abs/2303.00501v2","updated":"2023-07-08T16:50:22Z","published":"2023-03-01T13:35:22Z","title":"OmniForce: On Human-Centered, Large Model Empowered and Cloud-Edge\n  Collaborative AutoML System","summary":"  Automated machine learning (AutoML) seeks to build ML models with minimal\nhuman effort. While considerable research has been conducted in the area of\nAutoML in general, aiming to take humans out of the loop when building\nartificial intelligence (AI) applications, scant literature has focused on how\nAutoML works well in open-environment scenarios such as the process of training\nand updating large models, industrial supply chains or the industrial\nmetaverse, where people often face open-loop problems during the search\nprocess: they must continuously collect data, update data and models, satisfy\nthe requirements of the development and deployment environment, support massive\ndevices, modify evaluation metrics, etc. Addressing the open-environment issue\nwith pure data-driven approaches requires considerable data, computing\nresources, and effort from dedicated data engineers, making current AutoML\nsystems and platforms inefficient and computationally intractable.\nHuman-computer interaction is a practical and feasible way to tackle the\nproblem of open-environment AI. In this paper, we introduce OmniForce, a\nhuman-centered AutoML (HAML) system that yields both human-assisted ML and\nML-assisted human techniques, to put an AutoML system into practice and build\nadaptive AI in open-environment scenarios. Specifically, we present OmniForce\nin terms of ML version management; pipeline-driven development and deployment\ncollaborations; a flexible search strategy framework; and widely provisioned\nand crowdsourced application algorithms, including large models. Furthermore,\nthe (large) models constructed by OmniForce can be automatically turned into\nremote services in a few minutes; this process is dubbed model as a service\n(MaaS). Experimental results obtained in multiple search spaces and real-world\nuse cases demonstrate the efficacy and efficiency of OmniForce.\n","authors":["Chao Xue","Wei Liu","Shuai Xie","Zhenfang Wang","Jiaxing Li","Xuyang Peng","Liang Ding","Shanshan Zhao","Qiong Cao","Yibo Yang","Fengxiang He","Bohua Cai","Rongcheng Bian","Yiyan Zhao","Heliang Zheng","Xiangyang Liu","Dongkai Liu","Daqing Liu","Li Shen","Chang Li","Shijin Zhang","Yukang Zhang","Guanpu Chen","Shixiang Chen","Yibing Zhan","Jing Zhang","Chaoyue Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.00501v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17607v2","updated":"2023-07-08T16:37:46Z","published":"2023-03-18T07:31:58Z","title":"Machine learning for discovering laws of nature","summary":"  Based on Darwin's natural selection, we developed \"machine scientists\" to\ndiscover the laws of nature by learning from raw data. \"Machine scientists\"\nconstruct physical theories by applying a logic tree (state Decision Tree) and\na value tree (observation Function Tree); the logical tree determines the state\nof the entity, and the value tree determines the absolute value between the two\nobservations of the entity. A logic Tree and a value tree together can\nreconstruct an entity's trajectory and make predictions about its future\noutcomes. Our proposed algorithmic model has an emphasis on machine learning -\nwhere \"machine scientists\" builds up its experience by being rewarded or\npunished for each decision they make - eventually leading to rediscovering\nNewton's equation (classical physics) and the Born's rule (quantum mechanics).\n","authors":["Lizhi Xin","Kevin Xin","Houwen Xin"],"pdf_url":"https://arxiv.org/pdf/2303.17607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04005v1","updated":"2023-07-08T16:22:42Z","published":"2023-07-08T16:22:42Z","title":"Proceedings Ninetheenth conference on Theoretical Aspects of Rationality\n  and Knowledge","summary":"  The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a\nconference that aims to bring together researchers from a wide variety of\nfields, including computer science, artificial intelligence, game theory,\ndecision theory, philosophy, logic, linguistics, and cognitive science. Its\ngoal is to further our understanding of interdisciplinary issues involving\nreasoning about rationality and knowledge.\n  Previous conferences have been held biennially around the world since 1986,\non the initiative of Joe Halpern (Cornell University). Topics of interest\ninclude, but are not limited to, semantic models for knowledge, belief,\nawareness and uncertainty, bounded rationality and resource-bounded reasoning,\ncommonsense epistemic reasoning, epistemic logic, epistemic game theory,\nknowledge and action, applications of reasoning about knowledge and other\nmental states, belief revision, computational social choice, algorithmic game\ntheory, and foundations of multi-agent systems. Information about TARK,\nincluding conference proceedings, is available at the website\nhttp://www.tark.org/\n  These proceedings contain the papers that have been accepted for presentation\nat the Nineteenth Conference on Theoretical Aspects of Rationality and\nKnowledge (TARK 2023), held between June 28 and June 30, 2023, at the\nUniversity of Oxford, United Kingdom. The conference website can be found at\nhttps://sites.google.com/view/tark-2023\n","authors":["Rineke Verbrugge"],"pdf_url":"https://arxiv.org/pdf/2307.04005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.11931v3","updated":"2023-07-08T16:18:03Z","published":"2022-01-28T04:50:37Z","title":"Fast Interpretable Greedy-Tree Sums","summary":"  Modern machine learning has achieved impressive prediction performance, but\noften sacrifices interpretability, a critical consideration in high-stakes\ndomains such as medicine. In such settings, practitioners often use highly\ninterpretable decision tree models, but these suffer from inductive bias\nagainst additive structure. To overcome this bias, we propose Fast\nInterpretable Greedy-Tree Sums (FIGS), which generalizes the CART algorithm to\nsimultaneously grow a flexible number of trees in summation. By combining\nlogical rules with addition, FIGS is able to adapt to additive structure while\nremaining highly interpretable. Extensive experiments on real-world datasets\nshow that FIGS achieves state-of-the-art prediction performance. To demonstrate\nthe usefulness of FIGS in high-stakes domains, we adapt FIGS to learn clinical\ndecision instruments (CDIs), which are tools for guiding clinical\ndecision-making. Specifically, we introduce a variant of FIGS known as G-FIGS\nthat accounts for the heterogeneity in medical data. G-FIGS derives CDIs that\nreflect domain knowledge and enjoy improved specificity (by up to 20% over\nCART) without sacrificing sensitivity or interpretability. To provide further\ninsight into FIGS, we prove that FIGS learns components of additive models, a\nproperty we refer to as disentanglement. Further, we show (under oracle\nconditions) that unconstrained tree-sum models leverage disentanglement to\ngeneralize more efficiently than single decision tree models when fitted to\nadditive regression functions. Finally, to avoid overfitting with an\nunconstrained number of splits, we develop Bagging-FIGS, an ensemble version of\nFIGS that borrows the variance reduction techniques of random forests.\nBagging-FIGS enjoys competitive performance with random forests and XGBoost on\nreal-world datasets.\n","authors":["Yan Shuo Tan","Chandan Singh","Keyan Nasseri","Abhineet Agarwal","James Duncan","Omer Ronen","Matthew Epland","Aaron Kornblith","Bin Yu"],"pdf_url":"https://arxiv.org/pdf/2201.11931v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03712v2","updated":"2023-07-08T15:48:43Z","published":"2022-12-06T05:48:11Z","title":"Enhanced Multi-Objective A* with Partial Expansion","summary":"  The Multi-Objective Shortest Path Problem (MO-SPP), typically posed on a\ngraph, determines a set of paths from a start vertex to a destination vertex\nwhile optimizing multiple objectives. In general, there does not exist a single\nsolution path that can simultaneously optimize all the objectives and the\nproblem thus seeks to find a set of so-called Pareto-optimal solutions. To\naddress this problem, several Multi-Objective A* (MOA*) algorithms were\nrecently developed to quickly compute solutions with quality guarantees.\nHowever, these MOA* algorithms often suffer from high memory usage, especially\nwhen the branching factor (i.e. the number of neighbors of any vertex) of the\ngraph is large. This work thus aims at reducing the high memory consumption of\nMOA* with little increase in the runtime. By generalizing and unifying several\nsingle- and multi-objective search algorithms, we develop the Runtime and\nMemory Efficient MOA* (RME-MOA*) approach, which can balance between runtime\nand memory efficiency by tuning two user-defined hyper-parameters.\n","authors":["Valmiki Kothare","Zhongqiang Ren","Sivakumar Rathinam","Howie Choset"],"pdf_url":"https://arxiv.org/pdf/2212.03712v2.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2307.03988v1","updated":"2023-07-08T14:33:06Z","published":"2023-07-08T14:33:06Z","title":"PCG-based Static Underground Garage Scenario Generation","summary":"  Autonomous driving technology has five levels, from L0 to L5. Currently, only\nthe L2 level (partial automation) can be achieved, and there is a long way to\ngo before reaching the final level of L5 (full automation). The key to crossing\nthese levels lies in training the autonomous driving model. However, relying\nsolely on real-world road data to train the model is far from enough and\nconsumes a great deal of resources. Although there are already examples of\ntraining autonomous driving models through simulators that simulate real-world\nscenarios, these scenarios require complete manual construction. Directly\nconverting 3D scenes from road network formats will lack a large amount of\ndetail and cannot be used as training sets. Underground parking garage static\nscenario simulation is regarded as a procedural content generation (PCG)\nproblem. This paper will use the Sarsa algorithm to solve procedural content\ngeneration on underground garage structures.\n","authors":["Wenjin Li","Kai Li"],"pdf_url":"https://arxiv.org/pdf/2307.03988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03973v1","updated":"2023-07-08T13:13:20Z","published":"2023-07-08T13:13:20Z","title":"Autonomy 2.0: The Quest for Economies of Scale","summary":"  With the advancement of robotics and AI technologies in the past decade, we\nhave now entered the age of autonomous machines. In this new age of information\ntechnology, autonomous machines, such as service robots, autonomous drones,\ndelivery robots, and autonomous vehicles, rather than humans, will provide\nservices. In this article, through examining the technical challenges and\neconomic impact of the digital economy, we argue that scalability is both\nhighly necessary from a technical perspective and significantly advantageous\nfrom an economic perspective, thus is the key for the autonomy industry to\nachieve its full potential. Nonetheless, the current development paradigm,\ndubbed Autonomy 1.0, scales with the number of engineers, instead of with the\namount of data or compute resources, hence preventing the autonomy industry to\nfully benefit from the economies of scale, especially the exponentially\ncheapening compute cost and the explosion of available data. We further analyze\nthe key scalability blockers and explain how a new development paradigm, dubbed\nAutonomy 2.0, can address these problems to greatly boost the autonomy\nindustry.\n","authors":["Shuang Wu","Bo Yu","Shaoshan Liu","Yuhao Zhu"],"pdf_url":"https://arxiv.org/pdf/2307.03973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01018v4","updated":"2023-07-08T12:43:42Z","published":"2023-02-02T11:12:51Z","title":"Graph Neural Networks for temporal graphs: State of the art, open\n  challenges, and opportunities","summary":"  Graph Neural Networks (GNNs) have become the leading paradigm for learning on\n(static) graph-structured data. However, many real-world systems are dynamic in\nnature, since the graph and node/edge attributes change over time. In recent\nyears, GNN-based models for temporal graphs have emerged as a promising area of\nresearch to extend the capabilities of GNNs. In this work, we provide the first\ncomprehensive overview of the current state-of-the-art of temporal GNN,\nintroducing a rigorous formalization of learning settings and tasks and a novel\ntaxonomy categorizing existing approaches in terms of how the temporal aspect\nis represented and processed. We conclude the survey with a discussion of the\nmost relevant open challenges for the field, from both research and application\nperspectives.\n","authors":["Antonio Longa","Veronica Lachi","Gabriele Santin","Monica Bianchini","Bruno Lepri","Pietro Lio","Franco Scarselli","Andrea Passerini"],"pdf_url":"https://arxiv.org/pdf/2302.01018v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03966v1","updated":"2023-07-08T12:35:10Z","published":"2023-07-08T12:35:10Z","title":"Multi-Intent Detection in User Provided Annotations for Programming by\n  Examples Systems","summary":"  In mapping enterprise applications, data mapping remains a fundamental part\nof integration development, but its time consuming. An increasing number of\napplications lack naming standards, and nested field structures further add\ncomplexity for the integration developers. Once the mapping is done, data\ntransformation is the next challenge for the users since each application\nexpects data to be in a certain format. Also, while building integration flow,\ndevelopers need to understand the format of the source and target data field\nand come up with transformation program that can change data from source to\ntarget format. The problem of automatic generation of a transformation program\nthrough program synthesis paradigm from some specifications has been studied\nsince the early days of Artificial Intelligence (AI). Programming by Example\n(PBE) is one such kind of technique that targets automatic inferencing of a\ncomputer program to accomplish a format or string conversion task from\nuser-provided input and output samples. To learn the correct intent, a diverse\nset of samples from the user is required. However, there is a possibility that\nthe user fails to provide a diverse set of samples. This can lead to multiple\nintents or ambiguity in the input and output samples. Hence, PBE systems can\nget confused in generating the correct intent program. In this paper, we\npropose a deep neural network based ambiguity prediction model, which analyzes\nthe input-output strings and maps them to a different set of properties\nresponsible for multiple intent. Users can analyze these properties and\naccordingly can provide new samples or modify existing samples which can help\nin building a better PBE system for mapping enterprise applications.\n","authors":["Nischal Ashok Kumar","Nitin Gupta","Shanmukha Guttula","Hima Patel"],"pdf_url":"https://arxiv.org/pdf/2307.03966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14773v2","updated":"2023-07-08T12:13:50Z","published":"2023-03-26T16:42:05Z","title":"BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning","summary":"  With the surge of large-scale pre-trained models (PTMs), fine-tuning these\nmodels to numerous downstream tasks becomes a crucial problem. Consequently,\nparameter efficient transfer learning (PETL) of large models has grasped huge\nattention. While recent PETL methods showcase impressive performance, they rely\non optimistic assumptions: 1) the entire parameter set of a PTM is available,\nand 2) a sufficiently large memory capacity for the fine-tuning is equipped.\nHowever, in most real-world applications, PTMs are served as a black-box API or\nproprietary software without explicit parameter accessibility. Besides, it is\nhard to meet a large memory requirement for modern PTMs. In this work, we\npropose black-box visual prompting (BlackVIP), which efficiently adapts the\nPTMs without knowledge about model architectures and parameters. BlackVIP has\ntwo components; 1) Coordinator and 2) simultaneous perturbation stochastic\napproximation with gradient correction (SPSA-GC). The Coordinator designs\ninput-dependent image-shaped visual prompts, which improves few-shot adaptation\nand robustness on distribution/location shift. SPSA-GC efficiently estimates\nthe gradient of a target model to update Coordinator. Extensive experiments on\n16 datasets demonstrate that BlackVIP enables robust adaptation to diverse\ndomains without accessing PTMs' parameters, with minimal memory requirements.\nCode: \\url{https://github.com/changdaeoh/BlackVIP}\n","authors":["Changdae Oh","Hyeji Hwang","Hee-young Lee","YongTaek Lim","Geunyoung Jung","Jiyoung Jung","Hosik Choi","Kyungwoo Song"],"pdf_url":"https://arxiv.org/pdf/2303.14773v2.pdf","comment":"Accepted to CVPR 2023 (v2: citation error was fixed)"},{"id":"http://arxiv.org/abs/2212.02098v2","updated":"2023-07-08T10:50:19Z","published":"2022-12-05T08:34:23Z","title":"A Machine with Short-Term, Episodic, and Semantic Memory Systems","summary":"  Inspired by the cognitive science theory of the explicit human memory\nsystems, we have modeled an agent with short-term, episodic, and semantic\nmemory systems, each of which is modeled with a knowledge graph. To evaluate\nthis system and analyze the behavior of this agent, we designed and released\nour own reinforcement learning agent environment, \"the Room\", where an agent\nhas to learn how to encode, store, and retrieve memories to maximize its return\nby answering questions. We show that our deep Q-learning based agent\nsuccessfully learns whether a short-term memory should be forgotten, or rather\nbe stored in the episodic or semantic memory systems. Our experiments indicate\nthat an agent with human-like memory systems can outperform an agent without\nthis memory structure in the environment.\n","authors":["Taewoon Kim","Michael Cochez","Vincent François-Lavet","Mark Neerincx","Piek Vossen"],"pdf_url":"https://arxiv.org/pdf/2212.02098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06951v5","updated":"2023-07-08T10:00:29Z","published":"2022-12-14T00:04:56Z","title":"AI Ethics on Blockchain: Topic Analysis on Twitter Data for Blockchain\n  Security","summary":"  Blockchain has empowered computer systems to be more secure using a\ndistributed network. However, the current blockchain design suffers from\nfairness issues in transaction ordering. Miners are able to reorder\ntransactions to generate profits, the so-called miner extractable value (MEV).\nExisting research recognizes MEV as a severe security issue and proposes\npotential solutions, including prominent Flashbots. However, previous studies\nhave mostly analyzed blockchain data, which might not capture the impacts of\nMEV in a much broader AI society. Thus, in this research, we applied natural\nlanguage processing (NLP) methods to comprehensively analyze topics in tweets\non MEV. We collected more than 20000 tweets with #MEV and #Flashbots hashtags\nand analyzed their topics. Our results show that the tweets discussed profound\ntopics of ethical concern, including security, equity, emotional sentiments,\nand the desire for solutions to MEV. We also identify the co-movements of MEV\nactivities on blockchain and social media platforms. Our study contributes to\nthe literature at the interface of blockchain security, MEV solutions, and AI\nethics.\n","authors":["Yihang Fu","Zesen Zhuang","Luyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.06951v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12893v8","updated":"2023-07-08T09:52:27Z","published":"2022-01-30T19:01:23Z","title":"Cryptocurrency Valuation: An Explainable AI Approach","summary":"  Currently, there are no convincing proxies for the fundamentals of\ncryptocurrency assets. We propose a new market-to-fundamental ratio, the\nprice-to-utility (PU) ratio, utilizing unique blockchain accounting methods. We\nthen proxy various existing fundamental-to-market ratios by Bitcoin historical\ndata and find they have little predictive power for short-term bitcoin returns.\nHowever, PU ratio effectively predicts long-term bitcoin returns than\nalternative methods. Furthermore, we verify the explainability of PU ratio\nusing machine learning. Finally, we present an automated trading strategy\nadvised by the PU ratio that outperforms the conventional buy-and-hold and\nmarket-timing strategies. Our research contributes to explainable AI in finance\nfrom three facets: First, our market-to-fundamental ratio is based on classic\nmonetary theory and the unique UTXO model of Bitcoin accounting rather than ad\nhoc; Second, the empirical evidence testifies the buy-low and sell-high\nimplications of the ratio; Finally, we distribute the trading algorithms as\nopen-source software via Python Package Index for future research, which is\nexceptional in finance research.\n","authors":["Yulin Liu","Luyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2201.12893v8.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03941v1","updated":"2023-07-08T09:28:50Z","published":"2023-07-08T09:28:50Z","title":"Right to be Forgotten in the Era of Large Language Models: Implications,\n  Challenges, and Solutions","summary":"  The Right to be Forgotten (RTBF) was first established as the result of the\nruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\\'alez, and\nwas later included as the Right to Erasure under the General Data Protection\nRegulation (GDPR) of European Union to allow individuals the right to request\npersonal data be deleted by organizations. Specifically for search engines,\nindividuals can send requests to organizations to exclude their information\nfrom the query results. With the recent development of Large Language Models\n(LLMs) and their use in chatbots, LLM-enabled software systems have become\npopular. But they are not excluded from the RTBF. Compared with the indexing\napproach used by search engines, LLMs store, and process information in a\ncompletely different way. This poses new challenges for compliance with the\nRTBF. In this paper, we explore these challenges and provide our insights on\nhow to implement technical solutions for the RTBF, including the use of machine\nunlearning, model editing, and prompting engineering.\n","authors":["Dawen Zhang","Pamela Finckenberg-Broman","Thong Hoang","Shidong Pan","Zhenchang Xing","Mark Staples","Xiwei Xu"],"pdf_url":"https://arxiv.org/pdf/2307.03941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03937v1","updated":"2023-07-08T09:10:43Z","published":"2023-07-08T09:10:43Z","title":"Inductive Meta-path Learning for Schema-complex Heterogeneous\n  Information Networks","summary":"  Heterogeneous Information Networks (HINs) are information networks with\nmultiple types of nodes and edges. The concept of meta-path, i.e., a sequence\nof entity types and relation types connecting two entities, is proposed to\nprovide the meta-level explainable semantics for various HIN tasks.\nTraditionally, meta-paths are primarily used for schema-simple HINs, e.g.,\nbibliographic networks with only a few entity types, where meta-paths are often\nenumerated with domain knowledge. However, the adoption of meta-paths for\nschema-complex HINs, such as knowledge bases (KBs) with hundreds of entity and\nrelation types, has been limited due to the computational complexity associated\nwith meta-path enumeration. Additionally, effectively assessing meta-paths\nrequires enumerating relevant path instances, which adds further complexity to\nthe meta-path learning process. To address these challenges, we propose\nSchemaWalk, an inductive meta-path learning framework for schema-complex HINs.\nWe represent meta-paths with schema-level representations to support the\nlearning of the scores of meta-paths for varying relations, mitigating the need\nof exhaustive path instance enumeration for each relation. Further, we design a\nreinforcement-learning based path-finding agent, which directly navigates the\nnetwork schema (i.e., schema graph) to learn policies for establishing\nmeta-paths with high coverage and confidence for multiple relations. Extensive\nexperiments on real data sets demonstrate the effectiveness of our proposed\nparadigm.\n","authors":["Shixuan Liu","Changjun Fan","Kewei Cheng","Yunfei Wang","Peng Cui","Yizhou Sun","Zhong Liu"],"pdf_url":"https://arxiv.org/pdf/2307.03937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03936v1","updated":"2023-07-08T09:10:35Z","published":"2023-07-08T09:10:35Z","title":"Towards Efficient In-memory Computing Hardware for Quantized Neural\n  Networks: State-of-the-art, Open Challenges and Perspectives","summary":"  The amount of data processed in the cloud, the development of\nInternet-of-Things (IoT) applications, and growing data privacy concerns force\nthe transition from cloud-based to edge-based processing. Limited energy and\ncomputational resources on edge push the transition from traditional von\nNeumann architectures to In-memory Computing (IMC), especially for machine\nlearning and neural network applications. Network compression techniques are\napplied to implement a neural network on limited hardware resources.\nQuantization is one of the most efficient network compression techniques\nallowing to reduce the memory footprint, latency, and energy consumption. This\npaper provides a comprehensive review of IMC-based Quantized Neural Networks\n(QNN) and links software-based quantization approaches to IMC hardware\nimplementation. Moreover, open challenges, QNN design requirements,\nrecommendations, and perspectives along with an IMC-based QNN hardware roadmap\nare provided.\n","authors":["Olga Krestinskaya","Li Zhang","Khaled Nabil Salama"],"pdf_url":"https://arxiv.org/pdf/2307.03936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01772v2","updated":"2023-07-08T08:25:19Z","published":"2023-05-29T06:17:58Z","title":"Re-imagining health and well-being in low resource African settings\n  using an augmented AI system and a 3D digital twin","summary":"  This paper discusses and explores the potential and relevance of recent\ndevelopments in artificial intelligence (AI) and digital twins for health and\nwell-being in low-resource African countries. We use the case of public health\nemergency response to disease outbreaks and epidemic control. There is\npotential to take advantage of the increasing availability of data and\ndigitization to develop advanced AI methods for analysis and prediction. Using\nan AI systems perspective, we review emerging trends in AI systems and digital\ntwins and propose an initial augmented AI system architecture to illustrate how\nan AI system can work with a 3D digital twin to address public health goals. We\nhighlight scientific knowledge discovery, continual learning, pragmatic\ninteroperability, and interactive explanation and decision-making as essential\nresearch challenges for AI systems and digital twins.\n","authors":["Deshendran Moodley","Christopher Seebregts"],"pdf_url":"https://arxiv.org/pdf/2306.01772v2.pdf","comment":"Submitted to Workshop on AI for Digital Twins and Cyber-physical\n  applications at IJCAI 2023, August 19--21, 2023, Macau, S.A.R"},{"id":"http://arxiv.org/abs/2307.03928v1","updated":"2023-07-08T08:02:47Z","published":"2023-07-08T08:02:47Z","title":"Bounding data reconstruction attacks with the hypothesis testing\n  interpretation of differential privacy","summary":"  We explore Reconstruction Robustness (ReRo), which was recently proposed as\nan upper bound on the success of data reconstruction attacks against machine\nlearning models. Previous research has demonstrated that differential privacy\n(DP) mechanisms also provide ReRo, but so far, only asymptotic Monte Carlo\nestimates of a tight ReRo bound have been shown. Directly computable ReRo\nbounds for general DP mechanisms are thus desirable. In this work, we establish\na connection between hypothesis testing DP and ReRo and derive closed-form,\nanalytic or numerical ReRo bounds for the Laplace and Gaussian mechanisms and\ntheir subsampled variants.\n","authors":["Georgios Kaissis","Jamie Hayes","Alexander Ziller","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2307.03928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.07286v2","updated":"2023-07-08T06:49:46Z","published":"2022-01-18T19:45:43Z","title":"Conservative Distributional Reinforcement Learning with Safety\n  Constraints","summary":"  Safety exploration can be regarded as a constrained Markov decision problem\nwhere the expected long-term cost is constrained. Previous off-policy\nalgorithms convert the constrained optimization problem into the corresponding\nunconstrained dual problem by introducing the Lagrangian relaxation technique.\nHowever, the cost function of the above algorithms provides inaccurate\nestimations and causes the instability of the Lagrange multiplier learning. In\nthis paper, we present a novel off-policy reinforcement learning algorithm\ncalled Conservative Distributional Maximum a Posteriori Policy Optimization\n(CDMPO). At first, to accurately judge whether the current situation satisfies\nthe constraints, CDMPO adapts distributional reinforcement learning method to\nestimate the Q-function and C-function. Then, CDMPO uses a conservative value\nfunction loss to reduce the number of violations of constraints during the\nexploration process. In addition, we utilize Weighted Average Proportional\nIntegral Derivative (WAPID) to update the Lagrange multiplier stably. Empirical\nresults show that the proposed method has fewer violations of constraints in\nthe early exploration process. The final test results also illustrate that our\nmethod has better risk control.\n","authors":["Hengrui Zhang","Youfang Lin","Sheng Han","Shuo Wang","Kai Lv"],"pdf_url":"https://arxiv.org/pdf/2201.07286v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2307.03913v1","updated":"2023-07-08T06:26:38Z","published":"2023-07-08T06:26:38Z","title":"Applying human-centered AI in developing effective human-AI teaming: A\n  perspective of human-AI joint cognitive systems","summary":"  Research and application have used human-AI teaming (HAT) as a new paradigm\nto develop AI systems. HAT recognizes that AI will function as a teammate\ninstead of simply a tool in collaboration with humans. Effective human-AI teams\nneed to be capable of taking advantage of the unique abilities of both humans\nand AI while overcoming the known challenges and limitations of each member,\naugmenting human capabilities, and raising joint performance beyond that of\neither entity. The National AI Research and Strategic Plan 2023 update has\nrecognized that research programs focusing primarily on the independent\nperformance of AI systems generally fail to consider the functionality that AI\nmust provide within the context of dynamic, adaptive, and collaborative teams\nand calls for further research on human-AI teaming and collaboration. However,\nthere has been debate about whether AI can work as a teammate with humans. The\nprimary concern is that adopting the \"teaming\" paradigm contradicts the\nhuman-centered AI (HCAI) approach, resulting in humans losing control of AI\nsystems. This article further analyzes the HAT paradigm and the debates.\nSpecifically, we elaborate on our proposed conceptual framework of human-AI\njoint cognitive systems (HAIJCS) and apply it to represent HAT under the HCAI\numbrella. We believe that HAIJCS may help adopt HAI while enabling HCAI. The\nimplications and future work for HAIJCS are also discussed.\n  Insights: AI has led to the emergence of a new form of human-machine\nrelationship: human-AI teaming (HAT), a paradigmatic shift in human-AI systems;\nWe must follow a human-centered AI (HCAI) approach when applying HAT as a new\ndesign paradigm; We propose a conceptual framework of human-AI joint cognitive\nsystems (HAIJCS) to represent and implement HAT for developing effective\nhuman-AI teaming\n","authors":["Wei Xu","Zaifeng Gao"],"pdf_url":"https://arxiv.org/pdf/2307.03913v1.pdf","comment":"8"},{"id":"http://arxiv.org/abs/2307.03906v1","updated":"2023-07-08T05:43:03Z","published":"2023-07-08T05:43:03Z","title":"ScriptWorld: Text Based Environment For Learning Procedural Knowledge","summary":"  Text-based games provide a framework for developing natural language\nunderstanding and commonsense knowledge about the world in reinforcement\nlearning based agents. Existing text-based environments often rely on fictional\nsituations and characters to create a gaming framework and are far from\nreal-world scenarios. In this paper, we introduce ScriptWorld: a text-based\nenvironment for teaching agents about real-world daily chores and hence\nimparting commonsense knowledge. To the best of our knowledge, it is the first\ninteractive text-based gaming framework that consists of daily real-world human\nactivities designed using scripts dataset. We provide gaming environments for\n10 daily activities and perform a detailed analysis of the proposed\nenvironment. We develop RL-based baseline models/agents to play the games in\nScriptworld. To understand the role of language models in such environments, we\nleverage features obtained from pre-trained language models in the RL agents.\nOur experiments show that prior knowledge obtained from a pre-trained language\nmodel helps to solve real-world text-based gaming environments. We release the\nenvironment via Github: https://github.com/Exploration-Lab/ScriptWorld\n","authors":["Abhinav Joshi","Areeb Ahmad","Umang Pandey","Ashutosh Modi"],"pdf_url":"https://arxiv.org/pdf/2307.03906v1.pdf","comment":"Accepted at IJCAI 2023, 26 Pages (7 main + 19 for appendix)"},{"id":"http://arxiv.org/abs/2306.01076v2","updated":"2023-07-08T04:29:09Z","published":"2023-06-01T18:32:08Z","title":"Quantization-Aware and Tensor-Compressed Training of Transformers for\n  Natural Language Understanding","summary":"  Fine-tuned transformer models have shown superior performances in many\nnatural language tasks. However, the large model size prohibits deploying\nhigh-performance transformer models on resource-constrained devices. This paper\nproposes a quantization-aware tensor-compressed training approach to reduce the\nmodel size, arithmetic operations, and ultimately runtime latency of\ntransformer-based models. We compress the embedding and linear layers of\ntransformers into small low-rank tensor cores, which significantly reduces\nmodel parameters. A quantization-aware training with learnable scale factors is\nused to further obtain low-precision representations of the tensor-compressed\nmodels. The developed approach can be used for both end-to-end training and\ndistillation-based training. To improve the convergence, a layer-by-layer\ndistillation is applied to distill a quantized and tensor-compressed student\nmodel from a pre-trained transformer. The performance is demonstrated in two\nnatural language understanding tasks, showing up to $63\\times$ compression\nratio, little accuracy loss and remarkable inference and training speedup.\n","authors":["Zi Yang","Samridhi Choudhary","Siegfried Kunzmann","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.01076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03887v1","updated":"2023-07-08T03:42:54Z","published":"2023-07-08T03:42:54Z","title":"Improving Prototypical Part Networks with Reward Reweighing,\n  Reselection, and Retraining","summary":"  In recent years, work has gone into developing deep interpretable methods for\nimage classification that clearly attributes a model's output to specific\nfeatures of the data. One such of these methods is the prototypical part\nnetwork (ProtoPNet), which attempts to classify images based on meaningful\nparts of the input. While this method results in interpretable classifications,\nthis method often learns to classify from spurious or inconsistent parts of the\nimage. Hoping to remedy this, we take inspiration from the recent developments\nin Reinforcement Learning with Human Feedback (RLHF) to fine-tune these\nprototypes. By collecting human annotations of prototypes quality via a 1-5\nscale on the CUB-200-2011 dataset, we construct a reward model that learns to\nidentify non-spurious prototypes. In place of a full RL update, we propose the\nreweighted, reselected, and retrained prototypical part network (R3-ProtoPNet),\nwhich adds an additional three steps to the ProtoPNet training loop. The first\ntwo steps are reward-based reweighting and reselection, which align prototypes\nwith human feedback. The final step is retraining to realign the model's\nfeatures with the updated prototypes. We find that R3-ProtoPNet improves the\noverall consistency and meaningfulness of the prototypes, but lower the test\npredictive accuracy when used independently. When multiple R3-ProtoPNets are\nincorporated into an ensemble, we find an increase in test predictive\nperformance while maintaining interpretability.\n","authors":["Robin Netzorg","Jiaxun Li","Bin Yu"],"pdf_url":"https://arxiv.org/pdf/2307.03887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03877v1","updated":"2023-07-08T01:45:25Z","published":"2023-07-08T01:45:25Z","title":"Designing Mixed-Initiative Video Games","summary":"  The development of Artificial Intelligence (AI) enables humans to co-create\ncontent with machines. The unexpectedness of AI-generated content can bring\ninspiration and entertainment to users. However, the co-creation interactions\nare always designed for content creators and have poor accessibility. To\nexplore gamification of mixed-initiative co-creation and make human-AI\ninteractions accessible and fun for players, I prototyped Snake Story, a\nmixed-initiative game where players can select AI-generated texts to write a\nstory of a snake by playing a \"Snake\" like game. A controlled experiment was\nconducted to investigate the dynamics of player-AI interactions with and\nwithout the game component in the designed interface. As a result of a study\nwith 11 players (n=11), I found that players utilized different strategies when\nplaying with the two versions, game mechanics significantly affected the output\nstories, players' creative process, as well as role perceptions, and players\nwith different backgrounds showed different preferences for the two versions.\nBased on these results, I further discussed considerations for mixed-initiative\ngame design. This work aims to inspire the design of engaging co-creation\nexperiences.\n","authors":["Daijin Yang"],"pdf_url":"https://arxiv.org/pdf/2307.03877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03875v1","updated":"2023-07-08T01:42:22Z","published":"2023-07-08T01:42:22Z","title":"Large Language Models for Supply Chain Optimization","summary":"  Supply chain operations traditionally involve a variety of complex decision\nmaking problems. Over the last few decades, supply chains greatly benefited\nfrom advances in computation, which allowed the transition from manual\nprocessing to automation and cost-effective optimization. Nonetheless, business\noperators still need to spend substantial efforts in \\emph{explaining} and\ninterpreting the optimization outcomes to stakeholders. Motivated by the recent\nadvances in Large Language Models (LLMs), we study how this disruptive\ntechnology can help bridge the gap between supply chain automation and human\ncomprehension and trust thereof. We design \\name{} -- a framework that accepts\nas input queries in plain text, and outputs insights about the underlying\noptimization outcomes. Our framework does not forgo the state-of-the-art\ncombinatorial optimization technology, but rather leverages it to\nquantitatively answer what-if scenarios (e.g., how would the cost change if we\nused supplier B instead of supplier A for a given demand?). Importantly, our\ndesign does not require sending proprietary data over to LLMs, which can be a\nprivacy concern in some circumstances. We demonstrate the effectiveness of our\nframework on a real server placement scenario within Microsoft's cloud supply\nchain. Along the way, we develop a general evaluation benchmark, which can be\nused to evaluate the accuracy of the LLM output in other scenarios.\n","authors":["Beibin Li","Konstantina Mellou","Bo Zhang","Jeevan Pathuri","Ishai Menache"],"pdf_url":"https://arxiv.org/pdf/2307.03875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03872v1","updated":"2023-07-08T01:23:36Z","published":"2023-07-08T01:23:36Z","title":"Domain Adaptation using Silver Standard Labels for Ki-67 Scoring in\n  Digital Pathology: A Step Closer to Widescale Deployment","summary":"  Deep learning systems have been proposed to improve the objectivity and\nefficiency of Ki- 67 PI scoring. The challenge is that while very accurate,\ndeep learning techniques suffer from reduced performance when applied to\nout-of-domain data. This is a critical challenge for clinical translation, as\nmodels are typically trained using data available to the vendor, which is not\nfrom the target domain. To address this challenge, this study proposes a domain\nadaptation pipeline that employs an unsupervised framework to generate silver\nstandard (pseudo) labels in the target domain, which is used to augment the\ngold standard (GS) source domain data. Five training regimes were tested on two\nvalidated Ki-67 scoring architectures (UV-Net and piNET), (1) SS Only: trained\non target silver standard (SS) labels, (2) GS Only: trained on source GS\nlabels, (3) Mixed: trained on target SS and source GS labels, (4) GS+SS:\ntrained on source GS labels and fine-tuned on target SS labels, and our\nproposed method (5) SS+GS: trained on source SS labels and fine-tuned on source\nGS labels. The SS+GS method yielded significantly (p < 0.05) higher PI accuracy\n(95.9%) and more consistent results compared to the GS Only model on target\ndata. Analysis of t-SNE plots showed features learned by the SS+GS models are\nmore aligned for source and target data, resulting in improved generalization.\nThe proposed pipeline provides an efficient method for learning the target\ndistribution without manual annotations, which are time-consuming and costly to\ngenerate for medical images. This framework can be applied to any target site\nas a per-laboratory calibration method, for widescale deployment.\n","authors":["Amanda Dy","Ngoc-Nhu Jennifer Nguyen","Seyed Hossein Mirjahanmardi","Melanie Dawe","Anthony Fyles","Wei Shi","Fei-Fei Liu","Dimitrios Androutsos","Susan Done","April Khademi"],"pdf_url":"https://arxiv.org/pdf/2307.03872v1.pdf","comment":"Editors: Accepted for publication at MIDL 2023"},{"id":"http://arxiv.org/abs/2307.03867v1","updated":"2023-07-08T00:26:36Z","published":"2023-07-08T00:26:36Z","title":"Personalized Resource Allocation in Wireless Networks: An AI-Enabled and\n  Big Data-Driven Multi-Objective Optimization","summary":"  The design and optimization of wireless networks have mostly been based on\nstrong mathematical and theoretical modeling. Nonetheless, as novel\napplications emerge in the era of 5G and beyond, unprecedented levels of\ncomplexity will be encountered in the design and optimization of the network.\nAs a result, the use of Artificial Intelligence (AI) is envisioned for wireless\nnetwork design and optimization due to the flexibility and adaptability it\noffers in solving extremely complex problems in real-time. One of the main\nfuture applications of AI is enabling user-level personalization for numerous\nuse cases. AI will revolutionize the way we interact with computers in which\ncomputers will be able to sense commands and emotions from humans in a\nnon-intrusive manner, making the entire process transparent to users. By\nleveraging this capability, and accelerated by the advances in computing\ntechnologies, wireless networks can be redesigned to enable the personalization\nof network services to the user level in real-time. While current wireless\nnetworks are being optimized to achieve a predefined set of quality\nrequirements, the personalization technology advocated in this article is\nsupported by an intelligent big data-driven layer designed to micro-manage the\nscarce network resources. This layer provides the intelligence required to\ndecide the necessary service quality that achieves the target satisfaction\nlevel for each user. Due to its dynamic and flexible design, personalized\nnetworks are expected to achieve unprecedented improvements in optimizing two\ncontradicting objectives in wireless networks: saving resources and improving\nuser satisfaction levels.\n","authors":["Rawan Alkurd","Ibrahim Abualhaol","Halim Yanikomeroglu"],"pdf_url":"https://arxiv.org/pdf/2307.03867v1.pdf","comment":null}]},"2023-07-11T00:00:00Z":{"Sound":[{"id":"http://arxiv.org/abs/2206.03318v2","updated":"2023-07-11T17:43:57Z","published":"2022-06-07T14:08:07Z","title":"LegoNN: Building Modular Encoder-Decoder Models","summary":"  State-of-the-art encoder-decoder models (e.g. for machine translation (MT) or\nautomatic speech recognition (ASR)) are constructed and trained end-to-end as\nan atomic unit. No component of the model can be (re-)used without the others,\nmaking it impossible to share parts, e.g. a high resourced decoder, across\ntasks. We describe LegoNN, a procedure for building encoder-decoder\narchitectures in a way so that its parts can be applied to other tasks without\nthe need for any fine-tuning. To achieve this reusability, the interface\nbetween encoder and decoder modules is grounded to a sequence of marginal\ndistributions over a pre-defined discrete vocabulary. We present two approaches\nfor ingesting these marginals; one is differentiable, allowing the flow of\ngradients across the entire network, and the other is gradient-isolating. To\nenable the portability of decoder modules between MT tasks for different source\nlanguages and across other tasks like ASR, we introduce a modality agnostic\nencoder which consists of a length control mechanism to dynamically adapt\nencoders' output lengths in order to match the expected input length range of\npre-trained decoders. We present several experiments to demonstrate the\neffectiveness of LegoNN models: a trained language generation LegoNN decoder\nmodule from German-English (De-En) MT task can be reused without any\nfine-tuning for the Europarl English ASR and the Romanian-English (Ro-En) MT\ntasks, matching or beating the performance of baseline. After fine-tuning,\nLegoNN models improve the Ro-En MT task by 1.5 BLEU points and achieve 12.5%\nrelative WER reduction on the Europarl ASR task. To show how the approach\ngeneralizes, we compose a LegoNN ASR model from three modules -- each has been\nlearned within different end-to-end trained models on three different datasets\n-- achieving an overall WER reduction of 19.5%.\n","authors":["Siddharth Dalmia","Dmytro Okhonko","Mike Lewis","Sergey Edunov","Shinji Watanabe","Florian Metze","Luke Zettlemoyer","Abdelrahman Mohamed"],"pdf_url":"https://arxiv.org/pdf/2206.03318v2.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing\n  (TASLP)"},{"id":"http://arxiv.org/abs/2303.00747v2","updated":"2023-07-11T17:07:19Z","published":"2023-03-01T18:59:13Z","title":"WhisperX: Time-Accurate Speech Transcription of Long-Form Audio","summary":"  Large-scale, weakly-supervised speech recognition models, such as Whisper,\nhave demonstrated impressive results on speech recognition across domains and\nlanguages. However, their application to long audio transcription via buffered\nor sliding window approaches is prone to drifting, hallucination & repetition;\nand prohibits batched transcription due to their sequential nature. Further,\ntimestamps corresponding each utterance are prone to inaccuracies and\nword-level timestamps are not available out-of-the-box. To overcome these\nchallenges, we present WhisperX, a time-accurate speech recognition system with\nword-level timestamps utilising voice activity detection and forced phoneme\nalignment. In doing so, we demonstrate state-of-the-art performance on\nlong-form transcription and word segmentation benchmarks. Additionally, we show\nthat pre-segmenting audio with our proposed VAD Cut & Merge strategy improves\ntranscription quality and enables a twelve-fold transcription speedup via\nbatched inference.\n","authors":["Max Bain","Jaesung Huh","Tengda Han","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2303.00747v2.pdf","comment":"Accepted to INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2307.05328v1","updated":"2023-07-11T15:19:47Z","published":"2023-07-11T15:19:47Z","title":"ProgGP: From GuitarPro Tablature Neural Generation To Progressive Metal\n  Production","summary":"  Recent work in the field of symbolic music generation has shown value in\nusing a tokenization based on the GuitarPro format, a symbolic representation\nsupporting guitar expressive attributes, as an input and output representation.\nWe extend this work by fine-tuning a pre-trained Transformer model on ProgGP, a\ncustom dataset of 173 progressive metal songs, for the purposes of creating\ncompositions from that genre through a human-AI partnership. Our model is able\nto generate multiple guitar, bass guitar, drums, piano and orchestral parts. We\nexamine the validity of the generated music using a mixed methods approach by\ncombining quantitative analyses following a computational musicology paradigm\nand qualitative analyses following a practice-based research paradigm. Finally,\nwe demonstrate the value of the model by using it as a tool to create a\nprogressive metal song, fully produced and mixed by a human metal producer\nbased on AI-generated music.\n","authors":["Jackson Loth","Pedro Sarmento","CJ Carr","Zack Zukowski","Mathieu Barthet"],"pdf_url":"https://arxiv.org/pdf/2307.05328v1.pdf","comment":"Pre-print accepted for publication at CMMR2023"},{"id":"http://arxiv.org/abs/2307.05324v1","updated":"2023-07-11T15:11:02Z","published":"2023-07-11T15:11:02Z","title":"ShredGP: Guitarist Style-Conditioned Tablature Generation","summary":"  GuitarPro format tablatures are a type of digital music notation that\nencapsulates information about guitar playing techniques and fingerings. We\nintroduce ShredGP, a GuitarPro tablature generative Transformer-based model\nconditioned to imitate the style of four distinct iconic electric guitarists.\nIn order to assess the idiosyncrasies of each guitar player, we adopt a\ncomputational musicology methodology by analysing features computed from the\ntokens yielded by the DadaGP encoding scheme. Statistical analyses of the\nfeatures evidence significant differences between the four guitarists. We\ntrained two variants of the ShredGP model, one using a multi-instrument corpus,\nthe other using solo guitar data. We present a BERT-based model for guitar\nplayer classification and use it to evaluate the generated examples. Overall,\nresults from the classifier show that ShredGP is able to generate content\ncongruent with the style of the targeted guitar player. Finally, we reflect on\nprospective applications for ShredGP for human-AI music interaction.\n","authors":["Pedro Sarmento","Adarsh Kumar","Dekun Xie","CJ Carr","Zack Zukowski","Mathieu Barthet"],"pdf_url":"https://arxiv.org/pdf/2307.05324v1.pdf","comment":"Accepted for publication at CMMR 2023"},{"id":"http://arxiv.org/abs/2306.04301v2","updated":"2023-07-11T15:03:00Z","published":"2023-06-07T10:05:45Z","title":"Interpretable Style Transfer for Text-to-Speech with ControlVAE and\n  Diffusion Bridge","summary":"  With the demand for autonomous control and personalized speech generation,\nthe style control and transfer in Text-to-Speech (TTS) is becoming more and\nmore important. In this paper, we propose a new TTS system that can perform\nstyle transfer with interpretability and high fidelity. Firstly, we design a\nTTS system that combines variational autoencoder (VAE) and diffusion refiner to\nget refined mel-spectrograms. Specifically, a two-stage and a one-stage system\nare designed respectively, to improve the audio quality and the performance of\nstyle transfer. Secondly, a diffusion bridge of quantized VAE is designed to\nefficiently learn complex discrete style representations and improve the\nperformance of style transfer. To have a better ability of style transfer, we\nintroduce ControlVAE to improve the reconstruction quality and have good\ninterpretability simultaneously. Experiments on LibriTTS dataset demonstrate\nthat our method is more effective than baseline models.\n","authors":["Wenhao Guan","Tao Li","Yishuang Li","Hukai Huang","Qingyang Hong","Lin Li"],"pdf_url":"https://arxiv.org/pdf/2306.04301v2.pdf","comment":"Accepted at Interspeech2023"},{"id":"http://arxiv.org/abs/2307.05161v1","updated":"2023-07-11T10:37:57Z","published":"2023-07-11T10:37:57Z","title":"On the Effectiveness of Speech Self-supervised Learning for Music","summary":"  Self-supervised learning (SSL) has shown promising results in various speech\nand natural language processing applications. However, its efficacy in music\ninformation retrieval (MIR) still remains largely unexplored. While previous\nSSL models pre-trained on music recordings may have been mostly closed-sourced,\nrecent speech models such as wav2vec2.0 have shown promise in music modelling.\nNevertheless, research exploring the effectiveness of applying speech SSL\nmodels to music recordings has been limited. We explore the music adaption of\nSSL with two distinctive speech-related models, data2vec1.0 and Hubert, and\nrefer to them as music2vec and musicHuBERT, respectively. We train $12$ SSL\nmodels with 95M parameters under various pre-training configurations and\nsystematically evaluate the MIR task performances with 13 different MIR tasks.\nOur findings suggest that training with music data can generally improve\nperformance on MIR tasks, even when models are trained using paradigms designed\nfor speech. However, we identify the limitations of such existing\nspeech-oriented designs, especially in modelling polyphonic information. Based\non the experimental results, empirical suggestions are also given for designing\nfuture musical SSL strategies and paradigms.\n","authors":["Yinghao Ma","Ruibin Yuan","Yizhi Li","Ge Zhang","Xingran Chen","Hanzhi Yin","Chenghua Lin","Emmanouil Benetos","Anton Ragni","Norbert Gyenge","Ruibo Liu","Gus Xia","Roger Dannenberg","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2307.05161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05140v1","updated":"2023-07-11T09:34:12Z","published":"2023-07-11T09:34:12Z","title":"Aeroacoustic testing on a full aircraft model at high Reynolds numbers\n  in the European Transonic Windtunnel","summary":"  This paper presents an end-to-end approach for the assessment of pressurized\nand cryogenic wind tunnel measurements of an EMBRAER scaled full model close to\nreal-world Reynolds numbers. The choice of microphones, measurement parameters,\nthe design of the array, and the selection of flow parameters are discussed.\nDifferent wind tunnel conditions are proposed which allow separating the\ninfluence of the Reynolds number from the Mach number, as well as the influence\nof slotted and closed test sections. The paper provides three-dimensional\nbeamforming results with CLEAN-SC deconvolution, the selection of regions of\ninterest, and the corresponding source spectra. The results suggest that\nslotted test sections have little influence on the beamforming results compared\nto closed test sections and that the Reynolds number has a profound, non-linear\nimpact on the aeroacoustic emission that lessens with increasing Reynolds\nnumber. Further, sources show a non-linear Mach number dependency at constant\nReynolds number but are self-similar in the observed Mach number range. The\nfindings suggest that it is possible to study real-world phenomena on\nsmall-scale full models at real-world Reynolds numbers, which enable further\ninvestigations in the future such as the directivity of sources.\n","authors":["Thomas Ahlefeldt","Daniel Ernst","Armin Goudarzi"," Hans-Georg-Raumer","Carsten Spehr"],"pdf_url":"https://arxiv.org/pdf/2307.05140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05132v1","updated":"2023-07-11T09:22:10Z","published":"2023-07-11T09:22:10Z","title":"On the Use of Self-Supervised Speech Representations in Spontaneous\n  Speech Synthesis","summary":"  Self-supervised learning (SSL) speech representations learned from large\namounts of diverse, mixed-quality speech data without transcriptions are\ngaining ground in many speech technology applications. Prior work has shown\nthat SSL is an effective intermediate representation in two-stage\ntext-to-speech (TTS) for both read and spontaneous speech. However, it is still\nnot clear which SSL and which layer from each SSL model is most suited for\nspontaneous TTS. We address this shortcoming by extending the scope of\ncomparison for SSL in spontaneous TTS to 6 different SSLs and 3 layers within\neach SSL. Furthermore, SSL has also shown potential in predicting the mean\nopinion scores (MOS) of synthesized speech, but this has only been done in\nread-speech MOS prediction. We extend an SSL-based MOS prediction framework\npreviously developed for scoring read speech synthesis and evaluate its\nperformance on synthesized spontaneous speech. All experiments are conducted\ntwice on two different spontaneous corpora in order to find generalizable\ntrends. Overall, we present comprehensive experimental results on the use of\nSSL in spontaneous TTS and MOS prediction to further quantify and understand\nhow SSL can be used in spontaneous TTS. Audios samples:\nhttps://www.speech.kth.se/tts-demos/sp_ssl_tts\n","authors":["Siyang Wang","Gustav Eje Henter","Joakim Gustafson","Éva Székely"],"pdf_url":"https://arxiv.org/pdf/2307.05132v1.pdf","comment":"7 pages, 2 figures. 12th ISCA Speech Synthesis Workshop (SSW) 2023"},{"id":"http://arxiv.org/abs/2307.05107v1","updated":"2023-07-11T08:34:11Z","published":"2023-07-11T08:34:11Z","title":"Optimizing Feature Extraction for Symbolic Music","summary":"  This paper presents a comprehensive investigation of existing feature\nextraction tools for symbolic music and contrasts their performance to\ndetermine the set of features that best characterizes the musical style of a\ngiven music score. In this regard, we propose a novel feature extraction tool,\nnamed musif, and evaluate its efficacy on various repertoires and file formats,\nincluding MIDI, MusicXML, and **kern. Musif approximates existing tools such as\njSymbolic and music21 in terms of computational efficiency while attempting to\nenhance the usability for custom feature development. The proposed tool also\nenhances classification accuracy when combined with other sets of features. We\ndemonstrate the contribution of each set of features and the computational\nresources they require. Our findings indicate that the optimal tool for feature\nextraction is a combination of the best features from each tool rather than\nthose of a single one. To facilitate future research in music information\nretrieval, we release the source code of the tool and benchmarks.\n","authors":["Federico Simonetta","Ana Llorens","Martín Serrano","Eduardo García-Portugués","Álvaro Torrente"],"pdf_url":"https://arxiv.org/pdf/2307.05107v1.pdf","comment":"Published at ISMIR 2023"},{"id":"http://arxiv.org/abs/2307.05096v1","updated":"2023-07-11T08:10:58Z","published":"2023-07-11T08:10:58Z","title":"The smarty4covid dataset and knowledge base: a framework enabling\n  interpretable analysis of audio signals","summary":"  Harnessing the power of Artificial Intelligence (AI) and m-health towards\ndetecting new bio-markers indicative of the onset and progress of respiratory\nabnormalities/conditions has greatly attracted the scientific and research\ninterest especially during COVID-19 pandemic. The smarty4covid dataset contains\naudio signals of cough (4,676), regular breathing (4,665), deep breathing\n(4,695) and voice (4,291) as recorded by means of mobile devices following a\ncrowd-sourcing approach. Other self reported information is also included (e.g.\nCOVID-19 virus tests), thus providing a comprehensive dataset for the\ndevelopment of COVID-19 risk detection models. The smarty4covid dataset is\nreleased in the form of a web-ontology language (OWL) knowledge base enabling\ndata consolidation from other relevant datasets, complex queries and reasoning.\nIt has been utilized towards the development of models able to: (i) extract\nclinically informative respiratory indicators from regular breathing records,\nand (ii) identify cough, breath and voice segments in crowd-sourced audio\nrecordings. A new framework utilizing the smarty4covid OWL knowledge base\ntowards generating counterfactual explanations in opaque AI-based COVID-19 risk\ndetection models is proposed and validated.\n","authors":["Konstantia Zarkogianni","Edmund Dervakos","George Filandrianos","Theofanis Ganitidis","Vasiliki Gkatzou","Aikaterini Sakagianni","Raghu Raghavendra","C. L. Max Nikias","Giorgos Stamou","Konstantina S. Nikita"],"pdf_url":"https://arxiv.org/pdf/2307.05096v1.pdf","comment":"Submitted for publication in Nature Scientific Data"},{"id":"http://arxiv.org/abs/2307.05830v1","updated":"2023-07-11T22:51:54Z","published":"2023-07-11T22:51:54Z","title":"SnakeSynth: New Interactions for Generative Audio Synthesis","summary":"  I present \"SnakeSynth,\" a web-based lightweight audio synthesizer that\ncombines audio generated by a deep generative model and real-time continuous\ntwo-dimensional (2D) input to create and control variable-length generative\nsounds through 2D interaction gestures. Interaction gestures are touch and\nmobile-compatible with analogies to strummed, bowed, and plucked musical\ninstrument controls. Point-and-click and drag-and-drop gestures directly\ncontrol audio playback length and I show that sound length and intensity are\nmodulated by interactions with a programmable 2D coordinate grid. Leveraging\nthe speed and ubiquity of browser-based audio and hardware acceleration in\nGoogle's TensorFlow.js we generate time-varying high-fidelity sounds with\nreal-time interactivity. SnakeSynth adaptively reproduces and interpolates\nbetween sounds encountered during model training, notably without long training\ntimes, and I briefly discuss possible futures for deep generative models as an\ninteractive paradigm for musical expression.\n","authors":["Eric Easthope"],"pdf_url":"https://arxiv.org/pdf/2307.05830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05641v1","updated":"2023-07-11T10:14:59Z","published":"2023-07-11T10:14:59Z","title":"Point to the Hidden: Exposing Speech Audio Splicing via Signal Pointer\n  Nets","summary":"  Verifying the integrity of voice recording evidence for criminal\ninvestigations is an integral part of an audio forensic analyst's work. Here,\none focus is on detecting deletion or insertion operations, so called audio\nsplicing. While this is a rather easy approach to alter spoken statements,\ncareful editing can yield quite convincing results. For difficult cases or big\namounts of data, automated tools can support in detecting potential editing\nlocations. To this end, several analytical and deep learning methods have been\nproposed by now. Still, few address unconstrained splicing scenarios as\nexpected in practice. With SigPointer, we propose a pointer network framework\nfor continuous input that uncovers splice locations naturally and more\nefficiently than existing works. Extensive experiments on forensically\nchallenging data like strongly compressed and noisy signals quantify the\nbenefit of the pointer mechanism with performance increases between about 6 to\n10 percentage points.\n","authors":["Denise Moussa","Germans Hirsch","Sebastian Wankerl","Christian Riess"],"pdf_url":"https://arxiv.org/pdf/2307.05641v1.pdf","comment":"accepted at Interspeech 2023, code will be made available after paper\n  presentation (at the latest)"},{"id":"http://arxiv.org/abs/2307.05637v1","updated":"2023-07-11T09:25:39Z","published":"2023-07-11T09:25:39Z","title":"Speech Diarization and ASR with GMM","summary":"  In this research paper, we delve into the topics of Speech Diarization and\nAutomatic Speech Recognition (ASR). Speech diarization involves the separation\nof individual speakers within an audio stream. By employing the ASR transcript,\nthe diarization process aims to segregate each speaker's utterances, grouping\nthem based on their unique audio characteristics. On the other hand, Automatic\nSpeech Recognition refers to the capability of a machine or program to identify\nand convert spoken words and phrases into a machine-readable format. In our\nspeech diarization approach, we utilize the Gaussian Mixer Model (GMM) to\nrepresent speech segments. The inter-cluster distance is computed based on the\nGMM parameters, and the distance threshold serves as the stopping criterion.\nASR entails the conversion of an unknown speech waveform into a corresponding\nwritten transcription. The speech signal is analyzed using synchronized\nalgorithms, taking into account the pitch frequency. Our primary objective\ntypically revolves around developing a model that minimizes the Word Error Rate\n(WER) metric during speech transcription.\n","authors":["Aayush Kumar Sharma","Vineet Bhavikatti","Amogh Nidawani","Dr. Siddappaji","Sanath P","Dr Geetishree Mishra"],"pdf_url":"https://arxiv.org/pdf/2307.05637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06860v1","updated":"2023-07-11T22:25:21Z","published":"2023-07-11T22:25:21Z","title":"AnuraSet: A dataset for benchmarking Neotropical anuran calls\n  identification in passive acoustic monitoring","summary":"  Global change is predicted to induce shifts in anuran acoustic behavior,\nwhich can be studied through passive acoustic monitoring (PAM). Understanding\nchanges in calling behavior requires the identification of anuran species,\nwhich is challenging due to the particular characteristics of neotropical\nsoundscapes. In this paper, we introduce a large-scale multi-species dataset of\nanuran amphibians calls recorded by PAM, that comprises 27 hours of expert\nannotations for 42 different species from two Brazilian biomes. We provide open\naccess to the dataset, including the raw recordings, experimental setup code,\nand a benchmark with a baseline model of the fine-grained categorization\nproblem. Additionally, we highlight the challenges of the dataset to encourage\nmachine learning researchers to solve the problem of anuran call identification\ntowards conservation policy. All our experiments and resources can be found on\nour GitHub repository https://github.com/soundclim/anuraset.\n","authors":["Juan Sebastián Cañas","Maria Paula Toro-Gómez","Larissa Sayuri Moreira Sugai","Hernán Darío Benítez Restrepo","Jorge Rudas","Breyner Posso Bautista","Luís Felipe Toledo","Simone Dena","Adão Henrique Rosa Domingos","Franco Leandro de Souza","Selvino Neckel-Oliveira","Anderson da Rosa","Vítor Carvalho-Rocha","José Vinícius Bernardy","José Luiz Massao Moreira Sugai","Carolina Emília dos Santos","Rogério Pereira Bastos","Diego Llusia","Juan Sebastián Ulloa"],"pdf_url":"https://arxiv.org/pdf/2307.06860v1.pdf","comment":null}],"Audio and Speech Processing":[{"id":"http://arxiv.org/abs/2206.03318v2","updated":"2023-07-11T17:43:57Z","published":"2022-06-07T14:08:07Z","title":"LegoNN: Building Modular Encoder-Decoder Models","summary":"  State-of-the-art encoder-decoder models (e.g. for machine translation (MT) or\nautomatic speech recognition (ASR)) are constructed and trained end-to-end as\nan atomic unit. No component of the model can be (re-)used without the others,\nmaking it impossible to share parts, e.g. a high resourced decoder, across\ntasks. We describe LegoNN, a procedure for building encoder-decoder\narchitectures in a way so that its parts can be applied to other tasks without\nthe need for any fine-tuning. To achieve this reusability, the interface\nbetween encoder and decoder modules is grounded to a sequence of marginal\ndistributions over a pre-defined discrete vocabulary. We present two approaches\nfor ingesting these marginals; one is differentiable, allowing the flow of\ngradients across the entire network, and the other is gradient-isolating. To\nenable the portability of decoder modules between MT tasks for different source\nlanguages and across other tasks like ASR, we introduce a modality agnostic\nencoder which consists of a length control mechanism to dynamically adapt\nencoders' output lengths in order to match the expected input length range of\npre-trained decoders. We present several experiments to demonstrate the\neffectiveness of LegoNN models: a trained language generation LegoNN decoder\nmodule from German-English (De-En) MT task can be reused without any\nfine-tuning for the Europarl English ASR and the Romanian-English (Ro-En) MT\ntasks, matching or beating the performance of baseline. After fine-tuning,\nLegoNN models improve the Ro-En MT task by 1.5 BLEU points and achieve 12.5%\nrelative WER reduction on the Europarl ASR task. To show how the approach\ngeneralizes, we compose a LegoNN ASR model from three modules -- each has been\nlearned within different end-to-end trained models on three different datasets\n-- achieving an overall WER reduction of 19.5%.\n","authors":["Siddharth Dalmia","Dmytro Okhonko","Mike Lewis","Sergey Edunov","Shinji Watanabe","Florian Metze","Luke Zettlemoyer","Abdelrahman Mohamed"],"pdf_url":"https://arxiv.org/pdf/2206.03318v2.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing\n  (TASLP)"},{"id":"http://arxiv.org/abs/2303.00747v2","updated":"2023-07-11T17:07:19Z","published":"2023-03-01T18:59:13Z","title":"WhisperX: Time-Accurate Speech Transcription of Long-Form Audio","summary":"  Large-scale, weakly-supervised speech recognition models, such as Whisper,\nhave demonstrated impressive results on speech recognition across domains and\nlanguages. However, their application to long audio transcription via buffered\nor sliding window approaches is prone to drifting, hallucination & repetition;\nand prohibits batched transcription due to their sequential nature. Further,\ntimestamps corresponding each utterance are prone to inaccuracies and\nword-level timestamps are not available out-of-the-box. To overcome these\nchallenges, we present WhisperX, a time-accurate speech recognition system with\nword-level timestamps utilising voice activity detection and forced phoneme\nalignment. In doing so, we demonstrate state-of-the-art performance on\nlong-form transcription and word segmentation benchmarks. Additionally, we show\nthat pre-segmenting audio with our proposed VAD Cut & Merge strategy improves\ntranscription quality and enables a twelve-fold transcription speedup via\nbatched inference.\n","authors":["Max Bain","Jaesung Huh","Tengda Han","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2303.00747v2.pdf","comment":"Accepted to INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2307.05328v1","updated":"2023-07-11T15:19:47Z","published":"2023-07-11T15:19:47Z","title":"ProgGP: From GuitarPro Tablature Neural Generation To Progressive Metal\n  Production","summary":"  Recent work in the field of symbolic music generation has shown value in\nusing a tokenization based on the GuitarPro format, a symbolic representation\nsupporting guitar expressive attributes, as an input and output representation.\nWe extend this work by fine-tuning a pre-trained Transformer model on ProgGP, a\ncustom dataset of 173 progressive metal songs, for the purposes of creating\ncompositions from that genre through a human-AI partnership. Our model is able\nto generate multiple guitar, bass guitar, drums, piano and orchestral parts. We\nexamine the validity of the generated music using a mixed methods approach by\ncombining quantitative analyses following a computational musicology paradigm\nand qualitative analyses following a practice-based research paradigm. Finally,\nwe demonstrate the value of the model by using it as a tool to create a\nprogressive metal song, fully produced and mixed by a human metal producer\nbased on AI-generated music.\n","authors":["Jackson Loth","Pedro Sarmento","CJ Carr","Zack Zukowski","Mathieu Barthet"],"pdf_url":"https://arxiv.org/pdf/2307.05328v1.pdf","comment":"Pre-print accepted for publication at CMMR2023"},{"id":"http://arxiv.org/abs/2307.05324v1","updated":"2023-07-11T15:11:02Z","published":"2023-07-11T15:11:02Z","title":"ShredGP: Guitarist Style-Conditioned Tablature Generation","summary":"  GuitarPro format tablatures are a type of digital music notation that\nencapsulates information about guitar playing techniques and fingerings. We\nintroduce ShredGP, a GuitarPro tablature generative Transformer-based model\nconditioned to imitate the style of four distinct iconic electric guitarists.\nIn order to assess the idiosyncrasies of each guitar player, we adopt a\ncomputational musicology methodology by analysing features computed from the\ntokens yielded by the DadaGP encoding scheme. Statistical analyses of the\nfeatures evidence significant differences between the four guitarists. We\ntrained two variants of the ShredGP model, one using a multi-instrument corpus,\nthe other using solo guitar data. We present a BERT-based model for guitar\nplayer classification and use it to evaluate the generated examples. Overall,\nresults from the classifier show that ShredGP is able to generate content\ncongruent with the style of the targeted guitar player. Finally, we reflect on\nprospective applications for ShredGP for human-AI music interaction.\n","authors":["Pedro Sarmento","Adarsh Kumar","Dekun Xie","CJ Carr","Zack Zukowski","Mathieu Barthet"],"pdf_url":"https://arxiv.org/pdf/2307.05324v1.pdf","comment":"Accepted for publication at CMMR 2023"},{"id":"http://arxiv.org/abs/2306.04301v2","updated":"2023-07-11T15:03:00Z","published":"2023-06-07T10:05:45Z","title":"Interpretable Style Transfer for Text-to-Speech with ControlVAE and\n  Diffusion Bridge","summary":"  With the demand for autonomous control and personalized speech generation,\nthe style control and transfer in Text-to-Speech (TTS) is becoming more and\nmore important. In this paper, we propose a new TTS system that can perform\nstyle transfer with interpretability and high fidelity. Firstly, we design a\nTTS system that combines variational autoencoder (VAE) and diffusion refiner to\nget refined mel-spectrograms. Specifically, a two-stage and a one-stage system\nare designed respectively, to improve the audio quality and the performance of\nstyle transfer. Secondly, a diffusion bridge of quantized VAE is designed to\nefficiently learn complex discrete style representations and improve the\nperformance of style transfer. To have a better ability of style transfer, we\nintroduce ControlVAE to improve the reconstruction quality and have good\ninterpretability simultaneously. Experiments on LibriTTS dataset demonstrate\nthat our method is more effective than baseline models.\n","authors":["Wenhao Guan","Tao Li","Yishuang Li","Hukai Huang","Qingyang Hong","Lin Li"],"pdf_url":"https://arxiv.org/pdf/2306.04301v2.pdf","comment":"Accepted at Interspeech2023"},{"id":"http://arxiv.org/abs/2307.05161v1","updated":"2023-07-11T10:37:57Z","published":"2023-07-11T10:37:57Z","title":"On the Effectiveness of Speech Self-supervised Learning for Music","summary":"  Self-supervised learning (SSL) has shown promising results in various speech\nand natural language processing applications. However, its efficacy in music\ninformation retrieval (MIR) still remains largely unexplored. While previous\nSSL models pre-trained on music recordings may have been mostly closed-sourced,\nrecent speech models such as wav2vec2.0 have shown promise in music modelling.\nNevertheless, research exploring the effectiveness of applying speech SSL\nmodels to music recordings has been limited. We explore the music adaption of\nSSL with two distinctive speech-related models, data2vec1.0 and Hubert, and\nrefer to them as music2vec and musicHuBERT, respectively. We train $12$ SSL\nmodels with 95M parameters under various pre-training configurations and\nsystematically evaluate the MIR task performances with 13 different MIR tasks.\nOur findings suggest that training with music data can generally improve\nperformance on MIR tasks, even when models are trained using paradigms designed\nfor speech. However, we identify the limitations of such existing\nspeech-oriented designs, especially in modelling polyphonic information. Based\non the experimental results, empirical suggestions are also given for designing\nfuture musical SSL strategies and paradigms.\n","authors":["Yinghao Ma","Ruibin Yuan","Yizhi Li","Ge Zhang","Xingran Chen","Hanzhi Yin","Chenghua Lin","Emmanouil Benetos","Anton Ragni","Norbert Gyenge","Ruibo Liu","Gus Xia","Roger Dannenberg","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2307.05161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05140v1","updated":"2023-07-11T09:34:12Z","published":"2023-07-11T09:34:12Z","title":"Aeroacoustic testing on a full aircraft model at high Reynolds numbers\n  in the European Transonic Windtunnel","summary":"  This paper presents an end-to-end approach for the assessment of pressurized\nand cryogenic wind tunnel measurements of an EMBRAER scaled full model close to\nreal-world Reynolds numbers. The choice of microphones, measurement parameters,\nthe design of the array, and the selection of flow parameters are discussed.\nDifferent wind tunnel conditions are proposed which allow separating the\ninfluence of the Reynolds number from the Mach number, as well as the influence\nof slotted and closed test sections. The paper provides three-dimensional\nbeamforming results with CLEAN-SC deconvolution, the selection of regions of\ninterest, and the corresponding source spectra. The results suggest that\nslotted test sections have little influence on the beamforming results compared\nto closed test sections and that the Reynolds number has a profound, non-linear\nimpact on the aeroacoustic emission that lessens with increasing Reynolds\nnumber. Further, sources show a non-linear Mach number dependency at constant\nReynolds number but are self-similar in the observed Mach number range. The\nfindings suggest that it is possible to study real-world phenomena on\nsmall-scale full models at real-world Reynolds numbers, which enable further\ninvestigations in the future such as the directivity of sources.\n","authors":["Thomas Ahlefeldt","Daniel Ernst","Armin Goudarzi"," Hans-Georg-Raumer","Carsten Spehr"],"pdf_url":"https://arxiv.org/pdf/2307.05140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05132v1","updated":"2023-07-11T09:22:10Z","published":"2023-07-11T09:22:10Z","title":"On the Use of Self-Supervised Speech Representations in Spontaneous\n  Speech Synthesis","summary":"  Self-supervised learning (SSL) speech representations learned from large\namounts of diverse, mixed-quality speech data without transcriptions are\ngaining ground in many speech technology applications. Prior work has shown\nthat SSL is an effective intermediate representation in two-stage\ntext-to-speech (TTS) for both read and spontaneous speech. However, it is still\nnot clear which SSL and which layer from each SSL model is most suited for\nspontaneous TTS. We address this shortcoming by extending the scope of\ncomparison for SSL in spontaneous TTS to 6 different SSLs and 3 layers within\neach SSL. Furthermore, SSL has also shown potential in predicting the mean\nopinion scores (MOS) of synthesized speech, but this has only been done in\nread-speech MOS prediction. We extend an SSL-based MOS prediction framework\npreviously developed for scoring read speech synthesis and evaluate its\nperformance on synthesized spontaneous speech. All experiments are conducted\ntwice on two different spontaneous corpora in order to find generalizable\ntrends. Overall, we present comprehensive experimental results on the use of\nSSL in spontaneous TTS and MOS prediction to further quantify and understand\nhow SSL can be used in spontaneous TTS. Audios samples:\nhttps://www.speech.kth.se/tts-demos/sp_ssl_tts\n","authors":["Siyang Wang","Gustav Eje Henter","Joakim Gustafson","Éva Székely"],"pdf_url":"https://arxiv.org/pdf/2307.05132v1.pdf","comment":"7 pages, 2 figures. 12th ISCA Speech Synthesis Workshop (SSW) 2023"},{"id":"http://arxiv.org/abs/2307.05107v1","updated":"2023-07-11T08:34:11Z","published":"2023-07-11T08:34:11Z","title":"Optimizing Feature Extraction for Symbolic Music","summary":"  This paper presents a comprehensive investigation of existing feature\nextraction tools for symbolic music and contrasts their performance to\ndetermine the set of features that best characterizes the musical style of a\ngiven music score. In this regard, we propose a novel feature extraction tool,\nnamed musif, and evaluate its efficacy on various repertoires and file formats,\nincluding MIDI, MusicXML, and **kern. Musif approximates existing tools such as\njSymbolic and music21 in terms of computational efficiency while attempting to\nenhance the usability for custom feature development. The proposed tool also\nenhances classification accuracy when combined with other sets of features. We\ndemonstrate the contribution of each set of features and the computational\nresources they require. Our findings indicate that the optimal tool for feature\nextraction is a combination of the best features from each tool rather than\nthose of a single one. To facilitate future research in music information\nretrieval, we release the source code of the tool and benchmarks.\n","authors":["Federico Simonetta","Ana Llorens","Martín Serrano","Eduardo García-Portugués","Álvaro Torrente"],"pdf_url":"https://arxiv.org/pdf/2307.05107v1.pdf","comment":"Published at ISMIR 2023"},{"id":"http://arxiv.org/abs/2307.05096v1","updated":"2023-07-11T08:10:58Z","published":"2023-07-11T08:10:58Z","title":"The smarty4covid dataset and knowledge base: a framework enabling\n  interpretable analysis of audio signals","summary":"  Harnessing the power of Artificial Intelligence (AI) and m-health towards\ndetecting new bio-markers indicative of the onset and progress of respiratory\nabnormalities/conditions has greatly attracted the scientific and research\ninterest especially during COVID-19 pandemic. The smarty4covid dataset contains\naudio signals of cough (4,676), regular breathing (4,665), deep breathing\n(4,695) and voice (4,291) as recorded by means of mobile devices following a\ncrowd-sourcing approach. Other self reported information is also included (e.g.\nCOVID-19 virus tests), thus providing a comprehensive dataset for the\ndevelopment of COVID-19 risk detection models. The smarty4covid dataset is\nreleased in the form of a web-ontology language (OWL) knowledge base enabling\ndata consolidation from other relevant datasets, complex queries and reasoning.\nIt has been utilized towards the development of models able to: (i) extract\nclinically informative respiratory indicators from regular breathing records,\nand (ii) identify cough, breath and voice segments in crowd-sourced audio\nrecordings. A new framework utilizing the smarty4covid OWL knowledge base\ntowards generating counterfactual explanations in opaque AI-based COVID-19 risk\ndetection models is proposed and validated.\n","authors":["Konstantia Zarkogianni","Edmund Dervakos","George Filandrianos","Theofanis Ganitidis","Vasiliki Gkatzou","Aikaterini Sakagianni","Raghu Raghavendra","C. L. Max Nikias","Giorgos Stamou","Konstantina S. Nikita"],"pdf_url":"https://arxiv.org/pdf/2307.05096v1.pdf","comment":"Submitted for publication in Nature Scientific Data"},{"id":"http://arxiv.org/abs/2307.05006v1","updated":"2023-07-11T03:57:00Z","published":"2023-07-11T03:57:00Z","title":"Improving RNN-Transducers with Acoustic LookAhead","summary":"  RNN-Transducers (RNN-Ts) have gained widespread acceptance as an end-to-end\nmodel for speech to text conversion because of their high accuracy and\nstreaming capabilities. A typical RNN-T independently encodes the input audio\nand the text context, and combines the two encodings by a thin joint network.\nWhile this architecture provides SOTA streaming accuracy, it also makes the\nmodel vulnerable to strong LM biasing which manifests as multi-step\nhallucination of text without acoustic evidence. In this paper we propose\nLookAhead that makes text representations more acoustically grounded by looking\nahead into the future within the audio input. This technique yields a\nsignificant 5%-20% relative reduction in word error rate on both in-domain and\nout-of-domain evaluation sets.\n","authors":["Vinit S. Unni","Ashish Mittal","Preethi Jyothi","Sunita Sarawagi"],"pdf_url":"https://arxiv.org/pdf/2307.05006v1.pdf","comment":"5 pages, 1 fig, 7 tables, Proceedings of Interspeech 2023"},{"id":"http://arxiv.org/abs/2307.05830v1","updated":"2023-07-11T22:51:54Z","published":"2023-07-11T22:51:54Z","title":"SnakeSynth: New Interactions for Generative Audio Synthesis","summary":"  I present \"SnakeSynth,\" a web-based lightweight audio synthesizer that\ncombines audio generated by a deep generative model and real-time continuous\ntwo-dimensional (2D) input to create and control variable-length generative\nsounds through 2D interaction gestures. Interaction gestures are touch and\nmobile-compatible with analogies to strummed, bowed, and plucked musical\ninstrument controls. Point-and-click and drag-and-drop gestures directly\ncontrol audio playback length and I show that sound length and intensity are\nmodulated by interactions with a programmable 2D coordinate grid. Leveraging\nthe speed and ubiquity of browser-based audio and hardware acceleration in\nGoogle's TensorFlow.js we generate time-varying high-fidelity sounds with\nreal-time interactivity. SnakeSynth adaptively reproduces and interpolates\nbetween sounds encountered during model training, notably without long training\ntimes, and I briefly discuss possible futures for deep generative models as an\ninteractive paradigm for musical expression.\n","authors":["Eric Easthope"],"pdf_url":"https://arxiv.org/pdf/2307.05830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05641v1","updated":"2023-07-11T10:14:59Z","published":"2023-07-11T10:14:59Z","title":"Point to the Hidden: Exposing Speech Audio Splicing via Signal Pointer\n  Nets","summary":"  Verifying the integrity of voice recording evidence for criminal\ninvestigations is an integral part of an audio forensic analyst's work. Here,\none focus is on detecting deletion or insertion operations, so called audio\nsplicing. While this is a rather easy approach to alter spoken statements,\ncareful editing can yield quite convincing results. For difficult cases or big\namounts of data, automated tools can support in detecting potential editing\nlocations. To this end, several analytical and deep learning methods have been\nproposed by now. Still, few address unconstrained splicing scenarios as\nexpected in practice. With SigPointer, we propose a pointer network framework\nfor continuous input that uncovers splice locations naturally and more\nefficiently than existing works. Extensive experiments on forensically\nchallenging data like strongly compressed and noisy signals quantify the\nbenefit of the pointer mechanism with performance increases between about 6 to\n10 percentage points.\n","authors":["Denise Moussa","Germans Hirsch","Sebastian Wankerl","Christian Riess"],"pdf_url":"https://arxiv.org/pdf/2307.05641v1.pdf","comment":"accepted at Interspeech 2023, code will be made available after paper\n  presentation (at the latest)"},{"id":"http://arxiv.org/abs/2307.05637v1","updated":"2023-07-11T09:25:39Z","published":"2023-07-11T09:25:39Z","title":"Speech Diarization and ASR with GMM","summary":"  In this research paper, we delve into the topics of Speech Diarization and\nAutomatic Speech Recognition (ASR). Speech diarization involves the separation\nof individual speakers within an audio stream. By employing the ASR transcript,\nthe diarization process aims to segregate each speaker's utterances, grouping\nthem based on their unique audio characteristics. On the other hand, Automatic\nSpeech Recognition refers to the capability of a machine or program to identify\nand convert spoken words and phrases into a machine-readable format. In our\nspeech diarization approach, we utilize the Gaussian Mixer Model (GMM) to\nrepresent speech segments. The inter-cluster distance is computed based on the\nGMM parameters, and the distance threshold serves as the stopping criterion.\nASR entails the conversion of an unknown speech waveform into a corresponding\nwritten transcription. The speech signal is analyzed using synchronized\nalgorithms, taking into account the pitch frequency. Our primary objective\ntypically revolves around developing a model that minimizes the Word Error Rate\n(WER) metric during speech transcription.\n","authors":["Aayush Kumar Sharma","Vineet Bhavikatti","Amogh Nidawani","Dr. Siddappaji","Sanath P","Dr Geetishree Mishra"],"pdf_url":"https://arxiv.org/pdf/2307.05637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06860v1","updated":"2023-07-11T22:25:21Z","published":"2023-07-11T22:25:21Z","title":"AnuraSet: A dataset for benchmarking Neotropical anuran calls\n  identification in passive acoustic monitoring","summary":"  Global change is predicted to induce shifts in anuran acoustic behavior,\nwhich can be studied through passive acoustic monitoring (PAM). Understanding\nchanges in calling behavior requires the identification of anuran species,\nwhich is challenging due to the particular characteristics of neotropical\nsoundscapes. In this paper, we introduce a large-scale multi-species dataset of\nanuran amphibians calls recorded by PAM, that comprises 27 hours of expert\nannotations for 42 different species from two Brazilian biomes. We provide open\naccess to the dataset, including the raw recordings, experimental setup code,\nand a benchmark with a baseline model of the fine-grained categorization\nproblem. Additionally, we highlight the challenges of the dataset to encourage\nmachine learning researchers to solve the problem of anuran call identification\ntowards conservation policy. All our experiments and resources can be found on\nour GitHub repository https://github.com/soundclim/anuraset.\n","authors":["Juan Sebastián Cañas","Maria Paula Toro-Gómez","Larissa Sayuri Moreira Sugai","Hernán Darío Benítez Restrepo","Jorge Rudas","Breyner Posso Bautista","Luís Felipe Toledo","Simone Dena","Adão Henrique Rosa Domingos","Franco Leandro de Souza","Selvino Neckel-Oliveira","Anderson da Rosa","Vítor Carvalho-Rocha","José Vinícius Bernardy","José Luiz Massao Moreira Sugai","Carolina Emília dos Santos","Rogério Pereira Bastos","Diego Llusia","Juan Sebastián Ulloa"],"pdf_url":"https://arxiv.org/pdf/2307.06860v1.pdf","comment":null}],"Signal Processing":[{"id":"http://arxiv.org/abs/2307.05442v1","updated":"2023-07-11T17:07:39Z","published":"2023-07-11T17:07:39Z","title":"Channel State Information-Free Location-Privacy Enhancement: Fake Path\n  Injection","summary":"  In this paper, a channel state information-free, fake path injection (FPI)\nscheme is proposed for location-privacy preservation. Specifically, structured\nartificial noise is designed to introduce virtual fake paths into the channels\nof the illegitimate devices. By leveraging the geometrical feasibility of the\nfake paths, under mild conditions, it can be proved that the illegitimate\ndevice cannot distinguish between a fake and true path, thus degrading the\nillegitimate devices' ability to localize. Two closed-form, lower bounds on the\nillegitimate devices' estimation error are derived via the analysis of the\nFisher information of the location-relevant channel parameters, thus\ncharacterizing the enhanced location-privacy. A transmit beamformer is\nproposed, which efficiently injects the virtual fake paths. The intended device\nreceives the two parameters of the beamformer design over a secure channel in\norder to enable localization. The impact of leaking the beamformer structure\nand associated localization leakage are analyzed. Theoretical analyses are\nverified via simulation. Numerical results show that a 20dB degradation of the\nillegitimate devices' localization accuracy can be achieved thus validating the\nefficacy of the proposed FPI versus using unstructured Gaussian noise.\n","authors":["Jianxiu Li","Urbashi Mitra"],"pdf_url":"https://arxiv.org/pdf/2307.05442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05352v1","updated":"2023-07-11T15:41:34Z","published":"2023-07-11T15:41:34Z","title":"Leveraging Variational Autoencoders for Parameterized MMSE Channel\n  Estimation","summary":"  In this manuscript, we propose to utilize the generative neural network-based\nvariational autoencoder for channel estimation. The variational autoencoder\nmodels the underlying true but unknown channel distribution as a conditional\nGaussian distribution in a novel way. The derived channel estimator exploits\nthe internal structure of the variational autoencoder to parameterize an\napproximation of the mean squared error optimal estimator resulting from the\nconditional Gaussian channel models. We provide a rigorous analysis under which\nconditions a variational autoencoder-based estimator is mean squared error\noptimal. We then present considerations that make the variational\nautoencoder-based estimator practical and propose three different estimator\nvariants that differ in their access to channel knowledge during the training\nand evaluation phase. In particular, the proposed estimator variant trained\nsolely on noisy pilot observations is particularly noteworthy as it does not\nrequire access to noise-free, ground-truth channel data during training or\nevaluation. Extensive numerical simulations first analyze the internal behavior\nof the variational autoencoder-based estimators and then demonstrate excellent\nchannel estimation performance compared to related classical and machine\nlearning-based state-of-the-art channel estimators.\n","authors":["Michael Baur","Benedikt Fesl","Wolfgang Utschick"],"pdf_url":"https://arxiv.org/pdf/2307.05352v1.pdf","comment":"13 pages, 12 figures"},{"id":"http://arxiv.org/abs/2307.05295v1","updated":"2023-07-11T14:38:50Z","published":"2023-07-11T14:38:50Z","title":"Optimization of Rate-Splitting Multiple Access in Beyond Diagonal\n  RIS-assisted URLLC Systems","summary":"  This paper proposes a general optimization framework for rate splitting\nmultiple access (RSMA) in beyond diagonal (BD) reconfigurable intelligent\nsurface (RIS) assisted ultra-reliable low-latency communications (URLLC)\nsystems. This framework can solve a large family of optimization problems in\nwhich the objective and/or constraints are linear functions of the rates and/or\nenergy efficiency (EE) of users. Using this framework, we show that RSMA and\nRIS can be mutually beneficial tools when the system is overloaded, i.e., when\nthe number of users per cell is higher than the number of base station (BS)\nantennas. Additionally, we show that the benefits of RSMA increase when the\npackets are shorter and/or the reliability constraint is more stringent.\nFurthermore, we show that the RSMA benefits increase with the number of users\nper cell and decrease with the number of BS antennas. Finally, we show that RIS\n(either diagonal or BD) can highly improve the system performance, and BD-RIS\noutperforms regular RIS.\n","authors":["Mohammad Soleymani","Ignacio Santamaria","Eduard Jorswieck","Bruno Clerckx"],"pdf_url":"https://arxiv.org/pdf/2307.05295v1.pdf","comment":"submitted to at IEEE journal"},{"id":"http://arxiv.org/abs/2008.03739v2","updated":"2023-07-11T14:16:39Z","published":"2020-08-09T15:02:20Z","title":"Underdetermined Blind Identification via $k$-Sparse Component Analysis:\n  RANSAC-driven Orthogonal Subspace Search","summary":"  Two primary families of methods exist for underdetermined blind\nidentification (UBI) based on the sparsity of the source matrix: sparse\ncomponent analysis (SCA) and $k$-SCA. SCA assumes one active source at each\ntime instant, while $k$-SCA allows for varying numbers of active sources\nrepresented by $k$. However, existing $k$-SCA methods, which claim to solve UBI\nproblems by accommodating $k$-sparse sources, predominantly rely on $1$-sparse\nsources, limiting their effectiveness in real-world scenarios with high noise\nlevels.\n  In this paper, we propose an effective and computationally less complex\napproach for UBI, specifically focusing on the challenging case when the number\nof active sources is equal to the number of sensors minus one ($k=m-1$). Our\napproach overcomes limitations by using a two-step scenario: (1) estimating the\northogonal complement subspaces of the overall space and (2) identifying the\nmixing vectors. We present an integrated algorithm based on the Gram-Schmidt\nprocess and random sample consensus (RANSAC) method to solve both steps.\nExperimental results using simulated data demonstrate the superior\neffectiveness of our proposed method compared to existing algorithms.\n","authors":["Ehsan Eqlimi","Bahador Makkiabadi","Mayadeh Kouti","Ardeshir Fotouhi","Saeid Sanei"],"pdf_url":"https://arxiv.org/pdf/2008.03739v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05275v1","updated":"2023-07-11T14:08:51Z","published":"2023-07-11T14:08:51Z","title":"CareFall: Automatic Fall Detection through Wearable Devices and AI\n  Methods","summary":"  The aging population has led to a growing number of falls in our society,\naffecting global public health worldwide. This paper presents CareFall, an\nautomatic Fall Detection System (FDS) based on wearable devices and Artificial\nIntelligence (AI) methods. CareFall considers the accelerometer and gyroscope\ntime signals extracted from a smartwatch. Two different approaches are used for\nfeature extraction and classification: i) threshold-based, and ii) machine\nlearning-based. Experimental results on two public databases show that the\nmachine learning-based approach, which combines accelerometer and gyroscope\ninformation, outperforms the threshold-based approach in terms of accuracy,\nsensitivity, and specificity. This research contributes to the design of smart\nand user-friendly solutions to mitigate the negative consequences of falls\namong older people.\n","authors":["Juan Carlos Ruiz-Garcia","Ruben Tolosana","Ruben Vera-Rodriguez","Carlos Moro"],"pdf_url":"https://arxiv.org/pdf/2307.05275v1.pdf","comment":"3 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2303.01317v2","updated":"2023-07-11T12:51:12Z","published":"2023-03-02T14:44:00Z","title":"Evaluation Method and Design Guidance for Direction Finding Antenna\n  Systems","summary":"  A deterministic evaluation procedure for multi-port direction finding\nantennas is proposed. It is based on a direction finding uncertainty parameter,\nwhich describes how well different directions of arrival and polarizations are\ndistinguishable. By investigating a simple antenna array, it is shown that the\nproposed parameter provides additional insight into the behavior of an antenna\nsystem, when compared to established methods. Moreover, since the uncertainty\nparameter is calculated from a set of far fields, it is applicable to port far\nfields as well as Characteristic Modes. This finding is utilized to derive a\ndesign guidance: Starting with a set of Characteristic Mode far fields, the\nangular distribution of the uncertainty is investigated to verify that no\nambiguities are present. Different sets of far fields are compared and the\ndifferences regarding their direction finding behavior are visualized and\nexplained using the uncertainty in conjunction with an estimate of the incident\nfield. To quantify these differences, a key performance indicator is introduced\nthat summarizes the direction finding capabilities over a selected angular\nregion. To demonstrate the design process, a multi-mode multi-port antenna with\nthree uncorrelated ports is developed, manufactured and measured.\n","authors":["Lukas Grundmann","Dirk Manteuffel"],"pdf_url":"https://arxiv.org/pdf/2303.01317v2.pdf","comment":"This article has been accepted for publication in IEEE Transactions\n  on Antennas and Propagation. This is the author's version which has not been\n  fully edited and content may change prior to final publication"},{"id":"http://arxiv.org/abs/2305.13113v3","updated":"2023-07-11T11:42:05Z","published":"2023-05-22T15:12:45Z","title":"Symbol-Level Noise-Guessing Decoding with Antenna Sorting for URLLC\n  Massive MIMO","summary":"  Supporting ultra-reliable and low-latency communication (URLLC) is a\nchallenge in current wireless systems. Channel codes that generate large\ncodewords improve reliability but necessitate the use of interleavers, which\nintroduce undesirable latency. Only short codewords can eliminate the\nrequirement for interleaving and reduce decoding latency. This paper suggests a\ncoding and decoding method which, when combined with the high spectral\nefficiency of spatial multiplexing, can provide URLLC over a fading channel.\nRandom linear coding and high-order modulation are used to transmit information\nover a massive multiple-input multiple-output (mMIMO) channel, followed by\nzero-forcing detection and guessing random additive noise decoding (GRAND) at a\nreceiver. A variant of GRAND, called symbol-level GRAND, originally proposed\nfor single-antenna systems that employ high-order modulation schemes, is\ngeneralized to spatial multiplexing. The paper studies the impact of the\northogonality defect of the underlying mMIMO lattice on symbol-level GRAND, and\nproposes to leverage side-information that comes from the mMIMO channel-state\ninformation and relates to the reliability of each receive antenna. This\ninduces an antenna sorting step, which further reduces decoding complexity by\nover 80\\% when compared to bit-level GRAND.\n","authors":["Sahar Allahkaram","Francisco A. Monteiro","Ioannis Chatzigeorgiou"],"pdf_url":"https://arxiv.org/pdf/2305.13113v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05179v1","updated":"2023-07-11T11:30:39Z","published":"2023-07-11T11:30:39Z","title":"A Simplified Method for Optimising Geometrically Shaped Constellations\n  of Higher Dimensionality","summary":"  We introduce a simplified method for calculating the loss function for use in\ngeometric shaping, allowing for the optimisation of high dimensional\nconstellations. We design constellations up to 12D with 4096 points, with gains\nup to 0.31 dB compared to the state-of-the-art.\n","authors":["Kadir Gümüş","Bin Chen","Thomas Bradley","Chigo Okonkwo"],"pdf_url":"https://arxiv.org/pdf/2307.05179v1.pdf","comment":"This paper was accepted for the European Conference on Optical\n  Communications (ECOC) 2023, this version is a pre-print"},{"id":"http://arxiv.org/abs/2307.05127v1","updated":"2023-07-11T09:05:13Z","published":"2023-07-11T09:05:13Z","title":"Optimal Coordinated Transmit Beamforming for Networked Integrated\n  Sensing and Communications","summary":"  This paper studies a multi-antenna networked integrated sensing and\ncommunications (ISAC) system, in which a set of multi-antenna base stations\n(BSs) employ the coordinated transmit beamforming to serve multiple\nsingle-antenna communication users (CUs) and perform joint target detection by\nexploiting the reflected signals simultaneously. To facilitate target sensing,\nthe BSs transmit dedicated sensing signals combined with their information\nsignals. Accordingly, we consider two types of CU receivers with and without\nthe capability of canceling the interference from the dedicated sensing\nsignals, respectively. In addition, we investigate two scenarios with and\nwithout time synchronization among the BSs. For the scenario with\nsynchronization, the BSs can exploit the target-reflected signals over both the\ndirect links (BS-to-target-to-originated BS links) and the cross-links\n(BS-to-target-to-other BSs links) for joint detection, while in the\nunsynchronized scenario, the BSs can only utilize the target-reflected signals\nover the direct links. For each scenario under different types of CU receivers,\nwe optimize the coordinated transmit beamforming at the BSs to maximize the\nminimum detection probability over a particular targeted area, while\nguaranteeing the required minimum signal-to-interference-plus-noise ratio\n(SINR) constraints at the CUs. These SINR-constrained detection probability\nmaximization problems are recast as non-convex quadratically constrained\nquadratic programs (QCQPs), which are then optimally solved via the\nsemi-definite relaxation (SDR) technique.\n","authors":["Gaoyuan Cheng","Yuan Fang","Jie Xu","Derrick Wing Kwan Ng"],"pdf_url":"https://arxiv.org/pdf/2307.05127v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2211.01085"},{"id":"http://arxiv.org/abs/2307.05023v1","updated":"2023-07-11T05:56:21Z","published":"2023-07-11T05:56:21Z","title":"Best Arm Identification Based Beam Acquisition in Stationary and\n  Abruptly Changing Environments","summary":"  We study the initial beam acquisition problem in millimeter wave (mm-wave)\nnetworks from the perspective of best arm identification in multi-armed bandits\n(MABs). For the stationary environment, we propose a novel algorithm called\nconcurrent beam exploration, CBE, in which multiple beams are grouped based on\nthe beam indices and are simultaneously activated to detect the presence of the\nuser. The best beam is then identified using a Hamming decoding strategy. For\nthe case of orthogonal and highly directional thin beams, we characterize the\nperformance of CBE in terms of the probability of missed detection and false\nalarm in a beam group (BG). Leveraging this, we derive the probability of beam\nselection error and prove that CBE outperforms the state-of-the-art strategies\nin this metric.\n  Then, for the abruptly changing environments, e.g., in the case of moving\nblockages, we characterize the performance of the classical sequential halving\n(SH) algorithm. In particular, we derive the conditions on the distribution of\nthe change for which the beam selection error is exponentially bounded. In case\nthe change is restricted to a subset of the beams, we devise a strategy called\nK-sequential halving and exhaustive search, K-SHES, that leads to an improved\nbound for the beam selection error as compared to SH. This policy is\nparticularly useful when a near-optimal beam becomes optimal during the\nbeam-selection procedure due to abruptly changing channel conditions. Finally,\nwe demonstrate the efficacy of the proposed scheme by employing it in a tandem\nbeam refinement and data transmission scheme.\n","authors":["Gourab Ghatak"],"pdf_url":"https://arxiv.org/pdf/2307.05023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04977v1","updated":"2023-07-11T02:33:43Z","published":"2023-07-11T02:33:43Z","title":"Model-Driven Sensing-Node Selection and Power Allocation for Tracking\n  Maneuvering Targets in Perceptive Mobile Networks","summary":"  Maneuvering target tracking will be an important service of future wireless\nnetworks to assist innovative applications such as intelligent transportation.\nHowever, tracking maneuvering targets by cellular networks faces many\nchallenges. For example, the dense network and high-speed targets make the\nselection of the sensing nodes (SNs), e.g., base stations, and the associated\npower allocation very difficult, given the stringent latency requirement of\nsensing applications. Existing methods have demonstrated engaging tracking\nperformance, but with very high computational complexity. In this paper, we\npropose a model-driven deep learning approach for SN selection to meet the\nlatency requirement. To this end, we first propose an iterative SN selection\nmethod by jointly exploiting the majorization-minimization (MM) framework and\nthe alternating direction method of multipliers (ADMM). Then, we unfold the\niterative algorithm as a deep neural network (DNN) and prove its convergence.\nThe proposed model-driven method has a low computational complexity, because\nthe number of layers is less than the number of iterations required by the\noriginal algorithm, and each layer only involves simple matrix-vector\nadditions/multiplications. Finally, we propose an efficient power allocation\nmethod based on fixed point (FP) water filling (WF) and solve the joint SN\nselection and power allocation problem under the alternative optimization\nframework. Simulation results show that the proposed method achieves better\nperformance than the conventional optimization-based methods with much lower\ncomputational complexity.\n","authors":["Lei Xie","Shenghui Song","Yonina C. Eldar"],"pdf_url":"https://arxiv.org/pdf/2307.04977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04961v1","updated":"2023-07-11T01:51:43Z","published":"2023-07-11T01:51:43Z","title":"Still Waters Run Deep: Extend THz Coverage with Non-Intelligent\n  Reflecting Surface","summary":"  Large reflection and diffraction losses in the Terahertz (THz) band give rise\nto degraded coverage abilities in non-line-of-sight (NLoS) areas. To overcome\nthis, a non-intelligent reflecting surface (NIRS) can be used, which is\nessentially a rough surface made by metal materials. NIRS is not only able to\nenhance received power in large NLoS areas through rich reflections and\nscattering, but also costless and super-easy to fabricate and implement. In\nthis article, we first thoroughly compare NIRS with the lively discussed\nintelligent reflecting surface (IRS) and point out the unique advantages of\nNIRS over IRS. Furthermore, experimental results are elaborated to show the\neffectiveness of NIRS in improving coverage. Last but not least, open problems\nand future directions are highlighted to inspire future research efforts on\nNIRS.\n","authors":["Chong Han","Yuanbo Li","Yinqin Wang"],"pdf_url":"https://arxiv.org/pdf/2307.04961v1.pdf","comment":"6 page, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2307.04955v1","updated":"2023-07-11T01:15:29Z","published":"2023-07-11T01:15:29Z","title":"Joint Radio Frequency Fingerprints Identification via Multi-antenna\n  Receiver","summary":"  In Internet of Things (IoT), radio frequency fingerprints (RFF) technology\nhas been widely used for passive security authentication to identify the\nspecial emitter. However, few works took advantage of independent oscillator\ndistortions at the receiver side, and no work has yet considered filtering\nreceiver distortions. In this paper, we investigate the RFF identification\n(RFFI) involving unknown receiver distortions, where the phase noise caused by\neach antenna oscillator is independent. Three RFF schemes are proposed\naccording to the number of receiving antennas. When the number is small, the\nMutual Information Weighting Scheme (MIWS) is developed by calculating the\nweighted voting of RFFI result at each antenna; when the number is moderate,\nthe Distortions Filtering Scheme (DFS) is developed by filtering out the\nchannel noise and receiver distortions; when the number is large enough, the\nGroup-Distortions Filtering and Weighting Scheme (GDFWS) is developed, which\nintegrates the advantages of MIWS and DFS. Furthermore, the ability of DFS to\nfilter out the channel noise and receiver distortions is theoretically analyzed\nat a specific confidence level. Experiments are provided when both channel\nnoise and receiver distortions exist, which verify the effectiveness and\nrobustness of the proposed schemes.\n","authors":["Xiaofang Chen","Wenbo Xu","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2307.04955v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05748v1","updated":"2023-07-11T19:13:56Z","published":"2023-07-11T19:13:56Z","title":"Dual-Polarized IRS-Assisted MIMO Network","summary":"  This study considers a dual-polarized intelligent reflecting surface\n(DP-IRS)-assisted multiple-input multiple-output (MIMO) single-user wireless\ncommunication system. The transmitter and receiver are equipped with DP\nantennas, and each antenna features a separate phase shifter for each\npolarization. We attempt to maximize the system's spectral efficiency (SE) by\noptimizing the operations of the reflecting elements at the DP-IRS,\nprecoder/combiner at the transmitter/receiver, and vertical/horizontal phase\nshifters at the DP antennas. To address this problem, we propose a three-step\nalternating optimization (AO) algorithm based on the semi-definite relaxation\nmethod. Next, we consider asymptotically low/high signal-to-noise ratio (SNR)\nregimes and propose low-complexity algorithms. In particular, for the low-SNR\nregime, we derive computationally low-cost closed-form solutions. According to\nthe obtained numerical results, the proposed algorithm outperforms the various\nbenchmark schemes. Specifically, our main algorithm exhibits a 65.6 \\% increase\nin the SE performance compared to random operations. In addition, we compare\nthe SE performance of DP-IRS with that of simple IRS (S-IRS). For \\(N = 50\\),\nDP-IRS achieves 24.8 \\%, 28.2 \\%, and 30.3 \\% improvements in SE for \\({4}\n\\times {4}\\), \\({8} \\times {8}\\), and \\({16} \\times {16}\\) MIMO, respectively,\ncompared to S-IRS.\n","authors":["Muteen Munawar","Kyungchun Lee"],"pdf_url":"https://arxiv.org/pdf/2307.05748v1.pdf","comment":"32 pages, 13 figures, 1 table"},{"id":"http://arxiv.org/abs/2307.05742v1","updated":"2023-07-11T19:08:34Z","published":"2023-07-11T19:08:34Z","title":"Thin-Film Lithium Niobate Acoustic Resonator with High Q of 237 and k2\n  of 5.1% at 50.74 GHz","summary":"  This work reports a 50.74 GHz lithium niobate (LiNbO3) acoustic resonator\nwith a high quality factor (Q) of 237 and an electromechanical coupling (k2) of\n5.17% resulting in a figure of merit (FoM, Q x k2) of 12.2. The LiNbO3\nresonator employs a novel bilayer periodically poled piezoelectric film (P3F)\n128 Y-cut LiNbO3 on amorphous silicon (a-Si) on sapphire stack to achieve low\nlosses and high coupling at millimeter wave (mm-wave). The device also shows a\nQ of 159, k2 of 65.06%, and FoM of 103.4 for the 16.99 GHz tone. This result\nshows promising prospects of P3F LiNbO3 towards mm-wave front-end filters.\n","authors":["Jack Kramer","Vakhtang Chulukhadze","Kenny Huynh","Omar Barrera","Michael Liao","Sinwoo Cho","Lezli Matto","Mark S. Goorsky","Ruochen Lu"],"pdf_url":"https://arxiv.org/pdf/2307.05742v1.pdf","comment":"4 pages, 5 figures, published in 2023 Joint Conference of the IEEE\n  International Frequency Control Symposium & European Frequency and Time Forum\n  (IEEE IFCS 2023)"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2307.05419v1","updated":"2023-07-11T16:35:04Z","published":"2023-07-11T16:35:04Z","title":"Channel Selection for Wi-Fi 7 Multi-Link Operation via\n  Optimistic-Weighted VDN and Parallel Transfer Reinforcement Learning","summary":"  Dense and unplanned IEEE 802.11 Wireless Fidelity(Wi-Fi) deployments and the\ncontinuous increase of throughput and latency stringent services for users have\nled to machine learning algorithms to be considered as promising techniques in\nthe industry and the academia. Specifically, the ongoing IEEE 802.11be EHT --\nExtremely High Throughput, known as Wi-Fi 7 -- amendment propose, for the first\ntime, Multi-Link Operation (MLO). Among others, this new feature will increase\nthe complexity of channel selection due the novel multiple interfaces proposal.\nIn this paper, we present a Parallel Transfer Reinforcement Learning\n(PTRL)-based cooperative Multi-Agent Reinforcement Learning (MARL) algorithm\nnamed Parallel Transfer Reinforcement Learning Optimistic-Weighted Value\nDecomposition Networks (oVDN) to improve intelligent channel selection in IEEE\n802.11be MLO-capable networks. Additionally, we compare the impact of different\nparallel transfer learning alternatives and a centralized non-transfer MARL\nbaseline. Two PTRL methods are presented: Multi-Agent System (MAS) Joint\nQ-function Transfer, where the joint Q-function is transferred and MAS\nBest/Worst Experience Transfer where the best and worst experiences are\ntransferred among MASs. Simulation results show that oVDNg -- only the best\nexperiences are utilized -- is the best algorithm variant. Moreover, oVDNg\noffers a gain up to 3%, 7.2% and 11% when compared with VDN, VDN-nonQ and\nnon-PTRL baselines. Furthermore, oVDNg experienced a reward convergence gain in\nthe 5 GHz interface of 33.3% over oVDNb and oVDN where only worst and both\ntypes of experiences are considered, respectively. Finally, our best PTRL\nalternative showed an improvement over the non-PTRL baseline in terms of speed\nof convergence up to 40 episodes and reward up to 135%.\n","authors":["Pedro Enrique Iturria-Rivera","Marcel Chenier","Bernard Herscovici","Burak Kantarci","Melike Erol-Kantarci"],"pdf_url":"https://arxiv.org/pdf/2307.05419v1.pdf","comment":"Accepted in IEEE PIMRC'23"},{"id":"http://arxiv.org/abs/2211.08413v3","updated":"2023-07-11T16:00:32Z","published":"2022-11-15T18:51:20Z","title":"Decentralized Federated Learning: Fundamentals, State of the Art,\n  Frameworks, Trends, and Challenges","summary":"  In the last decade, Federated Learning (FL) has gained relevance in training\ncollaborative models without sharing sensitive data. Since its birth,\nCentralized FL (CFL) has been the most common approach in the literature, where\na central entity creates a global model. However, a centralized approach leads\nto increased latency due to bottlenecks, heightened vulnerability to system\nfailures, and trustworthiness concerns affecting the entity responsible for the\nglobal model creation. Decentralized Federated Learning (DFL) emerged to\naddress these concerns by promoting decentralized model aggregation and\nminimizing reliance on centralized architectures. However, despite the work\ndone in DFL, the literature has not (i) studied the main aspects\ndifferentiating DFL and CFL; (ii) analyzed DFL frameworks to create and\nevaluate new solutions; and (iii) reviewed application scenarios using DFL.\nThus, this article identifies and analyzes the main fundamentals of DFL in\nterms of federation architectures, topologies, communication mechanisms,\nsecurity approaches, and key performance indicators. Additionally, the paper at\nhand explores existing mechanisms to optimize critical DFL fundamentals. Then,\nthe most relevant features of the current DFL frameworks are reviewed and\ncompared. After that, it analyzes the most used DFL application scenarios,\nidentifying solutions based on the fundamentals and frameworks previously\ndefined. Finally, the evolution of existing DFL solutions is studied to provide\na list of trends, lessons learned, and open challenges.\n","authors":["Enrique Tomás Martínez Beltrán","Mario Quiles Pérez","Pedro Miguel Sánchez Sánchez","Sergio López Bernal","Gérôme Bovet","Manuel Gil Pérez","Gregorio Martínez Pérez","Alberto Huertas Celdrán"],"pdf_url":"https://arxiv.org/pdf/2211.08413v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05224v1","updated":"2023-07-11T12:46:39Z","published":"2023-07-11T12:46:39Z","title":"Reliable Packet Detection for Random Access Networks: Analysis,\n  Benchmark, and Optimization","summary":"  This paper reexamines and fundamentally improves the Schmidl-and-Cox (S&C)\nalgorithm, which is extensively used for packet detection in wireless networks,\nand enhances its adaptability for multi-antenna receivers. First, we introduce\na new \"compensated autocorrelation\" metric, providing a more analytically\ntractable solution with precise expressions for false-alarm and\nmissed-detection probabilities. Second, this paper proposes the Pareto\ncomparison principle for fair benchmarking packet-detection algorithms,\nconsidering both false alarms and missed detections simultaneously. Third, with\nthe Pareto benchmarking scheme, we experimentally confirm that the performance\nof S&C can be greatly improved by taking only the real part and discarding the\nimaginary part of the autocorrelation, leading to the novel real-part S&C\n(RP-S&C) scheme. Fourth, and perhaps most importantly, we utilize the\ncompensated autocorrelation metric we newly put forth to extend the\nsingle-antenna algorithm to multi-antenna scenarios through a weighted-sum\napproach. Two optimization problems, minimizing false-alarm and\nmissed-detection probabilities respectively, are formulated and solutions are\nprovided. Our experimental results reveal that the optimal weights for false\nalarms (WFA) scheme is more desirable than the optimal weights for missed\ndetections (WMD) due to its simplicity, reliability, and superior performance.\nThis study holds considerable implications for the design and deployment of\npacket-detection schemes in random-access networks.\n","authors":["Yuyang Du","Soung Chang Liew"],"pdf_url":"https://arxiv.org/pdf/2307.05224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05170v1","updated":"2023-07-11T11:05:10Z","published":"2023-07-11T11:05:10Z","title":"Neural Quantile Optimization for Edge-Cloud Computing","summary":"  We seek the best traffic allocation scheme for the edge-cloud computing\nnetwork that satisfies constraints and minimizes the cost based on burstable\nbilling. First, for a fixed network topology, we formulate a family of integer\nprogramming problems with random parameters describing the various traffic\ndemands. Then, to overcome the difficulty caused by the discrete feature of the\nproblem, we generalize the Gumbel-softmax reparameterization method to induce\nan unconstrained continuous optimization problem as a regularized continuation\nof the discrete problem. Finally, we introduce the Gumbel-softmax sampling\nnetwork to solve the optimization problems via unsupervised learning. The\nnetwork structure reflects the edge-cloud computing topology and is trained to\nminimize the expectation of the cost function for unconstrained continuous\noptimization problems. The trained network works as an efficient traffic\nallocation scheme sampler, remarkably outperforming the random strategy in\nfeasibility and cost function value. Besides testing the quality of the output\nallocation scheme, we examine the generalization property of the network by\nincreasing the time steps and the number of users. We also feed the solution to\nexisting integer optimization solvers as initial conditions and verify the\nwarm-starts can accelerate the short-time iteration process. The framework is\ngeneral with solid performance, and the decoupled feature of the random neural\nnetworks is adequate for practical implementations.\n","authors":["Bin Du","He Zhang","Xiangle Cheng","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.05170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02835v2","updated":"2023-07-11T09:16:47Z","published":"2022-09-06T22:25:17Z","title":"Security and Privacy of IP-ICN Coexistence: A Comprehensive Survey","summary":"  Today Internet is experiencing a massive number of users with a continuously\nincreasing need for data, which is the leading cause of introduced limitations\namong security and privacy issues. To overcome these limitations, a shift from\nhost-centric to data-centric is proposed, and in this context,\nInformation-Centric Networking (ICN) represents a promising solution.\nNevertheless, unsettling the current Internet network layer, i.e., Internet\nProtocol (IP), with ICN is a challenging, expensive task since it requires\nworldwide coordination among Internet Service Providers (ISPs), backbone, and\nAutonomous Services (AS). Therefore, researchers foresee that the replacement\nprocess of the current Internet will transition through the coexistence of IP\nand ICN. In this perspective, novel architectures combine IP and ICN protocols.\nHowever, only a few of the proposed architectures place the security-by-design\nfeature. Therefore, this article provides the first comprehensive Security and\nPrivacy (SP) analysis of the state-of-the-art IP-ICN coexistence architectures\nby horizontally comparing the SP features among three deployment approaches,\ni.e., overlay, underlay, and hybrid, and vertically comparing among the ten\nconsidered SP features. Lastly, the article sheds light on the open issues and\npossible future directions for IP-ICN coexistence. Our analysis shows that most\narchitectures fail to provide several SP features, including data and traffic\nflow confidentiality, availability, and anonymity of communication. Thus, this\narticle shows the secure combination of current and future protocol stacks\nduring the coexistence phase that the Internet will definitely walk across.\n","authors":["Enkeleda Bardhi","Mauro Conti","Riccardo Lazzeretti","Eleonora Losiouk"],"pdf_url":"https://arxiv.org/pdf/2209.02835v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05123v1","updated":"2023-07-11T09:00:20Z","published":"2023-07-11T09:00:20Z","title":"Entanglement Distribution in the Quantum Internet: Knowing when to Stop!","summary":"  Entanglement distribution is a key functionality of the Quantum Internet.\nHowever, quantum entanglement is very fragile, easily degraded by decoherence,\nwhich strictly constraints the time horizon within the distribution has to be\ncompleted. This, coupled with the quantum noise irremediably impinging on the\nchannels utilized for entanglement distribution, may imply the need to attempt\nthe distribution process multiple times before the targeted network nodes\nsuccessfully share the desired entangled state. And there is no guarantee that\nthis is accomplished within the time horizon dictated by the coherence times.\nAs a consequence, in noisy scenarios requiring multiple distribution attempts,\nit may be convenient to stop the distribution process early. In this paper, we\ntake steps in the direction of knowing when to stop the entanglement\ndistribution by developing a theoretical framework, able to capture the quantum\nnoise effects. Specifically, we first prove that the entanglement distribution\nprocess can be modeled as a Markov decision process. Then, we prove that the\noptimal decision policy exhibits attractive features, which we exploit to\nreduce the computational complexity. The developed framework provides quantum\nnetwork designers with flexible tools to optimally engineer the design\nparameters of the entanglement distribution process.\n","authors":["Angela Sara Cacciapuoti","Michele Viscardi","Jessica Illiano","Marcello Caleffi"],"pdf_url":"https://arxiv.org/pdf/2307.05123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04957v1","updated":"2023-07-11T01:20:09Z","published":"2023-07-11T01:20:09Z","title":"Reinforcement Learning with Non-Cumulative Objective","summary":"  In reinforcement learning, the objective is almost always defined as a\n\\emph{cumulative} function over the rewards along the process. However, there\nare many optimal control and reinforcement learning problems in various\napplication fields, especially in communications and networking, where the\nobjectives are not naturally expressed as summations of the rewards. In this\npaper, we recognize the prevalence of non-cumulative objectives in various\nproblems, and propose a modification to existing algorithms for optimizing such\nobjectives. Specifically, we dive into the fundamental building block for many\noptimal control and reinforcement learning algorithms: the Bellman optimality\nequation. To optimize a non-cumulative objective, we replace the original\nsummation operation in the Bellman update rule with a generalized operation\ncorresponding to the objective. Furthermore, we provide sufficient conditions\non the form of the generalized operation as well as assumptions on the Markov\ndecision process under which the globally optimal convergence of the\ngeneralized Bellman updates can be guaranteed. We demonstrate the idea\nexperimentally with the bottleneck objective, i.e., the objectives determined\nby the minimum reward along the process, on classical optimal control and\nreinforcement learning tasks, as well as on two network routing problems on\nmaximizing the flow rates.\n","authors":["Wei Cui","Wei Yu"],"pdf_url":"https://arxiv.org/pdf/2307.04957v1.pdf","comment":"13 pages, 6 figures. To appear in IEEE Transactions on Machine\n  Learning in Communications and Networking (TMLCN)"},{"id":"http://arxiv.org/abs/2307.04945v1","updated":"2023-07-11T00:21:21Z","published":"2023-07-11T00:21:21Z","title":"What do LLMs need to Synthesize Correct Router Configurations?","summary":"  We investigate whether Large Language Models (e.g., GPT-4) can synthesize\ncorrect router configurations with reduced manual effort. We find GPT-4 works\nvery badly by itself, producing promising draft configurations but with\negregious errors in topology, syntax, and semantics. Our strategy, that we call\nVerified Prompt Programming, is to combine GPT-4 with verifiers, and use\nlocalized feedback from the verifier to automatically correct errors.\nVerification requires a specification and actionable localized feedback to be\neffective. We show results for two use cases: translating from Cisco to Juniper\nconfigurations on a single router, and implementing no-transit policy on\nmultiple routers. While human input is still required, if we define the\nleverage as the number of automated prompts to the number of human prompts, our\nexperiments show a leverage of 10X for Juniper translation, and 6X for\nimplementing no-transit policy, ending with verified configurations.\n","authors":["Rajdeep Mondal","Alan Tang","Ryan Beckett","Todd Millstein","George Varghese"],"pdf_url":"https://arxiv.org/pdf/2307.04945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04129v2","updated":"2023-07-11T11:27:08Z","published":"2022-09-09T06:06:21Z","title":"A Worldwide Look Into Mobile Access Networks Through the Eyes of AmiGos","summary":"  How does the mobile experience compare between Germany and Nigeria? There is\ncurrently no public data or test-bed to provide an answer to this question.\nThis is because deploying and maintaining such test-bed can be both challenging\nand expensive. To fill this gap, this paper proposes a novel test-bed design\ncalled \"AmiGo\", which relies on travelers carrying mobile phones to act as\nvantage points and collect data on mobile network performance. The \"AmiGo\"\ndesign has three key advantages: it is easy to deploy, has realistic user\nmobility, and runs on real Android devices. We further developed a suite of\nmeasurement tools for \"AmiGo\" to perform network measurements, e.g., pings,\nspeedtests, and webpage loads. We leverage these tools to measure the\nperformance of 24 mobile networks across five continents over a month via an\n\"AmiGo\" deployment involving 31 students. We find that 50% of networks face a\n40-70% chance of providing low data rates, only 20% achieve low latencies, and\nnetworks in Asia, Central/South America, and Africa have significantly higher\nCDN download times than in Europe. Most news websites load slowly, while\nYouTube performs well. We made both test-bed and measurement tools open source.\n","authors":["Matteo Varvello","Yasir Zaki"],"pdf_url":"https://arxiv.org/pdf/2209.04129v2.pdf","comment":"11 pages, 11 figures"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2307.05451v1","updated":"2023-07-11T17:27:43Z","published":"2023-07-11T17:27:43Z","title":"Detection Threshold of Audio Haptic Asynchrony in a Driving Context","summary":"  In order to provide perceptually accurate multimodal feedback during driving\nsituations, it is vital to understand the threshold at which drivers are able\nto recognize asyncrony between multiple incoming Stimuli. In this work, we\ninvestigated and report the \\textit{detection threshold} (DT) of asynchrony\nbetween audio and haptic feedback, in the context of a force feedback steering\nwheel. We designed the experiment to loosely resemble a driving situation where\nthe haptic feedback was provided through a steering wheel\n(\\textit{Sensodrive}), while the accompanying audio was played through noise\ncancelling headphones. Both feedbacks were designed to resemble rumble strips,\nthat are generally installed on the side of major roadways as a safety tool.\nThe results indicate that, for $50\\%$ of the participants, asynchrony was\ndetectable outside the range of -75 ms and 110 ms, where the former is related\nto perceiving audio before haptic and vice versa for the latter. We were also\nable to concur with previous studies, which state that latency is perceivable\nat a lower threshold when audio precedes haptic stimuli.\n","authors":["Gyanendra Sharma","Hiroshi Yasuda","Manuel Kuehner"],"pdf_url":"https://arxiv.org/pdf/2307.05451v1.pdf","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2307.05443v1","updated":"2023-07-11T17:09:26Z","published":"2023-07-11T17:09:26Z","title":"Testing for Reviewer Anchoring in Peer Review: A Randomized Controlled\n  Trial","summary":"  Peer review frequently follows a process where reviewers first provide\ninitial reviews, authors respond to these reviews, then reviewers update their\nreviews based on the authors' response. There is mixed evidence regarding\nwhether this process is useful, including frequent anecdotal complaints that\nreviewers insufficiently update their scores. In this study, we aim to\ninvestigate whether reviewers anchor to their original scores when updating\ntheir reviews, which serves as a potential explanation for the lack of updates\nin reviewer scores.\n  We design a novel randomized controlled trial to test if reviewers exhibit\nanchoring. In the experimental condition, participants initially see a flawed\nversion of a paper that is later corrected, while in the control condition,\nparticipants only see the correct version. We take various measures to ensure\nthat in the absence of anchoring, reviewers in the experimental group should\nrevise their scores to be identically distributed to the scores from the\ncontrol group. Furthermore, we construct the reviewed paper to maximize the\ndifference between the flawed and corrected versions, and employ deception to\nhide the true experiment purpose.\n  Our randomized controlled trial consists of 108 researchers as participants.\nFirst, we find that our intervention was successful at creating a difference in\nperceived paper quality between the flawed and corrected versions: Using a\npermutation test with the Mann-Whitney U statistic, we find that the\nexperimental group's initial scores are lower than the control group's scores\nin both the Evaluation category (Vargha-Delaney A=0.64, p=0.0096) and Overall\nscore (A=0.59, p=0.058). Next, we test for anchoring by comparing the\nexperimental group's revised scores with the control group's scores. We find no\nsignificant evidence of anchoring in either the Overall (A=0.50, p=0.61) or\nEvaluation category (A=0.49, p=0.61).\n","authors":["Ryan Liu","Steven Jecmen","Vincent Conitzer","Fei Fang","Nihar B. Shah"],"pdf_url":"https://arxiv.org/pdf/2307.05443v1.pdf","comment":"14 pages (19 including references and appendix), 2 figures"},{"id":"http://arxiv.org/abs/2307.05171v1","updated":"2023-07-11T11:05:17Z","published":"2023-07-11T11:05:17Z","title":"Enriching Verbal Feedback from Usability Testing: Automatic Linking of\n  Thinking-Aloud Recordings and Stimulus using Eye Tracking and Mouse Data","summary":"  The think aloud method is an important and commonly used tool for usability\noptimization. However, analyzing think aloud data could be time consuming. In\nthis paper, we put forth an automatic analysis of verbal protocols and test the\nlink between spoken feedback and the stimulus using eye tracking and mouse\ntracking. The gained data - user feedback linked to a specific area of the\nstimulus - could be used to let an expert review the feedback on specific web\npage elements or to visualize on which parts of the web page the feedback was\ngiven. Specifically, we test if participants fixate on or point with the mouse\nto the content of the webpage that they are verbalizing. During the testing,\nparticipants were shown three websites and asked to verbally give their\nopinion. The verbal responses, along with the eye and cursor movements were\nrecorded. We compared the hit rate, defined as the percentage of verbally\nmentioned areas of interest (AOIs) that were fixated with gaze or pointed to\nwith the mouse. The results revealed a significantly higher hit rate for the\ngaze compared to the mouse data. Further investigation revealed that, while the\nmouse was mostly used passively to scroll, the gaze was often directed towards\nrelevant AOIs, thus establishing a strong association between spoken words and\nstimuli. Therefore, eye tracking data possibly provides more detailed\ninformation and more valuable insights about the verbalizations compared to the\nmouse data.\n","authors":["Supriya Murali","Tina Walber","Christoph Schaefer","Sezen Lim"],"pdf_url":"https://arxiv.org/pdf/2307.05171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05132v1","updated":"2023-07-11T09:22:10Z","published":"2023-07-11T09:22:10Z","title":"On the Use of Self-Supervised Speech Representations in Spontaneous\n  Speech Synthesis","summary":"  Self-supervised learning (SSL) speech representations learned from large\namounts of diverse, mixed-quality speech data without transcriptions are\ngaining ground in many speech technology applications. Prior work has shown\nthat SSL is an effective intermediate representation in two-stage\ntext-to-speech (TTS) for both read and spontaneous speech. However, it is still\nnot clear which SSL and which layer from each SSL model is most suited for\nspontaneous TTS. We address this shortcoming by extending the scope of\ncomparison for SSL in spontaneous TTS to 6 different SSLs and 3 layers within\neach SSL. Furthermore, SSL has also shown potential in predicting the mean\nopinion scores (MOS) of synthesized speech, but this has only been done in\nread-speech MOS prediction. We extend an SSL-based MOS prediction framework\npreviously developed for scoring read speech synthesis and evaluate its\nperformance on synthesized spontaneous speech. All experiments are conducted\ntwice on two different spontaneous corpora in order to find generalizable\ntrends. Overall, we present comprehensive experimental results on the use of\nSSL in spontaneous TTS and MOS prediction to further quantify and understand\nhow SSL can be used in spontaneous TTS. Audios samples:\nhttps://www.speech.kth.se/tts-demos/sp_ssl_tts\n","authors":["Siyang Wang","Gustav Eje Henter","Joakim Gustafson","Éva Székely"],"pdf_url":"https://arxiv.org/pdf/2307.05132v1.pdf","comment":"7 pages, 2 figures. 12th ISCA Speech Synthesis Workshop (SSW) 2023"},{"id":"http://arxiv.org/abs/2307.05082v1","updated":"2023-07-11T07:31:58Z","published":"2023-07-11T07:31:58Z","title":"OntoChatGPT Information System: Ontology-Driven Structured Prompts for\n  ChatGPT Meta-Learning","summary":"  This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.\n","authors":["Oleksandr Palagin","Vladislav Kaverinskiy","Anna Litvin","Kyrylo Malakhov"],"pdf_url":"https://arxiv.org/pdf/2307.05082v1.pdf","comment":"14 pages, 1 figure. Published. International Journal of Computing,\n  22(2), 170-183. https://doi.org/10.47839/ijc.22.2.3086"},{"id":"http://arxiv.org/abs/2307.03913v2","updated":"2023-07-11T01:10:08Z","published":"2023-07-08T06:26:38Z","title":"Applying human-centered AI in developing effective human-AI teaming: A\n  perspective of human-AI joint cognitive systems","summary":"  Research and application have used human-AI teaming (HAT) as a new paradigm\nto develop AI systems. HAT recognizes that AI will function as a teammate\ninstead of simply a tool in collaboration with humans. Effective human-AI teams\nneed to be capable of taking advantage of the unique abilities of both humans\nand AI while overcoming the known challenges and limitations of each member,\naugmenting human capabilities, and raising joint performance beyond that of\neither entity. The National AI Research and Strategic Plan 2023 update has\nrecognized that research programs focusing primarily on the independent\nperformance of AI systems generally fail to consider the functionality that AI\nmust provide within the context of dynamic, adaptive, and collaborative teams\nand calls for further research on human-AI teaming and collaboration. However,\nthere has been debate about whether AI can work as a teammate with humans. The\nprimary concern is that adopting the \"teaming\" paradigm contradicts the\nhuman-centered AI (HCAI) approach, resulting in humans losing control of AI\nsystems. This article further analyzes the HAT paradigm and the debates.\nSpecifically, we elaborate on our proposed conceptual framework of human-AI\njoint cognitive systems (HAIJCS) and apply it to represent HAT under the HCAI\numbrella. We believe that HAIJCS may help adopt HAI while enabling HCAI. The\nimplications and future work for HAIJCS are also discussed.\n  Insights: AI has led to the emergence of a new form of human-machine\nrelationship: human-AI teaming (HAT), a paradigmatic shift in human-AI systems;\nWe must follow a human-centered AI (HCAI) approach when applying HAT as a new\ndesign paradigm; We propose a conceptual framework of human-AI joint cognitive\nsystems (HAIJCS) to represent and implement HAT for developing effective\nhuman-AI teaming\n","authors":["Wei Xu","Zaifeng Gao"],"pdf_url":"https://arxiv.org/pdf/2307.03913v2.pdf","comment":"8"},{"id":"http://arxiv.org/abs/2307.05830v1","updated":"2023-07-11T22:51:54Z","published":"2023-07-11T22:51:54Z","title":"SnakeSynth: New Interactions for Generative Audio Synthesis","summary":"  I present \"SnakeSynth,\" a web-based lightweight audio synthesizer that\ncombines audio generated by a deep generative model and real-time continuous\ntwo-dimensional (2D) input to create and control variable-length generative\nsounds through 2D interaction gestures. Interaction gestures are touch and\nmobile-compatible with analogies to strummed, bowed, and plucked musical\ninstrument controls. Point-and-click and drag-and-drop gestures directly\ncontrol audio playback length and I show that sound length and intensity are\nmodulated by interactions with a programmable 2D coordinate grid. Leveraging\nthe speed and ubiquity of browser-based audio and hardware acceleration in\nGoogle's TensorFlow.js we generate time-varying high-fidelity sounds with\nreal-time interactivity. SnakeSynth adaptively reproduces and interpolates\nbetween sounds encountered during model training, notably without long training\ntimes, and I briefly discuss possible futures for deep generative models as an\ninteractive paradigm for musical expression.\n","authors":["Eric Easthope"],"pdf_url":"https://arxiv.org/pdf/2307.05830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04195v2","updated":"2023-07-11T22:34:51Z","published":"2023-07-09T15:02:34Z","title":"Natural Language Instructions for Intuitive Human Interaction with\n  Robotic Assistants in Field Construction Work","summary":"  The introduction of robots is widely considered to have significant potential\nof alleviating the issues of worker shortage and stagnant productivity that\nafflict the construction industry. However, it is challenging to use fully\nautomated robots in complex and unstructured construction sites. Human-Robot\nCollaboration (HRC) has shown promise of combining human workers' flexibility\nand robot assistants' physical abilities to jointly address the uncertainties\ninherent in construction work. When introducing HRC in construction, it is\ncritical to recognize the importance of teamwork and supervision in field\nconstruction and establish a natural and intuitive communication system for the\nhuman workers and robotic assistants. Natural language-based interaction can\nenable intuitive and familiar communication with robots for human workers who\nare non-experts in robot programming. However, limited research has been\nconducted on this topic in construction. This paper proposes a framework to\nallow human workers to interact with construction robots based on natural\nlanguage instructions. The proposed method consists of three stages: Natural\nLanguage Understanding (NLU), Information Mapping (IM), and Robot Control (RC).\nNatural language instructions are input to a language model to predict a tag\nfor each word in the NLU module. The IM module uses the result of the NLU\nmodule and building component information to generate the final instructional\noutput essential for a robot to acknowledge and perform the construction task.\nA case study for drywall installation is conducted to evaluate the proposed\napproach. The obtained results highlight the potential of using natural\nlanguage-based interaction to replicate the communication that occurs between\nhuman workers within the context of human-robot teams.\n","authors":["Somin Park","Xi Wang","Carol C. Menassa","Vineet R. Kamat","Joyce Y. Chai"],"pdf_url":"https://arxiv.org/pdf/2307.04195v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05807v1","updated":"2023-07-11T21:11:21Z","published":"2023-07-11T21:11:21Z","title":"Can a Chatbot Support Exploratory Software Testing? Preliminary Results","summary":"  Tests executed by human testers are still widespread in practice and fill the\ngap left by limitations of automated approaches. Among the human-centered\napproaches, exploratory testing is the de facto approach in agile teams.\nAlthough it is focused on the expertise and creativity of the tester, the\nactivity of exploratory testing may benefit from support provided by an\nautomated agent that interacts with the human testers. This paper presents a\nchatbot, called BotExpTest, designed to support testers while performing\nexploratory tests of software applications. We implemented BotExpTest on top of\nthe instant messaging social platform Discord; this version includes\nfunctionalities to report bugs and issues, time management of test sessions,\nguidelines for app testing, and presentation of exploratory testing strategies.\nTo assess BotExpTest, we conducted a user study with six software engineering\nprofessionals. They carried out two sessions performing exploratory tests along\nwith BotExpTest. Participants were capable of revealing bugs and found the\nexperience to interact with the chatbot positive. Preliminary analyses indicate\nthat chatbot-enabled exploratory testing may be as effective as similar\napproaches and help testers to uncover different bugs. Bots are shown to be\nvaluable resources for Software Engineering, and initiatives like BotExpTest\nmay help to improve the effectiveness of testing activities like exploratory\ntesting.\n","authors":["Rubens Copche","Yohan Duarte Pessanha","Vinicius Durelli","Marcelo Medeiros Eler","Andre Takeshi Endo"],"pdf_url":"https://arxiv.org/pdf/2307.05807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05795v1","updated":"2023-07-11T20:40:51Z","published":"2023-07-11T20:40:51Z","title":"Research Protocol for the Google Health Digital Well-being Study","summary":"  The impact of digital device use on health and well-being is a pressing\nquestion to which individuals, families, schools, policy makers, legislators,\nand digital designers are all demanding answers. However, the scientific\nliterature on this topic to date is marred by small and/or unrepresentative\nsamples, poor measurement of core constructs (e.g., device use, smartphone\naddiction), and a limited ability to address the psychological and behavioral\nmechanisms that may underlie the relationships between device use and\nwell-being. A number of recent authoritative reviews have made urgent calls for\nfuture research projects to address these limitations. The critical role of\nresearch is to identify which patterns of use are associated with benefits\nversus risks, and who is more vulnerable to harmful versus beneficial outcomes,\nso that we can pursue evidence-based product design, education, and regulation\naimed at maximizing benefits and minimizing risks of smartphones and other\ndigital devices. We describe a protocol for a Digital Well-Being (DWB) study to\nhelp answer these questions.\n","authors":["Daniel McDuff","Andrew Barakat","Ari Winbush","Allen Jiang","Felicia Cordeiro","Ryann Crowley","Lauren E. Kahn","John Hernandez","Nicholas B. Allen"],"pdf_url":"https://arxiv.org/pdf/2307.05795v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05650v1","updated":"2023-07-11T13:30:37Z","published":"2023-07-11T13:30:37Z","title":"Evidence-based Hand Hygiene. Can You Trust the Fluorescent-based\n  Assessment Methods?","summary":"  Healthcare-Associated Infections present a major threat to patient safety\nglobally. According to studies, more than 50% of HAI could be prevented by\nproper hand hygiene. Effectiveness of hand hygiene is regularly evaluated with\nthe fluorescent method: performing hand hygiene with a handrub containing an\nultra violet (UV) fluorescent marker. Typically, human experts evaluate the\nhands under UV-A light, and decide whether the applied handrub covered the\nwhole hand surface. The aim of this study was to investigate how different\nexperts judge the same UV-pattern, and compare that to microbiology for\nobjective validation. Hands of volunteer participants were contaminated with\nhigh concentration of a Staphylococcus epidermidis suspension. Hands were\nincompletely disinfected with UV-labeled handrub. Four different UV-box type\ndevices were used to take CCD pictures of the hands under UV light. Size of\ninadequately disinfected areas on the hands were determined in two different\nways. First, based on microbiology; the areas where colonies were grown were\nmeasured. Second, four independent senior infection control specialists were\nasked to mark the missed areas on printed image, captured under UV light. 8\nhands of healthy volunteers were examined. Expert evaluations were highly\nuncorrelated (regarding interrater reliability) and inconsistent. Microbiology\nresults weakly correlated with the expert evaluations. In half of the cases,\nthere were more than 10% difference in the size of properly disinfected area,\nas measured by microbiology versus human experts. Considering the result of the\nexpert evaluations, variability was disconcertingly high. Evaluating the\nfluorescent method is challenging, even for highly experienced professionals. A\npatient safety quality assurance system cannot be built on these data quality.\n","authors":["Száva Bánsághi","Viola Sári","Péter Szerémy","Ákos Lehotsky","Bence Takács","Brigitta K. Tóth","Tamás Haidegger"],"pdf_url":"https://arxiv.org/pdf/2307.05650v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2211.11030v4","updated":"2023-07-11T17:31:34Z","published":"2022-11-20T17:17:56Z","title":"Adversarial Cheap Talk","summary":"  Adversarial attacks in reinforcement learning (RL) often assume\nhighly-privileged access to the victim's parameters, environment, or data.\nInstead, this paper proposes a novel adversarial setting called a Cheap Talk\nMDP in which an Adversary can merely append deterministic messages to the\nVictim's observation, resulting in a minimal range of influence. The Adversary\ncannot occlude ground truth, influence underlying environment dynamics or\nreward signals, introduce non-stationarity, add stochasticity, see the Victim's\nactions, or access their parameters. Additionally, we present a simple\nmeta-learning algorithm called Adversarial Cheap Talk (ACT) to train\nAdversaries in this setting. We demonstrate that an Adversary trained with ACT\nstill significantly influences the Victim's training and testing performance,\ndespite the highly constrained setting. Affecting train-time performance\nreveals a new attack vector and provides insight into the success and failure\nmodes of existing RL algorithms. More specifically, we show that an ACT\nAdversary is capable of harming performance by interfering with the learner's\nfunction approximation, or instead helping the Victim's performance by\noutputting useful features. Finally, we show that an ACT Adversary can\nmanipulate messages during train-time to directly and arbitrarily control the\nVictim at test-time. Project video and code are available at\nhttps://sites.google.com/view/adversarial-cheap-talk\n","authors":["Chris Lu","Timon Willi","Alistair Letcher","Jakob Foerster"],"pdf_url":"https://arxiv.org/pdf/2211.11030v4.pdf","comment":"To be published at ICML 2023. Project video and code are available at\n  https://sites.google.com/view/adversarial-cheap-talk"},{"id":"http://arxiv.org/abs/2307.05447v1","updated":"2023-07-11T17:22:22Z","published":"2023-07-11T17:22:22Z","title":"Bio-Inspired Night Image Enhancement Based on Contrast Enhancement and\n  Denoising","summary":"  Due to the low accuracy of object detection and recognition in many\nintelligent surveillance systems at nighttime, the quality of night images is\ncrucial. Compared with the corresponding daytime image, nighttime image is\ncharacterized as low brightness, low contrast and high noise. In this paper, a\nbio-inspired image enhancement algorithm is proposed to convert a low\nilluminance image to a brighter and clear one. Different from existing\nbio-inspired algorithm, the proposed method doesn't use any training sequences,\nwe depend on a novel chain of contrast enhancement and denoising algorithms\nwithout using any forms of recursive functions. Our method can largely improve\nthe brightness and contrast of night images, besides, suppress noise. Then we\nimplement on real experiment, and simulation experiment to test our algorithms.\nBoth results show the advantages of proposed algorithm over contrast pair,\nMeylan and Retinex.\n","authors":["Xinyi Bai","Steffi Agino Priyanka","Hsiao-Jung Tung","Yuankai Wang"],"pdf_url":"https://arxiv.org/pdf/2307.05447v1.pdf","comment":"International Conference on Cognitive Systems and Signal Processing\n  (2016)"},{"id":"http://arxiv.org/abs/2307.05440v1","updated":"2023-07-11T17:06:52Z","published":"2023-07-11T17:06:52Z","title":"ISLTranslate: Dataset for Translating Indian Sign Language","summary":"  Sign languages are the primary means of communication for many\nhard-of-hearing people worldwide. Recently, to bridge the communication gap\nbetween the hard-of-hearing community and the rest of the population, several\nsign language translation datasets have been proposed to enable the development\nof statistical sign language translation systems. However, there is a dearth of\nsign language resources for the Indian sign language. This resource paper\nintroduces ISLTranslate, a translation dataset for continuous Indian Sign\nLanguage (ISL) consisting of 31k ISL-English sentence/phrase pairs. To the best\nof our knowledge, it is the largest translation dataset for continuous Indian\nSign Language. We provide a detailed analysis of the dataset. To validate the\nperformance of existing end-to-end Sign language to spoken language translation\nsystems, we benchmark the created dataset with a transformer-based model for\nISL translation.\n","authors":["Abhinav Joshi","Susmit Agrawal","Ashutosh Modi"],"pdf_url":"https://arxiv.org/pdf/2307.05440v1.pdf","comment":"Accepted at ACL 2023 Findings, 8 Pages"},{"id":"http://arxiv.org/abs/2302.00390v2","updated":"2023-07-11T16:42:19Z","published":"2023-02-01T11:59:17Z","title":"Hierarchical Classification of Research Fields in the \"Web of Science\"\n  Using Deep Learning","summary":"  This paper presents a hierarchical classification system that automatically\ncategorizes a scholarly publication using its abstract into a three-tier\nhierarchical label set (discipline, field, subfield) in a multi-class setting.\nThis system enables a holistic categorization of research activities in the\nmentioned hierarchy in terms of knowledge production through articles and\nimpact through citations, permitting those activities to fall into multiple\ncategories. The classification system distinguishes 44 disciplines, 718 fields\nand 1,485 subfields among 160 million abstract snippets in Microsoft Academic\nGraph (version 2018-05-17). We used batch training in a modularized and\ndistributed fashion to address and allow for interdisciplinary and interfield\nclassifications in single-label and multi-label settings. In total, we have\nconducted 3,140 experiments in all considered models (Convolutional Neural\nNetworks, Recurrent Neural Networks, Transformers). The classification accuracy\nis > 90% in 77.13% and 78.19% of the single-label and multi-label\nclassifications, respectively. We examine the advantages of our classification\nby its ability to better align research texts and output with disciplines, to\nadequately classify them in an automated way, and to capture the degree of\ninterdisciplinarity. The proposed system (a set of pre-trained models) can\nserve as a backbone to an interactive system for indexing scientific\npublications in the future.\n","authors":["Susie Xi Rao","Peter H. Egger","Ce Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00390v2.pdf","comment":"Under review in QSS"},{"id":"http://arxiv.org/abs/2307.05409v1","updated":"2023-07-11T16:23:19Z","published":"2023-07-11T16:23:19Z","title":"3D detection of roof sections from a single satellite image and\n  application to LOD2-building reconstruction","summary":"  Reconstructing urban areas in 3D out of satellite raster images has been a\nlong-standing and challenging goal of both academical and industrial research.\nThe rare methods today achieving this objective at a Level Of Details $2$ rely\non procedural approaches based on geometry, and need stereo images and/or LIDAR\ndata as input. We here propose a method for urban 3D reconstruction named\nKIBS(\\textit{Keypoints Inference By Segmentation}), which comprises two novel\nfeatures: i) a full deep learning approach for the 3D detection of the roof\nsections, and ii) only one single (non-orthogonal) satellite raster image as\nmodel input. This is achieved in two steps: i) by a Mask R-CNN model performing\na 2D segmentation of the buildings' roof sections, and after blending these\nlatter segmented pixels within the RGB satellite raster image, ii) by another\nidentical Mask R-CNN model inferring the heights-to-ground of the roof\nsections' corners via panoptic segmentation, unto full 3D reconstruction of the\nbuildings and city. We demonstrate the potential of the KIBS method by\nreconstructing different urban areas in a few minutes, with a Jaccard index for\nthe 2D segmentation of individual roof sections of $88.55\\%$ and $75.21\\%$ on\nour two data sets resp., and a height's mean error of such correctly segmented\npixels for the 3D reconstruction of $1.60$ m and $2.06$ m on our two data sets\nresp., hence within the LOD2 precision range.\n","authors":["Johann Lussange","Mulin Yu","Yuliya Tarabalka","Florent Lafarge"],"pdf_url":"https://arxiv.org/pdf/2307.05409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05399v1","updated":"2023-07-11T16:01:44Z","published":"2023-07-11T16:01:44Z","title":"Domain-Agnostic Neural Architecture for Class Incremental Continual\n  Learning in Document Processing Platform","summary":"  Production deployments in complex systems require ML architectures to be\nhighly efficient and usable against multiple tasks. Particularly demanding are\nclassification problems in which data arrives in a streaming fashion and each\nclass is presented separately. Recent methods with stochastic gradient learning\nhave been shown to struggle in such setups or have limitations like memory\nbuffers, and being restricted to specific domains that disable its usage in\nreal-world scenarios. For this reason, we present a fully differentiable\narchitecture based on the Mixture of Experts model, that enables the training\nof high-performance classifiers when examples from each class are presented\nseparately. We conducted exhaustive experiments that proved its applicability\nin various domains and ability to learn online in production environments. The\nproposed technique achieves SOTA results without a memory buffer and clearly\noutperforms the reference methods.\n","authors":["Mateusz Wójcik","Witold Kościukiewicz","Mateusz Baran","Tomasz Kajdanowicz","Adam Gonczarek"],"pdf_url":"https://arxiv.org/pdf/2307.05399v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2211.14963"},{"id":"http://arxiv.org/abs/2307.05396v1","updated":"2023-07-11T15:57:15Z","published":"2023-07-11T15:57:15Z","title":"Handwritten Text Recognition Using Convolutional Neural Network","summary":"  OCR (Optical Character Recognition) is a technology that offers comprehensive\nalphanumeric recognition of handwritten and printed characters at electronic\nspeed by merely scanning the document. Recently, the understanding of visual\ndata has been termed Intelligent Character Recognition (ICR). Intelligent\nCharacter Recognition (ICR) is the OCR module that can convert scans of\nhandwritten or printed characters into ASCII text. ASCII data is the standard\nformat for data encoding in electronic communication. ASCII assigns standard\nnumeric values to letters, numeral, symbols, white-spaces and other characters.\nIn more technical terms, OCR is the process of using an electronic device to\ntransform 2-Dimensional textual information into machine-encoded text. Anything\nthat contains text both machine written or handwritten can be scanned either\nthrough a scanner or just simply a picture of the text is enough for the\nrecognition system to distinguish the text. The goal of this papers is to show\nthe results of a Convolutional Neural Network model which has been trained on\nNational Institute of Science and Technology (NIST) dataset containing over a\n100,000 images. The network learns from the features extracted from the images\nand use it to generate the probability of each class to which the picture\nbelongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.\n","authors":["Atman Mishra","A. Sharath Ram","Kavyashree C"],"pdf_url":"https://arxiv.org/pdf/2307.05396v1.pdf","comment":"6 pages, 15 figures"},{"id":"http://arxiv.org/abs/2301.12313v3","updated":"2023-07-11T15:48:48Z","published":"2023-01-29T00:17:16Z","title":"Adapting Neural Link Predictors for Data-Efficient Complex Query\n  Answering","summary":"  Answering complex queries on incomplete knowledge graphs is a challenging\ntask where a model needs to answer complex logical queries in the presence of\nmissing knowledge. Prior work in the literature has proposed to address this\nproblem by designing architectures trained end-to-end for the complex query\nanswering task with a reasoning process that is hard to interpret while\nrequiring data and resource-intensive training. Other lines of research have\nproposed re-using simple neural link predictors to answer complex queries,\nreducing the amount of training data by orders of magnitude while providing\ninterpretable answers. The neural link predictor used in such approaches is not\nexplicitly optimised for the complex query answering task, implying that its\nscores are not calibrated to interact together. We propose to address these\nproblems via CQD$^{\\mathcal{A}}$, a parameter-efficient score \\emph{adaptation}\nmodel optimised to re-calibrate neural link prediction scores for the complex\nquery answering task. While the neural link predictor is frozen, the adaptation\ncomponent -- which only increases the number of model parameters by $0.03\\%$ --\nis trained on the downstream complex query answering task. Furthermore, the\ncalibration component enables us to support reasoning over queries that include\natomic negations, which was previously impossible with link predictors. In our\nexperiments, CQD$^{\\mathcal{A}}$ produces significantly more accurate results\nthan current state-of-the-art methods, improving from $34.4$ to $35.1$ Mean\nReciprocal Rank values averaged across all datasets and query types while using\n$\\leq 30\\%$ of the available training query types. We further show that\nCQD$^{\\mathcal{A}}$ is data-efficient, achieving competitive results with only\n$1\\%$ of the training complex queries, and robust in out-of-domain evaluations.\n","authors":["Erik Arakelyan","Pasquale Minervini","Daniel Daza","Michael Cochez","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2301.12313v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05358v1","updated":"2023-07-11T15:45:03Z","published":"2023-07-11T15:45:03Z","title":"Combating Data Imbalances in Federated Semi-supervised Learning with\n  Dual Regulators","summary":"  Federated learning has become a popular method to learn from decentralized\nheterogeneous data. Federated semi-supervised learning (FSSL) emerges to train\nmodels from a small fraction of labeled data due to label scarcity on\ndecentralized clients. Existing FSSL methods assume independent and identically\ndistributed (IID) labeled data across clients and consistent class distribution\nbetween labeled and unlabeled data within a client. This work studies a more\npractical and challenging scenario of FSSL, where data distribution is\ndifferent not only across clients but also within a client between labeled and\nunlabeled data. To address this challenge, we propose a novel FSSL framework\nwith dual regulators, FedDure.} FedDure lifts the previous assumption with a\ncoarse-grained regulator (C-reg) and a fine-grained regulator (F-reg): C-reg\nregularizes the updating of the local model by tracking the learning effect on\nlabeled data distribution; F-reg learns an adaptive weighting scheme tailored\nfor unlabeled instances in each client. We further formulate the client model\ntraining as bi-level optimization that adaptively optimizes the model in the\nclient with two regulators. Theoretically, we show the convergence guarantee of\nthe dual regulators. Empirically, we demonstrate that FedDure is superior to\nthe existing methods across a wide range of settings, notably by more than 11%\non CIFAR-10 and CINIC-10 datasets.\n","authors":["Sikai Bai","Shuaicheng Li","Weiming Zhuang","Kunlin Yang","Jun Hou","Shuai Yi","Shuai Zhang","Junyu Gao","Jie Zhang","Song Guo"],"pdf_url":"https://arxiv.org/pdf/2307.05358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05328v1","updated":"2023-07-11T15:19:47Z","published":"2023-07-11T15:19:47Z","title":"ProgGP: From GuitarPro Tablature Neural Generation To Progressive Metal\n  Production","summary":"  Recent work in the field of symbolic music generation has shown value in\nusing a tokenization based on the GuitarPro format, a symbolic representation\nsupporting guitar expressive attributes, as an input and output representation.\nWe extend this work by fine-tuning a pre-trained Transformer model on ProgGP, a\ncustom dataset of 173 progressive metal songs, for the purposes of creating\ncompositions from that genre through a human-AI partnership. Our model is able\nto generate multiple guitar, bass guitar, drums, piano and orchestral parts. We\nexamine the validity of the generated music using a mixed methods approach by\ncombining quantitative analyses following a computational musicology paradigm\nand qualitative analyses following a practice-based research paradigm. Finally,\nwe demonstrate the value of the model by using it as a tool to create a\nprogressive metal song, fully produced and mixed by a human metal producer\nbased on AI-generated music.\n","authors":["Jackson Loth","Pedro Sarmento","CJ Carr","Zack Zukowski","Mathieu Barthet"],"pdf_url":"https://arxiv.org/pdf/2307.05328v1.pdf","comment":"Pre-print accepted for publication at CMMR2023"},{"id":"http://arxiv.org/abs/2305.15066v2","updated":"2023-07-11T15:08:00Z","published":"2023-05-24T11:53:19Z","title":"GPT4Graph: Can Large Language Models Understand Graph Structured Data ?\n  An Empirical Evaluation and Benchmarking","summary":"  Large language models~(LLM) like ChatGPT have become indispensable to\nartificial general intelligence~(AGI), demonstrating excellent performance in\nvarious natural language processing tasks. In the real world, graph data is\nubiquitous and an essential part of AGI and prevails in domains like social\nnetwork analysis, bioinformatics and recommender systems. The training corpus\nof large language models often includes some algorithmic components, which\nallows them to achieve certain effects on some graph data-related problems.\nHowever, there is still little research on their performance on a broader range\nof graph-structured data. In this study, we conduct an extensive investigation\nto assess the proficiency of LLMs in comprehending graph data, employing a\ndiverse range of structural and semantic-related tasks. Our analysis\nencompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph\nunderstanding. Through our study, we not only uncover the current limitations\nof language models in comprehending graph structures and performing associated\nreasoning tasks but also emphasize the necessity for further advancements and\nnovel approaches to enhance their graph processing capabilities. Our findings\ncontribute valuable insights towards bridging the gap between language models\nand graph understanding, paving the way for more effective graph mining and\nknowledge extraction.\n","authors":["Jiayan Guo","Lun Du","Hengyu Liu","Mengyu Zhou","Xinyi He","Shi Han"],"pdf_url":"https://arxiv.org/pdf/2305.15066v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05317v1","updated":"2023-07-11T15:01:42Z","published":"2023-07-11T15:01:42Z","title":"Automatic Generation of Semantic Parts for Face Image Synthesis","summary":"  Semantic image synthesis (SIS) refers to the problem of generating realistic\nimagery given a semantic segmentation mask that defines the spatial layout of\nobject classes. Most of the approaches in the literature, other than the\nquality of the generated images, put effort in finding solutions to increase\nthe generation diversity in terms of style i.e. texture. However, they all\nneglect a different feature, which is the possibility of manipulating the\nlayout provided by the mask. Currently, the only way to do so is manually by\nmeans of graphical users interfaces. In this paper, we describe a network\narchitecture to address the problem of automatically manipulating or generating\nthe shape of object classes in semantic segmentation masks, with specific focus\non human faces. Our proposed model allows embedding the mask class-wise into a\nlatent space where each class embedding can be independently edited. Then, a\nbi-directional LSTM block and a convolutional decoder output a new, locally\nmanipulated mask. We report quantitative and qualitative results on the\nCelebMask-HQ dataset, which show our model can both faithfully reconstruct and\nmodify a segmentation mask at the class level. Also, we show our model can be\nput before a SIS generator, opening the way to a fully automatic generation\ncontrol of both shape and texture. Code available at\nhttps://github.com/TFonta/Semantic-VAE.\n","authors":["Tomaso Fontanini","Claudio Ferrari","Massimo Bertozzi","Andrea Prati"],"pdf_url":"https://arxiv.org/pdf/2307.05317v1.pdf","comment":"Preprint, accepted for publication at ICIAP 2023"},{"id":"http://arxiv.org/abs/2307.05314v1","updated":"2023-07-11T15:00:11Z","published":"2023-07-11T15:00:11Z","title":"Masked Vision and Language Pre-training with Unimodal and Multimodal\n  Contrastive Losses for Medical Visual Question Answering","summary":"  Medical visual question answering (VQA) is a challenging task that requires\nanswering clinical questions of a given medical image, by taking consider of\nboth visual and language information. However, due to the small scale of\ntraining data for medical VQA, pre-training fine-tuning paradigms have been a\ncommonly used solution to improve model generalization performance. In this\npaper, we present a novel self-supervised approach that learns unimodal and\nmultimodal feature representations of input images and text using medical image\ncaption datasets, by leveraging both unimodal and multimodal contrastive\nlosses, along with masked language modeling and image text matching as\npretraining objectives. The pre-trained model is then transferred to downstream\nmedical VQA tasks. The proposed approach achieves state-of-the-art (SOTA)\nperformance on three publicly available medical VQA datasets with significant\naccuracy improvements of 2.2%, 14.7%, and 1.7% respectively. Besides, we\nconduct a comprehensive analysis to validate the effectiveness of different\ncomponents of the approach and study different pre-training settings. Our codes\nand models are available at https://github.com/pengfeiliHEU/MUMC.\n","authors":["Pengfei Li","Gang Liu","Jinlong He","Zixu Zhao","Shenjun Zhong"],"pdf_url":"https://arxiv.org/pdf/2307.05314v1.pdf","comment":"accepted by MICCAI2023"},{"id":"http://arxiv.org/abs/2307.05300v1","updated":"2023-07-11T14:45:19Z","published":"2023-07-11T14:45:19Z","title":"Unleashing Cognitive Synergy in Large Language Models: A Task-Solving\n  Agent through Multi-Persona Self-Collaboration","summary":"  Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nhttps://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.\n","authors":["Zhenhailong Wang","Shaoguang Mao","Wenshan Wu","Tao Ge","Furu Wei","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2307.05300v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2307.05284v1","updated":"2023-07-11T14:25:10Z","published":"2023-07-11T14:25:10Z","title":"On the Need for a Language Describing Distribution Shifts: Illustrations\n  on Tabular Datasets","summary":"  Different distribution shifts require different algorithmic and operational\ninterventions. Methodological research must be grounded by the specific shifts\nthey address. Although nascent benchmarks provide a promising empirical\nfoundation, they implicitly focus on covariate shifts, and the validity of\nempirical findings depends on the type of shift, e.g., previous observations on\nalgorithmic performance can fail to be valid when the $Y|X$ distribution\nchanges. We conduct a thorough investigation of natural shifts in 5 tabular\ndatasets over 86,000 model configurations, and find that $Y|X$-shifts are most\nprevalent. To encourage researchers to develop a refined language for\ndistribution shifts, we build WhyShift, an empirical testbed of curated\nreal-world shifts where we characterize the type of shift we benchmark\nperformance over. Since $Y|X$-shifts are prevalent in tabular settings, we\nidentify covariate regions that suffer the biggest $Y|X$-shifts and discuss\nimplications for algorithmic and data-based interventions. Our testbed\nhighlights the importance of future research that builds an understanding of\nhow distributions differ.\n","authors":["Jiashuo Liu","Tianyu Wang","Peng Cui","Hongseok Namkoong"],"pdf_url":"https://arxiv.org/pdf/2307.05284v1.pdf","comment":"41 pages"},{"id":"http://arxiv.org/abs/2302.14468v2","updated":"2023-07-11T14:13:54Z","published":"2023-02-28T10:19:57Z","title":"SAINE: Scientific Annotation and Inference Engine of Scientific Research","summary":"  We present SAINE, an Scientific Annotation and Inference ENgine based on a\nset of standard open-source software, such as Label Studio and MLflow. We show\nthat our annotation engine can benefit the further development of a more\naccurate classification. Based on our previous work on hierarchical discipline\nclassifications, we demonstrate its application using SAINE in understanding\nthe space for scholarly publications. The user study of our annotation results\nshows that user input collected with the help of our system can help us better\nunderstand the classification process. We believe that our work will help to\nfoster greater transparency and better understand scientific research. Our\nannotation and inference engine can further support the downstream meta-science\nprojects. We welcome collaboration and feedback from the scientific community\non these projects. The demonstration video can be accessed from\nhttps://youtu.be/yToO-G9YQK4. A live demo website is available at\nhttps://app.heartex.com/user/signup/?token=e2435a2f97449fa1 upon free\nregistration.\n","authors":["Susie Xi Rao","Yilei Tu","Peter H. Egger"],"pdf_url":"https://arxiv.org/pdf/2302.14468v2.pdf","comment":"Under review in IJCNLP-AACL Demo 2023"},{"id":"http://arxiv.org/abs/2306.16177v2","updated":"2023-07-11T14:11:14Z","published":"2023-06-28T12:58:42Z","title":"Defining data science: a new field of inquiry","summary":"  Data science is not a science. It is a research paradigm. Its power, scope,\nand scale will surpass science, our most powerful research paradigm, to enable\nknowledge discovery and change our world. We have yet to understand and define\nit, vital to realizing its potential and managing its risks. Modern data\nscience is in its infancy. Emerging slowly since 1962 and rapidly since 2000,\nit is a fundamentally new field of inquiry, one of the most active, powerful,\nand rapidly evolving 21st century innovations. Due to its value, power, and\napplicability, it is emerging in 40+ disciplines, hundreds of research areas,\nand thousands of applications. Millions of data science publications contain\nmyriad definitions of data science and data science problem solving. Due to its\ninfancy, many definitions are independent, application-specific, mutually\nincomplete, redundant, or inconsistent, hence so is data science. This research\naddresses this data science multiple definitions challenge by proposing the\ndevelopment of coherent, unified definition based on a data science reference\nframework using a data science journal for the data science community to\nachieve such a definition. This paper provides candidate definitions for\nessential data science artifacts that are required to discuss such a\ndefinition. They are based on the classical research paradigm concept\nconsisting of a philosophy of data science, the data science problem solving\nparadigm, and the six component data science reference framework (axiology,\nontology, epistemology, methodology, methods, technology) that is a frequently\ncalled for unifying framework with which to define, unify, and evolve data\nscience. It presents challenges for defining data science, solution approaches,\ni.e., means for defining data science, and their requirements and benefits as\nthe basis of a comprehensive solution.\n","authors":["Michael L Brodie"],"pdf_url":"https://arxiv.org/pdf/2306.16177v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05260v1","updated":"2023-07-11T13:51:12Z","published":"2023-07-11T13:51:12Z","title":"U-CREAT: Unsupervised Case Retrieval using Events extrAcTion","summary":"  The task of Prior Case Retrieval (PCR) in the legal domain is about\nautomatically citing relevant (based on facts and precedence) prior legal cases\nin a given query case. To further promote research in PCR, in this paper, we\npropose a new large benchmark (in English) for the PCR task: IL-PCR (Indian\nLegal Prior Case Retrieval) corpus. Given the complex nature of case relevance\nand the long size of legal documents, BM25 remains a strong baseline for\nranking the cited prior documents. In this work, we explore the role of events\nin legal case retrieval and propose an unsupervised retrieval method-based\npipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction). We find\nthat the proposed unsupervised retrieval method significantly increases\nperformance compared to BM25 and makes retrieval faster by a considerable\nmargin, making it applicable to real-time case retrieval systems. Our proposed\nsystem is generic, we show that it generalizes across two different legal\nsystems (Indian and Canadian), and it shows state-of-the-art performance on the\nbenchmarks for both the legal systems (IL-PCR and COLIEE corpora).\n","authors":["Abhinav Joshi","Akshat Sharma","Sai Kiran Tanikella","Ashutosh Modi"],"pdf_url":"https://arxiv.org/pdf/2307.05260v1.pdf","comment":"Accepted at ACL 2023, 15 pages (12 main + 3 Appendix)"},{"id":"http://arxiv.org/abs/2307.05258v1","updated":"2023-07-11T13:47:26Z","published":"2023-07-11T13:47:26Z","title":"Integrated Planning in Hospitals: A Review","summary":"  Efficient planning of scarce resources in hospitals is a challenging task for\nwhich a large variety of Operations Research and Management Science approaches\nhave been developed since the 1950s. While efficient planning of single\nresources such as operating rooms, beds, or specific types of staff can already\nlead to enormous efficiency gains, integrated planning of several resources has\nbeen shown to hold even greater potential, and a large number of integrated\nplanning approaches have been presented in the literature over the past\ndecades.\n  This paper provides the first literature review that focuses specifically on\nthe Operations Research and Management Science literature related to integrated\nplanning of different resources in hospitals. We collect the relevant\nliterature and analyze it regarding different aspects such as uncertainty\nmodeling and the use of real-life data. Several cross comparisons reveal\ninteresting insights concerning, e.g., relations between the modeling and\nsolution methods used and the practical implementation of the approaches\ndeveloped. Moreover, we provide a high-level taxonomy for classifying different\nresource-focused integration approaches and point out gaps in the literature as\nwell as promising directions for future research.\n","authors":["Sebastian Rachuba","Melanie Reuter-Oppermann","Clemens Thielen"],"pdf_url":"https://arxiv.org/pdf/2307.05258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09841v2","updated":"2023-07-11T13:41:20Z","published":"2023-06-16T13:39:35Z","title":"Are Large Language Models Really Good Logical Reasoners? A Comprehensive\n  Evaluation and Beyond","summary":"  Logical reasoning consistently plays a fundamental and significant role in\nthe domains of knowledge engineering and artificial intelligence. Recently,\nLarge Language Models (LLMs) have emerged as a noteworthy innovation in natural\nlanguage processing (NLP), exhibiting impressive achievements across various\nclassic NLP tasks. However, the question of whether LLMs can effectively\naddress the task of logical reasoning, which requires gradual cognitive\ninference similar to human intelligence, remains unanswered. To this end, we\naim to bridge this gap and provide comprehensive evaluations in this paper.\nFirstly, to offer systematic evaluations, we select fifteen typical logical\nreasoning datasets and organize them into deductive, inductive, abductive and\nmixed-form reasoning settings. Considering the comprehensiveness of\nevaluations, we include three representative LLMs (i.e., text-davinci-003,\nChatGPT and BARD) and evaluate them on all selected datasets under zero-shot,\none-shot and three-shot settings. Secondly, different from previous evaluations\nrelying only on simple metrics (e.g., accuracy), we propose fine-level\nevaluations from objective and subjective manners, covering both answers and\nexplanations. Additionally, to uncover the logical flaws of LLMs, problematic\ncases will be attributed to five error types from two dimensions, i.e.,\nevidence selection process and reasoning process. Thirdly, to avoid the\ninfluences of knowledge bias and purely focus on benchmarking the logical\nreasoning capability of LLMs, we propose a new dataset with neutral content. It\ncontains 3,000 samples and covers deductive, inductive and abductive settings.\nBased on the in-depth evaluations, this paper finally forms a general\nevaluation scheme of logical reasoning capability from six dimensions. It\nreflects the pros and cons of LLMs and gives guiding directions for future\nworks.\n","authors":["Fangzhi Xu","Qika Lin","Jiawei Han","Tianzhe Zhao","Jun Liu","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2306.09841v2.pdf","comment":"14 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.01977v2","updated":"2023-07-11T13:09:37Z","published":"2022-12-05T01:58:45Z","title":"Distributed Pruning Towards Tiny Neural Networks in Federated Learning","summary":"  Neural network pruning is an essential technique for reducing the size and\ncomplexity of deep neural networks, enabling large-scale models on devices with\nlimited resources. However, existing pruning approaches heavily rely on\ntraining data for guiding the pruning strategies, making them ineffective for\nfederated learning over distributed and confidential datasets. Additionally,\nthe memory- and computation-intensive pruning process becomes infeasible for\nrecourse-constrained devices in federated learning. To address these\nchallenges, we propose FedTiny, a distributed pruning framework for federated\nlearning that generates specialized tiny models for memory- and\ncomputing-constrained devices. We introduce two key modules in FedTiny to\nadaptively search coarse- and finer-pruned specialized models to fit deployment\nscenarios with sparse and cheap local computation. First, an adaptive batch\nnormalization selection module is designed to mitigate biases in pruning caused\nby the heterogeneity of local data. Second, a lightweight progressive pruning\nmodule aims to finer prune the models under strict memory and computational\nbudgets, allowing the pruning policy for each layer to be gradually determined\nrather than evaluating the overall model structure. The experimental results\ndemonstrate the effectiveness of FedTiny, which outperforms state-of-the-art\napproaches, particularly when compressing deep models to extremely sparse tiny\nmodels. FedTiny achieves an accuracy improvement of 2.61% while significantly\nreducing the computational cost by 95.91% and the memory footprint by 94.01%\ncompared to state-of-the-art methods.\n","authors":["Hong Huang","Lan Zhang","Chaoyue Sun","Ruogu Fang","Xiaoyong Yuan","Dapeng Wu"],"pdf_url":"https://arxiv.org/pdf/2212.01977v2.pdf","comment":"This paper has been accepted to ICDCS 2023"},{"id":"http://arxiv.org/abs/2112.14586v2","updated":"2023-07-11T12:53:31Z","published":"2021-12-29T14:58:56Z","title":"Isotuning With Applications To Scale-Free Online Learning","summary":"  We extend and combine several tools of the literature to design fast,\nadaptive, anytime and scale-free online learning algorithms. Scale-free regret\nbounds must scale linearly with the maximum loss, both toward large losses and\ntoward very small losses. Adaptive regret bounds demonstrate that an algorithm\ncan take advantage of easy data and potentially have constant regret. We seek\nto develop fast algorithms that depend on as few parameters as possible, in\nparticular they should be anytime and thus not depend on the time horizon. Our\nfirst and main tool, isotuning, is a generalization of the idea of balancing\nthe trade-off of the regret. We develop a set of tools to design and analyze\nsuch learning rates easily and show that they adapts automatically to the rate\nof the regret (whether constant, $O(\\log T)$, $O(\\sqrt{T})$, etc.) within a\nfactor 2 of the optimal learning rate in hindsight for the same observed\nquantities. The second tool is an online correction, which allows us to obtain\ncentered bounds for many algorithms, to prevent the regret bounds from being\nvacuous when the domain is overly large or only partially constrained. The last\ntool, null updates, prevents the algorithm from performing overly large\nupdates, which could result in unbounded regret, or even invalid updates. We\ndevelop a general theory using these tools and apply it to several standard\nalgorithms. In particular, we (almost entirely) restore the adaptivity to small\nlosses of FTRL for unbounded domains, design and prove scale-free adaptive\nguarantees for a variant of Mirror Descent (at least when the Bregman\ndivergence is convex in its second argument), extend Adapt-ML-Prod to\nscale-free guarantees, and provide several other minor contributions about\nProd, AdaHedge, BOA and Soft-Bayes.\n","authors":["Laurent Orseau","Marcus Hutter"],"pdf_url":"https://arxiv.org/pdf/2112.14586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05213v1","updated":"2023-07-11T12:32:13Z","published":"2023-07-11T12:32:13Z","title":"Score Function Gradient Estimation to Widen the Applicability of\n  Decision-Focused Learning","summary":"  Many real-world optimization problems contain unknown parameters that must be\npredicted prior to solving. To train the predictive machine learning (ML)\nmodels involved, the commonly adopted approach focuses on maximizing predictive\naccuracy. However, this approach does not always lead to the minimization of\nthe downstream task loss. Decision-focused learning (DFL) is a recently\nproposed paradigm whose goal is to train the ML model by directly minimizing\nthe task loss. However, state-of-the-art DFL methods are limited by the\nassumptions they make about the structure of the optimization problem (e.g.,\nthat the problem is linear) and by the fact that can only predict parameters\nthat appear in the objective function. In this work, we address these\nlimitations by instead predicting \\textit{distributions} over parameters and\nadopting score function gradient estimation (SFGE) to compute decision-focused\nupdates to the predictive model, thereby widening the applicability of DFL. Our\nexperiments show that by using SFGE we can: (1) deal with predictions that\noccur both in the objective function and in the constraints; and (2)\neffectively tackle two-stage stochastic optimization problems.\n","authors":["Mattia Silvestri","Senne Berden","Jayanta Mandi","Ali İrfan Mahmutoğulları","Maxime Mulamba","Allegra De Filippo","Tias Guns","Michele Lombardi"],"pdf_url":"https://arxiv.org/pdf/2307.05213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05209v1","updated":"2023-07-11T12:28:05Z","published":"2023-07-11T12:28:05Z","title":"Contextual Pre-Planning on Reward Machine Abstractions for Enhanced\n  Transfer in Deep Reinforcement Learning","summary":"  Recent studies show that deep reinforcement learning (DRL) agents tend to\noverfit to the task on which they were trained and fail to adapt to minor\nenvironment changes. To expedite learning when transferring to unseen tasks, we\npropose a novel approach to representing the current task using reward machines\n(RM), state machine abstractions that induce subtasks based on the current\ntask's rewards and dynamics. Our method provides agents with symbolic\nrepresentations of optimal transitions from their current abstract state and\nrewards them for achieving these transitions. These representations are shared\nacross tasks, allowing agents to exploit knowledge of previously encountered\nsymbols and transitions, thus enhancing transfer. Our empirical evaluation\nshows that our representations improve sample efficiency and few-shot transfer\nin a variety of domains.\n","authors":["Guy Azran","Mohamad H. Danesh","Stefano V. Albrecht","Sarah Keren"],"pdf_url":"https://arxiv.org/pdf/2307.05209v1.pdf","comment":"IJCAI Workshop on Planning and Reinforcement Learning, 2023"},{"id":"http://arxiv.org/abs/2303.05066v2","updated":"2023-07-11T12:04:33Z","published":"2023-03-09T06:33:31Z","title":"Distortion-Disentangled Contrastive Learning","summary":"  Self-supervised learning is well known for its remarkable performance in\nrepresentation learning and various downstream computer vision tasks. Recently,\nPositive-pair-Only Contrastive Learning (POCL) has achieved reliable\nperformance without the need to construct positive-negative training sets. It\nreduces memory requirements by lessening the dependency on the batch size. The\nPOCL method typically uses a single loss function to extract the distortion\ninvariant representation (DIR) which describes the proximity of positive-pair\nrepresentations affected by different distortions. This loss function\nimplicitly enables the model to filter out or ignore the distortion variant\nrepresentation (DVR) affected by different distortions. However, existing POCL\nmethods do not explicitly enforce the disentanglement and exploitation of the\nactually valuable DVR. In addition, these POCL methods have been observed to be\nsensitive to augmentation strategies. To address these limitations, we propose\na novel POCL framework named Distortion-Disentangled Contrastive Learning\n(DDCL) and a Distortion-Disentangled Loss (DDL). Our approach is the first to\nexplicitly disentangle and exploit the DVR inside the model and feature stream\nto improve the overall representation utilization efficiency, robustness and\nrepresentation ability. Experiments carried out demonstrate the superiority of\nour framework to Barlow Twins and Simsiam in terms of convergence,\nrepresentation quality, and robustness on several benchmark datasets.\n","authors":["Jinfeng Wang","Sifan Song","Jionglong Su","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.05066v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05194v1","updated":"2023-07-11T12:00:15Z","published":"2023-07-11T12:00:15Z","title":"Differentially Private Statistical Inference through $β$-Divergence\n  One Posterior Sampling","summary":"  Differential privacy guarantees allow the results of a statistical analysis\ninvolving sensitive data to be released without compromising the privacy of any\nindividual taking part. Achieving such guarantees generally requires the\ninjection of noise, either directly into parameter estimates or into the\nestimation process. Instead of artificially introducing perturbations, sampling\nfrom Bayesian posterior distributions has been shown to be a special case of\nthe exponential mechanism, producing consistent, and efficient private\nestimates without altering the data generative process. The application of\ncurrent approaches has, however, been limited by their strong bounding\nassumptions which do not hold for basic models, such as simple linear\nregressors. To ameliorate this, we propose $\\beta$D-Bayes, a posterior sampling\nscheme from a generalised posterior targeting the minimisation of the\n$\\beta$-divergence between the model and the data generating process. This\nprovides private estimation that is generally applicable without requiring\nchanges to the underlying model and consistently learns the data generating\nparameter. We show that $\\beta$D-Bayes produces more precise inference\nestimation for the same privacy guarantees, and further facilitates\ndifferentially private estimation via posterior sampling for complex\nclassifiers and continuous regression models such as neural networks for the\nfirst time.\n","authors":["Jack Jewson","Sahra Ghalebikesabi","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2307.05194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05182v1","updated":"2023-07-11T11:35:40Z","published":"2023-07-11T11:35:40Z","title":"Co-Attention Gated Vision-Language Embedding for Visual Question\n  Localized-Answering in Robotic Surgery","summary":"  Medical students and junior surgeons often rely on senior surgeons and\nspecialists to answer their questions when learning surgery. However, experts\nare often busy with clinical and academic work, and have little time to give\nguidance. Meanwhile, existing deep learning (DL)-based surgical Visual Question\nAnswering (VQA) systems can only provide simple answers without the location of\nthe answers. In addition, vision-language (ViL) embedding is still a less\nexplored research in these kinds of tasks. Therefore, a surgical Visual\nQuestion Localized-Answering (VQLA) system would be helpful for medical\nstudents and junior surgeons to learn and understand from recorded surgical\nvideos. We propose an end-to-end Transformer with Co-Attention gaTed\nVision-Language (CAT-ViL) for VQLA in surgical scenarios, which does not\nrequire feature extraction through detection models. The CAT-ViL embedding\nmodule is designed to fuse heterogeneous features from visual and textual\nsources. The fused embedding will feed a standard Data-Efficient Image\nTransformer (DeiT) module, before the parallel classifier and detector for\njoint prediction. We conduct the experimental validation on public surgical\nvideos from MICCAI EndoVis Challenge 2017 and 2018. The experimental results\nhighlight the superior performance and robustness of our proposed model\ncompared to the state-of-the-art approaches. Ablation studies further prove the\noutstanding performance of all the proposed components. The proposed method\nprovides a promising solution for surgical scene understanding, and opens up a\nprimary step in the Artificial Intelligence (AI)-based VQLA system for surgical\ntraining. Our code is publicly available.\n","authors":["Long Bai","Mobarakol Islam","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2307.05182v1.pdf","comment":"To appear in MICCAI 2023. Code availability:\n  https://github.com/longbai1006/CAT-ViL"},{"id":"http://arxiv.org/abs/2306.01147v2","updated":"2023-07-11T11:33:25Z","published":"2023-06-01T21:03:06Z","title":"Smooth Monotonic Networks","summary":"  Monotonicity constraints are powerful regularizers in statistical modelling.\nThey can support fairness in computer supported decision making and increase\nplausibility in data-driven scientific models. The seminal min-max (MM) neural\nnetwork architecture ensures monotonicity, but often gets stuck in undesired\nlocal optima during training because of vanishing gradients. We propose a\nsimple modification of the MM network using strictly-increasing smooth\nnon-linearities that alleviates this problem. The resulting smooth min-max\n(SMM) network module inherits the asymptotic approximation properties from the\nMM architecture. It can be used within larger deep learning systems trained\nend-to-end. The SMM module is considerably simpler and less computationally\ndemanding than state-of-the-art neural networks for monotonic modelling. Still,\nin our experiments, it compared favorably to alternative neural and non-neural\napproaches in terms of generalization performance.\n","authors":["Christian Igel"],"pdf_url":"https://arxiv.org/pdf/2306.01147v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05171v1","updated":"2023-07-11T11:05:17Z","published":"2023-07-11T11:05:17Z","title":"Enriching Verbal Feedback from Usability Testing: Automatic Linking of\n  Thinking-Aloud Recordings and Stimulus using Eye Tracking and Mouse Data","summary":"  The think aloud method is an important and commonly used tool for usability\noptimization. However, analyzing think aloud data could be time consuming. In\nthis paper, we put forth an automatic analysis of verbal protocols and test the\nlink between spoken feedback and the stimulus using eye tracking and mouse\ntracking. The gained data - user feedback linked to a specific area of the\nstimulus - could be used to let an expert review the feedback on specific web\npage elements or to visualize on which parts of the web page the feedback was\ngiven. Specifically, we test if participants fixate on or point with the mouse\nto the content of the webpage that they are verbalizing. During the testing,\nparticipants were shown three websites and asked to verbally give their\nopinion. The verbal responses, along with the eye and cursor movements were\nrecorded. We compared the hit rate, defined as the percentage of verbally\nmentioned areas of interest (AOIs) that were fixated with gaze or pointed to\nwith the mouse. The results revealed a significantly higher hit rate for the\ngaze compared to the mouse data. Further investigation revealed that, while the\nmouse was mostly used passively to scroll, the gaze was often directed towards\nrelevant AOIs, thus establishing a strong association between spoken words and\nstimuli. Therefore, eye tracking data possibly provides more detailed\ninformation and more valuable insights about the verbalizations compared to the\nmouse data.\n","authors":["Supriya Murali","Tina Walber","Christoph Schaefer","Sezen Lim"],"pdf_url":"https://arxiv.org/pdf/2307.05171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05170v1","updated":"2023-07-11T11:05:10Z","published":"2023-07-11T11:05:10Z","title":"Neural Quantile Optimization for Edge-Cloud Computing","summary":"  We seek the best traffic allocation scheme for the edge-cloud computing\nnetwork that satisfies constraints and minimizes the cost based on burstable\nbilling. First, for a fixed network topology, we formulate a family of integer\nprogramming problems with random parameters describing the various traffic\ndemands. Then, to overcome the difficulty caused by the discrete feature of the\nproblem, we generalize the Gumbel-softmax reparameterization method to induce\nan unconstrained continuous optimization problem as a regularized continuation\nof the discrete problem. Finally, we introduce the Gumbel-softmax sampling\nnetwork to solve the optimization problems via unsupervised learning. The\nnetwork structure reflects the edge-cloud computing topology and is trained to\nminimize the expectation of the cost function for unconstrained continuous\noptimization problems. The trained network works as an efficient traffic\nallocation scheme sampler, remarkably outperforming the random strategy in\nfeasibility and cost function value. Besides testing the quality of the output\nallocation scheme, we examine the generalization property of the network by\nincreasing the time steps and the number of users. We also feed the solution to\nexisting integer optimization solvers as initial conditions and verify the\nwarm-starts can accelerate the short-time iteration process. The framework is\ngeneral with solid performance, and the decoupled feature of the random neural\nnetworks is adequate for practical implementations.\n","authors":["Bin Du","He Zhang","Xiangle Cheng","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.05170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05162v1","updated":"2023-07-11T10:38:58Z","published":"2023-07-11T10:38:58Z","title":"SuryaKiran at MEDIQA-Sum 2023: Leveraging LoRA for Clinical Dialogue\n  Summarization","summary":"  Finetuning Large Language Models helps improve the results for\ndomain-specific use cases. End-to-end finetuning of large language models is\ntime and resource intensive and has high storage requirements to store the\nfinetuned version of the large language model. Parameter Efficient Fine Tuning\n(PEFT) methods address the time and resource challenges by keeping the large\nlanguage model as a fixed base and add additional layers, which the PEFT\nmethods finetune. This paper demonstrates the evaluation results for one such\nPEFT method Low Rank Adaptation (LoRA), for Clinical Dialogue Summarization.\nThe evaluation results show that LoRA works at par with end-to-end finetuning\nfor a large language model. The paper presents the evaluations done for solving\nboth the Subtask A and B from ImageCLEFmedical\n{https://www.imageclef.org/2023/medical}\n","authors":["Kunal Suri","Prakhar Mishra","Saumajit Saha","Atul Singh"],"pdf_url":"https://arxiv.org/pdf/2307.05162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05161v1","updated":"2023-07-11T10:37:57Z","published":"2023-07-11T10:37:57Z","title":"On the Effectiveness of Speech Self-supervised Learning for Music","summary":"  Self-supervised learning (SSL) has shown promising results in various speech\nand natural language processing applications. However, its efficacy in music\ninformation retrieval (MIR) still remains largely unexplored. While previous\nSSL models pre-trained on music recordings may have been mostly closed-sourced,\nrecent speech models such as wav2vec2.0 have shown promise in music modelling.\nNevertheless, research exploring the effectiveness of applying speech SSL\nmodels to music recordings has been limited. We explore the music adaption of\nSSL with two distinctive speech-related models, data2vec1.0 and Hubert, and\nrefer to them as music2vec and musicHuBERT, respectively. We train $12$ SSL\nmodels with 95M parameters under various pre-training configurations and\nsystematically evaluate the MIR task performances with 13 different MIR tasks.\nOur findings suggest that training with music data can generally improve\nperformance on MIR tasks, even when models are trained using paradigms designed\nfor speech. However, we identify the limitations of such existing\nspeech-oriented designs, especially in modelling polyphonic information. Based\non the experimental results, empirical suggestions are also given for designing\nfuture musical SSL strategies and paradigms.\n","authors":["Yinghao Ma","Ruibin Yuan","Yizhi Li","Ge Zhang","Xingran Chen","Hanzhi Yin","Chenghua Lin","Emmanouil Benetos","Anton Ragni","Norbert Gyenge","Ruibo Liu","Gus Xia","Roger Dannenberg","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2307.05161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05156v1","updated":"2023-07-11T10:26:05Z","published":"2023-07-11T10:26:05Z","title":"Stable Normative Explanations: From Argumentation to Deontic Logic","summary":"  This paper examines how a notion of stable explanation developed elsewhere in\nDefeasible Logic can be expressed in the context of formal argumentation. With\nthis done, we discuss the deontic meaning of this reconstruction and show how\nto build from argumentation neighborhood structures for deontic logic where\nthis notion of explanation can be characterised. Some direct complexity results\nare offered.\n","authors":["Cecilia Di Florio","Guido Governatori","Antonino Rotolo","Giovanni Sartor"],"pdf_url":"https://arxiv.org/pdf/2307.05156v1.pdf","comment":"15 pages, extended version of the short paper accepted at JELIA 2023"},{"id":"http://arxiv.org/abs/2307.05150v1","updated":"2023-07-11T10:13:25Z","published":"2023-07-11T10:13:25Z","title":"A Modal Logic for Explaining some Graph Neural Networks","summary":"  In this paper, we propose a modal logic in which counting modalities appear\nin linear inequalities. We show that each formula can be transformed into an\nequivalent graph neural network (GNN). We also show that each GNN can be\ntransformed into a formula. We show that the satisfiability problem is\ndecidable. We also discuss some variants that are in PSPACE.\n","authors":["Pierre Nunn","François Schwarzentruber"],"pdf_url":"https://arxiv.org/pdf/2307.05150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05134v1","updated":"2023-07-11T09:23:05Z","published":"2023-07-11T09:23:05Z","title":"TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation","summary":"  The progress in the generation of synthetic images has made it crucial to\nassess their quality. While several metrics have been proposed to assess the\nrendering of images, it is crucial for Text-to-Image (T2I) models, which\ngenerate images based on a prompt, to consider additional aspects such as to\nwhich extent the generated image matches the important content of the prompt.\nMoreover, although the generated images usually result from a random starting\npoint, the influence of this one is generally not considered. In this article,\nwe propose a new metric based on prompt templates to study the alignment\nbetween the content specified in the prompt and the corresponding generated\nimages. It allows us to better characterize the alignment in terms of the type\nof the specified objects, their number, and their color. We conducted a study\non several recent T2I models about various aspects. An additional interesting\nresult we obtained with our approach is that image quality can vary drastically\ndepending on the latent noise used as a seed for the images. We also quantify\nthe influence of the number of concepts in the prompt, their order as well as\ntheir (color) attributes. Finally, our method allows us to identify some latent\nseeds that produce better images than others, opening novel directions of\nresearch on this understudied topic.\n","authors":["Paul Grimal","Hervé Le Borgne","Olivier Ferret","Julien Tourille"],"pdf_url":"https://arxiv.org/pdf/2307.05134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05104v1","updated":"2023-07-11T08:26:08Z","published":"2023-07-11T08:26:08Z","title":"A Deep Dive into Perturbations as Evaluation Technique for Time Series\n  XAI","summary":"  Explainable Artificial Intelligence (XAI) has gained significant attention\nrecently as the demand for transparency and interpretability of machine\nlearning models has increased. In particular, XAI for time series data has\nbecome increasingly important in finance, healthcare, and climate science.\nHowever, evaluating the quality of explanations, such as attributions provided\nby XAI techniques, remains challenging. This paper provides an in-depth\nanalysis of using perturbations to evaluate attributions extracted from time\nseries models. A perturbation analysis involves systematically modifying the\ninput data and evaluating the impact on the attributions generated by the XAI\nmethod. We apply this approach to several state-of-the-art XAI techniques and\nevaluate their performance on three time series classification datasets. Our\nresults demonstrate that the perturbation analysis approach can effectively\nevaluate the quality of attributions and provide insights into the strengths\nand limitations of XAI techniques. Such an approach can guide the selection of\nXAI methods for time series data, e.g., focusing on return time rather than\nprecision, and facilitate the development of more reliable and interpretable\nmachine learning models for time series analysis.\n","authors":["Udo Schlegel","Daniel A. Keim"],"pdf_url":"https://arxiv.org/pdf/2307.05104v1.pdf","comment":"16 pages, 2 pages references, 5 figures, 3 tables, submitted and\n  accepted at xAI 2023"},{"id":"http://arxiv.org/abs/2307.05095v1","updated":"2023-07-11T08:07:10Z","published":"2023-07-11T08:07:10Z","title":"ATWM: Defense against adversarial malware based on adversarial training","summary":"  Deep learning technology has made great achievements in the field of image.\nIn order to defend against malware attacks, researchers have proposed many\nWindows malware detection models based on deep learning. However, deep learning\nmodels are vulnerable to adversarial example attacks. Malware can generate\nadversarial malware with the same malicious function to attack the malware\ndetection model and evade detection of the model. Currently, many adversarial\ndefense studies have been proposed, but existing adversarial defense studies\nare based on image sample and cannot be directly applied to malware sample.\nTherefore, this paper proposes an adversarial malware defense method based on\nadversarial training. This method uses preprocessing to defend simple\nadversarial examples to reduce the difficulty of adversarial training.\nMoreover, this method improves the adversarial defense capability of the model\nthrough adversarial training. We experimented with three attack methods in two\nsets of datasets, and the results show that the method in this paper can\nimprove the adversarial defense capability of the model without reducing the\naccuracy of the model.\n","authors":["Kun Li","Fan Zhang","Wei Guo"],"pdf_url":"https://arxiv.org/pdf/2307.05095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05082v1","updated":"2023-07-11T07:31:58Z","published":"2023-07-11T07:31:58Z","title":"OntoChatGPT Information System: Ontology-Driven Structured Prompts for\n  ChatGPT Meta-Learning","summary":"  This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.\n","authors":["Oleksandr Palagin","Vladislav Kaverinskiy","Anna Litvin","Kyrylo Malakhov"],"pdf_url":"https://arxiv.org/pdf/2307.05082v1.pdf","comment":"14 pages, 1 figure. Published. International Journal of Computing,\n  22(2), 170-183. https://doi.org/10.47839/ijc.22.2.3086"},{"id":"http://arxiv.org/abs/2307.05075v1","updated":"2023-07-11T07:18:15Z","published":"2023-07-11T07:18:15Z","title":"Uni-Removal: A Semi-Supervised Framework for Simultaneously Addressing\n  Multiple Degradations in Real-World Images","summary":"  Removing multiple degradations, such as haze, rain, and blur, from real-world\nimages poses a challenging and illposed problem. Recently, unified models that\ncan handle different degradations have been proposed and yield promising\nresults. However, these approaches focus on synthetic images and experience a\nsignificant performance drop when applied to realworld images. In this paper,\nwe introduce Uni-Removal, a twostage semi-supervised framework for addressing\nthe removal of multiple degradations in real-world images using a unified model\nand parameters. In the knowledge transfer stage, Uni-Removal leverages a\nsupervised multi-teacher and student architecture in the knowledge transfer\nstage to facilitate learning from pretrained teacher networks specialized in\ndifferent degradation types. A multi-grained contrastive loss is introduced to\nenhance learning from feature and image spaces. In the domain adaptation stage,\nunsupervised fine-tuning is performed by incorporating an adversarial\ndiscriminator on real-world images. The integration of an extended\nmulti-grained contrastive loss and generative adversarial loss enables the\nadaptation of the student network from synthetic to real-world domains.\nExtensive experiments on real-world degraded datasets demonstrate the\neffectiveness of our proposed method. We compare our Uni-Removal framework with\nstate-of-the-art supervised and unsupervised methods, showcasing its promising\nresults in real-world image dehazing, deraining, and deblurring simultaneously.\n","authors":["Yongheng Zhang","Danfeng Yan","Yuanqiang Cai"],"pdf_url":"https://arxiv.org/pdf/2307.05075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05074v1","updated":"2023-07-11T07:16:22Z","published":"2023-07-11T07:16:22Z","title":"Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with\n  Sample-aware Prompting and Dynamic Revision Chain","summary":"  Text-to-SQL aims at generating SQL queries for the given natural language\nquestions and thus helping users to query databases. Prompt learning with large\nlanguage models (LLMs) has emerged as a recent approach, which designs prompts\nto lead LLMs to understand the input question and generate the corresponding\nSQL. However, it faces challenges with strict SQL syntax requirements. Existing\nwork prompts the LLMs with a list of demonstration examples (i.e. question-SQL\npairs) to generate SQL, but the fixed prompts can hardly handle the scenario\nwhere the semantic gap between the retrieved demonstration and the input\nquestion is large. In this paper, we propose a retrieval-augmented prompting\nmethod for a LLM-based Text-to-SQL framework, involving sample-aware prompting\nand a dynamic revision chain. Our approach incorporates sample-aware\ndemonstrations, which include the composition of SQL operators and fine-grained\ninformation related to the given question. To retrieve questions sharing\nsimilar intents with input questions, we propose two strategies for assisting\nretrieval. Firstly, we leverage LLMs to simplify the original questions,\nunifying the syntax and thereby clarifying the users' intentions. To generate\nexecutable and accurate SQLs without human intervention, we design a dynamic\nrevision chain which iteratively adapts fine-grained feedback from the\npreviously generated SQL. Experimental results on three Text-to-SQL benchmarks\ndemonstrate the superiority of our method over strong baseline models.\n","authors":["Chunxi Guo","Zhiliang Tian","Jintao Tang","Shasha Li","Zhihua Wen","Kaixuan Wang","Ting Wang"],"pdf_url":"https://arxiv.org/pdf/2307.05074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05072v1","updated":"2023-07-11T07:15:11Z","published":"2023-07-11T07:15:11Z","title":"Aggregating Credences into Beliefs: Agenda Conditions for Impossibility\n  Results","summary":"  Binarizing belief aggregation addresses how to rationally aggregate\nindividual probabilistic beliefs into collective binary beliefs. Similar to the\ndevelopment of judgment aggregation theory, formulating axiomatic requirements,\nproving impossibility theorems, and identifying exact agenda conditions of\nimpossibility theorems are natural and important research topics in binarizing\nbelief aggregation. Building on our previous research on impossibility\ntheorems, we use an agenda-theoretic approach to generalize the results and to\ndetermine the necessary and sufficient level of logical interconnection between\nthe issues in an agenda for the impossibility theorems to arise. We demonstrate\nthat (1) path-connectedness and even-negatability constitute the exact agenda\ncondition for the oligarchy result stating that binarizing belief aggregation\nsatisfying proposition-wise independence and deductive closure of collective\nbeliefs yields the oligarchies under minor conditions; (2)\nnegation-connectedness is the condition for the triviality result obtained by\nadding anonymity to the oligarchy result; and (3) blockedness is the condition\nfor the impossibility result, which follows by adding completeness and\nconsistency of collective beliefs. Moreover, we compare these novel findings\nwith existing agenda-theoretic characterization theorems in judgment\naggregation and belief binarization.\n","authors":["Minkyung Wang","Chisu Kim"],"pdf_url":"https://arxiv.org/pdf/2307.05072v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05071v1","updated":"2023-07-11T07:14:53Z","published":"2023-07-11T07:14:53Z","title":"Mining for Unknown Unknowns","summary":"  Unknown unknowns are future relevant contingencies that lack an ex ante\ndescription. While there are numerous retrospective accounts showing that\nsignificant gains or losses might have been achieved or avoided had such\ncontingencies been previously uncovered, getting hold of unknown unknowns still\nremains elusive, both in practice and conceptually. Using Formal Concept\nAnalysis (FCA) - a subfield of lattice theory which is increasingly applied for\nmining and organizing data - this paper introduces a simple framework to\nsystematically think out of the box and direct the search for unknown unknowns.\n","authors":["Bernard Sinclair-Desgagné"],"pdf_url":"https://arxiv.org/pdf/2307.05071v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05069v1","updated":"2023-07-11T07:13:52Z","published":"2023-07-11T07:13:52Z","title":"Cognitive Bias and Belief Revision","summary":"  In this paper we formalise three types of cognitive bias within the framework\nof belief revision: confirmation bias, framing bias, and anchoring bias. We\ninterpret them generally, as restrictions on the process of iterated revision,\nand we apply them to three well-known belief revision methods: conditioning,\nlexicographic revision, and minimal revision. We investigate the reliability of\nbiased belief revision methods in truth tracking. We also run computer\nsimulations to assess the performance of biased belief revision in random\nscenarios.\n","authors":["Panagiotis Papadamos","Nina Gierasimczuk"],"pdf_url":"https://arxiv.org/pdf/2307.05069v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05068v1","updated":"2023-07-11T07:13:29Z","published":"2023-07-11T07:13:29Z","title":"A Theory of Bounded Inductive Rationality","summary":"  The dominant theories of rational choice assume logical omniscience. That is,\nthey assume that when facing a decision problem, an agent can perform all\nrelevant computations and determine the truth value of all relevant\nlogical/mathematical claims. This assumption is unrealistic when, for example,\nwe offer bets on remote digits of pi or when an agent faces a computationally\nintractable planning problem. Furthermore, the assumption of logical\nomniscience creates contradictions in cases where the environment can contain\ndescriptions of the agent itself. Importantly, strategic interactions as\nstudied in game theory are decision problems in which a rational agent is\npredicted by its environment (the other players). In this paper, we develop a\ntheory of rational decision making that does not assume logical omniscience. We\nconsider agents who repeatedly face decision problems (including ones like\nbetting on digits of pi or games against other agents). The main contribution\nof this paper is to provide a sensible theory of rationality for such agents.\nRoughly, we require that a boundedly rational inductive agent tests each\nefficiently computable hypothesis infinitely often and follows those hypotheses\nthat keep their promises of high rewards. We then prove that agents that are\nrational in this sense have other desirable properties. For example, they learn\nto value random and pseudo-random lotteries at their expected reward. Finally,\nwe consider strategic interactions between different agents and prove a folk\ntheorem for what strategies bounded rational inductive agents can converge to.\n","authors":["Caspar Oesterheld","Abram Demski","Vincent Conitzer"],"pdf_url":"https://arxiv.org/pdf/2307.05068v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05067v1","updated":"2023-07-11T07:13:09Z","published":"2023-07-11T07:13:09Z","title":"Exploiting Asymmetry in Logic Puzzles: Using ZDDs for Symbolic Model\n  Checking Dynamic Epistemic Logic","summary":"  Binary decision diagrams (BDDs) are widely used to mitigate the\nstate-explosion problem in model checking. A variation of BDDs are\nZero-suppressed Decision Diagrams (ZDDs) which omit variables that must be\nfalse, instead of omitting variables that do not matter. We use ZDDs to\nsymbolically encode Kripke models used in Dynamic Epistemic Logic, a framework\nto reason about knowledge and information dynamics in multi-agent systems. We\ncompare the memory usage of different ZDD variants for three well-known\nexamples from the literature: the Muddy Children, the Sum and Product puzzle\nand the Dining Cryptographers. Our implementation is based on the existing\nmodel checker SMCDEL and the CUDD library. Our results show that replacing BDDs\nwith the right variant of ZDDs can significantly reduce memory usage. This\nsuggests that ZDDs are a useful tool for model checking multi-agent systems.\n","authors":["Daniel Miedema","Malvin Gattinger"],"pdf_url":"https://arxiv.org/pdf/2307.05067v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05066v1","updated":"2023-07-11T07:12:51Z","published":"2023-07-11T07:12:51Z","title":"Tableaux for the Logic of Strategically Knowing How","summary":"  The logic of goal-directed knowing-how extends the standard epistemic logic\nwith an operator of knowing-how. The knowing-how operator is interpreted as\nthat there exists a strategy such that the agent knows that the strategy can\nmake sure that p. This paper presents a tableau procedure for the multi-agent\nversion of the logic of strategically knowing-how and shows the soundness and\ncompleteness of this tableau procedure. This paper also shows that the\nsatisfiability problem of the logic can be decided in PSPACE.\n","authors":["Yanjun Li"],"pdf_url":"https://arxiv.org/pdf/2307.05066v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05062v1","updated":"2023-07-11T07:10:39Z","published":"2023-07-11T07:10:39Z","title":"System of Spheres-based Two Level Credibility-limited Revisions","summary":"  Two level credibility-limited revision is a non-prioritized revision\noperation. When revising by a two level credibility-limited revision, two\nlevels of credibility and one level of incredibility are considered. When\nrevising by a sentence at the highest level of credibility, the operator\nbehaves as a standard revision, if the sentence is at the second level of\ncredibility, then the outcome of the revision process coincides with a standard\ncontraction by the negation of that sentence. If the sentence is not credible,\nthen the original belief set remains unchanged. In this paper, we propose a\nconstruction for two level credibility-limited revision operators based on\nGrove's systems of spheres and present an axiomatic characterization for these\noperators.\n","authors":["Marco Garapa","Eduardo Ferme","Maurício D. L. Reis"],"pdf_url":"https://arxiv.org/pdf/2307.05062v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2303.07185v2","updated":"2023-07-11T07:09:07Z","published":"2023-03-13T15:28:17Z","title":"Joint Behavior and Common Belief","summary":"  For over 25 years, common belief has been widely viewed as necessary for\njoint behavior. But this is not quite correct. We show by example that what can\nnaturally be thought of as joint behavior can occur without common belief. We\nthen present two variants of common belief that can lead to joint behavior,\neven without standard common belief ever being achieved, and show that one of\nthem, action-stamped common belief, is in a sense necessary and sufficient for\njoint behavior. These observations are significant because, as is well known,\ncommon belief is quite difficult to achieve in practice, whereas these variants\nare more easily achievable.\n","authors":["Meir Friedenberg","Joseph Y. Halpern"],"pdf_url":"https://arxiv.org/pdf/2303.07185v2.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05059v1","updated":"2023-07-11T07:08:34Z","published":"2023-07-11T07:08:34Z","title":"On Imperfect Recall in Multi-Agent Influence Diagrams","summary":"  Multi-agent influence diagrams (MAIDs) are a popular game-theoretic model\nbased on Bayesian networks. In some settings, MAIDs offer significant\nadvantages over extensive-form game representations. Previous work on MAIDs has\nassumed that agents employ behavioural policies, which set independent\nconditional probability distributions over actions for each of their decisions.\nIn settings with imperfect recall, however, a Nash equilibrium in behavioural\npolicies may not exist. We overcome this by showing how to solve MAIDs with\nforgetful and absent-minded agents using mixed policies and two types of\ncorrelated equilibrium. We also analyse the computational complexity of key\ndecision problems in MAIDs, and explore tractable cases. Finally, we describe\napplications of MAIDs to Markov games and team situations, where imperfect\nrecall is often unavoidable.\n","authors":["James Fox","Matt MacDermott","Lewis Hammond","Paul Harrenstein","Alessandro Abate","Michael Wooldridge"],"pdf_url":"https://arxiv.org/pdf/2307.05059v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05053v1","updated":"2023-07-11T07:05:37Z","published":"2023-07-11T07:05:37Z","title":"Strengthening Consistency Results in Modal Logic","summary":"  A fundamental question asked in modal logic is whether a given theory is\nconsistent. But consistent with what? A typical way to address this question\nidentifies a choice of background knowledge axioms (say, S4, D, etc.) and then\nshows the assumptions codified by the theory in question to be consistent with\nthose background axioms. But determining the specific choice and division of\nbackground axioms is, at least sometimes, little more than tradition. This\npaper introduces **generic theories** for propositional modal logic to address\nconsistency results in a more robust way. As building blocks for background\nknowledge, generic theories provide a standard for categorical determinations\nof consistency. We argue that the results and methods of this paper help to\nelucidate problems in epistemology and enjoy sufficient scope and power to have\npurchase on problems bearing on modalities in judgement, inference, and\ndecision making.\n","authors":["Samuel Allen Alexander","Arthur Paul Pedersen"],"pdf_url":"https://arxiv.org/pdf/2307.05053v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005. The authors thank three\n  anonymous reviewers as well as Rineke Verbrugge for valuable comments and\n  suggestions to help improve this manuscript. The authors also extend their\n  gratitude to Alessandro Aldini, Michael Grossberg, Ali Kahn, Rohit Parikh,\n  and Max Stinchcombe, for their generous feedback on prior drafts of this\n  manuscript"},{"id":"http://arxiv.org/abs/2307.05052v1","updated":"2023-07-11T07:03:29Z","published":"2023-07-11T07:03:29Z","title":"Towards Understanding In-Context Learning with Contrastive\n  Demonstrations and Saliency Maps","summary":"  We investigate the role of various demonstration components in the in-context\nlearning (ICL) performance of large language models (LLMs). Specifically, we\nexplore the impacts of ground-truth labels, input distribution, and\ncomplementary explanations, particularly when these are altered or perturbed.\nWe build on previous work, which offers mixed findings on how these elements\ninfluence ICL. To probe these questions, we employ explainable NLP (XNLP)\nmethods and utilize saliency maps of contrastive demonstrations for both\nqualitative and quantitative analysis. Our findings reveal that flipping\nground-truth labels significantly affects the saliency, though it's more\nnoticeable in larger LLMs. Our analysis of the input distribution at a granular\nlevel reveals that changing sentiment-indicative terms in a sentiment analysis\ntask to neutral ones does not have as substantial an impact as altering\nground-truth labels. Finally, we find that the effectiveness of complementary\nexplanations in boosting ICL performance is task-dependent, with limited\nbenefits seen in sentiment analysis tasks compared to symbolic reasoning tasks.\nThese insights are critical for understanding the functionality of LLMs and\nguiding the development of effective demonstrations, which is increasingly\nrelevant in light of the growing use of LLMs in applications such as ChatGPT.\nOur research code is publicly available at https://github.com/paihengxu/XICL.\n","authors":["Zongxia Li","Paiheng Xu","Fuxiao Liu","Hyemi Song"],"pdf_url":"https://arxiv.org/pdf/2307.05052v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2307.05043v1","updated":"2023-07-11T06:50:49Z","published":"2023-07-11T06:50:49Z","title":"Epistemic Syllogistic: First Steps","summary":"  Aristotle's discussions on modal syllogistic have often been viewed as\nerror-prone and have garnered significant attention in the literature due to\nhistorical and philosophical interests. However, from a contemporary\nstandpoint, they also introduced natural fragments of first-order modal logic,\nwarranting a comprehensive technical analysis. In this paper, drawing\ninspiration from the natural logic program, we propose and examine several\nvariants of modal syllogistic within the epistemic context, thereby coining the\nterm Epistemic Syllogistic. Specifically, we concentrate on the de re\ninterpretation of epistemic syllogisms containing non-trivial yet natural\nexpressions such as \"all things known to be A are also known to be not B.\" We\nexplore the epistemic apodeictic syllogistic and its extensions, which\naccommodate more complex terms. Our main contributions include several\naxiomatizations of these logics, with completeness proofs that may be of\nindependent interest.\n","authors":["Yipu Li","Yanjing Wang"],"pdf_url":"https://arxiv.org/pdf/2307.05043v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05036v1","updated":"2023-07-11T06:29:31Z","published":"2023-07-11T06:29:31Z","title":"Neural-Symbolic Recommendation with Graph-Enhanced Information","summary":"  The recommendation system is not only a problem of inductive statistics from\ndata but also a cognitive task that requires reasoning ability. The most\nadvanced graph neural networks have been widely used in recommendation systems\nbecause they can capture implicit structured information from graph-structured\ndata. However, like most neural network algorithms, they only learn matching\npatterns from a perception perspective. Some researchers use user behavior for\nlogic reasoning to achieve recommendation prediction from the perspective of\ncognitive reasoning, but this kind of reasoning is a local one and ignores\nimplicit information on a global scale. In this work, we combine the advantages\nof graph neural networks and propositional logic operations to construct a\nneuro-symbolic recommendation model with both global implicit reasoning ability\nand local explicit logic reasoning ability. We first build an item-item graph\nbased on the principle of adjacent interaction and use graph neural networks to\ncapture implicit information in global data. Then we transform user behavior\ninto propositional logic expressions to achieve recommendations from the\nperspective of cognitive reasoning. Extensive experiments on five public\ndatasets show that our proposed model outperforms several state-of-the-art\nmethods, source code is avaliable at [https://github.com/hanzo2020/GNNLR].\n","authors":["Bang Chen","Wei Peng","Maonian Wu","Bo Zheng","Shaojun Zhu"],"pdf_url":"https://arxiv.org/pdf/2307.05036v1.pdf","comment":"12 pages, 2 figures, conference"},{"id":"http://arxiv.org/abs/2307.05025v1","updated":"2023-07-11T05:58:20Z","published":"2023-07-11T05:58:20Z","title":"Unleashing the Potential of Regularization Strategies in Learning with\n  Noisy Labels","summary":"  In recent years, research on learning with noisy labels has focused on\ndevising novel algorithms that can achieve robustness to noisy training labels\nwhile generalizing to clean data. These algorithms often incorporate\nsophisticated techniques, such as noise modeling, label correction, and\nco-training. In this study, we demonstrate that a simple baseline using\ncross-entropy loss, combined with widely used regularization strategies like\nlearning rate decay, model weights average, and data augmentations, can\noutperform state-of-the-art methods. Our findings suggest that employing a\ncombination of regularization strategies can be more effective than intricate\nalgorithms in tackling the challenges of learning with noisy labels. While some\nof these regularization strategies have been utilized in previous noisy label\nlearning research, their full potential has not been thoroughly explored. Our\nresults encourage a reevaluation of benchmarks for learning with noisy labels\nand prompt reconsideration of the role of specialized learning algorithms\ndesigned for training with noisy labels.\n","authors":["Hui Kang","Sheng Liu","Huaxi Huang","Jun Yu","Bo Han","Dadong Wang","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2307.05025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05017v1","updated":"2023-07-11T05:33:46Z","published":"2023-07-11T05:33:46Z","title":"Feature Activation Map: Visual Explanation of Deep Learning Models for\n  Image Classification","summary":"  Decisions made by convolutional neural networks(CNN) can be understood and\nexplained by visualizing discriminative regions on images. To this end, Class\nActivation Map (CAM) based methods were proposed as powerful interpretation\ntools, making the prediction of deep learning models more explainable,\ntransparent, and trustworthy. However, all the CAM-based methods (e.g., CAM,\nGrad-CAM, and Relevance-CAM) can only be used for interpreting CNN models with\nfully-connected (FC) layers as a classifier. It is worth noting that many deep\nlearning models classify images without FC layers, e.g., few-shot learning\nimage classification, contrastive learning image classification, and image\nretrieval tasks. In this work, a post-hoc interpretation tool named feature\nactivation map (FAM) is proposed, which can interpret deep learning models\nwithout FC layers as a classifier. In the proposed FAM algorithm, the\nchannel-wise contribution weights are derived from the similarity scores\nbetween two image embeddings. The activation maps are linearly combined with\nthe corresponding normalized contribution weights, forming the explanation map\nfor visualization. The quantitative and qualitative experiments conducted on\nten deep learning models for few-shot image classification, contrastive\nlearning image classification and image retrieval tasks demonstrate the\neffectiveness of the proposed FAM algorithm.\n","authors":["Yi Liao","Yongsheng Gao","Weichuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.05017v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2307.05004v1","updated":"2023-07-11T03:53:46Z","published":"2023-07-11T03:53:46Z","title":"Control as Probabilistic Inference as an Emergent Communication\n  Mechanism in Multi-Agent Reinforcement Learning","summary":"  This paper proposes a generative probabilistic model integrating emergent\ncommunication and multi-agent reinforcement learning. The agents plan their\nactions by probabilistic inference, called control as inference, and\ncommunicate using messages that are latent variables and estimated based on the\nplanned actions. Through these messages, each agent can send information about\nits actions and know information about the actions of another agent. Therefore,\nthe agents change their actions according to the estimated messages to achieve\ncooperative tasks. This inference of messages can be considered as\ncommunication, and this procedure can be formulated by the Metropolis-Hasting\nnaming game. Through experiments in the grid world environment, we show that\nthe proposed PGM can infer meaningful messages to achieve the cooperative task.\n","authors":["Tomoaki Nakamura","Akira Taniguchi","Tadahiro Taniguchi"],"pdf_url":"https://arxiv.org/pdf/2307.05004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04998v1","updated":"2023-07-11T03:32:20Z","published":"2023-07-11T03:32:20Z","title":"Selective Sampling and Imitation Learning via Online Regression","summary":"  We consider the problem of Imitation Learning (IL) by actively querying noisy\nexpert for feedback. While imitation learning has been empirically successful,\nmuch of prior work assumes access to noiseless expert feedback which is not\npractical in many applications. In fact, when one only has access to noisy\nexpert feedback, algorithms that rely on purely offline data (non-interactive\nIL) can be shown to need a prohibitively large number of samples to be\nsuccessful. In contrast, in this work, we provide an interactive algorithm for\nIL that uses selective sampling to actively query the noisy expert for\nfeedback. Our contributions are twofold: First, we provide a new selective\nsampling algorithm that works with general function classes and multiple\nactions, and obtains the best-known bounds for the regret and the number of\nqueries. Next, we extend this analysis to the problem of IL with noisy expert\nfeedback and provide a new IL algorithm that makes limited queries.\n  Our algorithm for selective sampling leverages function approximation, and\nrelies on an online regression oracle w.r.t.~the given model class to predict\nactions, and to decide whether to query the expert for its label. On the\ntheoretical side, the regret bound of our algorithm is upper bounded by the\nregret of the online regression oracle, while the query complexity additionally\ndepends on the eluder dimension of the model class. We complement this with a\nlower bound that demonstrates that our results are tight. We extend our\nselective sampling algorithm for IL with general function approximation and\nprovide bounds on both the regret and the number of queries made to the noisy\nexpert. A key novelty here is that our regret and query complexity bounds only\ndepend on the number of times the optimal policy (and not the noisy expert, or\nthe learner) go to states that have a small margin.\n","authors":["Ayush Sekhari","Karthik Sridharan","Wen Sun","Runzhe Wu"],"pdf_url":"https://arxiv.org/pdf/2307.04998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.09523v2","updated":"2023-07-11T03:26:54Z","published":"2022-01-24T08:34:41Z","title":"BTPK-based interpretable method for NER tasks based on Talmudic Public\n  Announcement Logic","summary":"  As one of the basic tasks in natural language processing (NLP), named entity\nrecognition (NER) is an important basic tool for downstream tasks of NLP, such\nas information extraction, syntactic analysis, machine translation and so on.\nThe internal operation logic of current name entity recognition model is\nblack-box to the user, so the user has no basis to determine which name entity\nmakes more sense. Therefore, a user-friendly explainable recognition process\nwould be very useful for many people. In this paper, we propose a novel\ninterpretable method, BTPK (Binary Talmudic Public Announcement Logic model),\nto help users understand the internal recognition logic of the name entity\nrecognition tasks based on Talmudic Public Announcement Logic. BTPK model can\nalso capture the semantic information in the input sentences, that is, the\ncontext dependency of the sentence. We observed the public announcement of BTPK\npresents the inner decision logic of BRNNs, and the explanations obtained from\na BTPK model show us how BRNNs essentially handle NER tasks.\n","authors":["Yulin Chen","Beishui Liao","Bruno Bentzen","Bo Yuan","Zelai Yao","Haixiao Chi","Dov Gabbay"],"pdf_url":"https://arxiv.org/pdf/2201.09523v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2307.04996v1","updated":"2023-07-11T03:24:54Z","published":"2023-07-11T03:24:54Z","title":"Empowering recommender systems using automatically generated Knowledge\n  Graphs and Reinforcement Learning","summary":"  Personalized recommendations have a growing importance in direct marketing,\nwhich motivates research to enhance customer experiences by knowledge graph\n(KG) applications. For example, in financial services, companies may benefit\nfrom providing relevant financial articles to their customers to cultivate\nrelationships, foster client engagement and promote informed financial\ndecisions. While several approaches center on KG-based recommender systems for\nimproved content, in this study we focus on interpretable KG-based recommender\nsystems for decision making.To this end, we present two knowledge graph-based\napproaches for personalized article recommendations for a set of customers of a\nlarge multinational financial services company. The first approach employs\nReinforcement Learning and the second approach uses the XGBoost algorithm for\nrecommending articles to the customers. Both approaches make use of a KG\ngenerated from both structured (tabular data) and unstructured data (a large\nbody of text data).Using the Reinforcement Learning-based recommender system we\ncould leverage the graph traversal path leading to the recommendation as a way\nto generate interpretations (Path Directed Reasoning (PDR)). In the\nXGBoost-based approach, one can also provide explainable results using post-hoc\nmethods such as SHAP (SHapley Additive exPlanations) and ELI5 (Explain Like I\nam Five).Importantly, our approach offers explainable results, promoting better\ndecision-making. This study underscores the potential of combining advanced\nmachine learning techniques with KG-driven insights to bolster experience in\ncustomer relationship management.\n","authors":["Ghanshyam Verma","Shovon Sengupta","Simon Simanta","Huan Chen","Janos A. Perge","Devishree Pillai","John P. McCrae","Paul Buitelaar"],"pdf_url":"https://arxiv.org/pdf/2307.04996v1.pdf","comment":"Accepted at KDD (OARS) 2023 [https://oars-workshop.github.io/]"},{"id":"http://arxiv.org/abs/2307.04990v1","updated":"2023-07-11T03:02:44Z","published":"2023-07-11T03:02:44Z","title":"Monotone deep Boltzmann machines","summary":"  Deep Boltzmann machines (DBMs), one of the first ``deep'' learning methods\never studied, are multi-layered probabilistic models governed by a pairwise\nenergy function that describes the likelihood of all variables/nodes in the\nnetwork. In practice, DBMs are often constrained, i.e., via the\n\\emph{restricted} Boltzmann machine (RBM) architecture (which does not permit\nintra-layer connections), in order to allow for more efficient inference. In\nthis work, we revisit the generic DBM approach, and ask the question: are there\nother possible restrictions to their design that would enable efficient\n(approximate) inference? In particular, we develop a new class of restricted\nmodel, the monotone DBM, which allows for arbitrary self-connection in each\nlayer, but restricts the \\emph{weights} in a manner that guarantees the\nexistence and global uniqueness of a mean-field fixed point. To do this, we\nleverage tools from the recently-proposed monotone Deep Equilibrium model and\nshow that a particular choice of activation results in a fixed-point iteration\nthat gives a variational mean-field solution. While this approach is still\nlargely conceptual, it is the first architecture that allows for efficient\napproximate inference in fully-general weight structures for DBMs. We apply\nthis approach to simple deep convolutional Boltzmann architectures and\ndemonstrate that it allows for tasks such as the joint completion and\nclassification of images, within a single deep probabilistic setting, while\navoiding the pitfalls of mean-field inference in traditional RBMs.\n","authors":["Zhili Feng","Ezra Winston","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2307.04990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04986v1","updated":"2023-07-11T02:52:32Z","published":"2023-07-11T02:52:32Z","title":"Epidemic Modeling with Generative Agents","summary":"  This study offers a new paradigm of individual-level modeling to address the\ngrand challenge of incorporating human behavior in epidemic models. Using\ngenerative artificial intelligence in an agent-based epidemic model, each agent\nis empowered to make its own reasonings and decisions via connecting to a large\nlanguage model such as ChatGPT. Through various simulation experiments, we\npresent compelling evidence that generative agents mimic real-world behaviors\nsuch as quarantining when sick and self-isolation when cases rise.\nCollectively, the agents demonstrate patterns akin to multiple waves observed\nin recent pandemics followed by an endemic period. Moreover, the agents\nsuccessfully flatten the epidemic curve. This study creates potential to\nimprove dynamic system modeling by offering a way to represent human brain,\nreasoning, and decision making.\n","authors":["Ross Williams","Niyousha Hosseinichimeh","Aritra Majumdar","Navid Ghaffarzadegan"],"pdf_url":"https://arxiv.org/pdf/2307.04986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.08933v2","updated":"2023-07-11T02:04:36Z","published":"2021-12-15T04:22:56Z","title":"Responsive parallelized architecture for deploying deep learning models\n  in production environments","summary":"  Recruiters can easily shortlist candidates for jobs via viewing their\ncurriculum vitae (CV) document. Unstructured document CV beholds candidate's\nportfolio and named entities listing details. The main aim of this study is to\ndesign and propose a web oriented, highly responsive, computational pipeline\nthat systematically predicts CV entities using hierarchically-refined label\nattention networks. Deep learning models specialized for named entity\nrecognition were trained on large dataset to predict relevant fields. The\narticle suggests an optimal strategy to use a number of deep learning models in\nparallel and predict in real time. We demonstrate selection of light weight\nmicro web framework using Analytical Hierarchy Processing algorithm and focus\non an approach useful to deploy large deep learning model-based pipelines in\nproduction ready environments using microservices. Deployed models and\narchitecture proposed helped in parsing normal CV in less than 700 milliseconds\nfor sequential flow of requests.\n","authors":["Nikhil Verma","Krishna Prasad"],"pdf_url":"https://arxiv.org/pdf/2112.08933v2.pdf","comment":"20 Pages"},{"id":"http://arxiv.org/abs/2307.04964v1","updated":"2023-07-11T01:55:24Z","published":"2023-07-11T01:55:24Z","title":"Secrets of RLHF in Large Language Models Part I: PPO","summary":"  Large language models (LLMs) have formulated a blueprint for the advancement\nof artificial general intelligence. Its primary objective is to function as a\nhuman-centric (helpful, honest, and harmless) assistant. Alignment with humans\nassumes paramount significance, and reinforcement learning with human feedback\n(RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.\nCurrent technical routes usually include \\textbf{reward models} to measure\nhuman preferences, \\textbf{Proximal Policy Optimization} (PPO) to optimize\npolicy model outputs, and \\textbf{process supervision} to improve step-by-step\nreasoning capabilities. However, due to the challenges of reward design,\nenvironment interaction, and agent training, coupled with huge trial and error\ncost of large language models, there is a significant barrier for AI\nresearchers to motivate the development of technical alignment and safe landing\nof LLMs. The stable training of RLHF has still been a puzzle. In the first\nreport, we dissect the framework of RLHF, re-evaluate the inner workings of\nPPO, and explore how the parts comprising PPO algorithms impact policy agent\ntraining. We identify policy constraints being the key factor for the effective\nimplementation of the PPO algorithm. Therefore, we explore the PPO-max, an\nadvanced version of PPO algorithm, to efficiently improve the training\nstability of the policy model. Based on our main results, we perform a\ncomprehensive analysis of RLHF abilities compared with SFT models and ChatGPT.\nThe absence of open-source implementations has posed significant challenges to\nthe investigation of LLMs alignment. Therefore, we are eager to release\ntechnical reports, reward models and PPO codes\n","authors":["Rui Zheng","Shihan Dou","Songyang Gao","Wei Shen","Binghai Wang","Yan Liu","Senjie Jin","Qin Liu","Limao Xiong","Lu Chen","Zhiheng Xi","Yuhao Zhou","Nuo Xu","Wenbin Lai","Minghao Zhu","Rongxiang Weng","Wensen Cheng","Cheng Chang","Zhangyue Yin","Yuan Hua","Haoran Huang","Tianxiang Sun","Hang Yan","Tao Gui","Qi Zhang","Xipeng Qiu","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2307.04964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04962v1","updated":"2023-07-11T01:52:08Z","published":"2023-07-11T01:52:08Z","title":"Intrinsically motivated graph exploration using network theories of\n  human curiosity","summary":"  Intrinsically motivated exploration has proven useful for reinforcement\nlearning, even without additional extrinsic rewards. When the environment is\nnaturally represented as a graph, how to guide exploration best remains an open\nquestion. In this work, we propose a novel approach for exploring\ngraph-structured data motivated by two theories of human curiosity: the\ninformation gap theory and the compression progress theory. The theories view\ncuriosity as an intrinsic motivation to optimize for topological features of\nsubgraphs induced by the visited nodes in the environment. We use these\nproposed features as rewards for graph neural-network-based reinforcement\nlearning. On multiple classes of synthetically generated graphs, we find that\ntrained agents generalize to larger environments and to longer exploratory\nwalks than are seen during training. Our method computes more efficiently than\nthe greedy evaluation of the relevant topological properties. The proposed\nintrinsic motivations bear particular relevance for recommender systems. We\ndemonstrate that curiosity-based recommendations are more predictive of human\nbehavior than PageRank centrality for several real-world graph datasets,\nincluding MovieLens, Amazon Books, and Wikispeedia.\n","authors":["Shubhankar P. Patankar","Mathieu Ouellet","Juan Cervino","Alejandro Ribeiro","Kieran A. Murphy","Dani S. Bassett"],"pdf_url":"https://arxiv.org/pdf/2307.04962v1.pdf","comment":"14 pages, 5 figures in main text, and 15 pages, 8 figures in\n  supplement"},{"id":"http://arxiv.org/abs/2307.04957v1","updated":"2023-07-11T01:20:09Z","published":"2023-07-11T01:20:09Z","title":"Reinforcement Learning with Non-Cumulative Objective","summary":"  In reinforcement learning, the objective is almost always defined as a\n\\emph{cumulative} function over the rewards along the process. However, there\nare many optimal control and reinforcement learning problems in various\napplication fields, especially in communications and networking, where the\nobjectives are not naturally expressed as summations of the rewards. In this\npaper, we recognize the prevalence of non-cumulative objectives in various\nproblems, and propose a modification to existing algorithms for optimizing such\nobjectives. Specifically, we dive into the fundamental building block for many\noptimal control and reinforcement learning algorithms: the Bellman optimality\nequation. To optimize a non-cumulative objective, we replace the original\nsummation operation in the Bellman update rule with a generalized operation\ncorresponding to the objective. Furthermore, we provide sufficient conditions\non the form of the generalized operation as well as assumptions on the Markov\ndecision process under which the globally optimal convergence of the\ngeneralized Bellman updates can be guaranteed. We demonstrate the idea\nexperimentally with the bottleneck objective, i.e., the objectives determined\nby the minimum reward along the process, on classical optimal control and\nreinforcement learning tasks, as well as on two network routing problems on\nmaximizing the flow rates.\n","authors":["Wei Cui","Wei Yu"],"pdf_url":"https://arxiv.org/pdf/2307.04957v1.pdf","comment":"13 pages, 6 figures. To appear in IEEE Transactions on Machine\n  Learning in Communications and Networking (TMLCN)"},{"id":"http://arxiv.org/abs/2307.03913v2","updated":"2023-07-11T01:10:08Z","published":"2023-07-08T06:26:38Z","title":"Applying human-centered AI in developing effective human-AI teaming: A\n  perspective of human-AI joint cognitive systems","summary":"  Research and application have used human-AI teaming (HAT) as a new paradigm\nto develop AI systems. HAT recognizes that AI will function as a teammate\ninstead of simply a tool in collaboration with humans. Effective human-AI teams\nneed to be capable of taking advantage of the unique abilities of both humans\nand AI while overcoming the known challenges and limitations of each member,\naugmenting human capabilities, and raising joint performance beyond that of\neither entity. The National AI Research and Strategic Plan 2023 update has\nrecognized that research programs focusing primarily on the independent\nperformance of AI systems generally fail to consider the functionality that AI\nmust provide within the context of dynamic, adaptive, and collaborative teams\nand calls for further research on human-AI teaming and collaboration. However,\nthere has been debate about whether AI can work as a teammate with humans. The\nprimary concern is that adopting the \"teaming\" paradigm contradicts the\nhuman-centered AI (HCAI) approach, resulting in humans losing control of AI\nsystems. This article further analyzes the HAT paradigm and the debates.\nSpecifically, we elaborate on our proposed conceptual framework of human-AI\njoint cognitive systems (HAIJCS) and apply it to represent HAT under the HCAI\numbrella. We believe that HAIJCS may help adopt HAI while enabling HCAI. The\nimplications and future work for HAIJCS are also discussed.\n  Insights: AI has led to the emergence of a new form of human-machine\nrelationship: human-AI teaming (HAT), a paradigmatic shift in human-AI systems;\nWe must follow a human-centered AI (HCAI) approach when applying HAT as a new\ndesign paradigm; We propose a conceptual framework of human-AI joint cognitive\nsystems (HAIJCS) to represent and implement HAT for developing effective\nhuman-AI teaming\n","authors":["Wei Xu","Zaifeng Gao"],"pdf_url":"https://arxiv.org/pdf/2307.03913v2.pdf","comment":"8"},{"id":"http://arxiv.org/abs/2307.05841v1","updated":"2023-07-11T23:27:26Z","published":"2023-07-11T23:27:26Z","title":"Influential Simplices Mining via Simplicial Convolutional Network","summary":"  Simplicial complexes have recently been in the limelight of higher-order\nnetwork analysis, where a minority of simplices play crucial roles in\nstructures and functions due to network heterogeneity. We find a significant\ninconsistency between identifying influential nodes and simplices. Therefore,\nit remains elusive how to characterize simplices' influence and identify\ninfluential simplices, despite the relative maturity of research on influential\nnodes (0-simplices) identification. Meanwhile, graph neural networks (GNNs) are\npotent tools that can exploit network topology and node features\nsimultaneously, but they struggle to tackle higher-order tasks. In this paper,\nwe propose a higher-order graph learning model, named influential simplices\nmining neural network (ISMnet), to identify vital h-simplices in simplicial\ncomplexes. It can tackle higher-order tasks by leveraging novel higher-order\npresentations: hierarchical bipartite graphs and higher-order hierarchical\n(HoH) Laplacians, where targeted simplices are grouped into a hub set and can\ninteract with other simplices. Furthermore, ISMnet employs learnable graph\nconvolutional operators in each HoH Laplacian domain to capture interactions\namong simplices, and it can identify influential simplices of arbitrary order\nby changing the hub set. Empirical results demonstrate that ISMnet\nsignificantly outperforms existing methods in ranking 0-simplices (nodes) and\n2-simplices. In general, this novel framework excels in identifying influential\nsimplices and promises to serve as a potent tool in higher-order network\nanalysis.\n","authors":["Yujie Zeng","Yiming Huang","Qiang Wu","Linyuan Lü"],"pdf_url":"https://arxiv.org/pdf/2307.05841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03718v2","updated":"2023-07-11T23:08:50Z","published":"2023-07-06T17:03:25Z","title":"Frontier AI Regulation: Managing Emerging Risks to Public Safety","summary":"  Advanced AI models hold the promise of tremendous benefits for humanity, but\nsociety needs to proactively manage the accompanying risks. In this paper, we\nfocus on what we term \"frontier AI\" models: highly capable foundation models\nthat could possess dangerous capabilities sufficient to pose severe risks to\npublic safety. Frontier AI models pose a distinct regulatory challenge:\ndangerous capabilities can arise unexpectedly; it is difficult to robustly\nprevent a deployed model from being misused; and, it is difficult to stop a\nmodel's capabilities from proliferating broadly. To address these challenges,\nat least three building blocks for the regulation of frontier models are\nneeded: (1) standard-setting processes to identify appropriate requirements for\nfrontier AI developers, (2) registration and reporting requirements to provide\nregulators with visibility into frontier AI development processes, and (3)\nmechanisms to ensure compliance with safety standards for the development and\ndeployment of frontier AI models. Industry self-regulation is an important\nfirst step. However, wider societal discussions and government intervention\nwill be needed to create standards and to ensure compliance with them. We\nconsider several options to this end, including granting enforcement powers to\nsupervisory authorities and licensure regimes for frontier AI models. Finally,\nwe propose an initial set of safety standards. These include conducting\npre-deployment risk assessments; external scrutiny of model behavior; using\nrisk assessments to inform deployment decisions; and monitoring and responding\nto new information about model capabilities and uses post-deployment. We hope\nthis discussion contributes to the broader conversation on how to balance\npublic safety risks and innovation benefits from advances at the frontier of AI\ndevelopment.\n","authors":["Markus Anderljung","Joslyn Barnhart","Anton Korinek","Jade Leung","Cullen O'Keefe","Jess Whittlestone","Shahar Avin","Miles Brundage","Justin Bullock","Duncan Cass-Beggs","Ben Chang","Tantum Collins","Tim Fist","Gillian Hadfield","Alan Hayes","Lewis Ho","Sara Hooker","Eric Horvitz","Noam Kolt","Jonas Schuett","Yonadav Shavit","Divya Siddarth","Robert Trager","Kevin Wolf"],"pdf_url":"https://arxiv.org/pdf/2307.03718v2.pdf","comment":"Update July 11th: - Added missing footnote back in. - Adjusted author\n  order (mistakenly non-alphabetical among the first 6 authors) and adjusted\n  affiliations (Jess Whittlestone's affiliation was mistagged and Gillian\n  Hadfield had SRI added to her affiliations)"},{"id":"http://arxiv.org/abs/2307.05834v1","updated":"2023-07-11T22:58:53Z","published":"2023-07-11T22:58:53Z","title":"Scaling Distributed Multi-task Reinforcement Learning with Experience\n  Sharing","summary":"  Recently, DARPA launched the ShELL program, which aims to explore how\nexperience sharing can benefit distributed lifelong learning agents in adapting\nto new challenges. In this paper, we address this issue by conducting both\ntheoretical and empirical research on distributed multi-task reinforcement\nlearning (RL), where a group of $N$ agents collaboratively solves $M$ tasks\nwithout prior knowledge of their identities. We approach the problem by\nformulating it as linearly parameterized contextual Markov decision processes\n(MDPs), where each task is represented by a context that specifies the\ntransition dynamics and rewards. To tackle this problem, we propose an\nalgorithm called DistMT-LSVI. First, the agents identify the tasks, and then\nthey exchange information through a central server to derive $\\epsilon$-optimal\npolicies for the tasks. Our research demonstrates that to achieve\n$\\epsilon$-optimal policies for all $M$ tasks, a single agent using DistMT-LSVI\nneeds to run a total number of episodes that is at most\n$\\tilde{\\mathcal{O}}({d^3H^6(\\epsilon^{-2}+c_{\\rm sep}^{-2})}\\cdot M/N)$, where\n$c_{\\rm sep}>0$ is a constant representing task separability, $H$ is the\nhorizon of each episode, and $d$ is the feature dimension of the dynamics and\nrewards. Notably, DistMT-LSVI improves the sample complexity of non-distributed\nsettings by a factor of $1/N$, as each agent independently learns\n$\\epsilon$-optimal policies for all $M$ tasks using\n$\\tilde{\\mathcal{O}}(d^3H^6M\\epsilon^{-2})$ episodes. Additionally, we provide\nnumerical experiments conducted on OpenAI Gym Atari environments that validate\nour theoretical findings.\n","authors":["Sanae Amani","Khushbu Pahwa","Vladimir Braverman","Lin F. Yang"],"pdf_url":"https://arxiv.org/pdf/2307.05834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05832v1","updated":"2023-07-11T22:56:55Z","published":"2023-07-11T22:56:55Z","title":"Bag of Views: An Appearance-based Approach to Next-Best-View Planning\n  for 3D Reconstruction","summary":"  UAV-based intelligent data acquisition for 3D reconstruction and monitoring\nof infrastructure has been experiencing an increasing surge of interest due to\nthe recent advancements in image processing and deep learning-based techniques.\nView planning is an essential part of this task that dictates the information\ncapture strategy and heavily impacts the quality of the 3D model generated from\nthe captured data. Recent methods have used prior knowledge or partial\nreconstruction of the target to accomplish view planning for active\nreconstruction; the former approach poses a challenge for complex or newly\nidentified targets while the latter is computationally expensive. In this work,\nwe present Bag-of-Views (BoV), a fully appearance-based model used to assign\nutility to the captured views for both offline dataset refinement and online\nnext-best-view (NBV) planning applications targeting the task of 3D\nreconstruction. With this contribution, we also developed the View Planning\nToolbox (VPT), a lightweight package for training and testing machine\nlearning-based view planning frameworks, custom view dataset generation of\narbitrary 3D scenes, and 3D reconstruction. Through experiments which pair a\nBoV-based reinforcement learning model with VPT, we demonstrate the efficacy of\nour model in reducing the number of required views for high-quality\nreconstructions in dataset refinement and NBV planning.\n","authors":["Sara Hatami Gazani","Matthew Tucsok","Iraj Mantegh","Homayoun Najjaran"],"pdf_url":"https://arxiv.org/pdf/2307.05832v1.pdf","comment":"Submitted to IEEE Robotics and Automation Letters (RA-L)"},{"id":"http://arxiv.org/abs/2307.05831v1","updated":"2023-07-11T22:53:09Z","published":"2023-07-11T22:53:09Z","title":"Memorization Through the Lens of Curvature of Loss Function Around\n  Samples","summary":"  Neural networks are overparametrized and easily overfit the datasets they\ntrain on. In the extreme case, it is shown that they can memorize a training\nset with fully randomized labels. We propose using the curvature of loss\nfunction around the training sample as a measure of its memorization, averaged\nover all training epochs. We use this to study the generalization versus\nmemorization properties of different samples in popular image datasets. We\nvisualize samples with the highest curvature of loss around them, and show that\nthese visually correspond to long-tailed, mislabeled or conflicting samples.\nThis analysis helps us find a, to the best of our knowledge, novel failure\nmodel on the CIFAR100 dataset, that of duplicated images with different labels.\nWe also synthetically mislabel a proportion of the dataset by randomly\ncorrupting the labels of a few samples, and show that sorting by curvature\nyields high AUROC values for identifying the mislabeled samples.\n","authors":["Isha Garg","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2307.05831v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2307.05827v1","updated":"2023-07-11T22:36:47Z","published":"2023-07-11T22:36:47Z","title":"Relational Extraction on Wikipedia Tables using Convolutional and Memory\n  Networks","summary":"  Relation extraction (RE) is the task of extracting relations between entities\nin text. Most RE methods extract relations from free-form running text and\nleave out other rich data sources, such as tables. We explore RE from the\nperspective of applying neural methods on tabularly organized data. We\nintroduce a new model consisting of Convolutional Neural Network (CNN) and\nBidirectional-Long Short Term Memory (BiLSTM) network to encode entities and\nlearn dependencies among them, respectively. We evaluate our model on a large\nand recent dataset and compare results with previous neural methods.\nExperimental results show that our model consistently outperforms the previous\nmodel for the task of relation extraction on tabular data. We perform\ncomprehensive error analyses and ablation study to show the contribution of\nvarious components of our model. Finally, we discuss the usefulness and\ntrade-offs of our approach, and provide suggestions for fostering further\nresearch.\n","authors":["Arif Shahriar","Rohan Saha","Denilson Barbosa"],"pdf_url":"https://arxiv.org/pdf/2307.05827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04195v2","updated":"2023-07-11T22:34:51Z","published":"2023-07-09T15:02:34Z","title":"Natural Language Instructions for Intuitive Human Interaction with\n  Robotic Assistants in Field Construction Work","summary":"  The introduction of robots is widely considered to have significant potential\nof alleviating the issues of worker shortage and stagnant productivity that\nafflict the construction industry. However, it is challenging to use fully\nautomated robots in complex and unstructured construction sites. Human-Robot\nCollaboration (HRC) has shown promise of combining human workers' flexibility\nand robot assistants' physical abilities to jointly address the uncertainties\ninherent in construction work. When introducing HRC in construction, it is\ncritical to recognize the importance of teamwork and supervision in field\nconstruction and establish a natural and intuitive communication system for the\nhuman workers and robotic assistants. Natural language-based interaction can\nenable intuitive and familiar communication with robots for human workers who\nare non-experts in robot programming. However, limited research has been\nconducted on this topic in construction. This paper proposes a framework to\nallow human workers to interact with construction robots based on natural\nlanguage instructions. The proposed method consists of three stages: Natural\nLanguage Understanding (NLU), Information Mapping (IM), and Robot Control (RC).\nNatural language instructions are input to a language model to predict a tag\nfor each word in the NLU module. The IM module uses the result of the NLU\nmodule and building component information to generate the final instructional\noutput essential for a robot to acknowledge and perform the construction task.\nA case study for drywall installation is conducted to evaluate the proposed\napproach. The obtained results highlight the potential of using natural\nlanguage-based interaction to replicate the communication that occurs between\nhuman workers within the context of human-robot teams.\n","authors":["Somin Park","Xi Wang","Carol C. Menassa","Vineet R. Kamat","Joyce Y. Chai"],"pdf_url":"https://arxiv.org/pdf/2307.04195v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05793v1","updated":"2023-07-11T20:40:19Z","published":"2023-07-11T20:40:19Z","title":"Neuro-Inspired Efficient Map Building via Fragmentation and Recall","summary":"  Animals and robots navigate through environments by building and refining\nmaps of the space. These maps enable functions including navigating back to\nhome, planning, search, and foraging. In large environments, exploration of the\nspace is a hard problem: agents can become stuck in local regions. Here, we use\ninsights from neuroscience to propose and apply the concept of\nFragmentation-and-Recall (FarMap), with agents solving the mapping problem by\nbuilding local maps via a surprisal-based clustering of space, which they use\nto set subgoals for spatial exploration. Agents build and use a local map to\npredict their observations; high surprisal leads to a ``fragmentation event''\nthat truncates the local map. At these events, the recent local map is placed\ninto long-term memory (LTM), and a different local map is initialized. If\nobservations at a fracture point match observations in one of the stored local\nmaps, that map is recalled (and thus reused) from LTM. The fragmentation points\ninduce a natural online clustering of the larger space, forming a set of\nintrinsic potential subgoals that are stored in LTM as a topological graph.\nAgents choose their next subgoal from the set of near and far potential\nsubgoals from within the current local map or LTM, respectively. Thus, local\nmaps guide exploration locally, while LTM promotes global exploration. We\nevaluate FarMap on complex procedurally-generated spatial environments to\ndemonstrate that this mapping strategy much more rapidly covers the environment\n(number of agent steps and wall clock time) and is more efficient in active\nmemory usage, without loss of performance.\n","authors":["Jaedong Hwang","Zhang-Wei Hong","Eric Chen","Akhilan Boopathy","Pulkit Agrawal","Ila Fiete"],"pdf_url":"https://arxiv.org/pdf/2307.05793v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05786v1","updated":"2023-07-11T20:27:12Z","published":"2023-07-11T20:27:12Z","title":"Merging multiple input descriptors and supervisors in a deep neural\n  network for tractogram filtering","summary":"  One of the main issues of the current tractography methods is their high\nfalse-positive rate. Tractogram filtering is an option to remove false-positive\nstreamlines from tractography data in a post-processing step. In this paper, we\ntrain a deep neural network for filtering tractography data in which every\nstreamline of a tractogram is classified as {\\em plausible, implausible}, or\n{\\em inconclusive}. For this, we use four different tractogram filtering\nstrategies as supervisors: TractQuerier, RecobundlesX, TractSeg, and an\nanatomy-inspired filter. Their outputs are combined to obtain the\nclassification labels for the streamlines. We assessed the importance of\ndifferent types of information along the streamlines for performing this\nclassification task, including the coordinates of the streamlines, diffusion\ndata, landmarks, T1-weighted information, and a brain parcellation. We found\nthat the streamline coordinates are the most relevant followed by the diffusion\ndata in this particular classification task.\n","authors":["Daniel Jörgens","Pierre-Marc Jodoin","Maxime Descoteaux","Rodrigo Moreno"],"pdf_url":"https://arxiv.org/pdf/2307.05786v1.pdf","comment":"21 pages, 8 figures"},{"id":"http://arxiv.org/abs/2307.05784v1","updated":"2023-07-11T20:23:23Z","published":"2023-07-11T20:23:23Z","title":"EgoAdapt: A multi-stream evaluation study of adaptation to real-world\n  egocentric user video","summary":"  In egocentric action recognition a single population model is typically\ntrained and subsequently embodied on a head-mounted device, such as an\naugmented reality headset. While this model remains static for new users and\nenvironments, we introduce an adaptive paradigm of two phases, where after\npretraining a population model, the model adapts on-device and online to the\nuser's experience. This setting is highly challenging due to the change from\npopulation to user domain and the distribution shifts in the user's data\nstream. Coping with the latter in-stream distribution shifts is the focus of\ncontinual learning, where progress has been rooted in controlled benchmarks but\nchallenges faced in real-world applications often remain unaddressed. We\nintroduce EgoAdapt, a benchmark for real-world egocentric action recognition\nthat facilitates our two-phased adaptive paradigm, and real-world challenges\nnaturally occur in the egocentric video streams from Ego4d, such as long-tailed\naction distributions and large-scale classification over 2740 actions. We\nintroduce an evaluation framework that directly exploits the user's data stream\nwith new metrics to measure the adaptation gain over the population model,\nonline generalization, and hindsight performance. In contrast to single-stream\nevaluation in existing works, our framework proposes a meta-evaluation that\naggregates the results from 50 independent user streams. We provide an\nextensive empirical study for finetuning and experience replay.\n","authors":["Matthias De Lange","Hamid Eghbalzadeh","Reuben Tan","Michael Iuzzolino","Franziska Meier","Karl Ridgeway"],"pdf_url":"https://arxiv.org/pdf/2307.05784v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2211.01413v2","updated":"2023-07-11T20:22:08Z","published":"2022-11-02T18:16:17Z","title":"Harnessing the Power of Explanations for Incremental Training: A\n  LIME-Based Approach","summary":"  Explainability of neural network prediction is essential to understand\nfeature importance and gain interpretable insight into neural network\nperformance. However, explanations of neural network outcomes are mostly\nlimited to visualization, and there is scarce work that looks to use these\nexplanations as feedback to improve model performance. In this work, model\nexplanations are fed back to the feed-forward training to help the model\ngeneralize better. To this extent, a custom weighted loss where the weights are\ngenerated by considering the Euclidean distances between true LIME (Local\nInterpretable Model-Agnostic Explanations) explanations and model-predicted\nLIME explanations is proposed. Also, in practical training scenarios,\ndeveloping a solution that can help the model learn sequentially without losing\ninformation on previous data distribution is imperative due to the\nunavailability of all the training data at once. Thus, the framework\nincorporates the custom weighted loss with Elastic Weight Consolidation (EWC)\nto maintain performance in sequential testing sets. The proposed custom\ntraining procedure results in a consistent enhancement of accuracy ranging from\n0.5% to 1.5% throughout all phases of the incremental learning setup compared\nto traditional loss-based training methods for the keyword spotting task using\nthe Google Speech Commands dataset.\n","authors":["Arnab Neelim Mazumder","Niall Lyons","Ashutosh Pandey","Avik Santra","Tinoosh Mohsenin"],"pdf_url":"https://arxiv.org/pdf/2211.01413v2.pdf","comment":"Accepted at EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2307.05766v1","updated":"2023-07-11T19:47:05Z","published":"2023-07-11T19:47:05Z","title":"Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology\n  Reporting","summary":"  Radiology reporting is a crucial part of the communication between\nradiologists and other medical professionals, but it can be time-consuming and\nerror-prone. One approach to alleviate this is structured reporting, which\nsaves time and enables a more accurate evaluation than free-text reports.\nHowever, there is limited research on automating structured reporting, and no\npublic benchmark is available for evaluating and comparing different methods.\nTo close this gap, we introduce Rad-ReStruct, a new benchmark dataset that\nprovides fine-grained, hierarchically ordered annotations in the form of\nstructured reports for X-Ray images. We model the structured reporting task as\nhierarchical visual question answering (VQA) and propose hi-VQA, a novel method\nthat considers prior context in the form of previously asked questions and\nanswers for populating a structured radiology report. Our experiments show that\nhi-VQA achieves competitive performance to the state-of-the-art on the medical\nVQA benchmark VQARad while performing best among methods without\ndomain-specific vision-language pretraining and provides a strong baseline on\nRad-ReStruct. Our work represents a significant step towards the automated\npopulation of structured radiology reports and provides a valuable first\nbenchmark for future research in this area. We will make all annotations and\nour code for annotation generation, model evaluation, and training publicly\navailable upon acceptance. Our dataset and code is available at\nhttps://github.com/ChantalMP/Rad-ReStruct.\n","authors":["Chantal Pellegrini","Matthias Keicher","Ege Özsoy","Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2307.05766v1.pdf","comment":"accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2307.05728v1","updated":"2023-07-11T18:55:27Z","published":"2023-07-11T18:55:27Z","title":"Towards A Scalable Solution for Improving Multi-Group Fairness in\n  Compositional Classification","summary":"  Despite the rich literature on machine learning fairness, relatively little\nattention has been paid to remediating complex systems, where the final\nprediction is the combination of multiple classifiers and where multiple groups\nare present. In this paper, we first show that natural baseline approaches for\nimproving equal opportunity fairness scale linearly with the product of the\nnumber of remediated groups and the number of remediated prediction labels,\nrendering them impractical. We then introduce two simple techniques, called\n{\\em task-overconditioning} and {\\em group-interleaving}, to achieve a constant\nscaling in this multi-group multi-label setup. Our experimental results in\nacademic and real-world environments demonstrate the effectiveness of our\nproposal at mitigation within this environment.\n","authors":["James Atwood","Tina Tian","Ben Packer","Meghana Deodhar","Jilin Chen","Alex Beutel","Flavien Prost","Ahmad Beirami"],"pdf_url":"https://arxiv.org/pdf/2307.05728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05727v1","updated":"2023-07-11T18:55:09Z","published":"2023-07-11T18:55:09Z","title":"An Open-Source Knowledge Graph Ecosystem for the Life Sciences","summary":"  Translational research requires data at multiple scales of biological\norganization. Advancements in sequencing and multi-omics technologies have\nincreased the availability of these data but researchers face significant\nintegration challenges. Knowledge graphs (KGs) are used to model complex\nphenomena, and methods exist to automatically construct them. However, tackling\ncomplex biomedical integration problems requires flexibility in the way\nknowledge is modeled. Moreover, existing KG construction methods provide robust\ntooling at the cost of fixed or limited choices among knowledge representation\nmodels. PheKnowLator (Phenotype Knowledge Translator) is a semantic ecosystem\nfor automating the FAIR (Findable, Accessible, Interoperable, and Reusable)\nconstruction of ontologically grounded KGs with fully customizable knowledge\nrepresentation. The ecosystem includes KG construction resources (e.g., data\npreparation APIs), analysis tools (e.g., SPARQL endpoints and abstraction\nalgorithms), and benchmarks (e.g., prebuilt KGs and embeddings). We evaluate\nthe ecosystem by surveying open-source KG construction methods and analyzing\nits computational performance when constructing 12 large-scale KGs. With\nflexible knowledge representation, PheKnowLator enables fully customizable KGs\nwithout compromising performance or usability.\n","authors":["Tiffany J. Callahan","Ignacio J. Tripodi","Adrianne L. Stefanski","Luca Cappelletti","Sanya B. Taneja","Jordan M. Wyrwa","Elena Casiraghi","Nicolas A. Matentzoglu","Justin Reese","Jonathan C. Silverstein","Charles Tapley Hoyt","Richard D. Boyce","Scott A. Malec","Deepak R. Unni","Marcin P. Joachimiak","Peter N. Robinson","Christopher J. Mungall","Emanuele Cavalleri","Tommaso Fontana","Giorgio Valentini","Marco Mesiti","Lucas A. Gillenwater","Brook Santangelo","Nicole A. Vasilevsky","Robert Hoehndorf","Tellen D. Bennett","Patrick B. Ryan","George Hripcsak","Michael G. Kahn","Michael Bada","William A. Baumgartner Jr","Lawrence E. Hunter"],"pdf_url":"https://arxiv.org/pdf/2307.05727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09452v2","updated":"2023-07-11T18:46:45Z","published":"2022-10-17T21:43:32Z","title":"Multiple Instance Learning via Iterative Self-Paced Supervised\n  Contrastive Learning","summary":"  Learning representations for individual instances when only bag-level labels\nare available is a fundamental challenge in multiple instance learning (MIL).\nRecent works have shown promising results using contrastive self-supervised\nlearning (CSSL), which learns to push apart representations corresponding to\ntwo different randomly-selected instances. Unfortunately, in real-world\napplications such as medical image classification, there is often class\nimbalance, so randomly-selected instances mostly belong to the same majority\nclass, which precludes CSSL from learning inter-class differences. To address\nthis issue, we propose a novel framework, Iterative Self-paced Supervised\nContrastive Learning for MIL Representations (ItS2CLR), which improves the\nlearned representation by exploiting instance-level pseudo labels derived from\nthe bag-level labels. The framework employs a novel self-paced sampling\nstrategy to ensure the accuracy of pseudo labels. We evaluate ItS2CLR on three\nmedical datasets, showing that it improves the quality of instance-level pseudo\nlabels and representations, and outperforms existing MIL methods in terms of\nboth bag and instance level accuracy. Code is available at\nhttps://github.com/Kangningthu/ItS2CLR\n","authors":["Kangning Liu","Weicheng Zhu","Yiqiu Shen","Sheng Liu","Narges Razavian","Krzysztof J. Geras","Carlos Fernandez-Granda"],"pdf_url":"https://arxiv.org/pdf/2210.09452v2.pdf","comment":"CVPR 2023 camera-ready version. The first two authors contribute\n  equally. The last two authors are joint last authors"},{"id":"http://arxiv.org/abs/2305.18703v4","updated":"2023-07-11T18:34:08Z","published":"2023-05-30T03:00:30Z","title":"Domain Specialization as the Key to Make Large Language Models\n  Disruptive: A Comprehensive Survey","summary":"  Large language models (LLMs) have significantly advanced the field of natural\nlanguage processing (NLP), providing a highly useful, task-agnostic foundation\nfor a wide range of applications. However, directly applying LLMs to solve\nsophisticated problems in specific domains meets many hurdles, caused by the\nheterogeneity of domain data, the sophistication of domain knowledge, the\nuniqueness of domain objectives, and the diversity of the constraints (e.g.,\nvarious social norms, cultural conformity, religious beliefs, and ethical\nstandards in the domain applications). Domain specification techniques are key\nto make large language models disruptive in many applications. Specifically, to\nsolve these hurdles, there has been a notable increase in research and\npractices conducted in recent years on the domain specialization of LLMs. This\nemerging field of study, with its substantial potential for impact,\nnecessitates a comprehensive and systematic review to better summarize and\nguide ongoing work in this area. In this article, we present a comprehensive\nsurvey on domain specification techniques for large language models, an\nemerging direction critical for large language model applications. First, we\npropose a systematic taxonomy that categorizes the LLM domain-specialization\ntechniques based on the accessibility to LLMs and summarizes the framework for\nall the subcategories as well as their relations and differences to each other.\nSecond, we present an extensive taxonomy of critical application domains that\ncan benefit dramatically from specialized LLMs, discussing their practical\nsignificance and open challenges. Last, we offer our insights into the current\nresearch status and future trends in this area.\n","authors":["Chen Ling","Xujiang Zhao","Jiaying Lu","Chengyuan Deng","Can Zheng","Junxiang Wang","Tanmoy Chowdhury","Yun Li","Hejie Cui","Xuchao Zhang","Tianjiao Zhao","Amit Panalkar","Wei Cheng","Haoyu Wang","Yanchi Liu","Zhengzhang Chen","Haifeng Chen","Chris White","Quanquan Gu","Jian Pei","Carl Yang","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2305.18703v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05704v1","updated":"2023-07-11T18:12:05Z","published":"2023-07-11T18:12:05Z","title":"A Causal Ordering Prior for Unsupervised Representation Learning","summary":"  Unsupervised representation learning with variational inference relies\nheavily on independence assumptions over latent variables. Causal\nrepresentation learning (CRL), however, argues that factors of variation in a\ndataset are, in fact, causally related. Allowing latent variables to be\ncorrelated, as a consequence of causal relationships, is more realistic and\ngeneralisable. So far, provably identifiable methods rely on: auxiliary\ninformation, weak labels, and interventional or even counterfactual data.\nInspired by causal discovery with functional causal models, we propose a fully\nunsupervised representation learning method that considers a data generation\nprocess with a latent additive noise model (ANM). We encourage the latent space\nto follow a causal ordering via loss function based on the Hessian of the\nlatent distribution.\n","authors":["Avinash Kori","Pedro Sanchez","Konstantinos Vilouras","Ben Glocker","Sotirios A. Tsaftaris"],"pdf_url":"https://arxiv.org/pdf/2307.05704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05663v1","updated":"2023-07-11T17:57:40Z","published":"2023-07-11T17:57:40Z","title":"Objaverse-XL: A Universe of 10M+ 3D Objects","summary":"  Natural language processing and 2D vision models have attained remarkable\nproficiency on many tasks primarily by escalating the scale of training data.\nHowever, 3D vision tasks have not seen the same progress, in part due to the\nchallenges of acquiring high-quality 3D data. In this work, we present\nObjaverse-XL, a dataset of over 10 million 3D objects. Our dataset comprises\ndeduplicated 3D objects from a diverse set of sources, including manually\ndesigned objects, photogrammetry scans of landmarks and everyday items, and\nprofessional scans of historic and antique artifacts. Representing the largest\nscale and diversity in the realm of 3D datasets, Objaverse-XL enables\nsignificant new possibilities for 3D vision. Our experiments demonstrate the\nimprovements enabled with the scale provided by Objaverse-XL. We show that by\ntraining Zero123 on novel view synthesis, utilizing over 100 million multi-view\nrendered images, we achieve strong zero-shot generalization abilities. We hope\nthat releasing Objaverse-XL will enable further innovations in the field of 3D\nvision at scale.\n","authors":["Matt Deitke","Ruoshi Liu","Matthew Wallingford","Huong Ngo","Oscar Michel","Aditya Kusupati","Alan Fan","Christian Laforte","Vikram Voleti","Samir Yitzhak Gadre","Eli VanderBilt","Aniruddha Kembhavi","Carl Vondrick","Georgia Gkioxari","Kiana Ehsani","Ludwig Schmidt","Ali Farhadi"],"pdf_url":"https://arxiv.org/pdf/2307.05663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12001v3","updated":"2023-07-11T17:04:35Z","published":"2023-06-21T03:35:06Z","title":"An Overview of Catastrophic AI Risks","summary":"  Rapid advancements in artificial intelligence (AI) have sparked growing\nconcerns among experts, policymakers, and world leaders regarding the potential\nfor increasingly advanced AI systems to pose catastrophic risks. Although\nnumerous risks have been detailed separately, there is a pressing need for a\nsystematic discussion and illustration of the potential dangers to better\ninform efforts to mitigate them. This paper provides an overview of the main\nsources of catastrophic AI risks, which we organize into four categories:\nmalicious use, in which individuals or groups intentionally use AIs to cause\nharm; AI race, in which competitive environments compel actors to deploy unsafe\nAIs or cede control to AIs; organizational risks, highlighting how human\nfactors and complex systems can increase the chances of catastrophic accidents;\nand rogue AIs, describing the inherent difficulty in controlling agents far\nmore intelligent than humans. For each category of risk, we describe specific\nhazards, present illustrative stories, envision ideal scenarios, and propose\npractical suggestions for mitigating these dangers. Our goal is to foster a\ncomprehensive understanding of these risks and inspire collective and proactive\nefforts to ensure that AIs are developed and deployed in a safe manner.\nUltimately, we hope this will allow us to realize the benefits of this powerful\ntechnology while minimizing the potential for catastrophic outcomes.\n","authors":["Dan Hendrycks","Mantas Mazeika","Thomas Woodside"],"pdf_url":"https://arxiv.org/pdf/2306.12001v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07625v2","updated":"2023-07-11T13:47:07Z","published":"2022-11-14T18:48:08Z","title":"What Images are More Memorable to Machines?","summary":"  This paper studies the problem of measuring and predicting how memorable an\nimage is to pattern recognition machines, as a path to explore machine\nintelligence. Firstly, we propose a self-supervised machine memory\nquantification pipeline, dubbed ``MachineMem measurer'', to collect machine\nmemorability scores of images. Similar to humans, machines also tend to\nmemorize certain kinds of images, whereas the types of images that machines and\nhumans memorize are different. Through in-depth analysis and comprehensive\nvisualizations, we gradually unveil that``complex\" images are usually more\nmemorable to machines. We further conduct extensive experiments across 11\ndifferent machines (from linear classifiers to modern ViTs) and 9 pre-training\nmethods to analyze and understand machine memory. This work proposes the\nconcept of machine memorability and opens a new research direction at the\ninterface between machine memory and visual data.\n","authors":["Junlin Han","Huangying Zhan","Jie Hong","Pengfei Fang","Hongdong Li","Lars Petersson","Ian Reid"],"pdf_url":"https://arxiv.org/pdf/2211.07625v2.pdf","comment":"Code: https://github.com/JunlinHan/MachineMem Project page:\n  https://junlinhan.github.io/projects/machinemem.html"},{"id":"http://arxiv.org/abs/2307.05643v1","updated":"2023-07-11T10:38:31Z","published":"2023-07-11T10:38:31Z","title":"Multiobjective Hydropower Reservoir Operation Optimization with\n  Transformer-Based Deep Reinforcement Learning","summary":"  Due to shortage of water resources and increasing water demands, the joint\noperation of multireservoir systems for balancing power generation, ecological\nprotection, and the residential water supply has become a critical issue in\nhydropower management. However, the numerous constraints and nonlinearity of\nmultiple reservoirs make solving this problem time-consuming. To address this\nchallenge, a deep reinforcement learning approach that incorporates a\ntransformer framework is proposed. The multihead attention mechanism of the\nencoder effectively extracts information from reservoirs and residential areas,\nand the multireservoir attention network of the decoder generates suitable\noperational decisions. The proposed method is applied to Lake Mead and Lake\nPowell in the Colorado River Basin. The experimental results demonstrate that\nthe transformer-based deep reinforcement learning approach can produce\nappropriate operational outcomes. Compared to a state-of-the-art method, the\noperation strategies produced by the proposed approach generate 10.11% more\nelectricity, reduce the amended annual proportional flow deviation by 39.69%,\nand increase water supply revenue by 4.10%. Consequently, the proposed approach\noffers an effective method for the multiobjective operation of multihydropower\nreservoir systems.\n","authors":["Rixin Wu","Ran Wang","Jie Hao","Qiang Wu","Ping Wang"],"pdf_url":"https://arxiv.org/pdf/2307.05643v1.pdf","comment":"11 figures, 16 pages, submitted to Journal of Hydrology"},{"id":"http://arxiv.org/abs/2307.05639v1","updated":"2023-07-11T09:54:30Z","published":"2023-07-11T09:54:30Z","title":"Learning Active Subspaces and Discovering Important Features with\n  Gaussian Radial Basis Functions Neural Networks","summary":"  Providing a model that achieves a strong predictive performance and at the\nsame time is interpretable by humans is one of the most difficult challenges in\nmachine learning research due to the conflicting nature of these two\nobjectives. To address this challenge, we propose a modification of the Radial\nBasis Function Neural Network model by equipping its Gaussian kernel with a\nlearnable precision matrix. We show that precious information is contained in\nthe spectrum of the precision matrix that can be extracted once the training of\nthe model is completed. In particular, the eigenvectors explain the directions\nof maximum sensitivity of the model revealing the active subspace and\nsuggesting potential applications for supervised dimensionality reduction. At\nthe same time, the eigenvectors highlight the relationship in terms of absolute\nvariation between the input and the latent variables, thereby allowing us to\nextract a ranking of the input variables based on their importance to the\nprediction task enhancing the model interpretability. We conducted numerical\nexperiments for regression, classification, and feature selection tasks,\ncomparing our model against popular machine learning models and the\nstate-of-the-art deep learning-based embedding feature selection techniques.\nOur results demonstrate that the proposed model does not only yield an\nattractive prediction performance with respect to the competitors but also\nprovides meaningful and interpretable results that potentially could assist the\ndecision-making process in real-world applications. A PyTorch implementation of\nthe model is available on GitHub at the following link.\nhttps://github.com/dannyzx/GRBF-NNs\n","authors":["Danny D'Agostino","Ilija Ilievski","Christine Annette Shoemaker"],"pdf_url":"https://arxiv.org/pdf/2307.05639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05638v1","updated":"2023-07-11T09:37:52Z","published":"2023-07-11T09:37:52Z","title":"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection\n  in Industrial Time Series: Methods, Applications, and Directions","summary":"  Automating the monitoring of industrial processes has the potential to\nenhance efficiency and optimize quality by promptly detecting abnormal events\nand thus facilitating timely interventions. Deep learning, with its capacity to\ndiscern non-trivial patterns within large datasets, plays a pivotal role in\nthis process. Standard deep learning methods are suitable to solve a specific\ntask given a specific type of data. During training, the algorithms demand\nlarge volumes of labeled training data. However, due to the dynamic nature of\nprocesses and the environment, it is impractical to acquire the needed data for\nstandard deep learning training for every slightly different case anew. Deep\ntransfer learning offers a solution to this problem. By leveraging knowledge\nfrom related tasks and accounting for variations in data distributions, this\nlearning framework solves new tasks even with little or no additional labeled\ndata. The approach bypasses the need to retrain a model from scratch for every\nnew setup and dramatically reduces the labeled data requirement. This survey\nprovides an in-depth review of deep transfer learning, examining the problem\nsettings of transfer learning and classifying the prevailing deep transfer\nlearning methods. Moreover, we delve into applying deep transfer learning in\nthe context of a broad spectrum of time series anomaly detection tasks\nprevalent in primary industrial domains, e.g., manufacturing process\nmonitoring, predictive maintenance, energy management, and infrastructure\nfacility monitoring. We conclude this survey by underlining the challenges and\nlimitations of deep transfer learning in industrial contexts. We also provide\npractical directions for solution design and implementation for these tasks,\nleading to specific, actionable suggestions.\n","authors":["Peng Yan","Ahmed Abdulkadir","Matthias Rosenthal","Gerrit A. Schatte","Benjamin F. Grewe","Thilo Stadelmann"],"pdf_url":"https://arxiv.org/pdf/2307.05638v1.pdf","comment":"21 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2307.05632v1","updated":"2023-07-11T07:11:30Z","published":"2023-07-11T07:11:30Z","title":"Belief Revision from Probability","summary":"  In previous work (\"Knowledge from Probability\", TARK 2021) we develop a\nquestion-relative, probabilistic account of belief. On this account, what\nsomeone believes relative to a given question is (i) closed under entailment,\n(ii) sufficiently probable given their evidence, and (iii) sensitive to the\nrelative probabilities of the answers to the question. Here we explore the\nimplications of this account for the dynamics of belief. We show that the\nprinciples it validates are much weaker than those of orthodox theories of\nbelief revision like AGM, but still stronger than those valid according to the\npopular Lockean theory of belief, which equates belief with high subjective\nprobability. We then consider a restricted class of models, suitable for many\nbut not all applications, and identify some further natural principles valid on\nthis class. We conclude by arguing that the present framework compares\nfavorably to the rival probabilistic accounts of belief developed by Leitgeb\nand by Lin and Kelly.\n","authors":["Jeremy Goodman","Bernhard Salow"],"pdf_url":"https://arxiv.org/pdf/2307.05632v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05631v1","updated":"2023-07-11T07:08:14Z","published":"2023-07-11T07:08:14Z","title":"Causal Kripke Models","summary":"  This work extends Halpern and Pearl's causal models for actual causality to a\npossible world semantics environment. Using this framework we introduce a logic\nof actual causality with modal operators, which allows for reasoning about\ncausality in scenarios involving multiple possibilities, temporality, knowledge\nand uncertainty. We illustrate this with a number of examples, and conclude by\ndiscussing some future directions for research.\n","authors":["Yiwen Ding","Krishna Manoorkar","Apostolos Tzimoulis","Ruoding Wang","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2307.05631v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2307.05629v1","updated":"2023-07-11T07:07:15Z","published":"2023-07-11T07:07:15Z","title":"Characterization of AGM Belief Contraction in Terms of Conditionals","summary":"  We provide a semantic characterization of AGM belief contraction based on\nframes consisting of a Kripke belief relation and a Stalnaker-Lewis selection\nfunction. The central idea is as follows. Let K be the initial belief set and\nK-A be the contraction of K by the formula A; then B belongs to the set K-A if\nand only if, at the actual state, the agent believes B and believes that if\nnot-A is (were) the case then B is (would be) the case.\n","authors":["Giacomo Bonanno"],"pdf_url":"https://arxiv.org/pdf/2307.05629v1.pdf","comment":"In Proceedings TARK 2023, arXiv:2307.04005"},{"id":"http://arxiv.org/abs/2306.02121v2","updated":"2023-07-11T06:00:23Z","published":"2023-06-03T14:25:15Z","title":"Identifying Subgroups of ICU Patients Using End-to-End Multivariate\n  Time-Series Clustering Algorithm Based on Real-World Vital Signs Data","summary":"  This study employed the MIMIC-IV database as data source to investigate the\nuse of dynamic, high-frequency, multivariate time-series vital signs data,\nincluding temperature, heart rate, mean blood pressure, respiratory rate, and\nSpO2, monitored first 8 hours data in the ICU stay. Various clustering\nalgorithms were compared, and an end-to-end multivariate time series clustering\nsystem called Time2Feat, combined with K-Means, was chosen as the most\neffective method to cluster patients in the ICU. In clustering analysis, data\nof 8,080 patients admitted between 2008 and 2016 was used for model development\nand 2,038 patients admitted between 2017 and 2019 for model validation. By\nanalyzing the differences in clinical mortality prognosis among different\ncategories, varying risks of ICU mortality and hospital mortality were found\nbetween different subgroups. Furthermore, the study visualized the trajectory\nof vital signs changes. The findings of this study provide valuable insights\ninto the potential use of multivariate time-series clustering systems in\npatient management and monitoring in the ICU setting.\n","authors":["Tongyue Shi","Zhilong Zhang","Wentie Liu","Junhua Fang","Jianguo Hao","Shuai Jin","Huiying Zhao","Guilan Kong"],"pdf_url":"https://arxiv.org/pdf/2306.02121v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05624v1","updated":"2023-07-11T05:21:28Z","published":"2023-07-11T05:21:28Z","title":"CILF:Causality Inspired Learning Framework for Out-of-Distribution\n  Vehicle Trajectory Prediction","summary":"  Trajectory prediction is critical for autonomous driving vehicles. Most\nexisting methods tend to model the correlation between history trajectory\n(input) and future trajectory (output). Since correlation is just a superficial\ndescription of reality, these methods rely heavily on the i.i.d. assumption and\nevince a heightened susceptibility to out-of-distribution data. To address this\nproblem, we propose an Out-of- Distribution Causal Graph (OOD-CG), which\nexplicitly defines the underlying causal structure of the data with three\nentangled latent features: 1) domain-invariant causal feature (IC), 2)\ndomain-variant causal feature (VC), and 3) domain-variant non-causal feature\n(VN ). While these features are confounded by confounder (C) and domain\nselector (D). To leverage causal features for prediction, we propose a Causal\nInspired Learning Framework (CILF), which includes three steps: 1) extracting\ndomain-invariant causal feature by means of an invariance loss, 2) extracting\ndomain variant feature by domain contrastive learning, and 3) separating\ndomain-variant causal and non-causal feature by encouraging causal sufficiency.\nWe evaluate the performance of CILF in different vehicle trajectory prediction\nmodels on the mainstream datasets NGSIM and INTERACTION. Experiments show\npromising improvements in CILF on domain generalization.\n","authors":["Shengyi Li","Qifan Xue","Yezhuo Zhang","Xuanpeng Li"],"pdf_url":"https://arxiv.org/pdf/2307.05624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05623v1","updated":"2023-07-11T04:58:45Z","published":"2023-07-11T04:58:45Z","title":"A DeepLearning Framework for Dynamic Estimation of Origin-Destination\n  Sequence","summary":"  OD matrix estimation is a critical problem in the transportation domain. The\nprinciple method uses the traffic sensor measured information such as traffic\ncounts to estimate the traffic demand represented by the OD matrix. The problem\nis divided into two categories: static OD matrix estimation and dynamic OD\nmatrices sequence(OD sequence for short) estimation. The above two face the\nunderdetermination problem caused by abundant estimated parameters and\ninsufficient constraint information. In addition, OD sequence estimation also\nfaces the lag challenge: due to different traffic conditions such as\ncongestion, identical vehicle will appear on different road sections during the\nsame observation period, resulting in identical OD demands correspond to\ndifferent trips. To this end, this paper proposes an integrated method, which\nuses deep learning methods to infer the structure of OD sequence and uses\nstructural constraints to guide traditional numerical optimization. Our\nexperiments show that the neural network(NN) can effectively infer the\nstructure of the OD sequence and provide practical constraints for numerical\noptimization to obtain better results. Moreover, the experiments show that\nprovided structural information contains not only constraints on the spatial\nstructure of OD matrices but also provides constraints on the temporal\nstructure of OD sequence, which solve the effect of the lagging problem well.\n","authors":["Zheli Xiong","Defu Lian","Enhong Chen","Gang Chen","Xiaomin Cheng"],"pdf_url":"https://arxiv.org/pdf/2307.05623v1.pdf","comment":"11 pages,25 figures"}]},"2023-07-12T00:00:00Z":{"Sound":[{"id":"http://arxiv.org/abs/2305.12493v5","updated":"2023-07-12T17:41:53Z","published":"2023-05-21T16:08:04Z","title":"Contextualized End-to-End Speech Recognition with Contextual Phrase\n  Prediction Network","summary":"  Contextual information plays a crucial role in speech recognition\ntechnologies and incorporating it into the end-to-end speech recognition models\nhas drawn immense interest recently. However, previous deep bias methods lacked\nexplicit supervision for bias tasks. In this study, we introduce a contextual\nphrase prediction network for an attention-based deep bias method. This network\npredicts context phrases in utterances using contextual embeddings and\ncalculates bias loss to assist in the training of the contextualized model. Our\nmethod achieved a significant word error rate (WER) reduction across various\nend-to-end speech recognition models. Experiments on the LibriSpeech corpus\nshow that our proposed model obtains a 12.1% relative WER improvement over the\nbaseline model, and the WER of the context phrases decreases relatively by\n40.5%. Moreover, by applying a context phrase filtering strategy, we also\neffectively eliminate the WER degradation when using a larger biasing list.\n","authors":["Kaixun Huang","Ao Zhang","Zhanheng Yang","Pengcheng Guo","Bingshen Mu","Tianyi Xu","Lei Xie"],"pdf_url":"https://arxiv.org/pdf/2305.12493v5.pdf","comment":"Accepted by interspeech2023"},{"id":"http://arxiv.org/abs/2307.04686v2","updated":"2023-07-12T17:06:41Z","published":"2023-07-10T16:42:03Z","title":"VampNet: Music Generation via Masked Acoustic Token Modeling","summary":"  We introduce VampNet, a masked acoustic token modeling approach to music\nsynthesis, compression, inpainting, and variation. We use a variable masking\nschedule during training which allows us to sample coherent music from the\nmodel by applying a variety of masking approaches (called prompts) during\ninference. VampNet is non-autoregressive, leveraging a bidirectional\ntransformer architecture that attends to all tokens in a forward pass. With\njust 36 sampling passes, VampNet can generate coherent high-fidelity musical\nwaveforms. We show that by prompting VampNet in various ways, we can apply it\nto tasks like music compression, inpainting, outpainting, continuation, and\nlooping with variation (vamping). Appropriately prompted, VampNet is capable of\nmaintaining style, genre, instrumentation, and other high-level aspects of the\nmusic. This flexible prompting capability makes VampNet a powerful music\nco-creation tool. Code and audio samples are available online.\n","authors":["Hugo Flores Garcia","Prem Seetharaman","Rithesh Kumar","Bryan Pardo"],"pdf_url":"https://arxiv.org/pdf/2307.04686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06292v1","updated":"2023-07-12T16:39:02Z","published":"2023-07-12T16:39:02Z","title":"Feature Embeddings from Large-Scale Acoustic Bird Classifiers Enable\n  Few-Shot Transfer Learning","summary":"  Automated bioacoustic analysis aids understanding and protection of both\nmarine and terrestrial animals and their habitats across extensive\nspatiotemporal scales, and typically involves analyzing vast collections of\nacoustic data. With the advent of deep learning models, classification of\nimportant signals from these datasets has markedly improved. These models power\ncritical data analyses for research and decision-making in biodiversity\nmonitoring, animal behaviour studies, and natural resource management. However,\ndeep learning models are often data-hungry and require a significant amount of\nlabeled training data to perform well. While sufficient training data is\navailable for certain taxonomic groups (e.g., common bird species), many\nclasses (such as rare and endangered species, many non-bird taxa, and\ncall-type), lack enough data to train a robust model from scratch. This study\ninvestigates the utility of feature embeddings extracted from large-scale audio\nclassification models to identify bioacoustic classes other than the ones these\nmodels were originally trained on. We evaluate models on diverse datasets,\nincluding different bird calls and dialect types, bat calls, marine mammals\ncalls, and amphibians calls. The embeddings extracted from the models trained\non bird vocalization data consistently allowed higher quality classification\nthan the embeddings trained on general audio datasets. The results of this\nstudy indicate that high-quality feature embeddings from large-scale acoustic\nbird classifiers can be harnessed for few-shot transfer learning, enabling the\nlearning of new classes from a limited quantity of training data. Our findings\nreveal the potential for efficient analyses of novel bioacoustic tasks, even in\nscenarios where available training data is limited to a few samples.\n","authors":["Burooj Ghani","Tom Denton","Stefan Kahl","Holger Klinck"],"pdf_url":"https://arxiv.org/pdf/2307.06292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10548v3","updated":"2023-07-12T15:40:14Z","published":"2023-06-18T12:56:46Z","title":"MARBLE: Music Audio Representation Benchmark for Universal Evaluation","summary":"  In the era of extensive intersection between art and Artificial Intelligence\n(AI), such as image generation and fiction co-creation, AI for music remains\nrelatively nascent, particularly in music understanding. This is evident in the\nlimited work on deep music representations, the scarcity of large-scale\ndatasets, and the absence of a universal and community-driven benchmark. To\naddress this issue, we introduce the Music Audio Representation Benchmark for\nuniversaL Evaluation, termed MARBLE. It aims to provide a benchmark for various\nMusic Information Retrieval (MIR) tasks by defining a comprehensive taxonomy\nwith four hierarchy levels, including acoustic, performance, score, and\nhigh-level description. We then establish a unified protocol based on 14 tasks\non 8 public-available datasets, providing a fair and standard assessment of\nrepresentations of all open-sourced pre-trained models developed on music\nrecordings as baselines. Besides, MARBLE offers an easy-to-use, extendable, and\nreproducible suite for the community, with a clear statement on copyright\nissues on datasets. Results suggest recently proposed large-scale pre-trained\nmusical language models perform the best in most tasks, with room for further\nimprovement. The leaderboard and toolkit repository are published at\nhttps://marble-bm.shef.ac.uk to promote future music AI research.\n","authors":["Ruibin Yuan","Yinghao Ma","Yizhi Li","Ge Zhang","Xingran Chen","Hanzhi Yin","Le Zhuo","Yiqi Liu","Jiawen Huang","Zeyue Tian","Binyue Deng","Ningzhi Wang","Chenghua Lin","Emmanouil Benetos","Anton Ragni","Norbert Gyenge","Roger Dannenberg","Wenhu Chen","Gus Xia","Wei Xue","Si Liu","Shi Wang","Ruibo Liu","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2306.10548v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06181v1","updated":"2023-07-12T14:12:19Z","published":"2023-07-12T14:12:19Z","title":"B-CLEAN-SC: CLEAN-SC for broadband sources","summary":"  This paper presents B-CLEAN-SC, a variation of CLEAN-SC for broadband\nsources. Opposed to CLEAN-SC, which ``deconvolves'' the beamforming map for\neach frequency individually, B-CLEAN-SC processes frequency intervals. Instead\nof performing a deconvolution iteration at the location of the maximum level,\nB-CLEAN-SC performs it at the location of the over-frequency-averaged maximum\nto improve the location estimation. The method is validated and compared to\nstandard CLEAN-SC on synthetic cases, and real-world experiments, for broad-\nand narrowband sources. It improves the source reconstruction at low and high\nfrequencies and suppresses noise, while it only increases the need for memory\nbut not computational effort.\n","authors":["Armin Goudarzi"],"pdf_url":"https://arxiv.org/pdf/2307.06181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01429v4","updated":"2023-07-12T12:58:41Z","published":"2022-03-01T15:56:13Z","title":"SMTNet: Hierarchical cavitation intensity recognition based on sub-main\n  transfer network","summary":"  With the rapid development of smart manufacturing, data-driven machinery\nhealth management has been of growing attention. In situations where some\nclasses are more difficult to be distinguished compared to others and where\nclasses might be organised in a hierarchy of categories, current DL methods can\nnot work well. In this study, a novel hierarchical cavitation intensity\nrecognition framework using Sub-Main Transfer Network, termed SMTNet, is\nproposed to classify acoustic signals of valve cavitation. SMTNet model outputs\nmultiple predictions ordered from coarse to fine along a network corresponding\nto a hierarchy of target cavitation states. Firstly, a data augmentation method\nbased on Sliding Window with Fast Fourier Transform (Swin-FFT) is developed to\nsolve few-shot problem. Secondly, a 1-D double hierarchical residual block (1-D\nDHRB) is presented to capture sensitive features of the frequency domain valve\nacoustic signals. Thirdly, hierarchical multi-label tree is proposed to assist\nthe embedding of the semantic structure of target cavitation states into\nSMTNet. Fourthly, experience filtering mechanism is proposed to fully learn a\nprior knowledge of cavitation detection model. Finally, SMTNet has been\nevaluated on two cavitation datasets without noise (Dataset 1 and Dataset 2),\nand one cavitation dataset with real noise (Dataset 3) provided by SAMSON AG\n(Frankfurt). The prediction accurcies of SMTNet for cavitation intensity\nrecognition are as high as 95.32%, 97.16% and 100%, respectively. At the same\ntime, the testing accuracies of SMTNet for cavitation detection are as high as\n97.02%, 97.64% and 100%. In addition, SMTNet has also been tested for different\nfrequencies of samples and has achieved excellent results of the highest\nfrequency of samples of mobile phones.\n","authors":["Yu Sha","Johannes Faber","Shuiping Gou","Bo Liu","Wei Li","Stefan Schramm","Horst Stoecker","Thomas Steckenreiter","Domagoj Vnucec","Nadine Wetzstein","Andreas Widl","Kai Zhou"],"pdf_url":"https://arxiv.org/pdf/2203.01429v4.pdf","comment":"we need update this paper"},{"id":"http://arxiv.org/abs/2211.00923v3","updated":"2023-07-12T12:28:56Z","published":"2022-11-02T07:13:30Z","title":"SpeechBlender: Speech Augmentation Framework for Mispronunciation Data\n  Generation","summary":"  The lack of labeled second language (L2) speech data is a major challenge in\ndesigning mispronunciation detection models. We introduce SpeechBlender - a\nfine-grained data augmentation pipeline for generating mispronunciation errors\nto overcome such data scarcity. The SpeechBlender utilizes varieties of masks\nto target different regions of phonetic units, and use the mixing factors to\nlinearly interpolate raw speech signals while augmenting pronunciation. The\nmasks facilitate smooth blending of the signals, generating more effective\nsamples than the `Cut/Paste' method. Our proposed technique achieves\nstate-of-the-art results, with Speechocean762, on ASR dependent\nmispronunciation detection models at phoneme level, with a 2.0% gain in Pearson\nCorrelation Coefficient (PCC) compared to the previous state-of-the-art [1].\nAdditionally, we demonstrate a 5.0% improvement at the phoneme level compared\nto our baseline. We also observed a 4.6% increase in F1-score with Arabic\nAraVoiceL2 testset.\n","authors":["Yassine El Kheir","Shammur Absar Chowdhury","Ahmed Ali","Hamdy Mubarak","Shazia Afzal"],"pdf_url":"https://arxiv.org/pdf/2211.00923v3.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2307.03544v2","updated":"2023-07-12T12:15:32Z","published":"2023-07-07T12:20:56Z","title":"Roman Numeral Analysis with Graph Neural Networks: Onset-wise\n  Predictions from Note-wise Features","summary":"  Roman Numeral analysis is the important task of identifying chords and their\nfunctional context in pieces of tonal music. This paper presents a new approach\nto automatic Roman Numeral analysis in symbolic music. While existing\ntechniques rely on an intermediate lossy representation of the score, we\npropose a new method based on Graph Neural Networks (GNNs) that enable the\ndirect description and processing of each individual note in the score. The\nproposed architecture can leverage notewise features and interdependencies\nbetween notes but yield onset-wise representation by virtue of our novel edge\ncontraction algorithm. Our results demonstrate that ChordGNN outperforms\nexisting state-of-the-art models, achieving higher accuracy in Roman Numeral\nanalysis on the reference datasets. In addition, we investigate variants of our\nmodel using proposed techniques such as NADE, and post-processing of the chord\npredictions. The full source code for this work is available at\nhttps://github.com/manoskary/chordgnn\n","authors":["Emmanouil Karystinaios","Gerhard Widmer"],"pdf_url":"https://arxiv.org/pdf/2307.03544v2.pdf","comment":"In Proceedings of the 24th Conference of the International Society\n  for Music Information Retrieval (ISMIR 2023), Milan, Italy"},{"id":"http://arxiv.org/abs/2307.06090v1","updated":"2023-07-12T11:27:40Z","published":"2023-07-12T11:27:40Z","title":"Can Large Language Models Aid in Annotating Speech Emotional Data?\n  Uncovering New Frontiers","summary":"  Despite recent advancements in speech emotion recognition (SER) models,\nstate-of-the-art deep learning (DL) approaches face the challenge of the\nlimited availability of annotated data. Large language models (LLMs) have\nrevolutionised our understanding of natural language, introducing emergent\nproperties that broaden comprehension in language, speech, and vision. This\npaper examines the potential of LLMs to annotate abundant speech data, aiming\nto enhance the state-of-the-art in SER. We evaluate this capability across\nvarious settings using publicly available speech emotion classification\ndatasets. Leveraging ChatGPT, we experimentally demonstrate the promising role\nof LLMs in speech emotion data annotation. Our evaluation encompasses\nsingle-shot and few-shots scenarios, revealing performance variability in SER.\nNotably, we achieve improved results through data augmentation, incorporating\nChatGPT-annotated samples into existing datasets. Our work uncovers new\nfrontiers in speech emotion classification, highlighting the increasing\nsignificance of LLMs in this field moving forward.\n","authors":["Siddique Latif","Muhammad Usama","Mohammad Ibrahim Malik","Björn W. Schuller"],"pdf_url":"https://arxiv.org/pdf/2307.06090v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2307.06040v1","updated":"2023-07-12T09:35:16Z","published":"2023-07-12T09:35:16Z","title":"Rhythm Modeling for Voice Conversion","summary":"  Voice conversion aims to transform source speech into a different target\nvoice. However, typical voice conversion systems do not account for rhythm,\nwhich is an important factor in the perception of speaker identity. To bridge\nthis gap, we introduce Urhythmic-an unsupervised method for rhythm conversion\nthat does not require parallel data or text transcriptions. Using\nself-supervised representations, we first divide source audio into segments\napproximating sonorants, obstruents, and silences. Then we model rhythm by\nestimating speaking rate or the duration distribution of each segment type.\nFinally, we match the target speaking rate or rhythm by time-stretching the\nspeech segments. Experiments show that Urhythmic outperforms existing\nunsupervised methods in terms of quality and prosody. Code and checkpoints:\nhttps://github.com/bshall/urhythmic. Audio demo page:\nhttps://ubisoft-laforge.github.io/speech/urhythmic.\n","authors":["Benjamin van Niekerk","Marc-André Carbonneau","Herman Kamper"],"pdf_url":"https://arxiv.org/pdf/2307.06040v1.pdf","comment":"5 pages, 4 figures, 4 tables, submitted to IEEE Signal Processing\n  Letters"},{"id":"http://arxiv.org/abs/2307.05956v1","updated":"2023-07-12T07:00:12Z","published":"2023-07-12T07:00:12Z","title":"Language-Routing Mixture of Experts for Multilingual and Code-Switching\n  Speech Recognition","summary":"  Multilingual speech recognition for both monolingual and code-switching\nspeech is a challenging task. Recently, based on the Mixture of Experts (MoE),\nmany works have made good progress in multilingual and code-switching ASR, but\npresent huge computational complexity with the increase of supported languages.\nIn this work, we propose a computation-efficient network named Language-Routing\nMixture of Experts (LR-MoE) for multilingual and code-switching ASR. LR-MoE\nextracts language-specific representations through the Mixture of Language\nExperts (MLE), which is guided to learn by a frame-wise language routing\nmechanism. The weight-shared frame-level language identification (LID) network\nis jointly trained as the shared pre-router of each MoE layer. Experiments show\nthat the proposed method significantly improves multilingual and code-switching\nspeech recognition performances over baseline with comparable computational\nefficiency.\n","authors":["Wenxuan Wang","Guodong Ma","Yuke Li","Binbin Du"],"pdf_url":"https://arxiv.org/pdf/2307.05956v1.pdf","comment":"To appear in Proc. INTERSPEECH 2023, August 20-24, 2023, Dublin,\n  Ireland"},{"id":"http://arxiv.org/abs/2306.05320v3","updated":"2023-07-12T04:41:47Z","published":"2023-06-08T16:13:20Z","title":"KIT's Multilingual Speech Translation System for IWSLT 2023","summary":"  Many existing speech translation benchmarks focus on native-English speech in\nhigh-quality recording conditions, which often do not match the conditions in\nreal-life use-cases. In this paper, we describe our speech translation system\nfor the multilingual track of IWSLT 2023, which evaluates translation quality\non scientific conference talks. The test condition features accented input\nspeech and terminology-dense contents. The task requires translation into 10\nlanguages of varying amounts of resources. In absence of training data from the\ntarget domain, we use a retrieval-based approach (kNN-MT) for effective\nadaptation (+0.8 BLEU for speech translation). We also use adapters to easily\nintegrate incremental training data from data augmentation, and show that it\nmatches the performance of re-training. We observe that cascaded systems are\nmore easily adaptable towards specific target domains, due to their separate\nmodules. Our cascaded speech system substantially outperforms its end-to-end\ncounterpart on scientific talk translation, although their performance remains\nsimilar on TED talks.\n","authors":["Danni Liu","Thai Binh Nguyen","Sai Koneru","Enes Yavuz Ugan","Ngoc-Quan Pham","Tuan-Nam Nguyen","Tu Anh Dinh","Carlos Mullov","Alexander Waibel","Jan Niehues"],"pdf_url":"https://arxiv.org/pdf/2306.05320v3.pdf","comment":"IWSLT 2023"},{"id":"http://arxiv.org/abs/2307.06385v1","updated":"2023-07-12T18:13:58Z","published":"2023-07-12T18:13:58Z","title":"Temporal Label-Refinement for Weakly-Supervised Audio-Visual Event\n  Localization","summary":"  Audio-Visual Event Localization (AVEL) is the task of temporally localizing\nand classifying \\emph{audio-visual events}, i.e., events simultaneously visible\nand audible in a video. In this paper, we solve AVEL in a weakly-supervised\nsetting, where only video-level event labels (their presence/absence, but not\ntheir locations in time) are available as supervision for training. Our idea is\nto use a base model to estimate labels on the training data at a finer temporal\nresolution than at the video level and re-train the model with these labels.\nI.e., we determine the subset of labels for each \\emph{slice} of frames in a\ntraining video by (i) replacing the frames outside the slice with those from a\nsecond video having no overlap in video-level labels, and (ii) feeding this\nsynthetic video into the base model to extract labels for just the slice in\nquestion. To handle the out-of-distribution nature of our synthetic videos, we\npropose an auxiliary objective for the base model that induces more reliable\npredictions of the localized event labels as desired. Our three-stage pipeline\noutperforms several existing AVEL methods with no architectural changes and\nimproves performance on a related weakly-supervised task as well.\n","authors":["Kalyan Ramakrishnan"],"pdf_url":"https://arxiv.org/pdf/2307.06385v1.pdf","comment":null}],"Audio and Speech Processing":[{"id":"http://arxiv.org/abs/2305.12493v5","updated":"2023-07-12T17:41:53Z","published":"2023-05-21T16:08:04Z","title":"Contextualized End-to-End Speech Recognition with Contextual Phrase\n  Prediction Network","summary":"  Contextual information plays a crucial role in speech recognition\ntechnologies and incorporating it into the end-to-end speech recognition models\nhas drawn immense interest recently. However, previous deep bias methods lacked\nexplicit supervision for bias tasks. In this study, we introduce a contextual\nphrase prediction network for an attention-based deep bias method. This network\npredicts context phrases in utterances using contextual embeddings and\ncalculates bias loss to assist in the training of the contextualized model. Our\nmethod achieved a significant word error rate (WER) reduction across various\nend-to-end speech recognition models. Experiments on the LibriSpeech corpus\nshow that our proposed model obtains a 12.1% relative WER improvement over the\nbaseline model, and the WER of the context phrases decreases relatively by\n40.5%. Moreover, by applying a context phrase filtering strategy, we also\neffectively eliminate the WER degradation when using a larger biasing list.\n","authors":["Kaixun Huang","Ao Zhang","Zhanheng Yang","Pengcheng Guo","Bingshen Mu","Tianyi Xu","Lei Xie"],"pdf_url":"https://arxiv.org/pdf/2305.12493v5.pdf","comment":"Accepted by interspeech2023"},{"id":"http://arxiv.org/abs/2307.04686v2","updated":"2023-07-12T17:06:41Z","published":"2023-07-10T16:42:03Z","title":"VampNet: Music Generation via Masked Acoustic Token Modeling","summary":"  We introduce VampNet, a masked acoustic token modeling approach to music\nsynthesis, compression, inpainting, and variation. We use a variable masking\nschedule during training which allows us to sample coherent music from the\nmodel by applying a variety of masking approaches (called prompts) during\ninference. VampNet is non-autoregressive, leveraging a bidirectional\ntransformer architecture that attends to all tokens in a forward pass. With\njust 36 sampling passes, VampNet can generate coherent high-fidelity musical\nwaveforms. We show that by prompting VampNet in various ways, we can apply it\nto tasks like music compression, inpainting, outpainting, continuation, and\nlooping with variation (vamping). Appropriately prompted, VampNet is capable of\nmaintaining style, genre, instrumentation, and other high-level aspects of the\nmusic. This flexible prompting capability makes VampNet a powerful music\nco-creation tool. Code and audio samples are available online.\n","authors":["Hugo Flores Garcia","Prem Seetharaman","Rithesh Kumar","Bryan Pardo"],"pdf_url":"https://arxiv.org/pdf/2307.04686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06292v1","updated":"2023-07-12T16:39:02Z","published":"2023-07-12T16:39:02Z","title":"Feature Embeddings from Large-Scale Acoustic Bird Classifiers Enable\n  Few-Shot Transfer Learning","summary":"  Automated bioacoustic analysis aids understanding and protection of both\nmarine and terrestrial animals and their habitats across extensive\nspatiotemporal scales, and typically involves analyzing vast collections of\nacoustic data. With the advent of deep learning models, classification of\nimportant signals from these datasets has markedly improved. These models power\ncritical data analyses for research and decision-making in biodiversity\nmonitoring, animal behaviour studies, and natural resource management. However,\ndeep learning models are often data-hungry and require a significant amount of\nlabeled training data to perform well. While sufficient training data is\navailable for certain taxonomic groups (e.g., common bird species), many\nclasses (such as rare and endangered species, many non-bird taxa, and\ncall-type), lack enough data to train a robust model from scratch. This study\ninvestigates the utility of feature embeddings extracted from large-scale audio\nclassification models to identify bioacoustic classes other than the ones these\nmodels were originally trained on. We evaluate models on diverse datasets,\nincluding different bird calls and dialect types, bat calls, marine mammals\ncalls, and amphibians calls. The embeddings extracted from the models trained\non bird vocalization data consistently allowed higher quality classification\nthan the embeddings trained on general audio datasets. The results of this\nstudy indicate that high-quality feature embeddings from large-scale acoustic\nbird classifiers can be harnessed for few-shot transfer learning, enabling the\nlearning of new classes from a limited quantity of training data. Our findings\nreveal the potential for efficient analyses of novel bioacoustic tasks, even in\nscenarios where available training data is limited to a few samples.\n","authors":["Burooj Ghani","Tom Denton","Stefan Kahl","Holger Klinck"],"pdf_url":"https://arxiv.org/pdf/2307.06292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04842v2","updated":"2023-07-12T16:03:46Z","published":"2023-07-10T18:21:48Z","title":"Predicting Tuberculosis from Real-World Cough Audio Recordings and\n  Metadata","summary":"  Tuberculosis (TB) is an infectious disease caused by the bacterium\nMycobacterium tuberculosis and primarily affects the lungs, as well as other\nbody parts. TB is spread through the air when an infected person coughs,\nsneezes, or talks. Medical doctors diagnose TB in patients via clinical\nexaminations and specialized tests. However, coughing is a common symptom of\nrespiratory diseases such as TB. Literature suggests that cough sounds coming\nfrom different respiratory diseases can be distinguished by both medical\ndoctors and computer algorithms. Therefore, cough recordings associated with\npatients with and without TB seems to be a reasonable avenue of investigation.\nIn this work, we utilize a very large dataset of TB and non-TB cough audio\nrecordings obtained from the south-east of Africa, India, and the south-east of\nAsia using a fully automated phone-based application (Hyfe), without manual\nannotation. We fit statistical classifiers based on spectral and time domain\nfeatures with and without clinical metadata. A stratified grouped\ncross-validation approach shows that an average Area Under Curve (AUC) of\napproximately 0.70 $\\pm$ 0.05 both for a cough-level and a participant-level\nclassification can be achieved using cough sounds alone. The addition of\ndemographic and clinical factors increases performance, resulting in an average\nAUC of approximately 0.81 $\\pm$ 0.05. Our results suggest mobile phone-based\napplications that integrate clinical symptoms and cough sound analysis could\nhelp community health workers and, most importantly, health service programs to\nimprove TB case-finding efforts while reducing costs, which could substantially\nimprove public health.\n","authors":["George P. Kafentzis","Stephane Tetsing","Joe Brew","Lola Jover","Mindaugas Galvosas","Carlos Chaccour","Peter M. Small"],"pdf_url":"https://arxiv.org/pdf/2307.04842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10548v3","updated":"2023-07-12T15:40:14Z","published":"2023-06-18T12:56:46Z","title":"MARBLE: Music Audio Representation Benchmark for Universal Evaluation","summary":"  In the era of extensive intersection between art and Artificial Intelligence\n(AI), such as image generation and fiction co-creation, AI for music remains\nrelatively nascent, particularly in music understanding. This is evident in the\nlimited work on deep music representations, the scarcity of large-scale\ndatasets, and the absence of a universal and community-driven benchmark. To\naddress this issue, we introduce the Music Audio Representation Benchmark for\nuniversaL Evaluation, termed MARBLE. It aims to provide a benchmark for various\nMusic Information Retrieval (MIR) tasks by defining a comprehensive taxonomy\nwith four hierarchy levels, including acoustic, performance, score, and\nhigh-level description. We then establish a unified protocol based on 14 tasks\non 8 public-available datasets, providing a fair and standard assessment of\nrepresentations of all open-sourced pre-trained models developed on music\nrecordings as baselines. Besides, MARBLE offers an easy-to-use, extendable, and\nreproducible suite for the community, with a clear statement on copyright\nissues on datasets. Results suggest recently proposed large-scale pre-trained\nmusical language models perform the best in most tasks, with room for further\nimprovement. The leaderboard and toolkit repository are published at\nhttps://marble-bm.shef.ac.uk to promote future music AI research.\n","authors":["Ruibin Yuan","Yinghao Ma","Yizhi Li","Ge Zhang","Xingran Chen","Hanzhi Yin","Le Zhuo","Yiqi Liu","Jiawen Huang","Zeyue Tian","Binyue Deng","Ningzhi Wang","Chenghua Lin","Emmanouil Benetos","Anton Ragni","Norbert Gyenge","Roger Dannenberg","Wenhu Chen","Gus Xia","Wei Xue","Si Liu","Shi Wang","Ruibo Liu","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2306.10548v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06181v1","updated":"2023-07-12T14:12:19Z","published":"2023-07-12T14:12:19Z","title":"B-CLEAN-SC: CLEAN-SC for broadband sources","summary":"  This paper presents B-CLEAN-SC, a variation of CLEAN-SC for broadband\nsources. Opposed to CLEAN-SC, which ``deconvolves'' the beamforming map for\neach frequency individually, B-CLEAN-SC processes frequency intervals. Instead\nof performing a deconvolution iteration at the location of the maximum level,\nB-CLEAN-SC performs it at the location of the over-frequency-averaged maximum\nto improve the location estimation. The method is validated and compared to\nstandard CLEAN-SC on synthetic cases, and real-world experiments, for broad-\nand narrowband sources. It improves the source reconstruction at low and high\nfrequencies and suppresses noise, while it only increases the need for memory\nbut not computational effort.\n","authors":["Armin Goudarzi"],"pdf_url":"https://arxiv.org/pdf/2307.06181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01429v4","updated":"2023-07-12T12:58:41Z","published":"2022-03-01T15:56:13Z","title":"SMTNet: Hierarchical cavitation intensity recognition based on sub-main\n  transfer network","summary":"  With the rapid development of smart manufacturing, data-driven machinery\nhealth management has been of growing attention. In situations where some\nclasses are more difficult to be distinguished compared to others and where\nclasses might be organised in a hierarchy of categories, current DL methods can\nnot work well. In this study, a novel hierarchical cavitation intensity\nrecognition framework using Sub-Main Transfer Network, termed SMTNet, is\nproposed to classify acoustic signals of valve cavitation. SMTNet model outputs\nmultiple predictions ordered from coarse to fine along a network corresponding\nto a hierarchy of target cavitation states. Firstly, a data augmentation method\nbased on Sliding Window with Fast Fourier Transform (Swin-FFT) is developed to\nsolve few-shot problem. Secondly, a 1-D double hierarchical residual block (1-D\nDHRB) is presented to capture sensitive features of the frequency domain valve\nacoustic signals. Thirdly, hierarchical multi-label tree is proposed to assist\nthe embedding of the semantic structure of target cavitation states into\nSMTNet. Fourthly, experience filtering mechanism is proposed to fully learn a\nprior knowledge of cavitation detection model. Finally, SMTNet has been\nevaluated on two cavitation datasets without noise (Dataset 1 and Dataset 2),\nand one cavitation dataset with real noise (Dataset 3) provided by SAMSON AG\n(Frankfurt). The prediction accurcies of SMTNet for cavitation intensity\nrecognition are as high as 95.32%, 97.16% and 100%, respectively. At the same\ntime, the testing accuracies of SMTNet for cavitation detection are as high as\n97.02%, 97.64% and 100%. In addition, SMTNet has also been tested for different\nfrequencies of samples and has achieved excellent results of the highest\nfrequency of samples of mobile phones.\n","authors":["Yu Sha","Johannes Faber","Shuiping Gou","Bo Liu","Wei Li","Stefan Schramm","Horst Stoecker","Thomas Steckenreiter","Domagoj Vnucec","Nadine Wetzstein","Andreas Widl","Kai Zhou"],"pdf_url":"https://arxiv.org/pdf/2203.01429v4.pdf","comment":"we need update this paper"},{"id":"http://arxiv.org/abs/2211.00923v3","updated":"2023-07-12T12:28:56Z","published":"2022-11-02T07:13:30Z","title":"SpeechBlender: Speech Augmentation Framework for Mispronunciation Data\n  Generation","summary":"  The lack of labeled second language (L2) speech data is a major challenge in\ndesigning mispronunciation detection models. We introduce SpeechBlender - a\nfine-grained data augmentation pipeline for generating mispronunciation errors\nto overcome such data scarcity. The SpeechBlender utilizes varieties of masks\nto target different regions of phonetic units, and use the mixing factors to\nlinearly interpolate raw speech signals while augmenting pronunciation. The\nmasks facilitate smooth blending of the signals, generating more effective\nsamples than the `Cut/Paste' method. Our proposed technique achieves\nstate-of-the-art results, with Speechocean762, on ASR dependent\nmispronunciation detection models at phoneme level, with a 2.0% gain in Pearson\nCorrelation Coefficient (PCC) compared to the previous state-of-the-art [1].\nAdditionally, we demonstrate a 5.0% improvement at the phoneme level compared\nto our baseline. We also observed a 4.6% increase in F1-score with Arabic\nAraVoiceL2 testset.\n","authors":["Yassine El Kheir","Shammur Absar Chowdhury","Ahmed Ali","Hamdy Mubarak","Shazia Afzal"],"pdf_url":"https://arxiv.org/pdf/2211.00923v3.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2307.06090v1","updated":"2023-07-12T11:27:40Z","published":"2023-07-12T11:27:40Z","title":"Can Large Language Models Aid in Annotating Speech Emotional Data?\n  Uncovering New Frontiers","summary":"  Despite recent advancements in speech emotion recognition (SER) models,\nstate-of-the-art deep learning (DL) approaches face the challenge of the\nlimited availability of annotated data. Large language models (LLMs) have\nrevolutionised our understanding of natural language, introducing emergent\nproperties that broaden comprehension in language, speech, and vision. This\npaper examines the potential of LLMs to annotate abundant speech data, aiming\nto enhance the state-of-the-art in SER. We evaluate this capability across\nvarious settings using publicly available speech emotion classification\ndatasets. Leveraging ChatGPT, we experimentally demonstrate the promising role\nof LLMs in speech emotion data annotation. Our evaluation encompasses\nsingle-shot and few-shots scenarios, revealing performance variability in SER.\nNotably, we achieve improved results through data augmentation, incorporating\nChatGPT-annotated samples into existing datasets. Our work uncovers new\nfrontiers in speech emotion classification, highlighting the increasing\nsignificance of LLMs in this field moving forward.\n","authors":["Siddique Latif","Muhammad Usama","Mohammad Ibrahim Malik","Björn W. Schuller"],"pdf_url":"https://arxiv.org/pdf/2307.06090v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2307.06040v1","updated":"2023-07-12T09:35:16Z","published":"2023-07-12T09:35:16Z","title":"Rhythm Modeling for Voice Conversion","summary":"  Voice conversion aims to transform source speech into a different target\nvoice. However, typical voice conversion systems do not account for rhythm,\nwhich is an important factor in the perception of speaker identity. To bridge\nthis gap, we introduce Urhythmic-an unsupervised method for rhythm conversion\nthat does not require parallel data or text transcriptions. Using\nself-supervised representations, we first divide source audio into segments\napproximating sonorants, obstruents, and silences. Then we model rhythm by\nestimating speaking rate or the duration distribution of each segment type.\nFinally, we match the target speaking rate or rhythm by time-stretching the\nspeech segments. Experiments show that Urhythmic outperforms existing\nunsupervised methods in terms of quality and prosody. Code and checkpoints:\nhttps://github.com/bshall/urhythmic. Audio demo page:\nhttps://ubisoft-laforge.github.io/speech/urhythmic.\n","authors":["Benjamin van Niekerk","Marc-André Carbonneau","Herman Kamper"],"pdf_url":"https://arxiv.org/pdf/2307.06040v1.pdf","comment":"5 pages, 4 figures, 4 tables, submitted to IEEE Signal Processing\n  Letters"},{"id":"http://arxiv.org/abs/2307.05956v1","updated":"2023-07-12T07:00:12Z","published":"2023-07-12T07:00:12Z","title":"Language-Routing Mixture of Experts for Multilingual and Code-Switching\n  Speech Recognition","summary":"  Multilingual speech recognition for both monolingual and code-switching\nspeech is a challenging task. Recently, based on the Mixture of Experts (MoE),\nmany works have made good progress in multilingual and code-switching ASR, but\npresent huge computational complexity with the increase of supported languages.\nIn this work, we propose a computation-efficient network named Language-Routing\nMixture of Experts (LR-MoE) for multilingual and code-switching ASR. LR-MoE\nextracts language-specific representations through the Mixture of Language\nExperts (MLE), which is guided to learn by a frame-wise language routing\nmechanism. The weight-shared frame-level language identification (LID) network\nis jointly trained as the shared pre-router of each MoE layer. Experiments show\nthat the proposed method significantly improves multilingual and code-switching\nspeech recognition performances over baseline with comparable computational\nefficiency.\n","authors":["Wenxuan Wang","Guodong Ma","Yuke Li","Binbin Du"],"pdf_url":"https://arxiv.org/pdf/2307.05956v1.pdf","comment":"To appear in Proc. INTERSPEECH 2023, August 20-24, 2023, Dublin,\n  Ireland"},{"id":"http://arxiv.org/abs/2307.06385v1","updated":"2023-07-12T18:13:58Z","published":"2023-07-12T18:13:58Z","title":"Temporal Label-Refinement for Weakly-Supervised Audio-Visual Event\n  Localization","summary":"  Audio-Visual Event Localization (AVEL) is the task of temporally localizing\nand classifying \\emph{audio-visual events}, i.e., events simultaneously visible\nand audible in a video. In this paper, we solve AVEL in a weakly-supervised\nsetting, where only video-level event labels (their presence/absence, but not\ntheir locations in time) are available as supervision for training. Our idea is\nto use a base model to estimate labels on the training data at a finer temporal\nresolution than at the video level and re-train the model with these labels.\nI.e., we determine the subset of labels for each \\emph{slice} of frames in a\ntraining video by (i) replacing the frames outside the slice with those from a\nsecond video having no overlap in video-level labels, and (ii) feeding this\nsynthetic video into the base model to extract labels for just the slice in\nquestion. To handle the out-of-distribution nature of our synthetic videos, we\npropose an auxiliary objective for the base model that induces more reliable\npredictions of the localized event labels as desired. Our three-stage pipeline\noutperforms several existing AVEL methods with no architectural changes and\nimproves performance on a related weakly-supervised task as well.\n","authors":["Kalyan Ramakrishnan"],"pdf_url":"https://arxiv.org/pdf/2307.06385v1.pdf","comment":null}],"Signal Processing":[{"id":"http://arxiv.org/abs/2307.06323v1","updated":"2023-07-12T17:40:21Z","published":"2023-07-12T17:40:21Z","title":"Information-Theoretically Private Federated Submodel Learning with\n  Storage Constrained Databases","summary":"  In federated submodel learning (FSL), a machine learning model is divided\ninto multiple submodels based on different types of data used for training.\nEach user involved in the training process only downloads and updates the\nsubmodel relevant to the user's local data, which significantly reduces the\ncommunication cost compared to classical federated learning (FL). However, the\nindex of the submodel updated by the user and the values of the updates reveal\ninformation about the user's private data. In order to guarantee\ninformation-theoretic privacy in FSL, the model is stored at multiple\nnon-colluding databases, and the user sends queries and updates to each\ndatabase in such a way that no information is revealed on the updating submodel\nindex or the values of the updates. In this work, we consider the practical\nscenario where the multiple non-colluding databases are allowed to have\narbitrary storage constraints. The goal of this work is to develop read-write\nschemes and storage mechanisms for FSL that efficiently utilize the available\nstorage in each database to store the submodel parameters in such a way that\nthe total communication cost is minimized while guaranteeing\ninformation-theoretic privacy of the updating submodel index and the values of\nthe updates. As the main result, we consider both heterogeneous and homogeneous\nstorage constrained databases, and propose private read-write and storage\nschemes for the two cases.\n","authors":["Sajani Vithana","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2307.06323v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2302.03670"},{"id":"http://arxiv.org/abs/2307.06310v1","updated":"2023-07-12T17:13:42Z","published":"2023-07-12T17:13:42Z","title":"Kriging-Based 3-D Spectrum Awareness for Radio Dynamic Zones Using\n  Aerial Spectrum Sensors","summary":"  Radio dynamic zones (RDZs) are geographical areas within which dedicated\nspectrum resources are monitored and controlled to enable the development and\ntesting of new spectrum technologies. Real-time spectrum awareness within an\nRDZ is critical for preventing interference with nearby incumbent users of the\nspectrum. In this paper, we consider a 3D RDZ scenario and propose to use\nunmanned aerial vehicles (UAVs) equipped with spectrum sensors to create and\nmaintain a 3D radio map of received signal power from different sources within\nthe RDZ. In particular, we introduce a 3D Kriging interpolation technique that\nuses realistic 3D correlation models of the signal power extracted from\nextensive measurements carried out at the NSF AERPAW platform. Using C-Band\nsignal measurements by a UAV at altitudes between 30 m-110 m, we first develop\nrealistic propagation models on air-to-ground path loss, shadowing, spatial\ncorrelation, and semi-variogram, while taking into account the knowledge of\nantenna radiation patterns and ground reflection. Subsequently, we generate a\n3D radio map of a signal source within the RDZ using the Kriging interpolation\nand evaluate its sensitivity to the number of measurements used and their\nspatial distribution. Our results show that the proposed 3D Kriging\ninterpolation technique provides significantly better radio maps when compared\nwith an approach that assumes perfect knowledge of path loss.\n","authors":["Sung Joon Maeng","Ozgur Ozdemir","Ismail Guvenc","Mihail L. Sichitiu"],"pdf_url":"https://arxiv.org/pdf/2307.06310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.00429v2","updated":"2023-07-12T14:03:17Z","published":"2023-04-30T09:12:11Z","title":"A Dynamic Obstacle Tracking Strategy for Proactive Handoffs in\n  Millimeter-wave Networks","summary":"  Stringent line-of-sight demands necessitated by the fast attenuating nature\nof millimeter waves (mmWaves) through obstacles pose one of the central\nproblems of next generation wireless networks. These mmWave links are easily\ndisrupted due to obstacles, including vehicles and pedestrians, which cause\ndegradation in link quality and even link failure. Dynamic obstacles are\nusually tracked by dedicated tracking hardware like RGB-D cameras, which\nusually have small ranges, and hence lead to prohibitively increased deployment\ncosts to achieve complete coverage of the deployment area. In this manuscript,\nwe propose an altogether different approach to track multiple dynamic obstacles\nin an mmWave network, solely based on short-term historical link failure\ninformation, without resorting to any dedicated tracking hardware. After\nproving that the said problem is NP-complete, we employ a greedy set-cover\nbased approach to solve it. Using the obtained trajectories, we perform\nproactive handoffs for at-risk links. We compare our approach with an RGB-D\ncamera-based approach and show that our approach provides better tracking and\nhandoff performances when the camera coverage is low to moderate, which is\noften the case in real deployment scenarios.\n","authors":["Rathindra Nath Dutta","Subhojit Sarkar","Sasthi C. Ghosh"],"pdf_url":"https://arxiv.org/pdf/2305.00429v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10841v2","updated":"2023-07-12T13:56:10Z","published":"2022-08-23T09:46:33Z","title":"Network Slicing for eMBB, URLLC, and mMTC: An Uplink Rate-Splitting\n  Multiple Access Approach","summary":"  There are three generic services in 5G: enhanced mobile broadband (eMBB),\nultra-reliable low-latency communications (URLLC), and massive machine-type\ncommunications (mMTC). To guarantee the performance of heterogeneous services,\nnetwork slicing is proposed to allocate resources to different services.\nNetwork slicing is typically done in an orthogonal multiple access (OMA)\nfashion, which means different services are allocated non-interfering\nresources. However, as the number of users grows, OMA-based slicing is not\nalways optimal, and a non-orthogonal scheme may achieve a better performance.\nThis work aims to analyse the performances of different slicing schemes in\nuplink, and a promising scheme based on rate-splitting multiple access (RSMA)\nis studied. RSMA can provide a more flexible decoding order and theoretically\nhas the largest achievable rate region than OMA and non-orthogonal multiple\naccess (NOMA) without time-sharing. Hence, RSMA has the potential to increase\nthe rate of users requiring different services. In addition, it is not\nnecessary to decode the two split streams of one user successively, so RSMA\nlets suitable users split messages and designs an appropriate decoding order\ndepending on the service requirements. This work shows that for network slicing\nRSMA can outperform NOMA counterpart, and obtain significant gains over OMA in\nsome region.\n","authors":["Yuanwen Liu","Bruno Clerckx","Petar Popovski"],"pdf_url":"https://arxiv.org/pdf/2208.10841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06162v1","updated":"2023-07-12T13:42:09Z","published":"2023-07-12T13:42:09Z","title":"Deep Generative Models for Physiological Signals: A Systematic\n  Literature Review","summary":"  In this paper, we present a systematic literature review on deep generative\nmodels for physiological signals, particularly electrocardiogram,\nelectroencephalogram, photoplethysmogram and electromyogram. Compared to the\nexisting review papers, we present the first review that summarizes the recent\nstate-of-the-art deep generative models. By analysing the state-of-the-art\nresearch related to deep generative models along with their main applications\nand challenges, this review contributes to the overall understanding of these\nmodels applied to physiological signals. Additionally, by highlighting the\nemployed evaluation protocol and the most used physiological databases, this\nreview facilitates the assessment and benchmarking of deep generative models.\n","authors":["Nour Neifar","Afef Mdhaffar","Achraf Ben-Hamadou","Mohamed Jmaiel"],"pdf_url":"https://arxiv.org/pdf/2307.06162v1.pdf","comment":"paper under review, 34 pages"},{"id":"http://arxiv.org/abs/2307.06138v1","updated":"2023-07-12T12:41:23Z","published":"2023-07-12T12:41:23Z","title":"In silico Ptychography of Lithium-ion Cathode Materials from Subsampled\n  4-D STEM Data","summary":"  High quality scanning transmission electron microscopy (STEM) data\nacquisition and analysis has become increasingly important due to the\ncommercial demand for investigating the properties of complex materials such as\nbattery cathodes; however, multidimensional techniques (such as 4-D STEM) which\ncan improve resolution and sample information are ultimately limited by the\nbeam-damage properties of the materials or the signal-to-noise ratio of the\nresult. subsampling offers a solution to this problem by retaining high signal,\nbut distributing the dose across the sample such that the damage can be\nreduced. It is for these reasons that we propose a method of subsampling for\n4-D STEM, which can take advantage of the redundancy within said data to\nrecover functionally identical results to the ground truth. We apply these\nideas to a simulated 4-D STEM data set of a LiMnO2 sample and we obtained high\nquality reconstruction of phase images using 12.5% subsampling.\n","authors":["Alex W. Robinson","Amirafshar Moshtaghpour","Jack Wells","Daniel Nicholls","Zoe Broad","Angus I. Kirkland","Beata L. Mehdi","Nigel D. Browning"],"pdf_url":"https://arxiv.org/pdf/2307.06138v1.pdf","comment":"3 pages, 2 figures"},{"id":"http://arxiv.org/abs/2307.06129v1","updated":"2023-07-12T12:33:49Z","published":"2023-07-12T12:33:49Z","title":"Channel Estimation for Beyond Diagonal Reconfigurable Intelligent\n  Surfaces with Group-Connected Architectures","summary":"  We study channel estimation for a beyond diagonal reconfigurable intelligent\nsurface (BD-RIS) aided multiple input single output system. We first describe\nthe channel estimation strategy based on the least square (LS) method, derive\nthe mean square error (MSE) of the LS estimator, and formulate the BD-RIS\ndesign problem that minimizes the estimation MSE with unique constraints\ninduced by group-connected architectures of BD-RIS. Then, we propose an\nefficient BD-RIS design which theoretically guarantees to achieve the MSE lower\nbound. Finally, we provide simulation results to verify the effectiveness of\nthe proposed channel estimation scheme.\n","authors":["Hongyu Li","Yumeng Zhang","Bruno Clerckx"],"pdf_url":"https://arxiv.org/pdf/2307.06129v1.pdf","comment":"5 pages, 2 figures, submitted to conference for publication"},{"id":"http://arxiv.org/abs/2302.13948v2","updated":"2023-07-12T12:19:10Z","published":"2023-02-27T16:49:35Z","title":"Supervised topological data analysis for MALDI mass spectrometry imaging\n  applications","summary":"  Background: Matrix-assisted laser desorption/ionization mass spectrometry\nimaging (MALDI MSI) displays significant potential for applications in cancer\nresearch, especially in tumor typing and subtyping. Lung cancer is the primary\ncause of tumor-related deaths, where the most lethal entities are\nadenocarcinoma (ADC) and squamous cell carcinoma (SqCC). Distinguishing between\nthese two common subtypes is crucial for therapy decisions and successful\npatient management.\n  Results: We propose a new algebraic topological framework, which obtains\nintrinsic information from MALDI data and transforms it to reflect topological\npersistence. Our framework offers two main advantages. Firstly, topological\npersistence aids in distinguishing the signal from noise. Secondly, it\ncompresses the MALDI data, saving storage space and optimizes computational\ntime for subsequent classification tasks. We present an algorithm that\nefficiently implements our topological framework, relying on a single tuning\nparameter. Afterwards, logistic regression and random forest classifiers are\nemployed on the extracted persistence features, thereby accomplishing an\nautomated tumor (sub-)typing process. To demonstrate the competitiveness of our\nproposed framework, we conduct experiments on a real-world MALDI dataset using\ncross-validation. Furthermore, we showcase the effectiveness of the single\ndenoising parameter by evaluating its performance on synthetic MALDI images\nwith varying levels of noise.\n  Conclusion: Our empirical experiments demonstrate that the proposed algebraic\ntopological framework successfully captures and leverages the intrinsic\nspectral information from MALDI data, leading to competitive results in\nclassifying lung cancer subtypes. Moreover, the frameworks ability to be\nfine-tuned for denoising highlights its versatility and potential for enhancing\ndata analysis in MALDI applications.\n","authors":["Gideon Klaila","Vladimir Vutov","Anastasios Stefanou"],"pdf_url":"https://arxiv.org/pdf/2302.13948v2.pdf","comment":"22 pages, 10 figures"},{"id":"http://arxiv.org/abs/2101.10870v2","updated":"2023-07-12T08:11:19Z","published":"2021-01-23T12:42:41Z","title":"B-HAR: an open-source baseline framework for in depth study of human\n  activity recognition datasets and workflows","summary":"  Human Activity Recognition (HAR), based on machine and deep learning\nalgorithms is considered one of the most promising technologies to monitor\nprofessional and daily life activities for different categories of people\n(e.g., athletes, elderly, kids, employers) in order to provide a variety of\nservices related, for example to well-being, empowering of technical\nperformances, prevention of risky situation, and educational purposes. However,\nthe analysis of the effectiveness and the efficiency of HAR methodologies\nsuffers from the lack of a standard workflow, which might represent the\nbaseline for the estimation of the quality of the developed pattern recognition\nmodels. This makes the comparison among different approaches a challenging\ntask. In addition, researchers can make mistakes that, when not detected,\ndefinitely affect the achieved results. To mitigate such issues, this paper\nproposes an open-source automatic and highly configurable framework, named\nB-HAR, for the definition, standardization, and development of a baseline\nframework in order to evaluate and compare HAR methodologies. It implements the\nmost popular data processing methods for data preparation and the most commonly\nused machine and deep learning pattern recognition models.\n","authors":["Florenc Demrozi","Cristian Turetta","Graziano Pravadelli"],"pdf_url":"https://arxiv.org/pdf/2101.10870v2.pdf","comment":"9 Pages, 3 Figures, 3 Tables, Link to B-HAR Library:\n  https://github.com/B-HAR-HumanActivityRecognition/B-HAR"},{"id":"http://arxiv.org/abs/2304.08697v2","updated":"2023-07-12T07:02:57Z","published":"2023-04-18T02:09:38Z","title":"Performance Analysis and Comparison of Non-ideal Wireless PBFT and RAFT\n  Consensus Networks in 6G Communications","summary":"  Due to advantages in security and privacy, blockchain is considered a key\nenabling technology to support 6G communications. Practical Byzantine Fault\nTolerance (PBFT) and RAFT are seen as the most applicable consensus mechanisms\n(CMs) in blockchain-enabled wireless networks. However, previous studies on\nPBFT and RAFT rarely consider the channel performance of the physical layer,\nsuch as path loss and channel fading, resulting in research results that are\nfar from real networks. Additionally, 6G communications will widely deploy\nhigh-frequency signals such as terahertz (THz) and millimeter wave (mmWave),\nwhile performances of PBFT and RAFT are still unknown when these signals are\ntransmitted in wireless PBFT or RAFT networks. Therefore, it is urgent to study\nthe performance of non-ideal wireless PBFT and RAFT networks with THz and\nmmWave signals, to better make PBFT and RAFT play a role in the 6G era. In this\npaper, we study and compare the performance of THz and mmWave signals in\nnon-ideal wireless PBFT and RAFT networks, considering Rayleigh Fading (RF) and\nclose-in Free Space (FS) reference distance path loss. Performance is evaluated\nby five metrics: consensus success rate, latency, throughput, reliability gain,\nand energy consumption. Meanwhile, we find and derive that there is a maximum\ndistance between two nodes that can make CMs inevitably successful, and it is\nnamed the active distance of CMs. The research results analyze the performance\nof non-ideal wireless PBFT and RAFT networks, and provide important references\nfor the future transmission of THz and mmWave signals in PBFT and RAFT\nnetworks.\n","authors":["Haoxiang Luo","Xiangyue Yang","Hongfang Yu","Gang Sun","Bo Lei","Mohsen Guizani"],"pdf_url":"https://arxiv.org/pdf/2304.08697v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2303.15759"},{"id":"http://arxiv.org/abs/2307.05944v1","updated":"2023-07-12T06:20:19Z","published":"2023-07-12T06:20:19Z","title":"A 137.5 TOPS/W SRAM Compute-in-Memory Macro with 9-b Memory\n  Cell-Embedded ADCs and Signal Margin Enhancement Techniques for AI Edge\n  Applications","summary":"  In this paper, we propose a high-precision SRAM-based CIM macro that can\nperform 4x4-bit MAC operations and yield 9-bit signed output. The inherent\ndischarge branches of SRAM cells are utilized to apply time-modulated MAC and\n9-bit ADC readout operations on two bit-line capacitors. The same principle is\nused for both MAC and A-to-D conversion ensuring high linearity and thus\nsupporting large number of analog MAC accumulations. The memory cell-embedded\nADC eliminates the use of separate ADCs and enhances energy and area\nefficiency. Additionally, two signal margin enhancement techniques, namely the\nMAC-folding and boosted-clipping schemes, are proposed to further improve the\nCIM computation accuracy.\n","authors":["Xiaomeng Wang","Fengshi Tian","Xizi Chen","Jiakun Zheng","Xuejiao Liu","Fengbin Tu","Jie Yang","Mohamad Sawan"," Kwang-Ting"," Cheng","Chi-Ying Tsui"],"pdf_url":"https://arxiv.org/pdf/2307.05944v1.pdf","comment":"Submitted to IEEE ASSCC 2023"},{"id":"http://arxiv.org/abs/2307.05925v1","updated":"2023-07-12T05:45:27Z","published":"2023-07-12T05:45:27Z","title":"A Tractable Statistical Representation of IFTR Fading with Applications","summary":"  The recently introduced independent fluctuating two-ray (IFTR) fading model,\nconsisting of two specular components fluctuating independently plus a diffuse\ncomponent, has proven to provide an excellent fit to different wireless\nenvironments, including the millimeter-wave band. However, the original\nformulations of the probability density function (PDF) and cumulative\ndistribution function (CDF) of this model are not applicable to all possible\nvalues of its defining parameters, and are given in terms of multifold\ngeneralized hypergeometric functions, which prevents their widespread use for\nthe derivation of performance metric expressions. In this paper we present a\nnew formulation of the IFTR model as a countable mixture of Gamma distributions\nwhich greatly facilitates the performance evaluation for this model in terms of\nthe metrics already known for the much simpler and widely used Nakagami-m\nfading. Additionally, a closed-form expression is presented for the generalized\nmoment generating function (GMGF), which permits to readily obtain all the\nmoments of the distribution of the model, as well as several relevant\nperformance metrics. Based on these new derivations, the IFTR model is\nevaluated for the average channel capacity, the outage probability with and\nwithout co-channel interference, and the bit error rate (BER), which are\nverified by Monte Carlo simulations.\n","authors":["Maryam Olyaee","Hadi Hashemi","Juan M. Romero-Jerez"],"pdf_url":"https://arxiv.org/pdf/2307.05925v1.pdf","comment":"This work was submitted to the IEEE for publication. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible"},{"id":"http://arxiv.org/abs/2307.05914v1","updated":"2023-07-12T04:43:59Z","published":"2023-07-12T04:43:59Z","title":"FIS-ONE: Floor Identification System with One Label for Crowdsourced RF\n  Signals","summary":"  Floor labels of crowdsourced RF signals are crucial for many smart-city\napplications, such as multi-floor indoor localization, geofencing, and robot\nsurveillance. To build a prediction model to identify the floor number of a new\nRF signal upon its measurement, conventional approaches using the crowdsourced\nRF signals assume that at least few labeled signal samples are available on\neach floor. In this work, we push the envelope further and demonstrate that it\nis technically feasible to enable such floor identification with only one\nfloor-labeled signal sample on the bottom floor while having the rest of signal\nsamples unlabeled.\n  We propose FIS-ONE, a novel floor identification system with only one labeled\nsample. FIS-ONE consists of two steps, namely signal clustering and cluster\nindexing. We first build a bipartite graph to model the RF signal samples and\nobtain a latent representation of each node (each signal sample) using our\nattention-based graph neural network model so that the RF signal samples can be\nclustered more accurately. Then, we tackle the problem of indexing the clusters\nwith proper floor labels, by leveraging the observation that signals from an\naccess point can be detected on different floors, i.e., signal spillover.\nSpecifically, we formulate a cluster indexing problem as a combinatorial\noptimization problem and show that it is equivalent to solving a traveling\nsalesman problem, whose (near-)optimal solution can be found efficiently. We\nhave implemented FIS-ONE and validated its effectiveness on the Microsoft\ndataset and in three large shopping malls. Our results show that FIS-ONE\noutperforms other baseline algorithms significantly, with up to 23% improvement\nin adjusted rand index and 25% improvement in normalized mutual information\nusing only one floor-labeled signal sample.\n","authors":["Weipeng Zhuo","Ka Ho Chiu","Jierun Chen","Ziqi Zhao","S. -H. Gary Chan","Sangtae Ha","Chul-Ho Lee"],"pdf_url":"https://arxiv.org/pdf/2307.05914v1.pdf","comment":"Accepted by IEEE ICDCS 2023"},{"id":"http://arxiv.org/abs/2307.05893v1","updated":"2023-07-12T03:48:26Z","published":"2023-07-12T03:48:26Z","title":"Deep Unrolling for Nonconvex Robust Principal Component Analysis","summary":"  We design algorithms for Robust Principal Component Analysis (RPCA) which\nconsists in decomposing a matrix into the sum of a low rank matrix and a sparse\nmatrix. We propose a deep unrolled algorithm based on an accelerated\nalternating projection algorithm which aims to solve RPCA in its nonconvex\nform. The proposed procedure combines benefits of deep neural networks and the\ninterpretability of the original algorithm and it automatically learns\nhyperparameters. We demonstrate the unrolled algorithm's effectiveness on\nsynthetic datasets and also on a face modeling problem, where it leads to both\nbetter numerical and visual performances.\n","authors":["Elizabeth Z. C. Tan","Caroline Chaux","Emmanuel Soubies","Vincent Y. F. Tan"],"pdf_url":"https://arxiv.org/pdf/2307.05893v1.pdf","comment":"7 pages, 3 figures; Accepted to the 2023 IEEE International Workshop\n  on Machine Learning for Signal Processing"},{"id":"http://arxiv.org/abs/2307.06401v1","updated":"2023-07-12T18:34:00Z","published":"2023-07-12T18:34:00Z","title":"Deterministic Multi-sensor Measurement-adaptive Birth using Labeled\n  Random Finite Sets","summary":"  Measurement-adaptive track initiation remains a critical design requirement\nof many practical multi-target tracking systems. For labeled random finite sets\nmulti-object filters, prior work has been established to construct a labeled\nmulti-object birth density using measurements from multiple sensors. A\ntruncation procedure has also been provided that leverages a stochastic Gibbs\nsampler to truncate the birth density for scalability. In this work, we\nintroduce a deterministic herded Gibbs sampling truncation solution for\nefficient multi-sensor adaptive track initialization. Removing the stochastic\nbehavior of the track initialization procedure without impacting average\ntracking performance enables a more robust tracking solution more suitable for\nsafety-critical applications. Simulation results for linear sensing scenarios\nare provided to verify performance.\n","authors":["Jennifer Bondarchuk","Anthony Trezza","Donald J. Bucci Jr"],"pdf_url":"https://arxiv.org/pdf/2307.06401v1.pdf","comment":"Accepted to the 2023 Proc. IEEE 26th Int. Conf. Inf. Fusion"},{"id":"http://arxiv.org/abs/2307.06380v1","updated":"2023-07-12T18:05:05Z","published":"2023-07-12T18:05:05Z","title":"Personalized Anomaly Detection in PPG Data using Representation Learning\n  and Biometric Identification","summary":"  Photoplethysmography (PPG) signals, typically acquired from wearable devices,\nhold significant potential for continuous fitness-health monitoring. In\nparticular, heart conditions that manifest in rare and subtle deviating heart\npatterns may be interesting. However, robust and reliable anomaly detection\nwithin these data remains a challenge due to the scarcity of labeled data and\nhigh inter-subject variability. This paper introduces a two-stage framework\nleveraging representation learning and personalization to improve anomaly\ndetection performance in PPG data. The proposed framework first employs\nrepresentation learning to transform the original PPG signals into a more\ndiscriminative and compact representation. We then apply three different\nunsupervised anomaly detection methods for movement detection and biometric\nidentification. We validate our approach using two different datasets in both\ngeneralized and personalized scenarios. The results show that representation\nlearning significantly improves anomaly detection performance while reducing\nthe high inter-subject variability. Personalized models further enhance anomaly\ndetection performance, underscoring the role of personalization in PPG-based\nfitness-health monitoring systems. The results from biometric identification\nshow that it's easier to distinguish a new user from one intended authorized\nuser than from a group of users. Overall, this study provides evidence of the\neffectiveness of representation learning and personalization for anomaly\ndetection in PPG data.\n","authors":["Ramin Ghorbani","Marcel J. T. Reinders","David M. J. Tax"],"pdf_url":"https://arxiv.org/pdf/2307.06380v1.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2307.06334v1","updated":"2023-07-12T17:56:02Z","published":"2023-07-12T17:56:02Z","title":"Analysis of Half-Duplex Two-Node Slotted ALOHA Network With Asynchronous\n  Traffic","summary":"  Despite the long history of research on slotted ALOHA, the exact analysis of\nthe average delay is still in question as the performance of each node is\ncoupled with the activity of other nodes. In this paper, we consider a network\ncomprised of two half-duplex transmitter nodes with asynchronous arrival\ntraffic that follow the slotted ALOHA protocol. We propose a new queueing\ntheoretic model based on the state-dependent queues to analyze the network. In\naddition, we derive the exact values of delay and stability region for each\nnode. The numerical results demonstrate the accuracy of our proposed model.\n","authors":["Seyed Ali Hashemian","Farid Ashtiani"],"pdf_url":"https://arxiv.org/pdf/2307.06334v1.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2307.06323v1","updated":"2023-07-12T17:40:21Z","published":"2023-07-12T17:40:21Z","title":"Information-Theoretically Private Federated Submodel Learning with\n  Storage Constrained Databases","summary":"  In federated submodel learning (FSL), a machine learning model is divided\ninto multiple submodels based on different types of data used for training.\nEach user involved in the training process only downloads and updates the\nsubmodel relevant to the user's local data, which significantly reduces the\ncommunication cost compared to classical federated learning (FL). However, the\nindex of the submodel updated by the user and the values of the updates reveal\ninformation about the user's private data. In order to guarantee\ninformation-theoretic privacy in FSL, the model is stored at multiple\nnon-colluding databases, and the user sends queries and updates to each\ndatabase in such a way that no information is revealed on the updating submodel\nindex or the values of the updates. In this work, we consider the practical\nscenario where the multiple non-colluding databases are allowed to have\narbitrary storage constraints. The goal of this work is to develop read-write\nschemes and storage mechanisms for FSL that efficiently utilize the available\nstorage in each database to store the submodel parameters in such a way that\nthe total communication cost is minimized while guaranteeing\ninformation-theoretic privacy of the updating submodel index and the values of\nthe updates. As the main result, we consider both heterogeneous and homogeneous\nstorage constrained databases, and propose private read-write and storage\nschemes for the two cases.\n","authors":["Sajani Vithana","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2307.06323v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2302.03670"},{"id":"http://arxiv.org/abs/2307.06294v1","updated":"2023-07-12T16:42:44Z","published":"2023-07-12T16:42:44Z","title":"Corona: System Implications of Emerging Nanophotonic Technology","summary":"  We expect that many-core microprocessors will push performance per chip from\nthe 10 gigaflop to the 10 teraflop range in the coming decade. To support this\nincreased performance, memory and inter-core bandwidths will also have to scale\nby orders of magnitude. Pin limitations, the energy cost of electrical\nsignaling, and the non-scalability of chip-length global wires are significant\nbandwidth impediments. Recent developments in silicon nanophotonic technology\nhave the potential to meet these off- and on- stack bandwidth requirements at\nacceptable power levels.\n  Corona is a 3D many-core architecture that uses nanophotonic communication\nfor both inter-core communication and off-stack communication to memory or I/O\ndevices. Its peak floating-point performance is 10 teraflops. Dense wavelength\ndivision multiplexed optically connected memory modules provide 10 terabyte per\nsecond memory bandwidth. A photonic crossbar fully interconnects its 256\nlow-power multithreaded cores at 20 terabyte per second bandwidth. We have\nsimulated a 1024 thread Corona system running synthetic benchmarks and scaled\nversions of the SPLASH-2 benchmark suite. We believe that in comparison with an\nelectrically-connected many-core alternative that uses the same on-stack\ninterconnect power, Corona can provide 2 to 6 times more performance on many\nmemory-intensive workloads, while simultaneously reducing power.\n","authors":["Dana Vantrease","Robert Schreiber","Matteo Monchiero","Moray McLaren","Norman P. Jouppi","Marco Fiorentin","Al Davis","Nathan Binkert","Raymond G. Beausoleil","Jung Ho Ahn"],"pdf_url":"https://arxiv.org/pdf/2307.06294v1.pdf","comment":"This edition is recompiled from proceedings of ISCA-35 (the 35th\n  International Symposium on Computer Architecture, June 21 - 25, 2008,\n  Beijing, China) and has minor formatting differences. 13 pages; 11 figures"},{"id":"http://arxiv.org/abs/2307.06262v1","updated":"2023-07-12T16:02:56Z","published":"2023-07-12T16:02:56Z","title":"An Architecture for Control Plane Slicing in Beyond 5G Networks","summary":"  To accommodate various use cases with differing characteristics, the Fifth\nGeneration (5G) mobile communications system intends to utilize network\nslicing. Network slicing enables the creation of multiple logical networks over\na shared physical network infrastructure. While the problems such as resource\nallocation for multiple slices in mobile networks have been explored in\nconsiderable detail in the existing literature, the suitability of the existing\nmobile network architecture to support network slicing has not been analysed\nadequately. We think the existing 5G System (5GS) architecture suffers from\ncertain limitations, such as a lack of slice isolation in its control plane.\nThis work focuses on the future evolution of the existing 5GS architecture from\na slicing perspective, especially that of its control plane, addressing some of\nthe limitations of the existing 5GS architecture. We propose a new network\narchitecture which enables efficient slicing in beyond 5G networks. The\nproposed architecture results in enhanced modularity and scalability of the\ncontrol plane in sliced mobile networks. In addition, it also brings slice\nisolation to the control plane, which is not feasible in the existing 5G\nsystem. We also present a performance evaluation that confirms the improved\nperformance and scalability of the proposed system viz a viz the existing 5G\nsystem.\n","authors":["Rashmi Yadav","Rashmi Kamran","Pranav Jha","Abhay Karandikar"],"pdf_url":"https://arxiv.org/pdf/2307.06262v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2212.03087v2","updated":"2023-07-12T15:15:26Z","published":"2022-12-06T15:59:12Z","title":"Fresh-CSMA: A Distributed Protocol for Minimizing Age of Information","summary":"  We consider the design of distributed scheduling algorithms that minimize age\nof information in single-hop wireless networks. The centralized max-weight\npolicy is known to be nearly optimal in this setting; hence, our goal is to\ndesign a distributed CSMA scheme that can mimic its performance. To that end,\nwe propose a distributed protocol called Fresh-CSMA and show that in an\nidealized setting, Fresh-CSMA can match the scheduling decisions of the\nmax-weight policy with high probability in each frame, and also match the\ntheoretical performance guarantees of the max-weight policy over the entire\ntime horizon. We then consider a more realistic setting and study the impact of\nprotocol parameters on the probability of collisions and the overhead caused by\nthe distributed nature of the protocol. We also consider the monitoring of\nMarkov sources and extend our approach to CSMA protocols that incorporate Age\nof Incorrect Information (AoII) instead of AoI. Finally, we provide simulations\nthat support our theoretical results and show that the performance gap between\nthe ideal and realistic versions of Fresh-CSMA is small.\n","authors":["Vishrant Tripathi","Nicholas Jones","Eytan Modiano"],"pdf_url":"https://arxiv.org/pdf/2212.03087v2.pdf","comment":"Accepted at IEEE INFOCOM 2023"},{"id":"http://arxiv.org/abs/2305.00429v2","updated":"2023-07-12T14:03:17Z","published":"2023-04-30T09:12:11Z","title":"A Dynamic Obstacle Tracking Strategy for Proactive Handoffs in\n  Millimeter-wave Networks","summary":"  Stringent line-of-sight demands necessitated by the fast attenuating nature\nof millimeter waves (mmWaves) through obstacles pose one of the central\nproblems of next generation wireless networks. These mmWave links are easily\ndisrupted due to obstacles, including vehicles and pedestrians, which cause\ndegradation in link quality and even link failure. Dynamic obstacles are\nusually tracked by dedicated tracking hardware like RGB-D cameras, which\nusually have small ranges, and hence lead to prohibitively increased deployment\ncosts to achieve complete coverage of the deployment area. In this manuscript,\nwe propose an altogether different approach to track multiple dynamic obstacles\nin an mmWave network, solely based on short-term historical link failure\ninformation, without resorting to any dedicated tracking hardware. After\nproving that the said problem is NP-complete, we employ a greedy set-cover\nbased approach to solve it. Using the obtained trajectories, we perform\nproactive handoffs for at-risk links. We compare our approach with an RGB-D\ncamera-based approach and show that our approach provides better tracking and\nhandoff performances when the camera coverage is low to moderate, which is\noften the case in real deployment scenarios.\n","authors":["Rathindra Nath Dutta","Subhojit Sarkar","Sasthi C. Ghosh"],"pdf_url":"https://arxiv.org/pdf/2305.00429v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06131v1","updated":"2023-07-12T12:34:59Z","published":"2023-07-12T12:34:59Z","title":"Evaluating DNS Resiliency and Responsiveness with Truncation,\n  Fragmentation & DoTCP Fallback","summary":"  Since its introduction in 1987, the DNS has become one of the core components\nof the Internet. While it was designed to work with both TCP and UDP,\nDNS-over-UDP (DoUDP) has become the default option due to its low overhead. As\nnew Resource Records were introduced, the sizes of DNS responses increased\nconsiderably. This expansion of message body has led to truncation and IP\nfragmentation more often in recent years where large UDP responses make DNS an\neasy vector for amplifying denial-of-service attacks which can reduce the\nresiliency of DNS services. This paper investigates the resiliency,\nresponsiveness, and usage of DoTCP and DoUDP over IPv4 and IPv6 for 10 widely\nused public DNS resolvers. In these experiments, these aspects are investigated\nfrom the edge and from the core of the Internet to represent the communication\nof the resolvers with DNS clients and authoritative name servers. Overall, more\nthan 14M individual measurements from 2527 RIPE Atlas Probes have been\nanalyzed, highlighting that most resolvers show similar resiliency for both\nDoTCP and DoUDP. While DNS Flag Day 2020 recommended 1232 bytes of buffer sizes\nyet we find out that 3 out of 10 resolvers mainly announce very large EDNS(0)\nbuffer sizes both from the edge as well as from the core, which potentially\ncauses fragmentation. In reaction to large response sizes from authoritative\nname servers, we find that resolvers do not fall back to the usage of DoTCP in\nmany cases, bearing the risk of fragmented responses. As the message sizes in\nthe DNS are expected to grow further, this problem will become more urgent in\nthe future.\n","authors":["Pratyush Dikshit","Mike Kosek","Nils Faulhaber","Jayasree Sengupta","Vaibhav Bajpai"],"pdf_url":"https://arxiv.org/pdf/2307.06131v1.pdf","comment":"15 pages, 11 figures, 11 tables"},{"id":"http://arxiv.org/abs/2307.06095v1","updated":"2023-07-12T11:38:17Z","published":"2023-07-12T11:38:17Z","title":"Exact Resource Allocation over Fair Wireless Relay Networks","summary":"  In relay-enabled cellular networks, the intertwined nature of network agents\ncalls for complex schemes to allocate wireless resources. Resources need to be\ndistributed among mobile users while considering how relay resources are\nallocated, and constrained by the traffic rate achievable by base stations and\nover backhaul links. In this work, we derive a resource allocation scheme that\nachieves max-min fairness across mobile users. Furthermore, the optimal\nallocation is found with linear complexity with respect to the number of mobile\nusers and relays.\n","authors":["Edgar Arribas","Vicent Cholvi","Vincenzo Mancuso"],"pdf_url":"https://arxiv.org/pdf/2307.06095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06009v1","updated":"2023-07-12T08:41:17Z","published":"2023-07-12T08:41:17Z","title":"A Linear Algebraic Framework for Dynamic Scheduling Over Memory-Equipped\n  Quantum Networks","summary":"  Quantum Internetworking is a recent field that promises numerous interesting\napplications, many of which require the distribution of entanglement between\narbitrary pairs of users. This work deals with the problem of scheduling in an\narbitrary entanglement swapping quantum network - often called first generation\nquantum network - in its general topology, multicommodity, loss-aware\nformulation. We introduce a linear algebraic framework that exploits quantum\nmemory through the creation of intermediate entangled links. The framework is\nthen employed to mathematically derive a natural class of quadratic scheduling\npolicies for quantum networks by applying Lyapunov Drift Minimization, a\nstandard technique in classical network science. Moreover, an additional class\nof Max-Weight inspired policies is proposed and benchmarked, reducing\nsignificantly the computation cost, at the price of a slight performance\ndegradation. The policies are compared in terms of information availability,\nlocalization and overall network performance through an ad-hoc simulator that\nadmits user-provided network topologies and scheduling policies in order to\nshowcase the potential application of the provided tools to quantum network\ndesign.\n","authors":["Paolo Fittipaldi","Anastasios Giovanidis","Frédéric Grosshans"],"pdf_url":"https://arxiv.org/pdf/2307.06009v1.pdf","comment":"18 pages, 7 figures. To be submitted to the journal \"IEEE\n  Transactions on Quantum Engineering\""},{"id":"http://arxiv.org/abs/2304.08697v2","updated":"2023-07-12T07:02:57Z","published":"2023-04-18T02:09:38Z","title":"Performance Analysis and Comparison of Non-ideal Wireless PBFT and RAFT\n  Consensus Networks in 6G Communications","summary":"  Due to advantages in security and privacy, blockchain is considered a key\nenabling technology to support 6G communications. Practical Byzantine Fault\nTolerance (PBFT) and RAFT are seen as the most applicable consensus mechanisms\n(CMs) in blockchain-enabled wireless networks. However, previous studies on\nPBFT and RAFT rarely consider the channel performance of the physical layer,\nsuch as path loss and channel fading, resulting in research results that are\nfar from real networks. Additionally, 6G communications will widely deploy\nhigh-frequency signals such as terahertz (THz) and millimeter wave (mmWave),\nwhile performances of PBFT and RAFT are still unknown when these signals are\ntransmitted in wireless PBFT or RAFT networks. Therefore, it is urgent to study\nthe performance of non-ideal wireless PBFT and RAFT networks with THz and\nmmWave signals, to better make PBFT and RAFT play a role in the 6G era. In this\npaper, we study and compare the performance of THz and mmWave signals in\nnon-ideal wireless PBFT and RAFT networks, considering Rayleigh Fading (RF) and\nclose-in Free Space (FS) reference distance path loss. Performance is evaluated\nby five metrics: consensus success rate, latency, throughput, reliability gain,\nand energy consumption. Meanwhile, we find and derive that there is a maximum\ndistance between two nodes that can make CMs inevitably successful, and it is\nnamed the active distance of CMs. The research results analyze the performance\nof non-ideal wireless PBFT and RAFT networks, and provide important references\nfor the future transmission of THz and mmWave signals in PBFT and RAFT\nnetworks.\n","authors":["Haoxiang Luo","Xiangyue Yang","Hongfang Yu","Gang Sun","Bo Lei","Mohsen Guizani"],"pdf_url":"https://arxiv.org/pdf/2304.08697v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2303.15759"},{"id":"http://arxiv.org/abs/2307.05936v1","updated":"2023-07-12T06:04:01Z","published":"2023-07-12T06:04:01Z","title":"Introducing Packet-Level Analysis in Programmable Data Planes to Advance\n  Network Intrusion Detection","summary":"  Programmable data planes offer precise control over the low-level processing\nsteps applied to network packets, serving as a valuable tool for analysing\nmalicious flows in the field of intrusion detection. Albeit with limitations on\nphysical resources and capabilities, they allow for the efficient extraction of\ndetailed traffic information, which can then be utilised by Machine Learning\n(ML) algorithms responsible for identifying security threats. In addressing\nresource constraints, existing solutions in the literature rely on compressing\nnetwork data through the collection of statistical traffic features in the data\nplane. While this compression saves memory resources in switches and minimises\nthe burden on the control channel between the data and the control plane, it\nalso results in a loss of information available to the Network Intrusion\nDetection System (NIDS), limiting access to packet payload, categorical\nfeatures, and the semantic understanding of network communications, such as the\nbehaviour of packets within traffic flows. This paper proposes P4DDLe, a\nframework that exploits the flexibility of P4-based programmable data planes\nfor packet-level feature extraction and pre-processing. P4DDLe leverages the\nprogrammable data plane to extract raw packet features from the network\ntraffic, categorical features included, and to organise them in a way that the\nsemantics of traffic flows is preserved. To minimise memory and control channel\noverheads, P4DDLe selectively processes and filters packet-level data, so that\nall and only the relevant features required by the NIDS are collected. The\nexperimental evaluation with recent Distributed Denial of Service (DDoS) attack\ndata demonstrates that the proposed approach is very efficient in collecting\ncompact and high-quality representations of network flows, ensuring precise\ndetection of DDoS attacks.\n","authors":["Roberto Doriguzzi-Corin","Luis Augusto Dias Knob","Luca Mendozzi","Domenico Siracusa","Marco Savi"],"pdf_url":"https://arxiv.org/pdf/2307.05936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05924v1","updated":"2023-07-12T05:44:33Z","published":"2023-07-12T05:44:33Z","title":"Applying SDN to Mobile Networks: A New Perspective for 6G Architecture","summary":"  The upcoming Sixth Generation (6G) mobile communications system envisions\nsupporting a variety of use cases with differing characteristics, e.g., very\nlow to extremely high data rates, diverse latency needs, ultra massive\nconnectivity, sustainable communications, ultra-wide coverage etc. To\naccommodate these diverse use cases, the 6G system architecture needs to be\nscalable, modular, and flexible; both in its user plane and the control plane.\nIn this paper, we identify some limitations of the existing Fifth Generation\nSystem (5GS) architecture, especially that of its control plane. Further, we\npropose a novel architecture for the 6G System (6GS) employing Software Defined\nNetworking (SDN) technology to address these limitations of the control plane.\nThe control plane in existing 5GS supports two different categories of\nfunctionalities handling end user signalling (e.g., user registration,\nauthentication) and control of user plane functions. We propose to move the\nend-user signalling functionality out of the mobile network control plane and\ntreat it as user service, i.e., as payload or data. This proposal results in an\nevolved service-driven architecture for mobile networks bringing increased\nsimplicity, modularity, scalability, flexibility and security to its control\nplane. The proposed architecture can also support service specific signalling\nsupport, if needed, making it better suited for diverse 6GS use cases. To\ndemonstrate the advantages of the proposed architecture, we also compare its\nperformance with the 5GS using a process algebra-based simulation tool.\n","authors":["Rashmi Yadav","Rashmi Kamran","Pranav Jha","Abhay Karandikar"],"pdf_url":"https://arxiv.org/pdf/2307.05924v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2307.05914v1","updated":"2023-07-12T04:43:59Z","published":"2023-07-12T04:43:59Z","title":"FIS-ONE: Floor Identification System with One Label for Crowdsourced RF\n  Signals","summary":"  Floor labels of crowdsourced RF signals are crucial for many smart-city\napplications, such as multi-floor indoor localization, geofencing, and robot\nsurveillance. To build a prediction model to identify the floor number of a new\nRF signal upon its measurement, conventional approaches using the crowdsourced\nRF signals assume that at least few labeled signal samples are available on\neach floor. In this work, we push the envelope further and demonstrate that it\nis technically feasible to enable such floor identification with only one\nfloor-labeled signal sample on the bottom floor while having the rest of signal\nsamples unlabeled.\n  We propose FIS-ONE, a novel floor identification system with only one labeled\nsample. FIS-ONE consists of two steps, namely signal clustering and cluster\nindexing. We first build a bipartite graph to model the RF signal samples and\nobtain a latent representation of each node (each signal sample) using our\nattention-based graph neural network model so that the RF signal samples can be\nclustered more accurately. Then, we tackle the problem of indexing the clusters\nwith proper floor labels, by leveraging the observation that signals from an\naccess point can be detected on different floors, i.e., signal spillover.\nSpecifically, we formulate a cluster indexing problem as a combinatorial\noptimization problem and show that it is equivalent to solving a traveling\nsalesman problem, whose (near-)optimal solution can be found efficiently. We\nhave implemented FIS-ONE and validated its effectiveness on the Microsoft\ndataset and in three large shopping malls. Our results show that FIS-ONE\noutperforms other baseline algorithms significantly, with up to 23% improvement\nin adjusted rand index and 25% improvement in normalized mutual information\nusing only one floor-labeled signal sample.\n","authors":["Weipeng Zhuo","Ka Ho Chiu","Jierun Chen","Ziqi Zhao","S. -H. Gary Chan","Sangtae Ha","Chul-Ho Lee"],"pdf_url":"https://arxiv.org/pdf/2307.05914v1.pdf","comment":"Accepted by IEEE ICDCS 2023"},{"id":"http://arxiv.org/abs/2307.05888v1","updated":"2023-07-12T03:31:34Z","published":"2023-07-12T03:31:34Z","title":"Efficient Task Offloading Algorithm for Digital Twin in Edge/Cloud\n  Computing Environment","summary":"  In the era of Internet of Things (IoT), Digital Twin (DT) is envisioned to\nempower various areas as a bridge between physical objects and the digital\nworld. Through virtualization and simulation techniques, multiple functions can\nbe achieved by leveraging computing resources. In this process, Mobile Cloud\nComputing (MCC) and Mobile Edge Computing (MEC) have become two of the key\nfactors to achieve real-time feedback. However, current works only considered\nedge servers or cloud servers in the DT system models. Besides, The models\nignore the DT with not only one data resource. In this paper, we propose a new\nDT system model considering a heterogeneous MEC/MCC environment. Each DT in the\nmodel is maintained in one of the servers via multiple data collection devices.\nThe offloading decision-making problem is also considered and a new offloading\nscheme is proposed based on Distributed Deep Learning (DDL). Simulation results\ndemonstrate that our proposed algorithm can effectively and efficiently\ndecrease the system's average latency and energy consumption. Significant\nimprovement is achieved compared with the baselines under the dynamic\nenvironment of DTs.\n","authors":["Ziru Zhang","Xuling Zhang","Guangzhi Zhu","Yuyang Wang","Pan Hui"],"pdf_url":"https://arxiv.org/pdf/2307.05888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05854v1","updated":"2023-07-12T00:18:15Z","published":"2023-07-12T00:18:15Z","title":"On the Characterization of Quantum Flip Stars with Quantum Network\n  Tomography","summary":"  The experimental realization of quantum information systems will be difficult\ndue to how sensitive quantum information is to noise. Overcoming this\nsensitivity is central to designing quantum networks capable of transmitting\nquantum information reliably over large distances. Moreover, the ability to\ncharacterize communication noise in quantum networks is crucial in developing\nnetwork protocols capable of overcoming the effects of noise in quantum\nnetworks. In this context, quantum network tomography refers to the\ncharacterization of channel noise in a quantum network through end-to-end\nmeasurements. In this work, we propose network tomography protocols for quantum\nstar networks formed by quantum channels characterized by a single, non-trivial\nPauli operator. Our results further the end-to-end characterization of quantum\nbit-flip star networks by introducing tomography protocols where state\ndistribution and measurements are designed separately. We build upon previously\nproposed quantum network tomography protocols, as well as provide novel methods\nfor the unique characterization of bit-flip probabilities in stars. We\nintroduce a theoretical benchmark based on the Quantum Fisher Information\nmatrix to compare the efficiency of quantum network protocols. We apply our\ntechniques to the protocols proposed, and provide an initial analysis on the\npotential benefits of entanglement for Quantum Network Tomography. Furthermore,\nwe simulate the proposed protocols using NetSquid to assess the convergence\nproperties of the estimators obtained for particular parameter regimes. Our\nfindings show that the efficiency of protocols depend on parameter values and\nmotivate the search for adaptive quantum network tomography protocols.\n","authors":["Matheus Guedes de Andrade","Jake Navas","Inès Montaño","Don Towsley"],"pdf_url":"https://arxiv.org/pdf/2307.05854v1.pdf","comment":"12 pages, 3 figures. Accepted for publication in IEEE QCE23\n  proceedings"},{"id":"http://arxiv.org/abs/2307.06492v1","updated":"2023-07-12T23:43:37Z","published":"2023-07-12T23:43:37Z","title":"Universal Quantum Walk Control Plane for Quantum Networks","summary":"  Quantum networks are complex systems formed by the interaction among quantum\nprocessors through quantum channels. Analogous to classical computer networks,\nquantum networks allow for the distribution of quantum operations among quantum\nprocessors. In this work, we describe a Quantum Walk Control Protocol (QWCP) to\nperform distributed quantum operations in a quantum network. We consider a\ngeneralization of the discrete-time coined quantum walk model that accounts for\nthe interaction between quantum walks in the network graph with quantum\nregisters inside the network nodes. QWCP allows for the implementation of\nnetworked quantum services, such as distributed quantum computing and\nentanglement distribution, abstracting hardware implementation and the\ntransmission of quantum information through channels. Multiple interacting\nquantum walks can be used to propagate entangled control signals across the\nnetwork in parallel. We demonstrate how to use QWCP to perform distributed\nmulti-qubit controlled gates, which shows the universality of the protocol for\ndistributed quantum computing. Furthermore, we apply the QWCP to the task of\nentanglement distribution in a quantum network.\n","authors":["Matheus Guedes de Andrade","Nitish K. Panigrahy","Wenhan Dai","Saikat Guha","Don Towsley"],"pdf_url":"https://arxiv.org/pdf/2307.06492v1.pdf","comment":"27 pages; 2 figures. A preliminary version of this work was presented\n  at IEEE International Conference on Quantum Computing and Engineering 2021\n  (QCE21). arXiv admin note: text overlap with arXiv:2106.09839"},{"id":"http://arxiv.org/abs/2307.06488v1","updated":"2023-07-12T23:25:58Z","published":"2023-07-12T23:25:58Z","title":"Market Driven Multi-domain Network Service Orchestration in 5G Networks","summary":"  The advent of a new breed of enhanced multimedia services has put network\noperators into a position where they must support innovative services while\nensuring both end-to-end Quality of Service requirements and profitability.\nRecently, Network Function Virtualization (NFV) has been touted as a\ncost-effective underlying technology in 5G networks to efficiently provision\nnovel services. These NFV-based services have been increasingly associated with\nmulti-domain networks. However, several orchestration issues, linked to\ncross-domain interactions and emphasized by the heterogeneity of underlying\ntechnologies and administrative authorities, present an important challenge. In\nthis paper, we tackle the cross-domain interaction issue by proposing an\nintelligent and profitable auction-based approach to allow inter-domains\nresource allocation.\n","authors":["Mouhamad Dieye","Wael Jaafar","Halima Elbiaze","Roch Glitho"],"pdf_url":"https://arxiv.org/pdf/2307.06488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06409v1","updated":"2023-07-12T19:02:43Z","published":"2023-07-12T19:02:43Z","title":"Faster Control Plane Experimentation with Horse","summary":"  Simulation and emulation are popular approaches for experimentation in\nComputer Networks. However, due to their respective inherent drawbacks,\nexisting solutions cannot perform both fast and realistic control plane\nexperiments. To close this gap, we introduce Horse. Horse is a hybrid solution\nwith an emulated control plane, for realism, and simulated data plane, for\nspeed. Our decoupling of the control and data plane allows us to speed up the\nexperiments without sacrificing control plane realism.\n","authors":["Eder Leao Fernandes","Gianni Antichi","Timm Boettger","Ignacio Castro","Steve Uhlig"],"pdf_url":"https://arxiv.org/pdf/2307.06409v1.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2307.06333v1","updated":"2023-07-12T17:55:08Z","published":"2023-07-12T17:55:08Z","title":"Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for\n  Test-Time Policy Adaptation","summary":"  Policies often fail due to distribution shift -- changes in the state and\nreward that occur when a policy is deployed in new environments. Data\naugmentation can increase robustness by making the model invariant to\ntask-irrelevant changes in the agent's observation. However, designers don't\nknow which concepts are irrelevant a priori, especially when different end\nusers have different preferences about how the task is performed. We propose an\ninteractive framework to leverage feedback directly from the user to identify\npersonalized task-irrelevant concepts. Our key idea is to generate\ncounterfactual demonstrations that allow users to quickly identify possible\ntask-relevant and irrelevant concepts. The knowledge of task-irrelevant\nconcepts is then used to perform data augmentation and thus obtain a policy\nadapted to personalized user objectives. We present experiments validating our\nframework on discrete and continuous control tasks with real human users. Our\nmethod (1) enables users to better understand agent failure, (2) reduces the\nnumber of demonstrations required for fine-tuning, and (3) aligns the agent to\nindividual user task preferences.\n","authors":["Andi Peng","Aviv Netanyahu","Mark Ho","Tianmin Shu","Andreea Bobu","Julie Shah","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2307.06333v1.pdf","comment":"International Conference on Machine Learning (ICML) 2023"},{"id":"http://arxiv.org/abs/2307.06214v1","updated":"2023-07-12T15:02:53Z","published":"2023-07-12T15:02:53Z","title":"52 Weeks Later: Attitudes Towards COVID-19 Apps for Different Purposes\n  Over Time","summary":"  The COVID-19 pandemic has prompted countries around the world to introduce\nsmartphone apps to support disease control efforts. Their purposes range from\ndigital contact tracing to quarantine enforcement to vaccination passports, and\ntheir effectiveness often depends on widespread adoption. While previous work\nhas identified factors that promote or hinder adoption, it has typically\nexamined data collected at a single point in time or focused exclusively on\ndigital contact tracing apps. In this work, we conduct the first representative\nstudy that examines changes in people's attitudes towards COVID-19-related\nsmartphone apps for five different purposes over the first 1.5 years of the\npandemic. In three survey rounds conducted between Summer 2020 and Summer 2021\nin the United States and Germany, with approximately 1,000 participants per\nround and country, we investigate people's willingness to use such apps, their\nperceived utility, and people's attitudes towards them in different stages of\nthe pandemic. Our results indicate that privacy is a consistent concern for\nparticipants, even in a public health crisis, and the collection of\nidentity-related data significantly decreases acceptance of COVID-19 apps.\nTrust in authorities is essential to increase confidence in government-backed\napps and foster citizens' willingness to contribute to crisis management. There\nis a need for continuous communication with app users to emphasize the benefits\nof health crisis apps both for individuals and society, thus counteracting\ndecreasing willingness to use them and perceived usefulness as the pandemic\nevolves.\n","authors":["Marvin Kowalewski","Christine Utz","Martin Degeling","Theodor Schnitzler","Franziska Herbert","Leonie Schaewitz","Florian M. Farke","Steffen Becker","Markus Dürmuth"],"pdf_url":"https://arxiv.org/pdf/2307.06214v1.pdf","comment":"45 pages, 19 figures, 10 tables"},{"id":"http://arxiv.org/abs/2307.06173v1","updated":"2023-07-12T13:58:11Z","published":"2023-07-12T13:58:11Z","title":"Assessing Augmented Reality Selection Techniques for Passengers in\n  Moving Vehicles: A Real-World User Study","summary":"  Nowadays, cars offer many possibilities to explore the world around you by\nproviding location-based information displayed on a 2D-Map. However, this\ninformation is often only available to front-seat passengers while being\nrestricted to in-car displays. To propose a more natural way of interacting\nwith the environment, we implemented an augmented reality head-mounted display\nto overlay points of interest onto the real world. We aim to compare multiple\nselection techniques for digital objects located outside a moving car by\ninvestigating head gaze with dwell time, head gaze with hardware button, eye\ngaze with hardware button, and hand pointing with gesture confirmation. Our\nstudy was conducted in a moving car under real-world conditions (N=22), with\nsignificant results indicating that hand pointing usage led to slower and less\nprecise content selection while eye gaze was preferred by participants and\nperformed on par with the other techniques.\n","authors":["Robin Connor Schramm","Markus Sasalovici","Axel Hildebrand","Ulrich Schwanecke"],"pdf_url":"https://arxiv.org/pdf/2307.06173v1.pdf","comment":"10 pages, 5 figures, to be published in 15th International Conference\n  on Automotive User Interfaces and Interactive Vehicular Applications\n  (AutomotiveUI '23), September 18-22, 2023, Ingolstadt, Germany"},{"id":"http://arxiv.org/abs/2305.10642v2","updated":"2023-07-12T12:44:31Z","published":"2023-05-18T01:57:53Z","title":"Adaptive Learning based Upper-Limb Rehabilitation Training System with\n  Collaborative Robot","summary":"  Rehabilitation training for patients with motor disabilities usually requires\nspecialized devices in rehabilitation centers. Home-based multi-purpose\ntraining would significantly increase treatment accessibility and reduce\nmedical costs. While it is unlikely to equip a set of rehabilitation robots at\nhome, we investigate the feasibility to use the general-purpose collaborative\nrobot for rehabilitation therapies. In this work, we developed a new system for\nmulti-purpose upper-limb rehabilitation training using a generic robot arm with\nhuman motor feedback and preference. We integrated surface electromyography,\nforce/torque sensors, RGB-D cameras, and robot controllers with the Robot\nOperating System to enable sensing, communication, and control of the system.\nImitation learning methods were adopted to imitate expert-provided training\ntrajectories which could adapt to subject capabilities to facilitate in-home\ntraining. Our rehabilitation system is able to perform gross motor function and\nfine motor skill training with a gripper-based end-effector. We simulated\nsystem control in Gazebo and training effects (muscle activation level) in\nOpenSim and evaluated its real performance with human subjects. For all the\nsubjects enrolled, our system achieved better training outcomes compared to\nspecialist-assisted rehabilitation under the same conditions. Our work\ndemonstrates the potential of utilizing collaborative robots for in-home motor\nrehabilitation training.\n","authors":["Jun Hong Lim","Kaibo He","Zeji Yi","Chen Hou","Chen Zhang","Yanan Sui","Luming Li"],"pdf_url":"https://arxiv.org/pdf/2305.10642v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01241v2","updated":"2023-07-12T11:42:33Z","published":"2023-02-02T17:23:28Z","title":"Diagrammatization: Rationalizing with diagrammatic AI explanations for\n  abductive-deductive reasoning on hypotheses","summary":"  Many visualizations have been developed for explainable AI (XAI), but they\noften require further reasoning by users to interpret. We argue that XAI should\nsupport diagrammatic and abductive reasoning for the AI to perform hypothesis\ngeneration and evaluation to reduce the interpretability gap. We propose\nDiagrammatization to i) perform Peircean abductive-deductive reasoning, ii)\nfollow domain conventions, and iii) explain with diagrams visually or verbally.\nWe implemented DiagramNet for a clinical application to predict cardiac\ndiagnoses from heart auscultation, and explain with shape-based murmur\ndiagrams. In modeling studies, we found that DiagramNet not only provides\nfaithful murmur shape explanations, but also has better prediction performance\nthan baseline models. We further demonstrate the interpretability and\ntrustworthiness of diagrammatic explanations in a qualitative user study with\nmedical students, showing that clinically-relevant, diagrammatic explanations\nare preferred over technical saliency map explanations. This work contributes\ninsights into providing domain-conventional abductive explanations for\nuser-centric XAI.\n","authors":["Brian Y. Lim","Joseph P. Cahaly","Chester Y. F. Sng","Adam Chew"],"pdf_url":"https://arxiv.org/pdf/2302.01241v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06089v1","updated":"2023-07-12T11:27:09Z","published":"2023-07-12T11:27:09Z","title":"Exploring Millions of User Interactions with ICEBOAT: Big Data Analytics\n  for Automotive User Interfaces","summary":"  User Experience (UX) professionals need to be able to analyze large amounts\nof usage data on their own to make evidence-based design decisions. However,\nthe design process for In-Vehicle Information Systems (IVIS) lacks data-driven\nsupport and effective tools for visualizing and analyzing user interaction\ndata. Therefore, we propose ICEBOAT, an interactive visualization tool tailored\nto the needs of automotive UX experts to effectively and efficiently evaluate\ndriver interactions with IVISs. ICEBOAT visualizes telematics data collected\nfrom production line vehicles, allowing UX experts to perform task-specific\nanalyses. Following a mixed methods User-centered design (UCD) approach, we\nconducted an interview study (N=4) to extract the domain specific information\nand interaction needs of automotive UX experts and used a co-design approach\n(N=4) to develop an interactive analysis tool. Our evaluation (N=12) shows that\nICEBOAT enables UX experts to efficiently generate knowledge that facilitates\ndata-driven design decisions.\n","authors":["Patrick Ebel","Kim Julian Gülle","Christoph Lingenfelder","Andreas Vogelsang"],"pdf_url":"https://arxiv.org/pdf/2307.06089v1.pdf","comment":"to be published at the 15th International Conference on Automotive\n  User Interfaces and Interactive Vehicular Applications (AutomotiveUI '23),\n  September 18--22, 2023, Ingolstadt, Germany"},{"id":"http://arxiv.org/abs/2307.06007v1","updated":"2023-07-12T08:36:41Z","published":"2023-07-12T08:36:41Z","title":"Building Persuasive Robots with Social Power Strategies","summary":"  Can social power endow social robots with the capacity to persuade? This\npaper represents our recent endeavor to design persuasive social robots. We\nhave designed and run three different user studies to investigate the\neffectiveness of different bases of social power (inspired by French and\nRaven's theory) on peoples' compliance to the requests of social robots. The\nresults show that robotic persuaders that exert social power (specifically from\nexpert, reward, and coercion bases) demonstrate increased ability to influence\nhumans. The first study provides a positive answer and shows that under the\nsame circumstances, people with different personalities prefer robots using a\nspecific social power base. In addition, social rewards can be useful in\npersuading individuals. The second study suggests that by employing social\npower, social robots are capable of persuading people objectively to select a\nless desirable choice among others. Finally, the third study shows that the\neffect of power on persuasion does not decay over time and might strengthen\nunder specific circumstances. Moreover, exerting stronger social power does not\nnecessarily lead to higher persuasion. Overall, we argue that the results of\nthese studies are relevant for designing human--robot-interaction scenarios\nespecially the ones aiming at behavioral change.\n","authors":["Mojgan Hashemian","Marta Couto","Samuel Mascarenhas","Ana Paiva","Pedro A. Santos","Rui Prada"],"pdf_url":"https://arxiv.org/pdf/2307.06007v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07310v2","updated":"2023-07-12T08:27:36Z","published":"2023-06-12T17:53:06Z","title":"Employing Crowdsourcing for Enriching a Music Knowledge Base in Higher\n  Education","summary":"  This paper describes the methodology followed and the lessons learned from\nemploying crowdsourcing techniques as part of a homework assignment involving\nhigher education students of computer science. Making use of a platform that\nsupports crowdsourcing in the cultural heritage domain students were solicited\nto enrich the metadata associated with a selection of music tracks. The results\nof the campaign were further analyzed and exploited by students through the use\nof semantic web technologies. In total, 98 students participated in the\ncampaign, contributing more than 6400 annotations concerning 854 tracks. The\nprocess also led to the creation of an openly available annotated dataset,\nwhich can be useful for machine learning models for music tagging. The\ncampaign's results and the comments gathered through an online survey enable us\nto draw some useful insights about the benefits and challenges of integrating\ncrowdsourcing into computer science curricula and how this can enhance\nstudents' engagement in the learning process.\n","authors":["Vassilis Lyberatos","Spyridon Kantarelis","Eirini Kaldeli","Spyros Bekiaris","Panagiotis Tzortzis","Orfeas Menis - Mastromichalakis","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2306.07310v2.pdf","comment":"Presented in The 4th International Conference on Artificial\n  Intelligence in Education Technology (AIET 2023), Berlin, Germany, 31 June-2\n  July 2023. For The GitHub code for the created music dataset, see\n  https://github.com/vaslyb/MusicCrowd"},{"id":"http://arxiv.org/abs/2307.05988v1","updated":"2023-07-12T08:04:29Z","published":"2023-07-12T08:04:29Z","title":"A Comprehensive Review of Automated Data Annotation Techniques in Human\n  Activity Recognition","summary":"  Human Activity Recognition (HAR) has become one of the leading research\ntopics of the last decade. As sensing technologies have matured and their\neconomic costs have declined, a host of novel applications, e.g., in\nhealthcare, industry, sports, and daily life activities have become popular.\nThe design of HAR systems requires different time-consuming processing steps,\nsuch as data collection, annotation, and model training and optimization. In\nparticular, data annotation represents the most labor-intensive and cumbersome\nstep in HAR, since it requires extensive and detailed manual work from human\nannotators. Therefore, different methodologies concerning the automation of the\nannotation procedure in HAR have been proposed. The annotation problem occurs\nin different notions and scenarios, which all require individual solutions. In\nthis paper, we provide the first systematic review on data annotation\ntechniques for HAR. By grouping existing approaches into classes and providing\na taxonomy, our goal is to support the decision on which techniques can be\nbeneficially used in a given scenario.\n","authors":["Florenc Demrozi","Cristian Turetta","Fadi Al Machot","Graziano Pravadelli","Philipp H. Kindt"],"pdf_url":"https://arxiv.org/pdf/2307.05988v1.pdf","comment":"37 pages, 5 figures, 20 tables"},{"id":"http://arxiv.org/abs/2307.05986v1","updated":"2023-07-12T08:01:48Z","published":"2023-07-12T08:01:48Z","title":"Beyond Hiding and Revealing: Exploring Effects of Visibility and Form of\n  Interaction on the Witness Experience","summary":"  Our interactions with technology do not just shape our individual\nexperiences. They also affect people around us. Although previous research has\naddressed such \"witness\" experiences, the actual effect of interaction design\non the witness experience remains largely unknown. In an online study (n =\n407), we explored how witnesses perceive mid-air gesture-based interactions\nwith a hearing aid, using four video vignettes. We studied witnesses'\nsubjective visibility of manipulations and effects (following Reeves and\ncolleagues' taxonomy), perceived form of interaction, subjective experience,\nand relationships between these measures. Although visibility patterns matched\nthe intended form, they did not lead to the supposed experience (i.e.,\n\"suspenseful\" gestures did not lead to suspenseful experiences). The paper\nillustrates gaps in current research about witness experiences, demonstrates\nthe need to overcome basic hiding/revealing profiles, and indicates a path\nforward by focusing on aesthetic forms and experiences.\n","authors":["Alarith Uhde","Tim zum Hoff","Marc Hassenzahl"],"pdf_url":"https://arxiv.org/pdf/2307.05986v1.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2307.05909v1","updated":"2023-07-12T04:31:34Z","published":"2023-07-12T04:31:34Z","title":"Exploring the Sector-Specific Influence and Response of AI Tools: A\n  Critical Review","summary":"  AI Tool is designed to generate human-like responses in natural language\nconversations. Using deep learning techniques, AI Tool has been trained on a\ndiverse range of internet text to understand and generate coherent responses to\na wide array of prompts and questions. It can provide information, engage in\nconversations, assist with tasks, and even offer creative suggestions. The\nunderlying technology behind AI Tool is a transformer neural network.\nTransformers excel at capturing long-range dependencies in text, making them\nwell-suited for language-related tasks. AI Tool, has 175 billion parameters,\nmaking it one of the largest and most powerful language models to date. AI Tool\nhas been trained on a massive corpus of text from the internet, which allows it\nto leverage a broad understanding of language, general knowledge, and various\ndomains. While AI Tool aims to provide accurate and helpful responses, it may\noccasionally produce incorrect or nonsensical answers. It's essential to\ncritically evaluate the information it provides and verify it from reliable\nsources when necessary. This work presents an overview on AI Tool. It will\nhelps to research community and others users to understand the uses of AI Tool\nand its interaction pattern.\n","authors":["Hitesh Mohapatra","Soumya Ranjan Mishra"],"pdf_url":"https://arxiv.org/pdf/2307.05909v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05870v1","updated":"2023-07-12T01:55:55Z","published":"2023-07-12T01:55:55Z","title":"Useful but Distracting: Keyword Highlights and Time-Synchronization in\n  Captions for Language Learning","summary":"  Captions provide language learners with a scaffold for comprehension and\nvocabulary acquisition. Past work has proposed several enhancements such as\nkeyword highlights for increased learning gains. However, little is known about\nlearners' experience with enhanced captions, although this is critical for\nadoption in everyday life. We conducted a survey and focus group to elicit\nlearner preferences and requirements and implemented a processing pipeline for\nenhanced captions with keyword highlights, time-synchronized keyword\nhighlights, and keyword captions. A subsequent online study (n = 49) showed\nthat time-synchronized keyword highlights were the preferred design for\nlearning but were perceived as too distracting to replace standard captions in\neveryday viewing scenarios. We conclude that keyword highlights and\ntime-synchronization are suitable for integrating learning into an entertaining\neveryday-life activity, but the design should be optimized to provide a more\nseamless experience.\n","authors":["Fiona Draxler","Henrike Weingärtner","Maximiliane Windl","Albrecht Schmidt","Lewis L. Chuang"],"pdf_url":"https://arxiv.org/pdf/2307.05870v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2307.06333v1","updated":"2023-07-12T17:55:08Z","published":"2023-07-12T17:55:08Z","title":"Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for\n  Test-Time Policy Adaptation","summary":"  Policies often fail due to distribution shift -- changes in the state and\nreward that occur when a policy is deployed in new environments. Data\naugmentation can increase robustness by making the model invariant to\ntask-irrelevant changes in the agent's observation. However, designers don't\nknow which concepts are irrelevant a priori, especially when different end\nusers have different preferences about how the task is performed. We propose an\ninteractive framework to leverage feedback directly from the user to identify\npersonalized task-irrelevant concepts. Our key idea is to generate\ncounterfactual demonstrations that allow users to quickly identify possible\ntask-relevant and irrelevant concepts. The knowledge of task-irrelevant\nconcepts is then used to perform data augmentation and thus obtain a policy\nadapted to personalized user objectives. We present experiments validating our\nframework on discrete and continuous control tasks with real human users. Our\nmethod (1) enables users to better understand agent failure, (2) reduces the\nnumber of demonstrations required for fine-tuning, and (3) aligns the agent to\nindividual user task preferences.\n","authors":["Andi Peng","Aviv Netanyahu","Mark Ho","Tianmin Shu","Andreea Bobu","Julie Shah","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2307.06333v1.pdf","comment":"International Conference on Machine Learning (ICML) 2023"},{"id":"http://arxiv.org/abs/2307.06328v1","updated":"2023-07-12T17:47:35Z","published":"2023-07-12T17:47:35Z","title":"Budgeting Counterfactual for Offline RL","summary":"  The main challenge of offline reinforcement learning, where data is limited,\narises from a sequence of counterfactual reasoning dilemmas within the realm of\npotential actions: What if we were to choose a different course of action?\nThese circumstances frequently give rise to extrapolation errors, which tend to\naccumulate exponentially with the problem horizon. Hence, it becomes crucial to\nacknowledge that not all decision steps are equally important to the final\noutcome, and to budget the number of counterfactual decisions a policy make in\norder to control the extrapolation. Contrary to existing approaches that use\nregularization on either the policy or value function, we propose an approach\nto explicitly bound the amount of out-of-distribution actions during training.\nSpecifically, our method utilizes dynamic programming to decide where to\nextrapolate and where not to, with an upper bound on the decisions different\nfrom behavior policy. It balances between the potential for improvement from\ntaking out-of-distribution actions and the risk of making errors due to\nextrapolation. Theoretically, we justify our method by the constrained\noptimality of the fixed point solution to our $Q$ updating rules. Empirically,\nwe show that the overall performance of our method is better than the\nstate-of-the-art offline RL methods on tasks in the widely-used D4RL\nbenchmarks.\n","authors":["Yao Liu","Pratik Chaudhari","Rasool Fakoor"],"pdf_url":"https://arxiv.org/pdf/2307.06328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04686v2","updated":"2023-07-12T17:06:41Z","published":"2023-07-10T16:42:03Z","title":"VampNet: Music Generation via Masked Acoustic Token Modeling","summary":"  We introduce VampNet, a masked acoustic token modeling approach to music\nsynthesis, compression, inpainting, and variation. We use a variable masking\nschedule during training which allows us to sample coherent music from the\nmodel by applying a variety of masking approaches (called prompts) during\ninference. VampNet is non-autoregressive, leveraging a bidirectional\ntransformer architecture that attends to all tokens in a forward pass. With\njust 36 sampling passes, VampNet can generate coherent high-fidelity musical\nwaveforms. We show that by prompting VampNet in various ways, we can apply it\nto tasks like music compression, inpainting, outpainting, continuation, and\nlooping with variation (vamping). Appropriately prompted, VampNet is capable of\nmaintaining style, genre, instrumentation, and other high-level aspects of the\nmusic. This flexible prompting capability makes VampNet a powerful music\nco-creation tool. Code and audio samples are available online.\n","authors":["Hugo Flores Garcia","Prem Seetharaman","Rithesh Kumar","Bryan Pardo"],"pdf_url":"https://arxiv.org/pdf/2307.04686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06304v1","updated":"2023-07-12T17:01:03Z","published":"2023-07-12T17:01:03Z","title":"Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and\n  Resolution","summary":"  The ubiquitous and demonstrably suboptimal choice of resizing images to a\nfixed resolution before processing them with computer vision models has not yet\nbeen successfully challenged. However, models such as the Vision Transformer\n(ViT) offer flexible sequence-based modeling, and hence varying input sequence\nlengths. We take advantage of this with NaViT (Native Resolution ViT) which\nuses sequence packing during training to process inputs of arbitrary\nresolutions and aspect ratios. Alongside flexible model usage, we demonstrate\nimproved training efficiency for large-scale supervised and contrastive\nimage-text pretraining. NaViT can be efficiently transferred to standard tasks\nsuch as image and video classification, object detection, and semantic\nsegmentation and leads to improved results on robustness and fairness\nbenchmarks. At inference time, the input resolution flexibility can be used to\nsmoothly navigate the test-time cost-performance trade-off. We believe that\nNaViT marks a departure from the standard, CNN-designed, input and modelling\npipeline used by most computer vision models, and represents a promising\ndirection for ViTs.\n","authors":["Mostafa Dehghani","Basil Mustafa","Josip Djolonga","Jonathan Heek","Matthias Minderer","Mathilde Caron","Andreas Steiner","Joan Puigcerver","Robert Geirhos","Ibrahim Alabdulmohsin","Avital Oliver","Piotr Padlewski","Alexey Gritsenko","Mario Lučić","Neil Houlsby"],"pdf_url":"https://arxiv.org/pdf/2307.06304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.01424v2","updated":"2023-07-12T16:40:22Z","published":"2023-05-02T13:54:04Z","title":"Uncertain Machine Ethical Decisions Using Hypothetical Retrospection","summary":"  We propose the use of the hypothetical retrospection argumentation procedure,\ndeveloped by Sven Ove Hansson to improve existing approaches to machine ethical\nreasoning by accounting for probability and uncertainty from a position of\nPhilosophy that resonates with humans. Actions are represented with a branching\nset of potential outcomes, each with a state, utility, and either a numeric or\npoetic probability estimate. Actions are chosen based on comparisons between\nsets of arguments favouring actions from the perspective of their branches,\neven those branches that led to an undesirable outcome. This use of arguments\nallows a variety of philosophical theories for ethical reasoning to be used,\npotentially in flexible combination with each other. We implement the\nprocedure, applying consequentialist and deontological ethical theories,\nindependently and concurrently, to an autonomous library system use case. We\nintroduce a preliminary framework that seems to meet the varied requirements of\na machine ethics system: versatility under multiple theories and a resonance\nwith humans that enables transparency and explainability.\n","authors":["Simon Kolker","Louise Dennis","Ramon Fraga Pereira","Mengwei Xu"],"pdf_url":"https://arxiv.org/pdf/2305.01424v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06290v1","updated":"2023-07-12T16:37:31Z","published":"2023-07-12T16:37:31Z","title":"Instruction Mining: High-Quality Instruction Data Selection for Large\n  Language Models","summary":"  Large language models typically undergo two training stages, pretraining and\nfinetuning. Despite that large-scale pretraining endows the model with strong\ncapabilities to generate natural language responses, these pretrained models\ncan still fail to understand human instructions at times. To enhance language\nmodels' ability of interpreting and responding to instructions, instruction\nfinetuning has emerged as a critical method in this area. Recent studies found\nthat large language models can be finetuned to perform well even with a small\namount of high-quality instruction-following data. However, the selection of\nhigh-quality datasets for finetuning language models still lacks clear\nguidelines to follow. In this paper, we propose InstructMining, a linear rule\nfor evaluating instruction-following data quality. We formulate InstructMining\nusing specific natural language indicators. To investigate the relationship\nbetween data quality and these indicators, we further conduct extensive\nfinetuning experiments. The experiment results are then applied to estimating\nparameters in InstructMining. To further investigate its performance, we use\nInstructMining to select high-quality data from unseen datasets. Results\ndemonstrate that InstructMining can help select relatively high-quality samples\nfrom various instruction-following datasets. Compared to models finetuned on\nunfiltered datasets, models finetuned on InstructMining selected datasets\nperform better on 42.5% cases.\n","authors":["Yihan Cao","Yanbin Kang","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2307.06290v1.pdf","comment":"Work in progress. 12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2304.06848v2","updated":"2023-07-12T16:34:08Z","published":"2023-04-13T22:32:21Z","title":"CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in\n  Confounded Environments","summary":"  Robots operating in real-world environments must reason about possible\noutcomes of stochastic actions and make decisions based on partial observations\nof the true world state. A major challenge for making accurate and robust\naction predictions is the problem of confounding, which if left untreated can\nlead to prediction errors. The partially observable Markov decision process\n(POMDP) is a widely-used framework to model these stochastic and\npartially-observable decision-making problems. However, due to a lack of\nexplicit causal semantics, POMDP planning methods are prone to confounding bias\nand thus in the presence of unobserved confounders may produce underperforming\npolicies. This paper presents a novel causally-informed extension of \"anytime\nregularized determinized sparse partially observable tree\" (AR-DESPOT), a\nmodern anytime online POMDP planner, using causal modelling and inference to\neliminate errors caused by unmeasured confounder variables. We further propose\na method to learn offline the partial parameterisation of the causal model for\nplanning, from ground truth model data. We evaluate our methods on a toy\nproblem with an unobserved confounder and show that the learned causal model is\nhighly accurate, while our planning method is more robust to confounding and\nproduces overall higher performing policies than AR-DESPOT.\n","authors":["Ricardo Cannizzaro","Lars Kunze"],"pdf_url":"https://arxiv.org/pdf/2304.06848v2.pdf","comment":"8 pages, 3 figures, accepted to 2023 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)"},{"id":"http://arxiv.org/abs/2307.04149v2","updated":"2023-07-12T15:49:41Z","published":"2023-07-09T10:56:44Z","title":"Latent Graph Attention for Enhanced Spatial Context","summary":"  Global contexts in images are quite valuable in image-to-image translation\nproblems. Conventional attention-based and graph-based models capture the\nglobal context to a large extent, however, these are computationally expensive.\nMoreover, the existing approaches are limited to only learning the pairwise\nsemantic relation between any two points on the image. In this paper, we\npresent Latent Graph Attention (LGA) a computationally inexpensive (linear to\nthe number of nodes) and stable, modular framework for incorporating the global\ncontext in the existing architectures, especially empowering small-scale\narchitectures to give performance closer to large size architectures, thus\nmaking the light-weight architectures more useful for edge devices with lower\ncompute power and lower energy needs. LGA propagates information spatially\nusing a network of locally connected graphs, thereby facilitating to construct\na semantically coherent relation between any two spatially distant points that\nalso takes into account the influence of the intermediate pixels. Moreover, the\ndepth of the graph network can be used to adapt the extent of contextual spread\nto the target dataset, thereby being able to explicitly control the added\ncomputational cost. To enhance the learning mechanism of LGA, we also introduce\na novel contrastive loss term that helps our LGA module to couple well with the\noriginal architecture at the expense of minimal additional computational load.\nWe show that incorporating LGA improves the performance on three challenging\napplications, namely transparent object segmentation, image restoration for\ndehazing and optical flow estimation.\n","authors":["Ayush Singh","Yash Bhambhu","Himanshu Buckchash","Deepak K. Gupta","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2307.04149v2.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.11941v2","updated":"2023-07-12T15:44:22Z","published":"2023-06-20T23:38:24Z","title":"Efficient Dynamics Modeling in Interactive Environments with Koopman\n  Theory","summary":"  The accurate modeling of dynamics in interactive environments is critical for\nsuccessful long-range prediction. Such a capability could advance Reinforcement\nLearning (RL) and Planning algorithms, but achieving it is challenging.\nInaccuracies in model estimates can compound, resulting in increased errors\nover long horizons. We approach this problem from the lens of Koopman theory,\nwhere the nonlinear dynamics of the environment can be linearized in a\nhigh-dimensional latent space. This allows us to efficiently parallelize the\nsequential problem of long-range prediction using convolution, while accounting\nfor the agent's action at every time step. Our approach also enables stability\nanalysis and better control over gradients through time. Taken together, these\nadvantages result in significant improvement over the existing approaches, both\nin the efficiency and the accuracy of modeling dynamics over extended horizons.\nWe also report promising experimental results in dynamics modeling for the\nscenarios of both model-based planning and model-free RL.\n","authors":["Arnab Kumar Mondal","Siba Smarak Panigrahi","Sai Rajeswar","Kaleem Siddiqi","Siamak Ravanbakhsh"],"pdf_url":"https://arxiv.org/pdf/2306.11941v2.pdf","comment":"18 pages, 3 figures"},{"id":"http://arxiv.org/abs/2307.03109v3","updated":"2023-07-12T15:43:03Z","published":"2023-07-06T16:28:35Z","title":"A Survey on Evaluation of Large Language Models","summary":"  Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.\n","authors":["Yupeng Chang","Xu Wang","Jindong Wang","Yuan Wu","Kaijie Zhu","Hao Chen","Linyi Yang","Xiaoyuan Yi","Cunxiang Wang","Yidong Wang","Wei Ye","Yue Zhang","Yi Chang","Philip S. Yu","Qiang Yang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2307.03109v3.pdf","comment":"24 pages; code is at https://github.com/MLGroupJLU/LLM-eval-survey"},{"id":"http://arxiv.org/abs/2306.10548v3","updated":"2023-07-12T15:40:14Z","published":"2023-06-18T12:56:46Z","title":"MARBLE: Music Audio Representation Benchmark for Universal Evaluation","summary":"  In the era of extensive intersection between art and Artificial Intelligence\n(AI), such as image generation and fiction co-creation, AI for music remains\nrelatively nascent, particularly in music understanding. This is evident in the\nlimited work on deep music representations, the scarcity of large-scale\ndatasets, and the absence of a universal and community-driven benchmark. To\naddress this issue, we introduce the Music Audio Representation Benchmark for\nuniversaL Evaluation, termed MARBLE. It aims to provide a benchmark for various\nMusic Information Retrieval (MIR) tasks by defining a comprehensive taxonomy\nwith four hierarchy levels, including acoustic, performance, score, and\nhigh-level description. We then establish a unified protocol based on 14 tasks\non 8 public-available datasets, providing a fair and standard assessment of\nrepresentations of all open-sourced pre-trained models developed on music\nrecordings as baselines. Besides, MARBLE offers an easy-to-use, extendable, and\nreproducible suite for the community, with a clear statement on copyright\nissues on datasets. Results suggest recently proposed large-scale pre-trained\nmusical language models perform the best in most tasks, with room for further\nimprovement. The leaderboard and toolkit repository are published at\nhttps://marble-bm.shef.ac.uk to promote future music AI research.\n","authors":["Ruibin Yuan","Yinghao Ma","Yizhi Li","Ge Zhang","Xingran Chen","Hanzhi Yin","Le Zhuo","Yiqi Liu","Jiawen Huang","Zeyue Tian","Binyue Deng","Ningzhi Wang","Chenghua Lin","Emmanouil Benetos","Anton Ragni","Norbert Gyenge","Roger Dannenberg","Wenhu Chen","Gus Xia","Wei Xue","Si Liu","Shi Wang","Ruibo Liu","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2306.10548v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06240v1","updated":"2023-07-12T15:28:26Z","published":"2023-07-12T15:28:26Z","title":"DSSE: a drone swarm search environment","summary":"  The Drone Swarm Search project is an environment, based on PettingZoo, that\nis to be used in conjunction with multi-agent (or single-agent) reinforcement\nlearning algorithms. It is an environment in which the agents (drones), have to\nfind the targets (shipwrecked people). The agents do not know the position of\nthe target and do not receive rewards related to their own distance to the\ntarget(s). However, the agents receive the probabilities of the target(s) being\nin a certain cell of the map. The aim of this project is to aid in the study of\nreinforcement learning algorithms that require dynamic probabilities as inputs.\n","authors":["Manuel Castanares","Luis F. S. Carrete","Enrico F. Damiani","Leonardo D. M. de Abreu","José Fernando B. Brancalion","Fabrício J. Barth"],"pdf_url":"https://arxiv.org/pdf/2307.06240v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2307.04617v2","updated":"2023-07-12T15:04:16Z","published":"2023-07-10T15:02:13Z","title":"Weakly-supervised positional contrastive learning: application to\n  cirrhosis classification","summary":"  Large medical imaging datasets can be cheaply and quickly annotated with\nlow-confidence, weak labels (e.g., radiological scores). Access to\nhigh-confidence labels, such as histology-based diagnoses, is rare and costly.\nPretraining strategies, like contrastive learning (CL) methods, can leverage\nunlabeled or weakly-annotated datasets. These methods typically require large\nbatch sizes, which poses a difficulty in the case of large 3D images at full\nresolution, due to limited GPU memory. Nevertheless, volumetric positional\ninformation about the spatial context of each 2D slice can be very important\nfor some medical applications. In this work, we propose an efficient\nweakly-supervised positional (WSP) contrastive learning strategy where we\nintegrate both the spatial context of each 2D slice and a weak label via a\ngeneric kernel-based loss function. We illustrate our method on cirrhosis\nprediction using a large volume of weakly-labeled images, namely radiological\nlow-confidence annotations, and small strongly-labeled (i.e., high-confidence)\ndatasets. The proposed model improves the classification AUC by 5% with respect\nto a baseline model on our internal dataset, and by 26% on the public LIHC\ndataset from the Cancer Genome Atlas. The code is available at:\nhttps://github.com/Guerbet-AI/wsp-contrastive.\n","authors":["Emma Sarfati","Alexandre Bône","Marc-Michel Rohé","Pietro Gori","Isabelle Bloch"],"pdf_url":"https://arxiv.org/pdf/2307.04617v2.pdf","comment":"MICCAI 2023"},{"id":"http://arxiv.org/abs/2307.06213v1","updated":"2023-07-12T15:00:52Z","published":"2023-07-12T15:00:52Z","title":"Testing different Log Bases For Vector Model Weighting Technique","summary":"  Information retrieval systems retrieves relevant documents based on a query\nsubmitted by the user. The documents are initially indexed and the words in the\ndocuments are assigned weights using a weighting technique called TFIDF which\nis the product of Term Frequency (TF) and Inverse Document Frequency (IDF). TF\nrepresents the number of occurrences of a term in a document. IDF measures\nwhether the term is common or rare across all documents. It is computed by\ndividing the total number of documents in the system by the number of documents\ncontaining the term and then computing the logarithm of the quotient. By\ndefault, we use base 10 to calculate the logarithm. In this paper, we are going\nto test this weighting technique by using a range of log bases from 0.1 to\n100.0 to calculate the IDF. Testing different log bases for vector model\nweighting technique is to highlight the importance of understanding the\nperformance of the system at different weighting values. We use the documents\nof MED, CRAN, NPL, LISA, and CISI test collections that scientists assembled\nexplicitly for experiments in data information retrieval systems.\n","authors":["Kamel Assaf"],"pdf_url":"https://arxiv.org/pdf/2307.06213v1.pdf","comment":"15 pages, 7 figures, vector model, logarithms, tfidf"},{"id":"http://arxiv.org/abs/2304.11574v2","updated":"2023-07-12T14:57:28Z","published":"2023-04-23T08:15:20Z","title":"Meta-multigraph Search: Rethinking Meta-structure on Heterogeneous\n  Information Networks","summary":"  Meta-structures are widely used to define which subset of neighbors to\naggregate information in heterogeneous information networks (HINs). In this\nwork, we investigate existing meta-structures, including meta-path and\nmeta-graph, and observe that they are initially designed manually with fixed\npatterns and hence are insufficient to encode various rich semantic information\non diverse HINs. Through reflection on their limitation, we define a new\nconcept called meta-multigraph as a more expressive and flexible generalization\nof meta-graph, and propose a stable differentiable search method to\nautomatically optimize the meta-multigraph for specific HINs and tasks. As the\nflexibility of meta-multigraphs may propagate redundant messages, we further\nintroduce a complex-to-concise (C2C) meta-multigraph that propagates messages\nfrom complex to concise along the depth of meta-multigraph. Moreover, we\nobserve that the differentiable search typically suffers from unstable search\nand a significant gap between the meta-structures in search and evaluation. To\nthis end, we propose a progressive search algorithm by implicitly narrowing the\nsearch space to improve search stability and reduce inconsistency. Extensive\nexperiments are conducted on six medium-scale benchmark datasets and one\nlarge-scale benchmark dataset over two representative tasks, i.e., node\nclassification and recommendation. Empirical results demonstrate that our\nsearch methods can automatically find expressive meta-multigraphs and C2C\nmeta-multigraphs, enabling our model to outperform state-of-the-art\nheterogeneous graph neural networks.\n","authors":["Chao Li","Hao Xu","Kun He"],"pdf_url":"https://arxiv.org/pdf/2304.11574v2.pdf","comment":"17 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:2211.14752"},{"id":"http://arxiv.org/abs/2307.06187v1","updated":"2023-07-12T14:26:46Z","published":"2023-07-12T14:26:46Z","title":"Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems","summary":"  In autonomic computing, self-adaptation has been proposed as a fundamental\nparadigm to manage the complexity of multiagent systems (MASs). This achieved\nby extending a system with support to monitor and adapt itself to achieve\nspecific concerns of interest. Communication in these systems is key given that\nin scenarios involving agent interaction, it enhances cooperation and reduces\ncoordination challenges by enabling direct, clear information exchange.\nHowever, improving the expressiveness of the interaction communication with\nMASs is not without challenges. In this sense, the interplay between\nself-adaptive systems and effective communication is crucial for future MAS\nadvancements. In this paper, we propose the integration of large language\nmodels (LLMs) such as GPT-based technologies into multiagent systems. We anchor\nour methodology on the MAPE-K model, which is renowned for its robust support\nin monitoring, analyzing, planning, and executing system adaptations in\nresponse to dynamic environments. We also present a practical illustration of\nthe proposed approach, in which we implement and assess a basic MAS-based\napplication. The approach significantly advances the state-of-the-art of\nself-adaptive systems by proposing a new paradigm for MAS self-adaptation of\nautonomous systems based on LLM capabilities.\n","authors":["Nathalia Nascimento","Paulo Alencar","Donald Cowan"],"pdf_url":"https://arxiv.org/pdf/2307.06187v1.pdf","comment":"6 pages, submitted"},{"id":"http://arxiv.org/abs/2307.06166v1","updated":"2023-07-12T13:46:28Z","published":"2023-07-12T13:46:28Z","title":"Can Vision-Language Models be a Good Guesser? Exploring VLMs for Times\n  and Location Reasoning","summary":"  Vision-Language Models (VLMs) are expected to be capable of reasoning with\ncommonsense knowledge as human beings. One example is that humans can reason\nwhere and when an image is taken based on their knowledge. This makes us wonder\nif, based on visual cues, Vision-Language Models that are pre-trained with\nlarge-scale image-text resources can achieve and even outperform human's\ncapability in reasoning times and location. To address this question, we\npropose a two-stage \\recognition\\space and \\reasoning\\space probing task,\napplied to discriminative and generative VLMs to uncover whether VLMs can\nrecognize times and location-relevant features and further reason about it. To\nfacilitate the investigation, we introduce WikiTiLo, a well-curated image\ndataset compromising images with rich socio-cultural cues. In the extensive\nexperimental studies, we find that although VLMs can effectively retain\nrelevant features in visual encoders, they still fail to make perfect\nreasoning. We will release our dataset and codes to facilitate future studies.\n","authors":["Gengyuan Zhang","Yurui Zhang","Kerui Zhang","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2307.06166v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2307.06162v1","updated":"2023-07-12T13:42:09Z","published":"2023-07-12T13:42:09Z","title":"Deep Generative Models for Physiological Signals: A Systematic\n  Literature Review","summary":"  In this paper, we present a systematic literature review on deep generative\nmodels for physiological signals, particularly electrocardiogram,\nelectroencephalogram, photoplethysmogram and electromyogram. Compared to the\nexisting review papers, we present the first review that summarizes the recent\nstate-of-the-art deep generative models. By analysing the state-of-the-art\nresearch related to deep generative models along with their main applications\nand challenges, this review contributes to the overall understanding of these\nmodels applied to physiological signals. Additionally, by highlighting the\nemployed evaluation protocol and the most used physiological databases, this\nreview facilitates the assessment and benchmarking of deep generative models.\n","authors":["Nour Neifar","Afef Mdhaffar","Achraf Ben-Hamadou","Mohamed Jmaiel"],"pdf_url":"https://arxiv.org/pdf/2307.06162v1.pdf","comment":"paper under review, 34 pages"},{"id":"http://arxiv.org/abs/2302.06375v2","updated":"2023-07-12T13:40:00Z","published":"2023-02-13T14:08:40Z","title":"One Transformer for All Time Series: Representing and Training with\n  Time-Dependent Heterogeneous Tabular Data","summary":"  There is a recent growing interest in applying Deep Learning techniques to\ntabular data, in order to replicate the success of other Artificial\nIntelligence areas in this structured domain. Specifically interesting is the\ncase in which tabular data have a time dependence, such as, for instance\nfinancial transactions. However, the heterogeneity of the tabular values, in\nwhich categorical elements are mixed with numerical items, makes this\nadaptation difficult. In this paper we propose a Transformer architecture to\nrepresent heterogeneous time-dependent tabular data, in which numerical\nfeatures are represented using a set of frequency functions and the whole\nnetwork is uniformly trained with a unique loss function.\n","authors":["Simone Luetto","Fabrizio Garuti","Enver Sangineto","Lorenzo Forni","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2302.06375v2.pdf","comment":"9 pages, 2 figures, 7 tables"},{"id":"http://arxiv.org/abs/2307.06159v1","updated":"2023-07-12T13:32:24Z","published":"2023-07-12T13:32:24Z","title":"Reflective Hybrid Intelligence for Meaningful Human Control in\n  Decision-Support Systems","summary":"  With the growing capabilities and pervasiveness of AI systems, societies must\ncollectively choose between reduced human autonomy, endangered democracies and\nlimited human rights, and AI that is aligned to human and social values,\nnurturing collaboration, resilience, knowledge and ethical behaviour. In this\nchapter, we introduce the notion of self-reflective AI systems for meaningful\nhuman control over AI systems. Focusing on decision support systems, we propose\na framework that integrates knowledge from psychology and philosophy with\nformal reasoning methods and machine learning approaches to create AI systems\nresponsive to human values and social norms. We also propose a possible\nresearch approach to design and develop self-reflective capability in AI\nsystems. Finally, we argue that self-reflective AI systems can lead to\nself-reflective hybrid systems (human + AI), thus increasing meaningful human\ncontrol and empowering human moral reasoning by providing comprehensible\ninformation and insights on possible human moral blind spots.\n","authors":["Catholijn M. Jonker","Luciano Cavalcante Siebert","Pradeep K. Murukannaiah"],"pdf_url":"https://arxiv.org/pdf/2307.06159v1.pdf","comment":"Accepted for publication at the Research Handbook on Meaningful Human\n  Control of Artificial Intelligence Systems"},{"id":"http://arxiv.org/abs/2307.06152v1","updated":"2023-07-12T13:20:18Z","published":"2023-07-12T13:20:18Z","title":"Maneuver Decision-Making Through Automatic Curriculum Reinforcement\n  Learning Without Handcrafted Reward functions","summary":"  Maneuver decision-making is the core of unmanned combat aerial vehicle for\nautonomous air combat. To solve this problem, we propose an automatic\ncurriculum reinforcement learning method, which enables agents to learn\neffective decisions in air combat from scratch. The range of initial states are\nused for distinguishing curricula of different difficulty levels, thereby\nmaneuver decision is divided into a series of sub-tasks from easy to difficult,\nand test results are used to change sub-tasks. As sub-tasks change, agents\ngradually learn to complete a series of sub-tasks from easy to difficult,\nenabling them to make effective maneuvering decisions to cope with various\nstates without the need to spend effort designing reward functions. The\nablation studied show that the automatic curriculum learning proposed in this\narticle is an essential component for training through reinforcement learning,\nnamely, agents cannot complete effective decisions without curriculum learning.\nSimulation experiments show that, after training, agents are able to make\neffective decisions given different states, including tracking, attacking and\nescaping, which are both rational and interpretable.\n","authors":["Zhang Hong-Peng"],"pdf_url":"https://arxiv.org/pdf/2307.06152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01719v2","updated":"2023-07-12T12:58:02Z","published":"2023-07-04T13:45:52Z","title":"MOPO-LSI: A User Guide","summary":"  MOPO-LSI is an open-source Multi-Objective Portfolio Optimization Library for\nSustainable Investments. This document provides a user guide for MOPO-LSI\nversion 1.0, including problem setup, workflow and the hyper-parameters in\nconfigurations.\n","authors":["Yong Zheng","Kumar Neelotpal Shukla","Jasmine Xu"," David"," Wang","Michael O'Leary"],"pdf_url":"https://arxiv.org/pdf/2307.01719v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06135v1","updated":"2023-07-12T12:37:55Z","published":"2023-07-12T12:37:55Z","title":"SayPlan: Grounding Large Language Models using 3D Scene Graphs for\n  Scalable Task Planning","summary":"  Large language models (LLMs) have demonstrated impressive results in\ndeveloping generalist planning agents for diverse tasks. However, grounding\nthese plans in expansive, multi-floor, and multi-room environments presents a\nsignificant challenge for robotics. We introduce SayPlan, a scalable approach\nto LLM-based, large-scale task planning for robotics using 3D scene graph\n(3DSG) representations. To ensure the scalability of our approach, we: (1)\nexploit the hierarchical nature of 3DSGs to allow LLMs to conduct a semantic\nsearch for task-relevant subgraphs from a smaller, collapsed representation of\nthe full graph; (2) reduce the planning horizon for the LLM by integrating a\nclassical path planner and (3) introduce an iterative replanning pipeline that\nrefines the initial plan using feedback from a scene graph simulator,\ncorrecting infeasible actions and avoiding planning failures. We evaluate our\napproach on two large-scale environments spanning up to 3 floors, 36 rooms and\n140 objects, and show that our approach is capable of grounding large-scale,\nlong-horizon task plans from abstract, and natural language instruction for a\nmobile manipulator robot to execute.\n","authors":["Krishan Rana","Jesse Haviland","Sourav Garg","Jad Abou-Chakra","Ian Reid","Niko Suenderhauf"],"pdf_url":"https://arxiv.org/pdf/2307.06135v1.pdf","comment":"Under review for CoRL 2023. Project page can be found here:\n  https://sayplan.github.io"},{"id":"http://arxiv.org/abs/2305.11474v3","updated":"2023-07-12T12:36:49Z","published":"2023-05-19T06:55:04Z","title":"RAMiT: Reciprocal Attention Mixing Transformer for Lightweight Image\n  Restoration","summary":"  Although many recent works have made advancements in the image restoration\n(IR) field, they often suffer from an excessive number of parameters. Another\nissue is that most Transformer-based IR methods focus only on either local or\nglobal features, leading to limited receptive fields or deficient parameter\nissues. To address these problems, we propose a lightweight IR network,\nReciprocal Attention Mixing Transformer (RAMiT). It employs our proposed\ndimensional reciprocal attention mixing Transformer (D-RAMiT) blocks, which\ncompute bi-dimensional (spatial and channel) self-attentions in parallel with\ndifferent numbers of multi-heads. The bi-dimensional attentions help each other\nto complement their counterpart's drawbacks and are then mixed. Additionally,\nwe introduce a hierarchical reciprocal attention mixing (H-RAMi) layer that\ncompensates for pixel-level information losses and utilizes semantic\ninformation while maintaining an efficient hierarchical structure. Furthermore,\nwe revisit and modify MobileNet V1 and V2 to attach efficient convolutions to\nour proposed components. The experimental results demonstrate that RAMiT\nachieves state-of-the-art performance on multiple lightweight IR tasks,\nincluding super-resolution, color denoising, grayscale denoising, low-light\nenhancement, and deraining. Codes are available at\nhttps://github.com/rami0205/RAMiT.\n","authors":["Haram Choi","Cheolwoong Na","Jihyeon Oh","Seungjae Lee","Jinseop Kim","Subeen Choe","Jeongmin Lee","Taehoon Kim","Jihoon Yang"],"pdf_url":"https://arxiv.org/pdf/2305.11474v3.pdf","comment":"Technical report. 9 pages for main contents + 14 pages for appendix +\n  6 pages for references. Codes are available at\n  https://github.com/rami0205/RAMiT"},{"id":"http://arxiv.org/abs/2305.02759v3","updated":"2023-07-12T12:29:04Z","published":"2023-05-04T11:53:38Z","title":"Disentangled Contrastive Collaborative Filtering","summary":"  Recent studies show that graph neural networks (GNNs) are prevalent to model\nhigh-order relationships for collaborative filtering (CF). Towards this\nresearch line, graph contrastive learning (GCL) has exhibited powerful\nperformance in addressing the supervision label shortage issue by learning\naugmented user and item representations. While many of them show their\neffectiveness, two key questions still remain unexplored: i) Most existing\nGCL-based CF models are still limited by ignoring the fact that user-item\ninteraction behaviors are often driven by diverse latent intent factors (e.g.,\nshopping for family party, preferred color or brand of products); ii) Their\nintroduced non-adaptive augmentation techniques are vulnerable to noisy\ninformation, which raises concerns about the model's robustness and the risk of\nincorporating misleading self-supervised signals. In light of these\nlimitations, we propose a Disentangled Contrastive Collaborative Filtering\nframework (DCCF) to realize intent disentanglement with self-supervised\naugmentation in an adaptive fashion. With the learned disentangled\nrepresentations with global context, our DCCF is able to not only distill\nfiner-grained latent factors from the entangled self-supervision signals but\nalso alleviate the augmentation-induced noise. Finally, the cross-view\ncontrastive learning task is introduced to enable adaptive augmentation with\nour parameterized interaction mask generator. Experiments on various public\ndatasets demonstrate the superiority of our method compared to existing\nsolutions. Our model implementation is released at the link\nhttps://github.com/HKUDS/DCCF.\n","authors":["Xubin Ren","Lianghao Xia","Jiashu Zhao","Dawei Yin","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2305.02759v3.pdf","comment":"Published as a SIGIR'23 full paper"},{"id":"http://arxiv.org/abs/2307.06126v1","updated":"2023-07-12T12:25:37Z","published":"2023-07-12T12:25:37Z","title":"Guided Bottom-Up Interactive Constraint Acquisition","summary":"  Constraint Acquisition (CA) systems can be used to assist in the modeling of\nconstraint satisfaction problems. In (inter)active CA, the system is given a\nset of candidate constraints and posts queries to the user with the goal of\nfinding the right constraints among the candidates. Current interactive CA\nalgorithms suffer from at least two major bottlenecks. First, in order to\nconverge, they require a large number of queries to be asked to the user.\nSecond, they cannot handle large sets of candidate constraints, since these\nlead to large waiting times for the user. For this reason, the user must have\nfairly precise knowledge about what constraints the system should consider. In\nthis paper, we alleviate these bottlenecks by presenting two novel methods that\nimprove the efficiency of CA. First, we introduce a bottom-up approach named\nGrowAcq that reduces the maximum waiting time for the user and allows the\nsystem to handle much larger sets of candidate constraints. It also reduces the\ntotal number of queries for problems in which the target constraint network is\nnot sparse. Second, we propose a probability-based method to guide query\ngeneration and show that it can significantly reduce the number of queries\nrequired to converge. We also propose a new technique that allows the use of\nopenly accessible CP solvers in query generation, removing the dependency of\nexisting methods on less well-maintained custom solvers that are not publicly\navailable. Experimental results show that our proposed methods outperform\nstate-of-the-art CA methods, reducing the number of queries by up to 60%. Our\nmethods work well even in cases where the set of candidate constraints is 50\ntimes larger than the ones commonly used in the literature.\n","authors":["Dimos Tsouros","Senne Berden","Tias Guns"],"pdf_url":"https://arxiv.org/pdf/2307.06126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06125v1","updated":"2023-07-12T12:25:33Z","published":"2023-07-12T12:25:33Z","title":"Learning Hierarchical Interactive Multi-Object Search for Mobile\n  Manipulation","summary":"  Existing object-search approaches enable robots to search through free\npathways, however, robots operating in unstructured human-centered environments\nfrequently also have to manipulate the environment to their needs. In this\nwork, we introduce a novel interactive multi-object search task in which a\nrobot has to open doors to navigate rooms and search inside cabinets and\ndrawers to find target objects. These new challenges require combining\nmanipulation and navigation skills in unexplored environments. We present\nHIMOS, a hierarchical reinforcement learning approach that learns to compose\nexploration, navigation, and manipulation skills. To achieve this, we design an\nabstract high-level action space around a semantic map memory and leverage the\nexplored environment as instance navigation points. We perform extensive\nexperiments in simulation and the real-world that demonstrate that HIMOS\neffectively transfers to new environments in a zero-shot manner. It shows\nrobustness to unseen subpolicies, failures in their execution, and different\nrobot kinematics. These capabilities open the door to a wide range of\ndownstream tasks across embodied AI and real-world use cases.\n","authors":["Fabian Schmalstieg","Daniel Honerkamp","Tim Welschehold","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2307.06125v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2307.06118v1","updated":"2023-07-12T12:19:36Z","published":"2023-07-12T12:19:36Z","title":"TreeFormer: a Semi-Supervised Transformer-based Framework for Tree\n  Counting from a Single High Resolution Image","summary":"  Automatic tree density estimation and counting using single aerial and\nsatellite images is a challenging task in photogrammetry and remote sensing,\nyet has an important role in forest management. In this paper, we propose the\nfirst semisupervised transformer-based framework for tree counting which\nreduces the expensive tree annotations for remote sensing images. Our method,\ntermed as TreeFormer, first develops a pyramid tree representation module based\non transformer blocks to extract multi-scale features during the encoding\nstage. Contextual attention-based feature fusion and tree density regressor\nmodules are further designed to utilize the robust features from the encoder to\nestimate tree density maps in the decoder. Moreover, we propose a pyramid\nlearning strategy that includes local tree density consistency and local tree\ncount ranking losses to utilize unlabeled images into the training process.\nFinally, the tree counter token is introduced to regulate the network by\ncomputing the global tree counts for both labeled and unlabeled images. Our\nmodel was evaluated on two benchmark tree counting datasets, Jiangsu, and\nYosemite, as well as a new dataset, KCL-London, created by ourselves. Our\nTreeFormer outperforms the state of the art semi-supervised methods under the\nsame setting and exceeds the fully-supervised methods using the same number of\nlabeled images. The codes and datasets are available at\nhttps://github.com/HAAClassic/TreeFormer.\n","authors":["Hamed Amini Amirkolaee","Miaojing Shi","Mark Mulligan"],"pdf_url":"https://arxiv.org/pdf/2307.06118v1.pdf","comment":"Accepted in IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING"},{"id":"http://arxiv.org/abs/2306.15724v2","updated":"2023-07-12T12:15:38Z","published":"2023-06-27T18:03:15Z","title":"REFLECT: Summarizing Robot Experiences for Failure Explanation and\n  Correction","summary":"  The ability to detect and analyze failed executions automatically is crucial\nfor an explainable and robust robotic system. Recently, Large Language Models\n(LLMs) have demonstrated strong reasoning abilities on textual inputs. To\nleverage the power of LLM for robot failure explanation, we introduce a\nframework REFLECT, which queries LLM to identify and explain robot failures\ngiven a hierarchical summary of robot past experiences generated from\nmulti-sensory data. Conditioned on the explanation, a task planner will\ngenerate an executable plan for the robot to correct the failure and complete\nthe task. To systematically evaluate the framework, we create the RoboFail\ndataset with a variety of tasks and failure scenarios. We demonstrate that the\nLLM-based framework is able to generate informative failure explanations that\nassist successful correction planning. Videos and code available at:\nhttps://roboreflect.github.io/.\n","authors":["Zeyi Liu","Arpit Bahety","Shuran Song"],"pdf_url":"https://arxiv.org/pdf/2306.15724v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01241v2","updated":"2023-07-12T11:42:33Z","published":"2023-02-02T17:23:28Z","title":"Diagrammatization: Rationalizing with diagrammatic AI explanations for\n  abductive-deductive reasoning on hypotheses","summary":"  Many visualizations have been developed for explainable AI (XAI), but they\noften require further reasoning by users to interpret. We argue that XAI should\nsupport diagrammatic and abductive reasoning for the AI to perform hypothesis\ngeneration and evaluation to reduce the interpretability gap. We propose\nDiagrammatization to i) perform Peircean abductive-deductive reasoning, ii)\nfollow domain conventions, and iii) explain with diagrams visually or verbally.\nWe implemented DiagramNet for a clinical application to predict cardiac\ndiagnoses from heart auscultation, and explain with shape-based murmur\ndiagrams. In modeling studies, we found that DiagramNet not only provides\nfaithful murmur shape explanations, but also has better prediction performance\nthan baseline models. We further demonstrate the interpretability and\ntrustworthiness of diagrammatic explanations in a qualitative user study with\nmedical students, showing that clinically-relevant, diagrammatic explanations\nare preferred over technical saliency map explanations. This work contributes\ninsights into providing domain-conventional abductive explanations for\nuser-centric XAI.\n","authors":["Brian Y. Lim","Joseph P. Cahaly","Chester Y. F. Sng","Adam Chew"],"pdf_url":"https://arxiv.org/pdf/2302.01241v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06092v1","updated":"2023-07-12T11:35:37Z","published":"2023-07-12T11:35:37Z","title":"Quantitative CLTs in Deep Neural Networks","summary":"  We study the distribution of a fully connected neural network with random\nGaussian weights and biases in which the hidden layer widths are proportional\nto a large constant $n$. Under mild assumptions on the non-linearity, we obtain\nquantitative bounds on normal approximations valid at large but finite $n$ and\nany fixed network depth. Our theorems show, both for the finite-dimensional\ndistributions and the entire process, that the distance between a random fully\nconnected network (and its derivatives) to the corresponding infinite width\nGaussian process scales like $n^{-\\gamma}$ for $\\gamma>0,$ with the exponent\ndepending on the metric used to measure discrepancy. Our bounds are stronger in\nterms of their dependence on network width than any previously available in the\nliterature.\n","authors":["Stefano Favaro","Boris Hanin","Domenico Marinucci","Ivan Nourdin","Giovanni Peccati"],"pdf_url":"https://arxiv.org/pdf/2307.06092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03717v2","updated":"2023-07-12T11:22:47Z","published":"2023-06-06T14:27:03Z","title":"Description Logics with Abstraction and Refinement","summary":"  Ontologies often require knowledge representation on multiple levels of\nabstraction, but description logics (DLs) are not well-equipped for supporting\nthis. We propose an extension of DLs in which abstraction levels are\nfirst-class citizens and which provides explicit operators for the abstraction\nand refinement of concepts and roles across multiple abstraction levels, based\non conjunctive queries. We prove that reasoning in the resulting family of DLs\nis decidable while several seemingly harmless variations turn out to be\nundecidable. We also pinpoint the precise complexity of our logics and several\nrelevant fragments.\n","authors":["Carsten Lutz","Lukas Schulze"],"pdf_url":"https://arxiv.org/pdf/2306.03717v2.pdf","comment":"25 pages, Long version of paper accepted at KR 2023"},{"id":"http://arxiv.org/abs/2305.13783v2","updated":"2023-07-12T11:13:20Z","published":"2023-05-23T07:53:35Z","title":"Deep Reinforcement Learning-based Multi-objective Path Planning on the\n  Off-road Terrain Environment for Ground Vehicles","summary":"  Due to the vastly different energy consumption between up-slope and\ndown-slope, a path with the shortest length on a complex off-road terrain\nenvironment (2.5D map) is not always the path with the least energy\nconsumption. For any energy-sensitive vehicle, realizing a good trade-off\nbetween distance and energy consumption in 2.5D path planning is significantly\nmeaningful. In this paper, we propose a deep reinforcement learning-based 2.5D\nmulti-objective path planning method (DMOP). The DMOP can efficiently find the\ndesired path in three steps: (1) Transform the high-resolution 2.5D map into a\nsmall-size map. (2) Use a trained deep Q network (DQN) to find the desired path\non the small-size map. (3) Build the planned path to the original\nhigh-resolution map using a path-enhanced method. In addition, the hybrid\nexploration strategy and reward shaping theory are applied to train the DQN.\nThe reward function is constructed with the information of terrain, distance,\nand border. Simulation results show that the proposed method can finish the\nmulti-objective 2.5D path planning task with significantly high efficiency.\nWith similar planned paths, the speed of the proposed method is more than 100\ntimes faster than that of the A* method and 30 times faster than that of H3DM\nmethod. Also, simulation proves that the method has powerful reasoning\ncapability that enables it to perform arbitrary untrained planning tasks.\n","authors":["Shuqiao Huang","Xiru Wu","Guoming Huang"],"pdf_url":"https://arxiv.org/pdf/2305.13783v2.pdf","comment":"9 pages,8 figures"},{"id":"http://arxiv.org/abs/2307.06082v1","updated":"2023-07-12T11:08:24Z","published":"2023-07-12T11:08:24Z","title":"VELMA: Verbalization Embodiment of LLM Agents for Vision and Language\n  Navigation in Street View","summary":"  Incremental decision making in real-world environments is one of the most\nchallenging tasks in embodied artificial intelligence. One particularly\ndemanding scenario is Vision and Language Navigation~(VLN) which requires\nvisual and natural language understanding as well as spatial and temporal\nreasoning capabilities. The embodied agent needs to ground its understanding of\nnavigation instructions in observations of a real-world environment like Street\nView. Despite the impressive results of LLMs in other research areas, it is an\nongoing problem of how to best connect them with an interactive visual\nenvironment. In this work, we propose VELMA, an embodied LLM agent that uses a\nverbalization of the trajectory and of visual environment observations as\ncontextual prompt for the next action. Visual information is verbalized by a\npipeline that extracts landmarks from the human written navigation instructions\nand uses CLIP to determine their visibility in the current panorama view. We\nshow that VELMA is able to successfully follow navigation instructions in\nStreet View with only two in-context examples. We further finetune the LLM\nagent on a few thousand examples and achieve 25%-30% relative improvement in\ntask completion over the previous state-of-the-art for two datasets.\n","authors":["Raphael Schumann","Wanrong Zhu","Weixi Feng","Tsu-Jui Fu","Stefan Riezler","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2307.06082v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04132v2","updated":"2023-07-12T10:57:00Z","published":"2023-07-09T09:04:26Z","title":"Reasoning over the Behaviour of Objects in Video-Clips for Adverb-Type\n  Recognition","summary":"  In this work, following the intuition that adverbs describing scene-sequences\nare best identified by reasoning over high-level concepts of object-behavior,\nwe propose the design of a new framework that reasons over object-behaviours\nextracted from raw-video-clips to recognize the clip's corresponding\nadverb-types. Importantly, while previous works for general scene\nadverb-recognition assume knowledge of the clips underlying action-types, our\nmethod is directly applicable in the more general problem setting where the\naction-type of a video-clip is unknown. Specifically, we propose a novel\npipeline that extracts human-interpretable object-behaviour-facts from raw\nvideo clips and propose novel symbolic and transformer based reasoning methods\nthat operate over these extracted facts to identify adverb-types. Experiment\nresults demonstrate that our proposed methods perform favourably against the\nprevious state-of-the-art. Additionally, to support efforts in symbolic\nvideo-processing, we release two new datasets of object-behaviour-facts\nextracted from raw video clips - the MSR-VTT-ASP and ActivityNet-ASP datasets.\n","authors":["Amrit Diggavi Seshadri","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2307.04132v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06052v1","updated":"2023-07-12T10:12:57Z","published":"2023-07-12T10:12:57Z","title":"Visualization for Multivariate Gaussian Anomaly Detection in Images","summary":"  This paper introduces a simplified variation of the PaDiM (Pixel-Wise Anomaly\nDetection through Instance Modeling) method for anomaly detection in images,\nfitting a single multivariate Gaussian (MVG) distribution to the feature\nvectors extracted from a backbone convolutional neural network (CNN) and using\ntheir Mahalanobis distance as the anomaly score. We introduce an intermediate\nstep in this framework by applying a whitening transformation to the feature\nvectors, which enables the generation of heatmaps capable of visually\nexplaining the features learned by the MVG. The proposed technique is evaluated\non the MVTec-AD dataset, and the results show the importance of visual model\nvalidation, providing insights into issues in this framework that were\notherwise invisible. The visualizations generated for this paper are publicly\navailable at https://doi.org/10.5281/zenodo.7937978.\n","authors":["Joao P C Bertoldo","David Arrustico"],"pdf_url":"https://arxiv.org/pdf/2307.06052v1.pdf","comment":"6 pages, 8 figures, accepted to 2023 Twelfth International Conference\n  on Image Processing Theory, Tools and Applications (IPTA)"},{"id":"http://arxiv.org/abs/2010.02613v3","updated":"2023-07-12T10:00:51Z","published":"2020-10-06T10:46:27Z","title":"Deep Learning based Uncertainty Decomposition for Real-time Control","summary":"  Data-driven control in unknown environments requires a clear understanding of\nthe involved uncertainties for ensuring safety and efficient exploration. While\naleatoric uncertainty that arises from measurement noise can often be\nexplicitly modeled given a parametric description, it can be harder to model\nepistemic uncertainty, which describes the presence or absence of training\ndata. The latter can be particularly useful for implementing exploratory\ncontrol strategies when system dynamics are unknown. We propose a novel method\nfor detecting the absence of training data using deep learning, which gives a\ncontinuous valued scalar output between $0$ (indicating low uncertainty) and\n$1$ (indicating high uncertainty). We utilize this detector as a proxy for\nepistemic uncertainty and show its advantages over existing approaches on\nsynthetic and real-world datasets. Our approach can be directly combined with\naleatoric uncertainty estimates and allows for uncertainty estimation in\nreal-time as the inference is sample-free unlike existing approaches for\nuncertainty modeling. We further demonstrate the practicality of this\nuncertainty estimate in deploying online data-efficient control on a simulated\nquadcopter acted upon by an unknown disturbance model.\n","authors":["Neha Das","Jonas Umlauft","Armin Lederer","Thomas Beckers","Sandra Hirche"],"pdf_url":"https://arxiv.org/pdf/2010.02613v3.pdf","comment":"Accepted at IFAC World Congress 2023"},{"id":"http://arxiv.org/abs/2307.06046v1","updated":"2023-07-12T09:49:15Z","published":"2023-07-12T09:49:15Z","title":"An OOD Multi-Task Perspective for Link Prediction with New Relation\n  Types and Nodes","summary":"  The task of inductive link prediction in (discrete) attributed multigraphs\ninfers missing attributed links (relations) between nodes in new test\nmultigraphs. Traditional relational learning methods face the challenge of\nlimited generalization to OOD test multigraphs containing both novel nodes and\nnovel relation types not seen in training. Recently, under the only assumption\nthat all relation types share the same structural predictive patterns (single\ntask), Gao et al. (2023) proposed an OOD link prediction method using the\ntheoretical concept of double exchangeability (for nodes & relation types), in\ncontrast to the (single) exchangeability (only for nodes) used to design Graph\nNeural Networks (GNNs). In this work we further extend the double\nexchangeability concept to multi-task double exchangeability, where we define\nlink prediction in attributed multigraphs that can have distinct and\npotentially conflicting predictive patterns for different sets of relation\ntypes (multiple tasks). Our empirical results on real-world datasets\ndemonstrate that our approach can effectively generalize to entirely new\nrelation types in test, without access to additional information, yielding\nsignificant performance improvements over existing methods.\n","authors":["Jincheng Zhou","Beatrice Bevilacqua","Bruno Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2307.06046v1.pdf","comment":"23 pages, 3 figures"},{"id":"http://arxiv.org/abs/2102.00479v2","updated":"2023-07-12T09:33:34Z","published":"2021-01-31T16:17:56Z","title":"Fast Rates for the Regret of Offline Reinforcement Learning","summary":"  We study the regret of reinforcement learning from offline data generated by\na fixed behavior policy in an infinite-horizon discounted Markov decision\nprocess (MDP). While existing analyses of common approaches, such as fitted\n$Q$-iteration (FQI), suggest a $O(1/\\sqrt{n})$ convergence for regret,\nempirical behavior exhibits \\emph{much} faster convergence. In this paper, we\npresent a finer regret analysis that exactly characterizes this phenomenon by\nproviding fast rates for the regret convergence. First, we show that given any\nestimate for the optimal quality function $Q^*$, the regret of the policy it\ndefines converges at a rate given by the exponentiation of the $Q^*$-estimate's\npointwise convergence rate, thus speeding it up. The level of exponentiation\ndepends on the level of noise in the \\emph{decision-making} problem, rather\nthan the estimation problem. We establish such noise levels for linear and\ntabular MDPs as examples. Second, we provide new analyses of FQI and Bellman\nresidual minimization to establish the correct pointwise convergence\nguarantees. As specific cases, our results imply $O(1/n)$ regret rates in\nlinear cases and $\\exp(-\\Omega(n))$ regret rates in tabular cases. We extend\nour findings to general function approximation by extending our results to\nregret guarantees based on $L_p$-convergence rates for estimating $Q^*$ rather\nthan pointwise rates, where $L_2$ guarantees for nonparametric $Q^*$-estimation\ncan be ensured under mild conditions.\n","authors":["Yichun Hu","Nathan Kallus","Masatoshi Uehara"],"pdf_url":"https://arxiv.org/pdf/2102.00479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04026v3","updated":"2023-07-12T09:26:38Z","published":"2023-06-06T21:41:31Z","title":"Value Functions are Control Barrier Functions: Verification of Safe\n  Policies using Control Theory","summary":"  Guaranteeing safe behaviour of reinforcement learning (RL) policies poses\nsignificant challenges for safety-critical applications, despite RL's\ngenerality and scalability. To address this, we propose a new approach to apply\nverification methods from control theory to learned value functions. By\nanalyzing task structures for safety preservation, we formalize original\ntheorems that establish links between value functions and control barrier\nfunctions. Further, we propose novel metrics for verifying value functions in\nsafe control tasks and practical implementation details to improve learning.\nOur work presents a novel method for certificate learning, which unlocks a\ndiversity of verification techniques from control theory for RL policies, and\nmarks a significant step towards a formal framework for the general, scalable,\nand verifiable design of RL-based control systems. Code and videos are\navailable at this https url: https://rl-cbf.github.io/\n","authors":["Daniel C. H. Tan","Fernando Acero","Robert McCarthy","Dimitrios Kanoulas","Zhibin Li"],"pdf_url":"https://arxiv.org/pdf/2306.04026v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06033v1","updated":"2023-07-12T09:25:56Z","published":"2023-07-12T09:25:56Z","title":"AI-Generated Imagery: A New Era for the `Readymade'","summary":"  While the term `art' defies any concrete definition, this paper aims to\nexamine how digital images produced by generative AI systems, such as\nMidjourney, have come to be so regularly referred to as such. The discourse\naround the classification of AI-generated imagery as art is currently somewhat\nhomogeneous, lacking the more nuanced aspects that would apply to more\ntraditional modes of artistic media production. This paper aims to bring\nimportant philosophical considerations to the surface of the discussion around\nAI-generated imagery in the context of art. We employ existing philosophical\nframeworks and theories of language to suggest that some AI-generated imagery,\nby virtue of its visual properties within these frameworks, can be presented as\n`readymades' for consideration as art.\n","authors":["Amy Smith","Michael Cook"],"pdf_url":"https://arxiv.org/pdf/2307.06033v1.pdf","comment":"5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2305.04003v2","updated":"2023-07-12T09:24:34Z","published":"2023-05-06T10:36:39Z","title":"ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for\n  Verification","summary":"  Verification of machine learning models used in Natural Language Processing\n(NLP) is known to be a hard problem. In particular, many known neural network\nverification methods that work for computer vision and other numeric datasets\ndo not work for NLP. Here, we study technical reasons that underlie this\nproblem. Based on this analysis, we propose practical methods and heuristics\nfor preparing NLP datasets and models in a way that renders them amenable to\nknown verification methods based on abstract interpretation. We implement these\nmethods as a Python library called ANTONIO that links to the neural network\nverifiers ERAN and Marabou. We perform evaluation of the tool using an NLP\ndataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP\napplications. We hope that, thanks to its general applicability, this work will\nopen novel possibilities for including NLP verification problems into neural\nnetwork verification competitions, and will popularise NLP problems within this\ncommunity.\n","authors":["Marco Casadio","Luca Arnaboldi","Matthew L. Daggitt","Omri Isac","Tanvi Dinkar","Daniel Kienitz","Verena Rieser","Ekaterina Komendantskaya"],"pdf_url":"https://arxiv.org/pdf/2305.04003v2.pdf","comment":"To appear in proceedings of 6th Workshop on Formal Methods for\n  ML-Enabled Autonomous Systems (Affiliated with CAV 2023)"},{"id":"http://arxiv.org/abs/2307.01227v2","updated":"2023-07-12T09:14:53Z","published":"2023-07-03T04:47:42Z","title":"ESGCN: Edge Squeeze Attention Graph Convolutional Network for Traffic\n  Flow Forecasting","summary":"  Traffic forecasting is a highly challenging task owing to the dynamical\nspatio-temporal dependencies of traffic flows. To handle this, we focus on\nmodeling the spatio-temporal dynamics and propose a network termed Edge Squeeze\nGraph Convolutional Network (ESGCN) to forecast traffic flow in multiple\nregions. ESGCN consists of two modules: W-module and ES module. W-module is a\nfully node-wise convolutional network. It encodes the time-series of each\ntraffic region separately and decomposes the time-series at various scales to\ncapture fine and coarse features. The ES module models the spatio-temporal\ndynamics using Graph Convolutional Network (GCN) and generates an Adaptive\nAdjacency Matrix (AAM) with temporal features. To improve the accuracy of AAM,\nwe introduce three key concepts. 1) Using edge features to directly capture the\nspatiotemporal flow representation among regions. 2) Applying an edge attention\nmechanism to GCN to extract the AAM from the edge features. Here, the attention\nmechanism can effectively determine important spatio-temporal adjacency\nrelations. 3) Proposing a novel node contrastive loss to suppress obstructed\nconnections and emphasize related connections. Experimental results show that\nESGCN achieves state-of-the-art performance by a large margin on four\nreal-world datasets (PEMS03, 04, 07, and 08) with a low computational cost.\n","authors":["Sangrok Lee","Ha Young Kim"],"pdf_url":"https://arxiv.org/pdf/2307.01227v2.pdf","comment":"7 Pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.09582v3","updated":"2023-07-12T09:04:14Z","published":"2023-02-19T14:21:33Z","title":"Language-Specific Representation of Emotion-Concept Knowledge Causally\n  Supports Emotion Inference","summary":"  Understanding how language supports emotion inference remains a topic of\ndebate in emotion science. The present study investigated whether\nlanguage-derived emotion-concept knowledge would causally support emotion\ninference by manipulating the language-specific knowledge representations in\nlarge language models. Using the prompt technique, 14 attributes of emotion\nconcepts were found to be represented by distinct artificial neuron\npopulations. By manipulating these attribute-related neurons, the majority of\nthe emotion inference tasks showed performance deterioration compared to random\nmanipulations. The attribute-specific performance deterioration was related to\nthe importance of different attributes in human mental space. Our findings\nprovide causal evidence in support of a language-based mechanism for emotion\ninference and highlight the contributions of emotion-concept knowledge.\n","authors":["Ming Li","Yusheng Su","Hsiu-Yuan Huang","Jiali Cheng","Xin Hu","Xinmiao Zhang","Huadong Wang","Yujia Qin","Xiaozhi Wang","Zhiyuan Liu","Dan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.09582v3.pdf","comment":"39 pages, 13 figures, 2 tables, major revisions over previous\n  versions"},{"id":"http://arxiv.org/abs/2307.06013v1","updated":"2023-07-12T08:51:20Z","published":"2023-07-12T08:51:20Z","title":"An Effective and Efficient Time-aware Entity Alignment Framework via\n  Two-aspect Three-view Label Propagation","summary":"  Entity alignment (EA) aims to find the equivalent entity pairs between\ndifferent knowledge graphs (KGs), which is crucial to promote knowledge fusion.\nWith the wide use of temporal knowledge graphs (TKGs), time-aware EA (TEA)\nmethods appear to enhance EA. Existing TEA models are based on Graph Neural\nNetworks (GNN) and achieve state-of-the-art (SOTA) performance, but it is\ndifficult to transfer them to large-scale TKGs due to the scalability issue of\nGNN. In this paper, we propose an effective and efficient non-neural EA\nframework between TKGs, namely LightTEA, which consists of four essential\ncomponents: (1) Two-aspect Three-view Label Propagation, (2) Sparse Similarity\nwith Temporal Constraints, (3) Sinkhorn Operator, and (4) Temporal Iterative\nLearning. All of these modules work together to improve the performance of EA\nwhile reducing the time consumption of the model. Extensive experiments on\npublic datasets indicate that our proposed model significantly outperforms the\nSOTA methods for EA between TKGs, and the time consumed by LightTEA is only\ndozens of seconds at most, no more than 10% of the most efficient TEA method.\n","authors":["Li Cai","Xin Mao","Youshao Xiao","Changxu Wu","Man Lan"],"pdf_url":"https://arxiv.org/pdf/2307.06013v1.pdf","comment":"Accepted by IJCAI 2023"},{"id":"http://arxiv.org/abs/2306.07310v2","updated":"2023-07-12T08:27:36Z","published":"2023-06-12T17:53:06Z","title":"Employing Crowdsourcing for Enriching a Music Knowledge Base in Higher\n  Education","summary":"  This paper describes the methodology followed and the lessons learned from\nemploying crowdsourcing techniques as part of a homework assignment involving\nhigher education students of computer science. Making use of a platform that\nsupports crowdsourcing in the cultural heritage domain students were solicited\nto enrich the metadata associated with a selection of music tracks. The results\nof the campaign were further analyzed and exploited by students through the use\nof semantic web technologies. In total, 98 students participated in the\ncampaign, contributing more than 6400 annotations concerning 854 tracks. The\nprocess also led to the creation of an openly available annotated dataset,\nwhich can be useful for machine learning models for music tagging. The\ncampaign's results and the comments gathered through an online survey enable us\nto draw some useful insights about the benefits and challenges of integrating\ncrowdsourcing into computer science curricula and how this can enhance\nstudents' engagement in the learning process.\n","authors":["Vassilis Lyberatos","Spyridon Kantarelis","Eirini Kaldeli","Spyros Bekiaris","Panagiotis Tzortzis","Orfeas Menis - Mastromichalakis","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2306.07310v2.pdf","comment":"Presented in The 4th International Conference on Artificial\n  Intelligence in Education Technology (AIET 2023), Berlin, Germany, 31 June-2\n  July 2023. For The GitHub code for the created music dataset, see\n  https://github.com/vaslyb/MusicCrowd"},{"id":"http://arxiv.org/abs/2306.15951v2","updated":"2023-07-12T08:18:30Z","published":"2023-06-28T06:21:22Z","title":"Reduce Computational Complexity for Convolutional Layers by Skipping\n  Zeros","summary":"  Deep neural networks rely on parallel processors for acceleration. To design\noperators for them, it requires not only good algorithm to reduce complexity,\nbut also sufficient utilization of hardwares. Convolutional layers mainly\ncontain 3 kinds of operators: convolution in forward propagation, deconvolution\nand dilated-convolution in backward propagation. When executing these\noperators, 0s are always added to tensors, causing redundant calculations. This\npaper gives C-K-S algorithm (ConvV2, KS-deconv, Sk-dilated), which skips these\n0s in two ways: trim the filters to exclude padded 0s; transform sparse tensors\nto dense tensors, to avoid inserted 0s in deconvolution and\ndilated-convolution. In contrast to regular convolution, deconvolution is hard\nto accelerate due to its complicacy. This paper provides high-performance GPU\nimplementations of C-K-S, and verifies their effectiveness with comparison to\nPyTorch. According to the experiments, C-K-S has advantages over PyTorch in\ncertain cases, especially in deconvolution on small feature-maps. Further\nenhancement of C-K-S can be done by making full optimizations oriented at\nspecific GPU architectures.\n","authors":["Zhiyi Zhang","Pengfei Zhang","Zhuopin Xu","Qi Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15951v2.pdf","comment":"To download the code of Dragon-Alpha and experimental datas, please\n  go to https://github.com/GilgameshXYZ123/Dragon-Alpha"},{"id":"http://arxiv.org/abs/2101.10870v2","updated":"2023-07-12T08:11:19Z","published":"2021-01-23T12:42:41Z","title":"B-HAR: an open-source baseline framework for in depth study of human\n  activity recognition datasets and workflows","summary":"  Human Activity Recognition (HAR), based on machine and deep learning\nalgorithms is considered one of the most promising technologies to monitor\nprofessional and daily life activities for different categories of people\n(e.g., athletes, elderly, kids, employers) in order to provide a variety of\nservices related, for example to well-being, empowering of technical\nperformances, prevention of risky situation, and educational purposes. However,\nthe analysis of the effectiveness and the efficiency of HAR methodologies\nsuffers from the lack of a standard workflow, which might represent the\nbaseline for the estimation of the quality of the developed pattern recognition\nmodels. This makes the comparison among different approaches a challenging\ntask. In addition, researchers can make mistakes that, when not detected,\ndefinitely affect the achieved results. To mitigate such issues, this paper\nproposes an open-source automatic and highly configurable framework, named\nB-HAR, for the definition, standardization, and development of a baseline\nframework in order to evaluate and compare HAR methodologies. It implements the\nmost popular data processing methods for data preparation and the most commonly\nused machine and deep learning pattern recognition models.\n","authors":["Florenc Demrozi","Cristian Turetta","Graziano Pravadelli"],"pdf_url":"https://arxiv.org/pdf/2101.10870v2.pdf","comment":"9 Pages, 3 Figures, 3 Tables, Link to B-HAR Library:\n  https://github.com/B-HAR-HumanActivityRecognition/B-HAR"},{"id":"http://arxiv.org/abs/2307.05979v1","updated":"2023-07-12T07:51:12Z","published":"2023-07-12T07:51:12Z","title":"Transformers in Reinforcement Learning: A Survey","summary":"  Transformers have significantly impacted domains like natural language\nprocessing, computer vision, and robotics, where they improve performance\ncompared to other neural networks. This survey explores how transformers are\nused in reinforcement learning (RL), where they are seen as a promising\nsolution for addressing challenges such as unstable training, credit\nassignment, lack of interpretability, and partial observability. We begin by\nproviding a brief domain overview of RL, followed by a discussion on the\nchallenges of classical RL algorithms. Next, we delve into the properties of\nthe transformer and its variants and discuss the characteristics that make them\nwell-suited to address the challenges inherent in RL. We examine the\napplication of transformers to various aspects of RL, including representation\nlearning, transition and reward function modeling, and policy optimization. We\nalso discuss recent research that aims to enhance the interpretability and\nefficiency of transformers in RL, using visualization techniques and efficient\ntraining strategies. Often, the transformer architecture must be tailored to\nthe specific needs of a given application. We present a broad overview of how\ntransformers have been adapted for several applications, including robotics,\nmedicine, language modeling, cloud computing, and combinatorial optimization.\nWe conclude by discussing the limitations of using transformers in RL and\nassess their potential for catalyzing future breakthroughs in this field.\n","authors":["Pranav Agarwal","Aamer Abdul Rahman","Pierre-Luc St-Charles","Simon J. D. Prince","Samira Ebrahimi Kahou"],"pdf_url":"https://arxiv.org/pdf/2307.05979v1.pdf","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2307.05977v1","updated":"2023-07-12T07:48:29Z","published":"2023-07-12T07:48:29Z","title":"Towards Safe Self-Distillation of Internet-Scale Text-to-Image Diffusion\n  Models","summary":"  Large-scale image generation models, with impressive quality made possible by\nthe vast amount of data available on the Internet, raise social concerns that\nthese models may generate harmful or copyrighted content. The biases and\nharmfulness arise throughout the entire training process and are hard to\ncompletely remove, which have become significant hurdles to the safe deployment\nof these models. In this paper, we propose a method called SDD to prevent\nproblematic content generation in text-to-image diffusion models. We\nself-distill the diffusion model to guide the noise estimate conditioned on the\ntarget removal concept to match the unconditional one. Compared to the previous\nmethods, our method eliminates a much greater proportion of harmful content\nfrom the generated images without degrading the overall image quality.\nFurthermore, our method allows the removal of multiple concepts at once,\nwhereas previous works are limited to removing a single concept at a time.\n","authors":["Sanghyun Kim","Seohyeon Jung","Balhae Kim","Moonseok Choi","Jinwoo Shin","Juho Lee"],"pdf_url":"https://arxiv.org/pdf/2307.05977v1.pdf","comment":"17 pages, 13 figures, ICML 2023 Workshop on Challenges in Deployable\n  Generative AI"},{"id":"http://arxiv.org/abs/2307.05973v1","updated":"2023-07-12T07:40:48Z","published":"2023-07-12T07:40:48Z","title":"VoxPoser: Composable 3D Value Maps for Robotic Manipulation with\n  Language Models","summary":"  Large language models (LLMs) are shown to possess a wealth of actionable\nknowledge that can be extracted for robot manipulation in the form of reasoning\nand planning. Despite the progress, most still rely on pre-defined motion\nprimitives to carry out the physical interactions with the environment, which\nremains a major bottleneck. In this work, we aim to synthesize robot\ntrajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a\nlarge variety of manipulation tasks given an open-set of instructions and an\nopen-set of objects. We achieve this by first observing that LLMs excel at\ninferring affordances and constraints given a free-form language instruction.\nMore importantly, by leveraging their code-writing capabilities, they can\ninteract with a visual-language model (VLM) to compose 3D value maps to ground\nthe knowledge into the observation space of the agent. The composed value maps\nare then used in a model-based planning framework to zero-shot synthesize\nclosed-loop robot trajectories with robustness to dynamic perturbations. We\nfurther demonstrate how the proposed framework can benefit from online\nexperiences by efficiently learning a dynamics model for scenes that involve\ncontact-rich interactions. We present a large-scale study of the proposed\nmethod in both simulated and real-robot environments, showcasing the ability to\nperform a large variety of everyday manipulation tasks specified in free-form\nnatural language. Project website: https://voxposer.github.io\n","authors":["Wenlong Huang","Chen Wang","Ruohan Zhang","Yunzhu Li","Jiajun Wu","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2307.05973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05959v1","updated":"2023-07-12T07:04:53Z","published":"2023-07-12T07:04:53Z","title":"Giving Robots a Hand: Learning Generalizable Manipulation with\n  Eye-in-Hand Human Video Demonstrations","summary":"  Eye-in-hand cameras have shown promise in enabling greater sample efficiency\nand generalization in vision-based robotic manipulation. However, for robotic\nimitation, it is still expensive to have a human teleoperator collect large\namounts of expert demonstrations with a real robot. Videos of humans performing\ntasks, on the other hand, are much cheaper to collect since they eliminate the\nneed for expertise in robotic teleoperation and can be quickly captured in a\nwide range of scenarios. Therefore, human video demonstrations are a promising\ndata source for learning generalizable robotic manipulation policies at scale.\nIn this work, we augment narrow robotic imitation datasets with broad unlabeled\nhuman video demonstrations to greatly enhance the generalization of eye-in-hand\nvisuomotor policies. Although a clear visual domain gap exists between human\nand robot data, our framework does not need to employ any explicit domain\nadaptation method, as we leverage the partial observability of eye-in-hand\ncameras as well as a simple fixed image masking scheme. On a suite of eight\nreal-world tasks involving both 3-DoF and 6-DoF robot arm control, our method\nimproves the success rates of eye-in-hand manipulation policies by 58%\n(absolute) on average, enabling robots to generalize to both new environment\nconfigurations and new tasks that are unseen in the robot demonstration data.\nSee video results at https://giving-robots-a-hand.github.io/ .\n","authors":["Moo Jin Kim","Jiajun Wu","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2307.05959v1.pdf","comment":"21 pages, 7 figures, project webpage at\n  https://giving-robots-a-hand.github.io/"},{"id":"http://arxiv.org/abs/2307.05939v1","updated":"2023-07-12T06:07:53Z","published":"2023-07-12T06:07:53Z","title":"Automatically Reconciling the Trade-off between Prediction Accuracy and\n  Earliness in Prescriptive Business Process Monitoring","summary":"  Prescriptive business process monitoring provides decision support to process\nmanagers on when and how to adapt an ongoing business process to prevent or\nmitigate an undesired process outcome. We focus on the problem of automatically\nreconciling the trade-off between prediction accuracy and prediction earliness\nin determining when to adapt. Adaptations should happen sufficiently early to\nprovide enough lead time for the adaptation to become effective. However,\nearlier predictions are typically less accurate than later predictions. This\nmeans that acting on less accurate predictions may lead to unnecessary\nadaptations or missed adaptations.\n  Different approaches were presented in the literature to reconcile the\ntrade-off between prediction accuracy and earliness. So far, these approaches\nwere compared with different baselines, and evaluated using different data sets\nor even confidential data sets. This limits the comparability and replicability\nof the approaches and makes it difficult to choose a concrete approach in\npractice.\n  We perform a comparative evaluation of the main alternative approaches for\nreconciling the trade-off between prediction accuracy and earliness. Using four\npublic real-world event log data sets and two types of prediction models, we\nassess and compare the cost savings of these approaches. The experimental\nresults indicate which criteria affect the effectiveness of an approach and\nhelp us state initial recommendations for the selection of a concrete approach\nin practice.\n","authors":["Andreas Metzger","Tristan Kley","Aristide Rothweiler","Klaus Pohl"],"pdf_url":"https://arxiv.org/pdf/2307.05939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05933v1","updated":"2023-07-12T05:58:59Z","published":"2023-07-12T05:58:59Z","title":"BiRP: Learning Robot Generalized Bimanual Coordination using Relative\n  Parameterization Method on Human Demonstration","summary":"  Human bimanual manipulation can perform more complex tasks than a simple\ncombination of two single arms, which is credited to the spatio-temporal\ncoordination between the arms. However, the description of bimanual\ncoordination is still an open topic in robotics. This makes it difficult to\ngive an explainable coordination paradigm, let alone applied to robotics. In\nthis work, we divide the main bimanual tasks in human daily activities into two\ntypes: leader-follower and synergistic coordination. Then we propose a relative\nparameterization method to learn these types of coordination from human\ndemonstration. It represents coordination as Gaussian mixture models from\nbimanual demonstration to describe the change in the importance of coordination\nthroughout the motions by probability. The learned coordinated representation\ncan be generalized to new task parameters while ensuring spatio-temporal\ncoordination. We demonstrate the method using synthetic motions and human\ndemonstration data and deploy it to a humanoid robot to perform a generalized\nbimanual coordination motion. We believe that this easy-to-use bimanual\nlearning from demonstration (LfD) method has the potential to be used as a data\naugmentation plugin for robot large manipulation model training. The\ncorresponding codes are open-sourced in https://github.com/Skylark0924/Rofunc.\n","authors":["Junjia Liu","Hengyi Sim","Chenzui Li","Fei Chen"],"pdf_url":"https://arxiv.org/pdf/2307.05933v1.pdf","comment":"6 pages, 4 figures. Accepted by IEEE Conference on Decision and\n  Control (IEEE CDC 2023)"},{"id":"http://arxiv.org/abs/2307.05929v1","updated":"2023-07-12T05:49:21Z","published":"2023-07-12T05:49:21Z","title":"A New Dataset and Comparative Study for Aphid Cluster Detection","summary":"  Aphids are one of the main threats to crops, rural families, and global food\nsecurity. Chemical pest control is a necessary component of crop production for\nmaximizing yields, however, it is unnecessary to apply the chemical approaches\nto the entire fields in consideration of the environmental pollution and the\ncost. Thus, accurately localizing the aphid and estimating the infestation\nlevel is crucial to the precise local application of pesticides. Aphid\ndetection is very challenging as each individual aphid is really small and all\naphids are crowded together as clusters. In this paper, we propose to estimate\nthe infection level by detecting aphid clusters. We have taken millions of\nimages in the sorghum fields, manually selected 5,447 images that contain\naphids, and annotated each aphid cluster in the image. To use these images for\nmachine learning models, we crop the images into patches and created a labeled\ndataset with over 151,000 image patches. Then, we implement and compare the\nperformance of four state-of-the-art object detection models.\n","authors":["Tianxiao Zhang","Kaidong Li","Xiangyu Chen","Cuncong Zhong","Bo Luo","Ivan Grijalva Teran","Brian McCornack","Daniel Flippo","Ajay Sharda","Guanghui Wang"],"pdf_url":"https://arxiv.org/pdf/2307.05929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05921v1","updated":"2023-07-12T05:36:47Z","published":"2023-07-12T05:36:47Z","title":"Reading Radiology Imaging Like The Radiologist","summary":"  Automated radiology report generation aims to generate radiology reports that\ncontain rich, fine-grained descriptions of radiology imaging. Compared with\nimage captioning in the natural image domain, medical images are very similar\nto each other, with only minor differences in the occurrence of diseases. Given\nthe importance of these minor differences in the radiology report, it is\ncrucial to encourage the model to focus more on the subtle regions of disease\noccurrence. Secondly, the problem of visual and textual data biases is serious.\nNot only do normal cases make up the majority of the dataset, but sentences\ndescribing areas with pathological changes also constitute only a small part of\nthe paragraph. Lastly, generating medical image reports involves the challenge\nof long text generation, which requires more expertise and empirical training\nin medical knowledge. As a result, the difficulty of generating such reports is\nincreased. To address these challenges, we propose a disease-oriented retrieval\nframework that utilizes similar reports as prior knowledge references. We\ndesign a factual consistency captioning generator to generate more accurate and\nfactually consistent disease descriptions. Our framework can find most similar\nreports for a given disease from the CXR database by retrieving a\ndisease-oriented mask consisting of the position and morphological\ncharacteristics. By referencing the disease-oriented similar report and the\nvisual features, the factual consistency model can generate a more accurate\nradiology report.\n","authors":["Yuhao Wang"],"pdf_url":"https://arxiv.org/pdf/2307.05921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05913v1","updated":"2023-07-12T04:40:00Z","published":"2023-07-12T04:40:00Z","title":"Close-up View synthesis by Interpolating Optical Flow","summary":"  The virtual viewpoint is perceived as a new technique in virtual navigation,\nas yet not supported due to the lack of depth information and obscure camera\nparameters. In this paper, a method for achieving close-up virtual view is\nproposed and it only uses optical flow to build parallax effects to realize\npseudo 3D projection without using depth sensor. We develop a bidirectional\noptical flow method to obtain any virtual viewpoint by proportional\ninterpolation of optical flow. Moreover, with the ingenious application of the\noptical-flow-value, we achieve clear and visual-fidelity magnified results\nthrough lens stretching in any corner, which overcomes the visual distortion\nand image blur through viewpoint magnification and transition in Google Street\nView system.\n","authors":["Xinyi Bai","Ze Wang","Lu Yang","Hong Cheng"],"pdf_url":"https://arxiv.org/pdf/2307.05913v1.pdf","comment":"4 pages, 5 figures"},{"id":"http://arxiv.org/abs/2211.10590v4","updated":"2023-07-12T04:34:36Z","published":"2022-11-19T05:16:08Z","title":"Bidirectional Generation of Structure and Properties Through a Single\n  Molecular Foundation Model","summary":"  The recent success of large foundation models in artificial intelligence has\nprompted the emergence of chemical pre-trained models. Despite the growing\ninterest in large molecular pre-trained models that provide informative\nrepresentations for downstream tasks, attempts for multimodal pre-training\napproaches on the molecule domain were limited. To address this, we present a\nnovel multimodal molecular pre-trained model that incorporates the modalities\nof structure and biochemical properties, drawing inspiration from recent\nadvances in multimodal learning techniques. Our proposed model pipeline of data\nhandling and training objectives aligns the structure/property features in a\ncommon embedding space, which enables the model to regard bidirectional\ninformation between the molecules' structure and properties. These\ncontributions emerge synergistic knowledge, allowing us to tackle both\nmultimodal and unimodal downstream tasks through a single model. Through\nextensive experiments, we demonstrate that our model shows remarkable\ncapabilities in solving various meaningful chemical challenges, including\nconditional molecule generation, property prediction, molecule classification,\nand reaction prediction.\n","authors":["Jinho Chang","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2211.10590v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05902v1","updated":"2023-07-12T04:19:47Z","published":"2023-07-12T04:19:47Z","title":"Stability Guarantees for Feature Attributions with Multiplicative\n  Smoothing","summary":"  Explanation methods for machine learning models tend to not provide any\nformal guarantees and may not reflect the underlying decision-making process.\nIn this work, we analyze stability as a property for reliable feature\nattribution methods. We prove that relaxed variants of stability are guaranteed\nif the model is sufficiently Lipschitz with respect to the masking of features.\nTo achieve such a model, we develop a smoothing method called Multiplicative\nSmoothing (MuS). We show that MuS overcomes theoretical limitations of standard\nsmoothing techniques and can be integrated with any classifier and feature\nattribution method. We evaluate MuS on vision and language models with a\nvariety of feature attribution methods, such as LIME and SHAP, and demonstrate\nthat MuS endows feature attributions with non-trivial stability guarantees.\n","authors":["Anton Xue","Rajeev Alur","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2307.05902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05891v1","updated":"2023-07-12T03:42:24Z","published":"2023-07-12T03:42:24Z","title":"PID-Inspired Inductive Biases for Deep Reinforcement Learning in\n  Partially Observable Control Tasks","summary":"  Deep reinforcement learning (RL) has shown immense potential for learning to\ncontrol systems through data alone. However, one challenge deep RL faces is\nthat the full state of the system is often not observable. When this is the\ncase, the policy needs to leverage the history of observations to infer the\ncurrent state. At the same time, differences between the training and testing\nenvironments makes it critical for the policy not to overfit to the sequence of\nobservations it sees at training time. As such, there is an important balancing\nact between having the history encoder be flexible enough to extract relevant\ninformation, yet be robust to changes in the environment. To strike this\nbalance, we look to the PID controller for inspiration. We assert the PID\ncontroller's success shows that only summing and differencing are needed to\naccumulate information over time for many control tasks. Following this\nprinciple, we propose two architectures for encoding history: one that directly\nuses PID features and another that extends these core ideas and can be used in\narbitrary control tasks. When compared with prior approaches, our encoders\nproduce policies that are often more robust and achieve better performance on a\nvariety of tracking tasks. Going beyond tracking tasks, our policies achieve\n1.7x better performance on average over previous state-of-the-art methods on a\nsuite of high dimensional control tasks.\n","authors":["Ian Char","Jeff Schneider"],"pdf_url":"https://arxiv.org/pdf/2307.05891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.00129v5","updated":"2023-07-12T02:51:55Z","published":"2022-01-31T22:39:42Z","title":"Fundamental Limits for Sensor-Based Robot Control","summary":"  Our goal is to develop theory and algorithms for establishing fundamental\nlimits on performance imposed by a robot's sensors for a given task. In order\nto achieve this, we define a quantity that captures the amount of task-relevant\ninformation provided by a sensor. Using a novel version of the generalized Fano\ninequality from information theory, we demonstrate that this quantity provides\nan upper bound on the highest achievable expected reward for one-step decision\nmaking tasks. We then extend this bound to multi-step problems via a dynamic\nprogramming approach. We present algorithms for numerically computing the\nresulting bounds, and demonstrate our approach on three examples: (i) the lava\nproblem from the literature on partially observable Markov decision processes,\n(ii) an example with continuous state and observation spaces corresponding to a\nrobot catching a freely-falling object, and (iii) obstacle avoidance using a\ndepth sensor with non-Gaussian noise. We demonstrate the ability of our\napproach to establish strong limits on achievable performance for these\nproblems by comparing our upper bounds with achievable lower bounds (computed\nby synthesizing or learning concrete control policies).\n","authors":["Anirudha Majumdar","Zhiting Mei","Vincent Pacelli"],"pdf_url":"https://arxiv.org/pdf/2202.00129v5.pdf","comment":"Extended version of paper presented at the 2022 Robotics: Science and\n  Systems (RSS) conference"},{"id":"http://arxiv.org/abs/2307.00470v2","updated":"2023-07-12T02:36:05Z","published":"2023-07-02T04:32:41Z","title":"PatternGPT :A Pattern-Driven Framework for Large Language Model Text\n  Generation","summary":"  Large language models(LLMS) have shown excellent text generation\ncapabilities,capable of generating fluent responses for many downstream tasks.\nHowever,applying large language models to real-world critical tasks remains\nchallenging due to their susceptibility to hallucinations and inability to\ndirectly use external knowledge. To address the above challenges,this paper\nproposes PatternGPT, a pattern-driven text generation framework for large\nlanguage models. First,the framework utilizes the extraction capabilities of\nlarge language models to generate rich and diverse patterns and later draws on\nthe idea of federated learning. Using multiple agents to achieve sharing to\nobtain more diverse patterns. Finally, it searches for high-quality patterns\nusing judgment criteria and optimization algorithms and uses the searched\npatterns to guide the model for generation. This framework has the advantages\nof generating diversified patterns, protecting data privacy,combining external\nknowledge, and improving the quality of generation, which provides an effective\nmethod to optimize the text generation capability of large language models,and\nmake it better applied to the field of intelligent dialogue and content\ngeneration.\n","authors":["Le Xiao","Xin Shan"],"pdf_url":"https://arxiv.org/pdf/2307.00470v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05685v2","updated":"2023-07-12T01:42:26Z","published":"2023-06-09T05:55:52Z","title":"Judging LLM-as-a-judge with MT-Bench and Chatbot Arena","summary":"  Evaluating large language model (LLM) based chat assistants is challenging\ndue to their broad capabilities and the inadequacy of existing benchmarks in\nmeasuring human preferences. To address this, we explore using strong LLMs as\njudges to evaluate these models on more open-ended questions. We examine the\nusage and limitations of LLM-as-a-judge, including position, verbosity, and\nself-enhancement biases, as well as limited reasoning ability, and propose\nsolutions to mitigate some of them. We then verify the agreement between LLM\njudges and human preferences by introducing two benchmarks: MT-bench, a\nmulti-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our\nresults reveal that strong LLM judges like GPT-4 can match both controlled and\ncrowdsourced human preferences well, achieving over 80\\% agreement, the same\nlevel of agreement between humans. Hence, LLM-as-a-judge is a scalable and\nexplainable way to approximate human preferences, which are otherwise very\nexpensive to obtain. Additionally, we show our benchmark and traditional\nbenchmarks complement each other by evaluating several variants of LLaMA and\nVicuna. We will publicly release MT-bench questions, 3K expert votes, and 30K\nconversations with human preferences from Chatbot Arena.\n","authors":["Lianmin Zheng","Wei-Lin Chiang","Ying Sheng","Siyuan Zhuang","Zhanghao Wu","Yonghao Zhuang","Zi Lin","Zhuohan Li","Dacheng Li","Eric. P Xing","Hao Zhang","Joseph E. Gonzalez","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2306.05685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05862v1","updated":"2023-07-12T01:11:52Z","published":"2023-07-12T01:11:52Z","title":"Ecosystem-level Analysis of Deployed Machine Learning Reveals\n  Homogeneous Outcomes","summary":"  Machine learning is traditionally studied at the model level: researchers\nmeasure and improve the accuracy, robustness, bias, efficiency, and other\ndimensions of specific models. In practice, the societal impact of machine\nlearning is determined by the surrounding context of machine learning\ndeployments. To capture this, we introduce ecosystem-level analysis: rather\nthan analyzing a single model, we consider the collection of models that are\ndeployed in a given context. For example, ecosystem-level analysis in hiring\nrecognizes that a job candidate's outcomes are not only determined by a single\nhiring algorithm or firm but instead by the collective decisions of all the\nfirms they applied to. Across three modalities (text, images, speech) and 11\ndatasets, we establish a clear trend: deployed machine learning is prone to\nsystemic failure, meaning some users are exclusively misclassified by all\nmodels available. Even when individual models improve at the population level\nover time, we find these improvements rarely reduce the prevalence of systemic\nfailure. Instead, the benefits of these improvements predominantly accrue to\nindividuals who are already correctly classified by other models. In light of\nthese trends, we consider medical imaging for dermatology where the costs of\nsystemic failure are especially high. While traditional analyses reveal racial\nperformance disparities for both models and humans, ecosystem-level analysis\nreveals new forms of racial disparity in model predictions that do not present\nin human predictions. These examples demonstrate ecosystem-level analysis has\nunique strengths for characterizing the societal impact of machine learning.\n","authors":["Connor Toups","Rishi Bommasani","Kathleen A. Creel","Sarah H. Bana","Dan Jurafsky","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2307.05862v1.pdf","comment":"All code is available at\n  https://github.com/rishibommasani/EcosystemLevelAnalysis"},{"id":"http://arxiv.org/abs/2210.01892v3","updated":"2023-07-12T01:02:19Z","published":"2022-10-04T20:28:43Z","title":"Polysemanticity and Capacity in Neural Networks","summary":"  Individual neurons in neural networks often represent a mixture of unrelated\nfeatures. This phenomenon, called polysemanticity, can make interpreting neural\nnetworks more difficult and so we aim to understand its causes. We propose\ndoing so through the lens of feature \\emph{capacity}, which is the fractional\ndimension each feature consumes in the embedding space. We show that in a toy\nmodel the optimal capacity allocation tends to monosemantically represent the\nmost important features, polysemantically represent less important features (in\nproportion to their impact on the loss), and entirely ignore the least\nimportant features. Polysemanticity is more prevalent when the inputs have\nhigher kurtosis or sparsity and more prevalent in some architectures than\nothers. Given an optimal allocation of capacity, we go on to study the geometry\nof the embedding space. We find a block-semi-orthogonal structure, with\ndiffering block sizes in different models, highlighting the impact of model\narchitecture on the interpretability of its neurons.\n","authors":["Adam Scherlis","Kshitij Sachan","Adam S. Jermyn","Joe Benton","Buck Shlegeris"],"pdf_url":"https://arxiv.org/pdf/2210.01892v3.pdf","comment":"22 pages, 7 figures. Corrected typos in Figure 7, improved notation\n  to distinguish column and row vectors, corrected proof in Appendix A, and\n  other misc changes"},{"id":"http://arxiv.org/abs/2307.05857v1","updated":"2023-07-12T00:35:19Z","published":"2023-07-12T00:35:19Z","title":"FAIRO: Fairness-aware Adaptation in Sequential-Decision Making for\n  Human-in-the-Loop Systems","summary":"  Achieving fairness in sequential-decision making systems within\nHuman-in-the-Loop (HITL) environments is a critical concern, especially when\nmultiple humans with different behavior and expectations are affected by the\nsame adaptation decisions in the system. This human variability factor adds\nmore complexity since policies deemed fair at one point in time may become\ndiscriminatory over time due to variations in human preferences resulting from\ninter- and intra-human variability. This paper addresses the fairness problem\nfrom an equity lens, considering human behavior variability, and the changes in\nhuman preferences over time. We propose FAIRO, a novel algorithm for\nfairness-aware sequential-decision making in HITL adaptation, which\nincorporates these notions into the decision-making process. In particular,\nFAIRO decomposes this complex fairness task into adaptive sub-tasks based on\nindividual human preferences through leveraging the Options reinforcement\nlearning framework. We design FAIRO to generalize to three types of HITL\napplication setups that have the shared adaptation decision problem.\nFurthermore, we recognize that fairness-aware policies can sometimes conflict\nwith the application's utility. To address this challenge, we provide a\nfairness-utility tradeoff in FAIRO, allowing system designers to balance the\nobjectives of fairness and utility based on specific application requirements.\nExtensive evaluations of FAIRO on the three HITL applications demonstrate its\ngeneralizability and effectiveness in promoting fairness while accounting for\nhuman variability. On average, FAIRO can improve fairness compared with other\nmethods across all three applications by 35.36%.\n","authors":["Tianyu Zhao","Mojtaba Taherisadr","Salma Elmalaki"],"pdf_url":"https://arxiv.org/pdf/2307.05857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06483v1","updated":"2023-07-12T23:03:55Z","published":"2023-07-12T23:03:55Z","title":"Misclassification in Automated Content Analysis Causes Bias in\n  Regression. Can We Fix It? Yes We Can!","summary":"  Automated classifiers (ACs), often built via supervised machine learning\n(SML), can categorize large, statistically powerful samples of data ranging\nfrom text to images and video, and have become widely popular measurement\ndevices in communication science and related fields. Despite this popularity,\neven highly accurate classifiers make errors that cause misclassification bias\nand misleading results in downstream analyses-unless such analyses account for\nthese errors. As we show in a systematic literature review of SML applications,\ncommunication scholars largely ignore misclassification bias. In principle,\nexisting statistical methods can use \"gold standard\" validation data, such as\nthat created by human annotators, to correct misclassification bias and produce\nconsistent estimates. We introduce and test such methods, including a new\nmethod we design and implement in the R package misclassificationmodels, via\nMonte Carlo simulations designed to reveal each method's limitations, which we\nalso release. Based on our results, we recommend our new error correction\nmethod as it is versatile and efficient. In sum, automated classifiers, even\nthose below common accuracy standards or making systematic misclassifications,\ncan be useful for measurement with careful study design and appropriate error\ncorrection methods.\n","authors":["Nathan TeBlunthuis","Valerie Hase","Chung-Hong Chan"],"pdf_url":"https://arxiv.org/pdf/2307.06483v1.pdf","comment":"41 page, 21 Figures, Top Paper Award from the 2023 Annual Meeting of\n  The International Communication Association Computational Methods Division"},{"id":"http://arxiv.org/abs/2211.15944v2","updated":"2023-07-12T22:46:47Z","published":"2022-11-29T05:56:51Z","title":"The Effectiveness of World Models for Continual Reinforcement Learning","summary":"  World models power some of the most efficient reinforcement learning\nalgorithms. In this work, we showcase that they can be harnessed for continual\nlearning - a situation when the agent faces changing environments. World models\ntypically employ a replay buffer for training, which can be naturally extended\nto continual learning. We systematically study how different selective\nexperience replay methods affect performance, forgetting, and transfer. We also\nprovide recommendations regarding various modeling options for using world\nmodels. The best set of choices is called Continual-Dreamer, it is\ntask-agnostic and utilizes the world model for continual exploration.\nContinual-Dreamer is sample efficient and outperforms state-of-the-art\ntask-agnostic continual reinforcement learning methods on Minigrid and Minihack\nbenchmarks.\n","authors":["Samuel Kessler","Mateusz Ostaszewski","Michał Bortkiewicz","Mateusz Żarski","Maciej Wołczyk","Jack Parker-Holder","Stephen J. Roberts","Piotr Miłoś"],"pdf_url":"https://arxiv.org/pdf/2211.15944v2.pdf","comment":"Accepted at CoLLAs 2023, 21 pages, 15 figures"},{"id":"http://arxiv.org/abs/2302.01802v2","updated":"2023-07-12T22:04:28Z","published":"2023-02-03T15:13:57Z","title":"FR3D: Three-dimensional Flow Reconstruction and Force Estimation for\n  Unsteady Flows Around Extruded Bluff Bodies via Conformal Mapping Aided\n  Convolutional Autoencoders","summary":"  In many practical fluid dynamics experiments, measuring variables such as\nvelocity and pressure is possible only at a limited number of sensor locations,\n\\textcolor{black}{for a few two-dimensional planes, or for a small 3D domain in\nthe flow}. However, knowledge of the full fields is necessary to understand the\ndynamics of many flows. Deep learning reconstruction of full flow fields from\nsparse measurements has recently garnered significant research interest, as a\nway of overcoming this limitation. This task is referred to as the flow\nreconstruction (FR) task. In the present study, we propose a convolutional\nautoencoder based neural network model, dubbed FR3D, which enables FR to be\ncarried out for three-dimensional flows around extruded 3D objects with\ndifferent cross-sections. An innovative mapping approach, whereby multiple\nfluid domains are mapped to an annulus, enables FR3D to generalize its\nperformance to objects not encountered during training. We conclusively\ndemonstrate this generalization capability using a dataset composed of 80\ntraining and 20 testing geometries, all randomly generated. We show that the\nFR3D model reconstructs pressure and velocity components with a few percentage\npoints of error. Additionally, using these predictions, we accurately estimate\nthe Q-criterion fields as well lift and drag forces on the geometries.\n","authors":["Ali Girayhan Özbay","Sylvain Laizet"],"pdf_url":"https://arxiv.org/pdf/2302.01802v2.pdf","comment":"29 pages, 10 figures. Accepted at International Journal of Heat and\n  Fluid Flow"},{"id":"http://arxiv.org/abs/2307.06463v1","updated":"2023-07-12T21:39:13Z","published":"2023-07-12T21:39:13Z","title":"Efficiently-Verifiable Strong Uniquely Solvable Puzzles and Matrix\n  Multiplication","summary":"  We advance the Cohn-Umans framework for developing fast matrix multiplication\nalgorithms. We introduce, analyze, and search for a new subclass of strong\nuniquely solvable puzzles (SUSP), which we call simplifiable SUSPs. We show\nthat these puzzles are efficiently verifiable, which remains an open question\nfor general SUSPs. We also show that individual simplifiable SUSPs can achieve\nthe same strength of bounds on the matrix multiplication exponent $\\omega$ that\ninfinite families of SUSPs can. We report on the construction, by computer\nsearch, of larger SUSPs than previously known for small width. This, combined\nwith our tighter analysis, strengthens the upper bound on the matrix\nmultiplication exponent from $2.66$ to $2.505$ obtainable via this\ncomputational approach, and nears the results of the handcrafted constructions\nof Cohn et al.\n","authors":["Matthew Anderson","Vu Le"],"pdf_url":"https://arxiv.org/pdf/2307.06463v1.pdf","comment":"21 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2307.06440v1","updated":"2023-07-12T20:10:14Z","published":"2023-07-12T20:10:14Z","title":"No Train No Gain: Revisiting Efficient Training Algorithms For\n  Transformer-based Language Models","summary":"  The computation necessary for training Transformer-based language models has\nskyrocketed in recent years. This trend has motivated research on efficient\ntraining algorithms designed to improve training, validation, and downstream\nperformance faster than standard training. In this work, we revisit three\ncategories of such algorithms: dynamic architectures (layer stacking, layer\ndropping), batch selection (selective backprop, RHO loss), and efficient\noptimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed\ncomputation budget using such methods, we find that their training, validation,\nand downstream gains vanish compared to a baseline with a fully-decayed\nlearning rate. We define an evaluation protocol that enables computation to be\ndone on arbitrary machines by mapping all computation time to a reference\nmachine which we call reference system time. We discuss the limitations of our\nproposed protocol and release our code to encourage rigorous research in\nefficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.\n","authors":["Jean Kaddour","Oscar Key","Piotr Nawrot","Pasquale Minervini","Matt J. Kusner"],"pdf_url":"https://arxiv.org/pdf/2307.06440v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06439v1","updated":"2023-07-12T20:08:48Z","published":"2023-07-12T20:08:48Z","title":"Distilling Large Language Models for Biomedical Knowledge Extraction: A\n  Case Study on Adverse Drug Events","summary":"  Large language models (LLMs), such as GPT-4, have demonstrated remarkable\ncapabilities across a wide range of tasks, including health applications. In\nthis paper, we study how LLMs can be used to scale biomedical knowledge\ncuration. We find that while LLMs already possess decent competency in\nstructuring biomedical text, by distillation into a task-specific student model\nthrough self-supervised learning, substantial gains can be attained over\nout-of-box LLMs, with additional advantages such as cost, efficiency, and\nwhite-box model access.\n  We conduct a case study on adverse drug event (ADE) extraction, which is an\nimportant area for improving care. On standard ADE extraction evaluation, a\nGPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised\nstate-of-the-art models without using any labeled data. Despite being over\n1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by\nover 6 absolute points in F1 and GPT-4 by over 5 absolute points.\n  Ablation studies on distillation model choice (e.g., PubMedBERT vs BioGPT)\nand ADE extraction architecture shed light on best practice for biomedical\nknowledge extraction. Similar gains were attained by distillation for other\nstandard biomedical knowledge extraction tasks such as gene-disease\nassociations and protected health information, further illustrating the promise\nof this approach.\n","authors":["Yu Gu","Sheng Zhang","Naoto Usuyama","Yonas Woldesenbet","Cliff Wong","Praneeth Sanapathi","Mu Wei","Naveen Valluri","Erika Strandberg","Tristan Naumann","Hoifung Poon"],"pdf_url":"https://arxiv.org/pdf/2307.06439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11290v2","updated":"2023-07-12T19:26:04Z","published":"2022-07-22T18:32:38Z","title":"TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework\n  for Model Monitoring","summary":"  Continuous monitoring of trained ML models to determine when their\npredictions should and should not be trusted is essential for their safe\ndeployment. Such a framework ought to be high-performing, explainable, post-hoc\nand actionable. We propose TRUST-LAPSE, a \"mistrust\" scoring framework for\ncontinuous model monitoring. We assess the trustworthiness of each input\nsample's model prediction using a sequence of latent-space embeddings.\nSpecifically, (a) our latent-space mistrust score estimates mistrust using\ndistance metrics (Mahalanobis distance) and similarity metrics (cosine\nsimilarity) in the latent-space and (b) our sequential mistrust score\ndetermines deviations in correlations over the sequence of past input\nrepresentations in a non-parametric, sliding-window based algorithm for\nactionable continuous monitoring. We evaluate TRUST-LAPSE via two downstream\ntasks: (1) distributionally shifted input detection, and (2) data drift\ndetection. We evaluate across diverse domains - audio and vision using public\ndatasets and further benchmark our approach on challenging, real-world\nelectroencephalograms (EEG) datasets for seizure detection. Our latent-space\nmistrust scores achieve state-of-the-art results with AUROCs of 84.1 (vision),\n73.9 (audio), and 77.1 (clinical EEGs), outperforming baselines by over 10\npoints. We expose critical failures in popular baselines that remain\ninsensitive to input semantic content, rendering them unfit for real-world\nmodel monitoring. We show that our sequential mistrust scores achieve high\ndrift detection rates; over 90% of the streams show < 20% error for all\ndomains. Through extensive qualitative and quantitative evaluations, we show\nthat our mistrust scores are more robust and provide explainability for easy\nadoption into practice.\n","authors":["Nandita Bhaskhar","Daniel L. Rubin","Christopher Lee-Messer"],"pdf_url":"https://arxiv.org/pdf/2207.11290v2.pdf","comment":"Keywords: Mistrust Scores, Latent-Space, Model monitoring,\n  Trustworthy AI, Explainable AI, Semantic-guided AI"},{"id":"http://arxiv.org/abs/2305.05222v3","updated":"2023-07-12T18:55:53Z","published":"2023-05-09T07:38:09Z","title":"FishRecGAN: An End to End GAN Based Network for Fisheye Rectification\n  and Calibration","summary":"  We propose an end-to-end deep learning approach to rectify fisheye images and\nsimultaneously calibrate camera intrinsic and distortion parameters. Our method\nconsists of two parts: a Quick Image Rectification Module developed with a\nPix2Pix GAN and Wasserstein GAN (W-Pix2PixGAN), and a Calibration Module with a\nCNN architecture. Our Quick Rectification Network performs robust rectification\nwith good resolution, making it suitable for constant calibration in\ncamera-based surveillance equipment. To achieve high-quality calibration, we\nuse the straightened output from the Quick Rectification Module as a\nguidance-like semantic feature map for the Calibration Module to learn the\ngeometric relationship between the straightened feature and the distorted\nfeature. We train and validate our method with a large synthesized dataset\nlabeled with well-simulated parameters applied to a perspective image dataset.\nOur solution has achieved robust performance in high-resolution with a\nsignificant PSNR value of 22.343.\n","authors":["Xin Shen","Kyungdon Joo","Jean Oh"],"pdf_url":"https://arxiv.org/pdf/2305.05222v3.pdf","comment":"18 pages, 7 figures, 4 tables, accepted by AAIML 2023"},{"id":"http://arxiv.org/abs/2106.06613v3","updated":"2023-07-12T18:33:25Z","published":"2021-06-11T21:06:04Z","title":"A New Formalism, Method and Open Issues for Zero-Shot Coordination","summary":"  In many coordination problems, independently reasoning humans are able to\ndiscover mutually compatible policies. In contrast, independently trained\nself-play policies are often mutually incompatible. Zero-shot coordination\n(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement\nlearning to address this fundamental issue. Prior work approaches the ZSC\nproblem by assuming players can agree on a shared learning algorithm but not on\nlabels for actions and observations, and proposes other-play as an optimal\nsolution. However, until now, this \"label-free\" problem has only been\ninformally defined. We formalize this setting as the label-free coordination\n(LFC) problem by defining the label-free coordination game. We show that\nother-play is not an optimal solution to the LFC problem as it fails to\nconsistently break ties between incompatible maximizers of the other-play\nobjective. We introduce an extension of the algorithm, other-play with\ntie-breaking, and prove that it is optimal in the LFC problem and an\nequilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the\nZSC setting aims to prevent, we conclude that the LFC problem does not reflect\nthe aims of ZSC. To address this, we introduce an alternative informal\noperationalization of ZSC as a starting point for future work.\n","authors":["Johannes Treutlein","Michael Dennis","Caspar Oesterheld","Jakob Foerster"],"pdf_url":"https://arxiv.org/pdf/2106.06613v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06399v1","updated":"2023-07-12T18:29:37Z","published":"2023-07-12T18:29:37Z","title":"Designing Behavior Trees from Goal-Oriented LTLf Formulas","summary":"  Temporal logic can be used to formally specify autonomous agent goals, but\nsynthesizing planners that guarantee goal satisfaction can be computationally\nprohibitive. This paper shows how to turn goals specified using a subset of\nfinite trace Linear Temporal Logic (LTL) into a behavior tree (BT) that\nguarantees that successful traces satisfy the LTL goal. Useful LTL formulas for\nachievement goals can be derived using achievement-oriented task mission\ngrammars, leading to missions made up of tasks combined using LTL operators.\nConstructing BTs from LTL formulas leads to a relaxed behavior synthesis\nproblem in which a wide range of planners can implement the action nodes in the\nBT. Importantly, any successful trace induced by the planners satisfies the\ncorresponding LTL formula. The usefulness of the approach is demonstrated in\ntwo ways: a) exploring the alignment between two planners and LTL goals, and b)\nsolving a sequential key-door problem for a Fetch robot.\n","authors":["Aadesh Neupane","Michael A. Goodrich"],"pdf_url":"https://arxiv.org/pdf/2307.06399v1.pdf","comment":"Accepted as \"Most Visionary Paper\" in Autonomous Robots and\n  Multirobot Systems (ARMS) 2023 workshop affiliated with the 22nd\n  International Conference on Autonomous Agents and Multiagent Systems (AAMAS\n  2023)"},{"id":"http://arxiv.org/abs/2307.06382v1","updated":"2023-07-12T18:08:06Z","published":"2023-07-12T18:08:06Z","title":"Rethinking Answer Set Programming Templates","summary":"  In imperative programming, the Domain-Driven Design methodology helps in\ncoping with the complexity of software development by materializing in code the\ninvariants of a domain of interest. Code is cleaner and more secure because any\nimplicit assumption is removed in favor of invariants, thus enabling a fail\nfast mindset and the immediate reporting of unexpected conditions. This article\nintroduces a notion of template for Answer Set Programming that, in addition to\nthe don't repeat yourself principle, enforces locality of some predicates by\nmeans of a simple naming convention. Local predicates are mapped to the usual\nglobal namespace adopted by mainstream engines, using universally unique\nidentifiers to avoid name clashes. This way, local predicates can be used to\nenforce invariants on the expected outcome of a template in a possibly empty\ncontext of application, independently by other rules that can be added to such\na context. Template applications transpiled this way can be processed by\nmainstream engines and safely shared with other knowledge designers, even when\nthey have zero knowledge of templates.\n","authors":["Mario Alviano","Giovambattista Ianni","Francesco Pacenza","Jessica Zangari"],"pdf_url":"https://arxiv.org/pdf/2307.06382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06933v1","updated":"2023-07-12T17:04:28Z","published":"2023-07-12T17:04:28Z","title":"FDAPT: Federated Domain-adaptive Pre-training for Language Models","summary":"  Combining Domain-adaptive Pre-training (DAPT) with Federated Learning (FL)\ncan enhance model adaptation by leveraging more sensitive and distributed data\nwhile preserving data privacy. However, few studies have focused on this\nmethod. Therefore, we conduct the first comprehensive empirical study to\nevaluate the performance of Federated Domain-adaptive Pre-training (FDAPT). We\ndemonstrate that FDAPT can maintain competitive downstream task performance to\nthe centralized baseline in both IID and non-IID situations. Furthermore, we\npropose a novel algorithm, Frozen Federated Domain-adaptive Pre-training\n(FFDAPT). FFDAPT improves the computational efficiency by 12.1% on average and\nexhibits similar downstream task performance to standard FDAPT, with general\nperformance fluctuations remaining less than 1%. Finally, through a critical\nevaluation of our work, we identify promising future research directions for\nthis new research area.\n","authors":["Lekang Jiang","Filip Svoboda","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2307.06933v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2307.06824v1","updated":"2023-07-12T11:54:39Z","published":"2023-07-12T11:54:39Z","title":"CLAIMED -- the open source framework for building coarse-grained\n  operators for accelerated discovery in science","summary":"  In modern data-driven science, reproducibility and reusability are key\nchallenges. Scientists are well skilled in the process from data to\npublication. Although some publication channels require source code and data to\nbe made accessible, rerunning and verifying experiments is usually hard due to\na lack of standards. Therefore, reusing existing scientific data processing\ncode from state-of-the-art research is hard as well. This is why we introduce\nCLAIMED, which has a proven track record in scientific research for addressing\nthe repeatability and reusability issues in modern data-driven science. CLAIMED\nis a framework to build reusable operators and scalable scientific workflows by\nsupporting the scientist to draw from previous work by re-composing workflows\nfrom existing libraries of coarse-grained scientific operators. Although\nvarious implementations exist, CLAIMED is programming language, scientific\nlibrary, and execution environment agnostic.\n","authors":["Romeo Kienzler","Rafflesia Khan","Jerome Nilmeier","Ivan Nesic","Ibrahim Haddad"],"pdf_url":"https://arxiv.org/pdf/2307.06824v1.pdf","comment":"Received IEEE OSS Award 2023 -\n  https://conferences.computer.org/services/2023/symposia/oss.html"},{"id":"http://arxiv.org/abs/2307.06341v1","updated":"2023-07-12T10:58:29Z","published":"2023-07-12T10:58:29Z","title":"Assessment of the suitability of degradation models for the planning of\n  CCTV inspections of sewer pipes","summary":"  The degradation of sewer pipes poses significant economical, environmental\nand health concerns. The maintenance of such assets requires structured plans\nto perform inspections, which are more efficient when structural and\nenvironmental features are considered along with the results of previous\ninspection reports. The development of such plans requires degradation models\nthat can be based on statistical and machine learning methods. This work\nproposes a methodology to assess their suitability to plan inspections\nconsidering three dimensions: accuracy metrics, ability to produce long-term\ndegradation curves and explainability. Results suggest that although ensemble\nmodels yield the highest accuracy, they are unable to infer the long-term\ndegradation of the pipes, whereas the Logistic Regression offers a slightly\nless accurate model that is able to produce consistent degradation curves with\na high explainability. A use case is presented to demonstrate this methodology\nand the efficiency of model-based planning compared to the current inspection\nplan.\n","authors":["Fidae El Morer","Stefan Wittek","Andreas Rausch"],"pdf_url":"https://arxiv.org/pdf/2307.06341v1.pdf","comment":null}]},"2023-07-13T00:00:00Z":{"Sound":[{"id":"http://arxiv.org/abs/2307.06669v1","updated":"2023-07-13T10:25:30Z","published":"2023-07-13T10:25:30Z","title":"Uncovering the Deceptions: An Analysis on Audio Spoofing Detection and\n  Future Prospects","summary":"  Audio has become an increasingly crucial biometric modality due to its\nability to provide an intuitive way for humans to interact with machines. It is\ncurrently being used for a range of applications, including person\nauthentication to banking to virtual assistants. Research has shown that these\nsystems are also susceptible to spoofing and attacks. Therefore, protecting\naudio processing systems against fraudulent activities, such as identity theft,\nfinancial fraud, and spreading misinformation, is of paramount importance. This\npaper reviews the current state-of-the-art techniques for detecting audio\nspoofing and discusses the current challenges along with open research\nproblems. The paper further highlights the importance of considering the\nethical and privacy implications of audio spoofing detection systems. Lastly,\nthe work aims to accentuate the need for building more robust and generalizable\nmethods, the integration of automatic speaker verification and countermeasure\nsystems, and better evaluation protocols.\n","authors":["Rishabh Ranjan","Mayank Vatsa","Richa Singh"],"pdf_url":"https://arxiv.org/pdf/2307.06669v1.pdf","comment":"Accepted in IJCAI 2023"},{"id":"http://arxiv.org/abs/2307.06656v1","updated":"2023-07-13T09:59:09Z","published":"2023-07-13T09:59:09Z","title":"An Improved Metric of Informational Masking for Perceptual Audio Quality\n  Measurement","summary":"  Perceptual audio quality measurement systems algorithmically analyze the\noutput of audio processing systems to estimate possible perceived quality\ndegradation using perceptual models of human audition. In this manner, they\nsave the time and resources associated with the design and execution of\nlistening tests (LTs). Models of disturbance audibility predicting peripheral\nauditory masking in quality measurement systems have considerably increased\nsubjective quality prediction performance of signals processed by perceptual\naudio codecs. Additionally, cognitive effects have also been known to regulate\nperceived distortion severity by influencing their salience. However, the\nperformance gains due to cognitive effect models in quality measurement systems\nwere inconsistent so far, particularly for music signals. Firstly, this paper\npresents an improved model of informational masking (IM) -- an important\ncognitive effect in quality perception -- that considers disturbance\ninformation complexity around the masking threshold. Secondly, we incorporate\nthe proposed IM metric into a quality measurement systems using a novel\ninteraction analysis procedure between cognitive effects and distortion\nmetrics. The procedure establishes interactions between cognitive effects and\ndistortion metrics using LT data. The proposed IM metric is shown to outperform\npreviously proposed IM metrics in a validation task against subjective quality\nscores from large and diverse LT databases. Particularly, the proposed system\nshowed an increased quality prediction of music signals coded with bandwidth\nextension techniques, where other models frequently fail.\n","authors":["Pablo M. Delgado","Jürgen Herre"],"pdf_url":"https://arxiv.org/pdf/2307.06656v1.pdf","comment":"Accepted Publication for WASPAA 2023 - IEEE Workshop on Applications\n  of Signal Processing to Audio and Acoustics, Mohonk Mountain House, New\n  Paltz, NY, USA, Oct 22-25, 2023"},{"id":"http://arxiv.org/abs/2306.07848v4","updated":"2023-07-13T09:28:17Z","published":"2023-06-13T15:28:10Z","title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Speech Emotion Recognition","summary":"  Contrastive learning based pretraining methods have recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced contrastive language-audio\npretraining (CLAP) model for speech emotion recognition. To be specific, we\nfirst build an effective emotion CLAP model Emo-CLAP for emotion recognition,\nutilizing various self-supervised learning based pre-trained models. Then,\nconsidering the importance of the gender attribute in speech emotion modeling,\ntwo GEmo-CLAP approaches are further proposed to integrate the emotion and\ngender information of speech signals, forming more reasonable objectives.\nExtensive experiments on the IEMOCAP corpus demonstrate that our proposed two\nGEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with\ndifferent pre-trained models, while also achieving superior recognition\nperformance compared with other state-of-the-art methods.\n","authors":["Yu Pan","Yanni Hu","Yuguang Yang","Jixun Yao","Wen Fei","Lei Ma","Heng Lu"],"pdf_url":"https://arxiv.org/pdf/2306.07848v4.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2306.17252v2","updated":"2023-07-13T02:38:16Z","published":"2023-06-29T18:39:50Z","title":"Singing Voice Synthesis Using Differentiable LPC and\n  Glottal-Flow-Inspired Wavetables","summary":"  This paper introduces GlOttal-flow LPC Filter (GOLF), a novel method for\nsinging voice synthesis (SVS) that exploits the physical characteristics of the\nhuman voice using differentiable digital signal processing. GOLF employs a\nglottal model as the harmonic source and IIR filters to simulate the vocal\ntract, resulting in an interpretable and efficient approach. We show it is\ncompetitive with state-of-the-art singing voice vocoders, requiring fewer\nsynthesis parameters and less memory to train, and runs an order of magnitude\nfaster for inference. Additionally, we demonstrate that GOLF can model the\nphase components of the human voice, which has immense potential for rendering\nand analysing singing voices in a differentiable manner. Our results highlight\nthe effectiveness of incorporating the physical properties of the human voice\nmechanism into SVS and underscore the advantages of signal-processing-based\napproaches, which offer greater interpretability and efficiency in synthesis.\nAudio samples are available at https://yoyololicon.github.io/golf-demo/.\n","authors":["Chin-Yun Yu","György Fazekas"],"pdf_url":"https://arxiv.org/pdf/2306.17252v2.pdf","comment":"9 pages, 4 figures. Accepted at ISMIR 2023"},{"id":"http://arxiv.org/abs/2307.06530v1","updated":"2023-07-13T02:31:55Z","published":"2023-07-13T02:31:55Z","title":"Exploring the Integration of Large Language Models into Automatic Speech\n  Recognition Systems: An Empirical Study","summary":"  This paper explores the integration of Large Language Models (LLMs) into\nAutomatic Speech Recognition (ASR) systems to improve transcription accuracy.\nThe increasing sophistication of LLMs, with their in-context learning\ncapabilities and instruction-following behavior, has drawn significant\nattention in the field of Natural Language Processing (NLP). Our primary focus\nis to investigate the potential of using an LLM's in-context learning\ncapabilities to enhance the performance of ASR systems, which currently face\nchallenges such as ambient noise, speaker accents, and complex linguistic\ncontexts. We designed a study using the Aishell-1 and LibriSpeech datasets,\nwith ChatGPT and GPT-4 serving as benchmarks for LLM capabilities.\nUnfortunately, our initial experiments did not yield promising results,\nindicating the complexity of leveraging LLM's in-context learning for ASR\napplications. Despite further exploration with varied settings and models, the\ncorrected sentences from the LLMs frequently resulted in higher Word Error\nRates (WER), demonstrating the limitations of LLMs in speech applications. This\npaper provides a detailed overview of these experiments, their results, and\nimplications, establishing that using LLMs' in-context learning capabilities to\ncorrect potential errors in speech recognition transcriptions is still a\nchallenging task at the current stage.\n","authors":["Zeping Min","Jinbo Wang"],"pdf_url":"https://arxiv.org/pdf/2307.06530v1.pdf","comment":null}],"Audio and Speech Processing":[{"id":"http://arxiv.org/abs/2307.06832v1","updated":"2023-07-13T15:54:32Z","published":"2023-07-13T15:54:32Z","title":"Personalization for BERT-based Discriminative Speech Recognition\n  Rescoring","summary":"  Recognition of personalized content remains a challenge in end-to-end speech\nrecognition. We explore three novel approaches that use personalized content in\na neural rescoring step to improve recognition: gazetteers, prompting, and a\ncross-attention based encoder-decoder model. We use internal de-identified\nen-US data from interactions with a virtual voice assistant supplemented with\npersonalized named entities to compare these approaches. On a test set with\npersonalized named entities, we show that each of these approaches improves\nword error rate by over 10%, against a neural rescoring baseline. We also show\nthat on this test set, natural language prompts can improve word error rate by\n7% without any training and with a marginal loss in generalization. Overall,\ngazetteers were found to perform the best with a 10% improvement in word error\nrate (WER), while also improving WER on a general test set by 1%.\n","authors":["Jari Kolehmainen","Yile Gu","Aditya Gourav","Prashanth Gurunath Shivakumar","Ankur Gandhe","Ariya Rastrow","Ivan Bulyko"],"pdf_url":"https://arxiv.org/pdf/2307.06832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06669v1","updated":"2023-07-13T10:25:30Z","published":"2023-07-13T10:25:30Z","title":"Uncovering the Deceptions: An Analysis on Audio Spoofing Detection and\n  Future Prospects","summary":"  Audio has become an increasingly crucial biometric modality due to its\nability to provide an intuitive way for humans to interact with machines. It is\ncurrently being used for a range of applications, including person\nauthentication to banking to virtual assistants. Research has shown that these\nsystems are also susceptible to spoofing and attacks. Therefore, protecting\naudio processing systems against fraudulent activities, such as identity theft,\nfinancial fraud, and spreading misinformation, is of paramount importance. This\npaper reviews the current state-of-the-art techniques for detecting audio\nspoofing and discusses the current challenges along with open research\nproblems. The paper further highlights the importance of considering the\nethical and privacy implications of audio spoofing detection systems. Lastly,\nthe work aims to accentuate the need for building more robust and generalizable\nmethods, the integration of automatic speaker verification and countermeasure\nsystems, and better evaluation protocols.\n","authors":["Rishabh Ranjan","Mayank Vatsa","Richa Singh"],"pdf_url":"https://arxiv.org/pdf/2307.06669v1.pdf","comment":"Accepted in IJCAI 2023"},{"id":"http://arxiv.org/abs/2307.06656v1","updated":"2023-07-13T09:59:09Z","published":"2023-07-13T09:59:09Z","title":"An Improved Metric of Informational Masking for Perceptual Audio Quality\n  Measurement","summary":"  Perceptual audio quality measurement systems algorithmically analyze the\noutput of audio processing systems to estimate possible perceived quality\ndegradation using perceptual models of human audition. In this manner, they\nsave the time and resources associated with the design and execution of\nlistening tests (LTs). Models of disturbance audibility predicting peripheral\nauditory masking in quality measurement systems have considerably increased\nsubjective quality prediction performance of signals processed by perceptual\naudio codecs. Additionally, cognitive effects have also been known to regulate\nperceived distortion severity by influencing their salience. However, the\nperformance gains due to cognitive effect models in quality measurement systems\nwere inconsistent so far, particularly for music signals. Firstly, this paper\npresents an improved model of informational masking (IM) -- an important\ncognitive effect in quality perception -- that considers disturbance\ninformation complexity around the masking threshold. Secondly, we incorporate\nthe proposed IM metric into a quality measurement systems using a novel\ninteraction analysis procedure between cognitive effects and distortion\nmetrics. The procedure establishes interactions between cognitive effects and\ndistortion metrics using LT data. The proposed IM metric is shown to outperform\npreviously proposed IM metrics in a validation task against subjective quality\nscores from large and diverse LT databases. Particularly, the proposed system\nshowed an increased quality prediction of music signals coded with bandwidth\nextension techniques, where other models frequently fail.\n","authors":["Pablo M. Delgado","Jürgen Herre"],"pdf_url":"https://arxiv.org/pdf/2307.06656v1.pdf","comment":"Accepted Publication for WASPAA 2023 - IEEE Workshop on Applications\n  of Signal Processing to Audio and Acoustics, Mohonk Mountain House, New\n  Paltz, NY, USA, Oct 22-25, 2023"},{"id":"http://arxiv.org/abs/2306.07848v4","updated":"2023-07-13T09:28:17Z","published":"2023-06-13T15:28:10Z","title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Speech Emotion Recognition","summary":"  Contrastive learning based pretraining methods have recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced contrastive language-audio\npretraining (CLAP) model for speech emotion recognition. To be specific, we\nfirst build an effective emotion CLAP model Emo-CLAP for emotion recognition,\nutilizing various self-supervised learning based pre-trained models. Then,\nconsidering the importance of the gender attribute in speech emotion modeling,\ntwo GEmo-CLAP approaches are further proposed to integrate the emotion and\ngender information of speech signals, forming more reasonable objectives.\nExtensive experiments on the IEMOCAP corpus demonstrate that our proposed two\nGEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with\ndifferent pre-trained models, while also achieving superior recognition\nperformance compared with other state-of-the-art methods.\n","authors":["Yu Pan","Yanni Hu","Yuguang Yang","Jixun Yao","Wen Fei","Lei Ma","Heng Lu"],"pdf_url":"https://arxiv.org/pdf/2306.07848v4.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2307.06610v1","updated":"2023-07-13T08:17:36Z","published":"2023-07-13T08:17:36Z","title":"LACE: A light-weight, causal model for enhancing coded speech through\n  adaptive convolutions","summary":"  Classical speech coding uses low-complexity postfilters with zero lookahead\nto enhance the quality of coded speech, but their effectiveness is limited by\ntheir simplicity. Deep Neural Networks (DNNs) can be much more effective, but\nrequire high complexity and model size, or added delay. We propose a DNN model\nthat generates classical filter kernels on a per-frame basis with a model of\njust 300~K parameters and 100~MFLOPS complexity, which is a practical\ncomplexity for desktop or mobile device CPUs. The lack of added delay allows it\nto be integrated into the Opus codec, and we demonstrate that it enables\neffective wideband encoding for bitrates down to 6 kb/s.\n","authors":["Jan Büthe","Jean-Marc Valin","Ahmed Mustafa"],"pdf_url":"https://arxiv.org/pdf/2307.06610v1.pdf","comment":"5 pages, accepted at WASPAA 2023"},{"id":"http://arxiv.org/abs/2306.17252v2","updated":"2023-07-13T02:38:16Z","published":"2023-06-29T18:39:50Z","title":"Singing Voice Synthesis Using Differentiable LPC and\n  Glottal-Flow-Inspired Wavetables","summary":"  This paper introduces GlOttal-flow LPC Filter (GOLF), a novel method for\nsinging voice synthesis (SVS) that exploits the physical characteristics of the\nhuman voice using differentiable digital signal processing. GOLF employs a\nglottal model as the harmonic source and IIR filters to simulate the vocal\ntract, resulting in an interpretable and efficient approach. We show it is\ncompetitive with state-of-the-art singing voice vocoders, requiring fewer\nsynthesis parameters and less memory to train, and runs an order of magnitude\nfaster for inference. Additionally, we demonstrate that GOLF can model the\nphase components of the human voice, which has immense potential for rendering\nand analysing singing voices in a differentiable manner. Our results highlight\nthe effectiveness of incorporating the physical properties of the human voice\nmechanism into SVS and underscore the advantages of signal-processing-based\napproaches, which offer greater interpretability and efficiency in synthesis.\nAudio samples are available at https://yoyololicon.github.io/golf-demo/.\n","authors":["Chin-Yun Yu","György Fazekas"],"pdf_url":"https://arxiv.org/pdf/2306.17252v2.pdf","comment":"9 pages, 4 figures. Accepted at ISMIR 2023"},{"id":"http://arxiv.org/abs/2307.06530v1","updated":"2023-07-13T02:31:55Z","published":"2023-07-13T02:31:55Z","title":"Exploring the Integration of Large Language Models into Automatic Speech\n  Recognition Systems: An Empirical Study","summary":"  This paper explores the integration of Large Language Models (LLMs) into\nAutomatic Speech Recognition (ASR) systems to improve transcription accuracy.\nThe increasing sophistication of LLMs, with their in-context learning\ncapabilities and instruction-following behavior, has drawn significant\nattention in the field of Natural Language Processing (NLP). Our primary focus\nis to investigate the potential of using an LLM's in-context learning\ncapabilities to enhance the performance of ASR systems, which currently face\nchallenges such as ambient noise, speaker accents, and complex linguistic\ncontexts. We designed a study using the Aishell-1 and LibriSpeech datasets,\nwith ChatGPT and GPT-4 serving as benchmarks for LLM capabilities.\nUnfortunately, our initial experiments did not yield promising results,\nindicating the complexity of leveraging LLM's in-context learning for ASR\napplications. Despite further exploration with varied settings and models, the\ncorrected sentences from the LLMs frequently resulted in higher Word Error\nRates (WER), demonstrating the limitations of LLMs in speech applications. This\npaper provides a detailed overview of these experiments, their results, and\nimplications, establishing that using LLMs' in-context learning capabilities to\ncorrect potential errors in speech recognition transcriptions is still a\nchallenging task at the current stage.\n","authors":["Zeping Min","Jinbo Wang"],"pdf_url":"https://arxiv.org/pdf/2307.06530v1.pdf","comment":null}],"Signal Processing":[{"id":"http://arxiv.org/abs/2307.06862v1","updated":"2023-07-13T16:13:42Z","published":"2023-07-13T16:13:42Z","title":"Building a digital twin of EDFA: a grey-box modeling approach","summary":"  To enable intelligent and self-driving optical networks, high-accuracy\nphysical layer models are required. The dynamic wavelength-dependent gain\neffects of non-constant-pump erbium-doped fiber amplifiers (EDFAs) remain a\ncrucial problem in terms of modeling, as it determines optical-to-signal noise\nratio as well as the magnitude of fiber nonlinearities. Black-box data-driven\nmodels have been widely studied, but it requires a large size of data for\ntraining and suffers from poor generalizability. In this paper, we derive the\ngain spectra of EDFAs as a simple univariable linear function, and then based\non it we propose a grey-box EDFA gain modeling scheme. Experimental results\nshow that for both automatic gain control (AGC) and automatic power control\n(APC) EDFAs, our model built with 8 data samples can achieve better performance\nthan the neural network (NN) based model built with 900 data samples, which\nmeans the required data size for modeling can be reduced by at least two orders\nof magnitude. Moreover, in the experiment the proposed model demonstrates\nsuperior generalizability to unseen scenarios since it is based on the\nunderlying physics of EDFAs. The results indicate that building a customized\ndigital twin of each EDFA in optical networks become feasible, which is\nessential especially for next generation multi-band network operations.\n","authors":["Yichen Liu","Xiaomin Liu","Yihao Zhang","Meng Cai","Mengfan Fu","Xueying Zhong","Lilin Yi","Weisheng Hu","Qunbi Zhuge"],"pdf_url":"https://arxiv.org/pdf/2307.06862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01856v3","updated":"2023-07-13T16:07:33Z","published":"2022-11-03T14:49:02Z","title":"Human Biophysics as Network Weights: Conditional Generative Models for\n  Dynamic Simulation","summary":"  Simulations of biophysical systems are fundamental for studying physiological\nmechanisms and developing human machine interfaces. Whilst advanced numerical\nmethods, such as finite element models, can excel in this task, they are\nextremely computationally expensive to use when generating a large number of\nsimulations or simulating dynamic events with continuously changing structural\nparameters. We propose an architecture that uses a conditional generative model\nto interpolate between the numerical model states, dramatically lowering the\nmodeling time while maintaining a high generation accuracy. As a demonstration\nof this concept, we present BioMime, a hybrid-structured generative model that\nenables an accurate, ultra-fast, and arbitrarily high temporal-resolution\nsimulation of a specific biophysical system during dynamic changes. This\nmethodology has wide applications in physiological and clinical research as\nwell as in supporting data augmentation strategies for signal analysis,\nrepresenting a computationally efficient and highly accurate model for\nbiophysical simulations.\n","authors":["Shihan Ma","Alexander Kenneth Clarke","Kostiantyn Maksymenko","Samuel Deslauriers-Gauthier","Xinjun Sheng","Xiangyang Zhu","Dario Farina"],"pdf_url":"https://arxiv.org/pdf/2211.01856v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06796v1","updated":"2023-07-13T15:05:37Z","published":"2023-07-13T15:05:37Z","title":"Defeating Proactive Jammers Using Deep Reinforcement Learning for\n  Resource-Constrained IoT Networks","summary":"  Traditional anti-jamming techniques like spread spectrum, adaptive power/rate\ncontrol, and cognitive radio, have demonstrated effectiveness in mitigating\njamming attacks. However, their robustness against the growing complexity of\ninternet-of-thing (IoT) networks and diverse jamming attacks is still limited.\nTo address these challenges, machine learning (ML)-based techniques have\nemerged as promising solutions. By offering adaptive and intelligent\nanti-jamming capabilities, ML-based approaches can effectively adapt to dynamic\nattack scenarios and overcome the limitations of traditional methods. In this\npaper, we propose a deep reinforcement learning (DRL)-based approach that\nutilizes state input from realistic wireless network interface cards. We train\nfive different variants of deep Q-network (DQN) agents to mitigate the effects\nof jamming with the aim of identifying the most sample-efficient, lightweight,\nrobust, and least complex agent that is tailored for power-constrained devices.\nThe simulation results demonstrate the effectiveness of the proposed DRL-based\nanti-jamming approach against proactive jammers, regardless of their jamming\nstrategy which eliminates the need for a pattern recognition or jamming\nstrategy detection step. Our findings present a promising solution for securing\nIoT networks against jamming attacks and highlights substantial opportunities\nfor continued investigation and advancement within this field.\n","authors":["Abubakar Sani Ali","Shimaa Naser","Sami Muhaidat"],"pdf_url":"https://arxiv.org/pdf/2307.06796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06716v1","updated":"2023-07-13T12:13:38Z","published":"2023-07-13T12:13:38Z","title":"Experimental Demonstration of 3D Reflected Beamforming at sub6GHz thanks\n  to Varactor Based Reconfigurable Intelligent Surface","summary":"  Reconfigurable intelligent surface (RIS) is a promising solution to boost\ncoverage sustainably by reflecting waves from a transmitter to a receiver and\nacting as a low-power and passive relay. In this paper, for the first time, we\ndemonstrate experimentally that a reconfigurable intelligent surface designed\nfor sub6GHz, and using varactor technology, can perform three-dimensional\nreflective beamforming. This result is achieved with a RIS prototype of 984\nunit-cells, thanks to a compact control circuit individually addressing and\nconfiguring the voltage of each unit-cell, with a distinct voltage. To our\nknowledge, this prototype configures 17 to 70 times more distinct voltages than\nin the state-of-the-art. The experimental results in an indoor environment show\na 10 dB gain. They also show, for the first time, that producing such a new\nprototype is feasible with minimal energy footprint and environmental impact,\nthanks to refurbishing. Indeed, a reflectarray antenna originally designed for\nthree-dimensional beamforming has been turned into a RIS.\n","authors":["Philippe Ratajczak","Eric Séguenot","Dinh-Thuy Phan-Huy"],"pdf_url":"https://arxiv.org/pdf/2307.06716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06714v1","updated":"2023-07-13T12:11:46Z","published":"2023-07-13T12:11:46Z","title":"Asymptotic SEP Analysis and Optimization of Linear-Quantized Precoding\n  in Massive MIMO Systems","summary":"  A promising approach to deal with the high hardware cost and energy\nconsumption of massive MIMO transmitters is to use low-resolution\ndigital-to-analog converters (DACs) at each antenna element. This leads to a\ntransmission scheme where the transmitted signals are restricted to a finite\nset of voltage levels. This paper is concerned with the analysis and\noptimization of a low-cost quantized precoding strategy, referred to as\nlinear-quantized precoding, for a downlink massive MIMO system under Rayleigh\nfading. In linear-quantized precoding, the signals are first processed by a\nlinear precoding matrix and subsequently quantized component-wise by the DAC.\nIn this paper, we analyze both the signal-to-interference-plus-noise ratio\n(SINR) and the symbol error probability (SEP) performances of such\nlinear-quantized precoding schemes in an asymptotic framework where the number\nof transmit antennas and the number of users grow large with a fixed ratio. Our\nresults provide a rigorous justification for the heuristic arguments based on\nthe Bussgang decomposition that are commonly used in prior works. Based on the\nasymptotic analysis, we further derive the optimal precoder within a class of\nlinear-quantized precoders that includes several popular precoders as special\ncases. Our numerical results demonstrate the excellent accuracy of the\nasymptotic analysis for finite systems and the optimality of the derived\nprecoder.\n","authors":["Zheyu Wu","Junjie Ma","Ya-Feng Liu","A. Lee Swindlehurst"],"pdf_url":"https://arxiv.org/pdf/2307.06714v1.pdf","comment":"58 pages, 8 figures, submitted for possible publication"},{"id":"http://arxiv.org/abs/2307.06657v1","updated":"2023-07-13T10:01:21Z","published":"2023-07-13T10:01:21Z","title":"Downlink Precoding for Cell-free FBMC/OQAM Systems With Asynchronous\n  Reception","summary":"  In this work, an efficient precoding design scheme is proposed for downlink\ncell-free distributed massive multiple-input multiple-output (DM-MIMO) filter\nbank multi-carrier (FBMC) systems with asynchronous reception and highly\nfrequency selectivity. The proposed scheme includes a multiple interpolation\nstructure to eliminate the impact of response difference we recently\ndiscovered, which has better performance in highly frequency-selective\nchannels. Besides, we also consider the phase shift in asynchronous reception\nand introduce a phase compensation in the design process. The phase\ncompensation also benefits from the multiple interpolation structure and better\nadapts to asynchronous reception. Based on the proposed scheme, we\ntheoretically analyze its ergodic achievable rate performance and derive a\nclosed-form expression. Simulation results show that the derived expression can\naccurately characterize the rate performance, and FBMC with the proposed scheme\noutperforms orthogonal frequency-division multiplexing (OFDM) in the\nasynchronous scenario.\n","authors":["Yuhao Qi","Jian Dang","Zaichen Zhang","Liang Wu","Yongpeng Wu"],"pdf_url":"https://arxiv.org/pdf/2307.06657v1.pdf","comment":"16pages, 4 figures"},{"id":"http://arxiv.org/abs/2307.06656v1","updated":"2023-07-13T09:59:09Z","published":"2023-07-13T09:59:09Z","title":"An Improved Metric of Informational Masking for Perceptual Audio Quality\n  Measurement","summary":"  Perceptual audio quality measurement systems algorithmically analyze the\noutput of audio processing systems to estimate possible perceived quality\ndegradation using perceptual models of human audition. In this manner, they\nsave the time and resources associated with the design and execution of\nlistening tests (LTs). Models of disturbance audibility predicting peripheral\nauditory masking in quality measurement systems have considerably increased\nsubjective quality prediction performance of signals processed by perceptual\naudio codecs. Additionally, cognitive effects have also been known to regulate\nperceived distortion severity by influencing their salience. However, the\nperformance gains due to cognitive effect models in quality measurement systems\nwere inconsistent so far, particularly for music signals. Firstly, this paper\npresents an improved model of informational masking (IM) -- an important\ncognitive effect in quality perception -- that considers disturbance\ninformation complexity around the masking threshold. Secondly, we incorporate\nthe proposed IM metric into a quality measurement systems using a novel\ninteraction analysis procedure between cognitive effects and distortion\nmetrics. The procedure establishes interactions between cognitive effects and\ndistortion metrics using LT data. The proposed IM metric is shown to outperform\npreviously proposed IM metrics in a validation task against subjective quality\nscores from large and diverse LT databases. Particularly, the proposed system\nshowed an increased quality prediction of music signals coded with bandwidth\nextension techniques, where other models frequently fail.\n","authors":["Pablo M. Delgado","Jürgen Herre"],"pdf_url":"https://arxiv.org/pdf/2307.06656v1.pdf","comment":"Accepted Publication for WASPAA 2023 - IEEE Workshop on Applications\n  of Signal Processing to Audio and Acoustics, Mohonk Mountain House, New\n  Paltz, NY, USA, Oct 22-25, 2023"},{"id":"http://arxiv.org/abs/2002.01629v3","updated":"2023-07-13T09:53:59Z","published":"2020-02-05T04:10:04Z","title":"Broadband Channel Estimation for Intelligent Reflecting Surface Aided\n  mmWave Massive MIMO Systems","summary":"  This paper investigates the broadband channel estimation (CE) for intelligent\nreflecting surface (IRS)-aided millimeter-wave (mmWave) massive MIMO systems.\nThe CE for such systems is a challenging task due to the large dimension of\nboth the active massive MIMO at the base station (BS) and passive IRS. To\naddress this problem, this paper proposes a compressive sensing (CS)-based CE\nsolution for IRS-aided mmWave massive MIMO systems, whereby the angular channel\nsparsity of large-scale array at mmWave is exploited for improved CE with\nreduced pilot overhead. Specifically, we first propose a downlink pilot\ntransmission framework. By designing the pilot signals based on the prior\nknowledge that the line-of-sight dominated BS-to-IRS channel is known, the\nhigh-dimensional channels for BS-to-user and IRS-to-user can be jointly\nestimated based on CS theory. Moreover, to efficiently estimate broadband\nchannels, a distributed orthogonal matching pursuit algorithm is exploited,\nwhere the common sparsity shared by the channels at different subcarriers is\nutilized. Additionally, the redundant dictionary to combat the power leakage is\nalso designed for the enhanced CE performance. Simulation results demonstrate\nthe effectiveness of the proposed scheme.\n","authors":["Ziwei Wan","Zhen Gao","Mohamed-Slim Alouini"],"pdf_url":"https://arxiv.org/pdf/2002.01629v3.pdf","comment":"6 pages, 4 figures. Accepted by IEEE International Conference on\n  Communications (ICC) 2020, Dublin, Ireland"},{"id":"http://arxiv.org/abs/2307.06634v1","updated":"2023-07-13T09:01:25Z","published":"2023-07-13T09:01:25Z","title":"Coherent Compensation based ISAC Signal Processing for Long-range\n  Sensing","summary":"  Integrated sensing and communication (ISAC) will greatly enhance the\nefficiency of physical resource utilization. The design of ISAC signal based on\nthe orthogonal frequency division multiplex (OFDM) signal is the mainstream.\nHowever, when detecting the long-range target, the delay of echo signal exceeds\nCP duration, which will result in inter-symbol interference (ISI) and\ninter-carrier interference (ICI), limiting the sensing range. Facing the above\nproblem, we propose to increase useful signal power through coherent\ncompensation and improve the signal to interference plus noise power ratio\n(SINR) of each OFDM block. Compared with the traditional 2D-FFT algorithm, the\nimprovement of SINR of range-doppler map (RDM) is verified by simulation, which\nwill expand the sensing range.\n","authors":["Lin Wang","Zhiqing Wei","Liyan Su","Zhiyong Feng","Huici Wu","Dongsheng Xue"],"pdf_url":"https://arxiv.org/pdf/2307.06634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06605v1","updated":"2023-07-13T07:58:56Z","published":"2023-07-13T07:58:56Z","title":"Intelligent Omni Surfaces assisted Integrated Multi Target Sensing and\n  Multi User MIMO Communications","summary":"  Drawing inspiration from the advantages of intelligent reflecting surfaces\n(IRS) in wireless networks,this paper presents a novel design for intelligent\nomni surface (IOS) enabled integrated sensing and communications (ISAC). By\nharnessing the power of multi antennas and a multitude of elements, the\ndual-function base station (BS) and IOS collaborate to realize joint active and\npassive beamforming, enabling seamless 360-degree ISAC coverage. The objective\nis to maximize the minimum signal-tointerference-plus-noise ratio (SINR) of\nmulti-target sensing, while ensuring the multi-user multi-stream\ncommunications. To achieve this, a comprehensive optimization approach is\nemployed, encompassing the design of radar receive vector, transmit beamforming\nmatrix, and IOS transmissive and reflective coefficients. Due to the non-convex\nnature of the formulated problem, an auxiliary variable is introduced to\ntransform it into a more tractable form. Consequently, the problem is\ndecomposed into three subproblems based on the block coordinate descent\nalgorithm. Semidefinite relaxation and successive convex approximation methods\nare leveraged to convert the sub-problem into a convex problem, while the\niterative rank minimization algorithm and penalty function method ensure the\nequivalence. Furthermore,the scenario is extended to mode switching and time\nswitching protocols. Simulation results validate the convergence and superior\nperformance of the proposed algorithm compared to other benchmark algorithms.\n","authors":["Ziheng Zhang","Wen Chen","Qingqing Wu","Zhendong Li","Xusheng Zhu","Jinhong Yuan"],"pdf_url":"https://arxiv.org/pdf/2307.06605v1.pdf","comment":"30 pages, 7 figures"},{"id":"http://arxiv.org/abs/2209.06392v2","updated":"2023-07-13T02:33:05Z","published":"2022-09-14T03:18:23Z","title":"Joint User and Data Detection in Grant-Free NOMA with Attention-based\n  BiLSTM Network","summary":"  We consider the multi-user detection (MUD) problem in uplink grant-free\nnon-orthogonal multiple access (NOMA), where the access point has to identify\nthe total number and correct identity of the active Internet of Things (IoT)\ndevices and decode their transmitted data. We assume that IoT devices use\ncomplex spreading sequences and transmit information in a random-access manner\nfollowing the burst-sparsity model, where some IoT devices transmit their data\nin multiple adjacent time slots with a high probability, while others transmit\nonly once during a frame. Exploiting the temporal correlation, we propose an\nattention-based bidirectional long short-term memory (BiLSTM) network to solve\nthe MUD problem. The BiLSTM network creates a pattern of the device activation\nhistory using forward and reverse pass LSTMs, whereas the attention mechanism\nprovides essential context to the device activation points. By doing so, a\nhierarchical pathway is followed for detecting active devices in a grant-free\nscenario. Then, by utilising the complex spreading sequences, blind data\ndetection for the estimated active devices is performed. The proposed framework\ndoes not require prior knowledge of device sparsity levels and channels for\nperforming MUD. The results show that the proposed network achieves better\nperformance compared to existing benchmark schemes.\n","authors":["Saud Khan","Salman Durrani","Muhammad Basit Shahab","Sarah J. Johnson","Seyit Camtepe"],"pdf_url":"https://arxiv.org/pdf/2209.06392v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11247v2","updated":"2023-07-13T01:30:14Z","published":"2022-11-21T08:38:12Z","title":"Harmonic-Copuled Riccati Equations and its Applications in Distributed\n  Filtering","summary":"  The coupled Riccati equations are cosisted of multiple Riccati-like equations\nwith solutions coupled with each other, which can be applied to depict the\nproperties of more complex systems such as markovian systems or multi-agent\nsystems. This paper manages to formulate and investigate a new kind of coupled\nRiccati equations, called harmonic-coupled Riccati equations (HCRE), from the\nmatrix iterative law of the consensus on information-based distributed\nfiltering (CIDF) algortihm proposed in [1], where the solutions of the\nequations are coupled with harmonic means. Firstly, mild conditions of the\nexistence and uniqueness of the solution to HCRE are induced with collective\nobservability and primitiviness of weighting matrix. Then, it is proved that\nthe matrix iterative law of CIDF will converge to the unique solution of the\ncorresponding HCRE, hence can be used to obtain the solution to HCRE. Moreover,\nthrough applying the novel theory of HCRE, it is pointed out that the real\nestimation error covariance of CIDF will also become steady-state and the\nconvergent value is simplified as the solution to a discrete time Lyapunov\nequation (DLE). Altogether, these new results develop the theory of the coupled\nRiccati equations, and provide a novel perspective on the performance analysis\nof CIDF algorithm, which sufficiently reduces the conservativeness of the\nevaluation techniques in the literature. Finally, the theoretical results are\nverified with numerical experiments.\n","authors":["Jiachen Qian","Peihu Duan","Zhisheng Duan","Ling shi"],"pdf_url":"https://arxiv.org/pdf/2211.11247v2.pdf","comment":"14 pages, 4 figures"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2307.06919v1","updated":"2023-07-13T17:40:30Z","published":"2023-07-13T17:40:30Z","title":"DAXiot: A Decentralized Authentication and Authorization Scheme for\n  Dynamic IoT Networks","summary":"  Federated and decentralized networks supporting frequently changing system\nparticipants are a requirement for future Internet of Things (IoT) use cases.\nIoT devices and networks often lack adequate authentication and authorization\nmechanisms, resulting in insufficient privacy for entities in such systems. In\nthis work we address both issues by designing a privacy preserving\nchallenge-response style authentication and authorization scheme based on\nDecentralized Identifiers and Verifiable Credentials. Our solution allows a\ndecentralized permission management of frequently changing network participants\nand supports authenticated encryption for data confidentiality. We demonstrate\nour solution in an MQTT 5.0 scenario and evaluate its security, privacy\nguarantees, and performance.\n","authors":["Artur Philipp","Axel Küpper"],"pdf_url":"https://arxiv.org/pdf/2307.06919v1.pdf","comment":"6 pages, 2 figures, 3 listings, 1 table"},{"id":"http://arxiv.org/abs/2307.06905v1","updated":"2023-07-13T17:05:49Z","published":"2023-07-13T17:05:49Z","title":"Trajectory-Aware Rate Adaptation for Flying Networks","summary":"  Despite the trend towards ubiquitous wireless connectivity, there are\nscenarios where the communications infrastructure is damaged and wireless\ncoverage is insufficient or does not exist, such as in natural disasters and\ntemporary crowded events. Flying networks, composed of Unmanned Aerial Vehicles\n(UAV), have emerged as a flexible and cost-effective solution to provide\non-demand wireless connectivity in these scenarios. UAVs have the capability to\noperate virtually everywhere, and the growing payload capacity makes them\nsuitable platforms to carry wireless communications hardware. The state of the\nart in the field of flying networks is mainly focused on the optimal\npositioning of the flying nodes, while the wireless link parameters are\nconfigured with default values. On the other hand, current link adaptation\nalgorithms are mainly targeting fixed or low mobility scenarios.\n  We propose a novel rate adaptation approach for flying networks, named\nTrajectory Aware Rate Adaptation (TARA), which leverages the knowledge of\nflying nodes' movement to predict future channel conditions and perform rate\nadaptation accordingly. Simulation results of 100 different trajectories show\nthat our solution increases throughput by up to 53% and achieves an average\nimprovement of 14%, when compared with conventional rate adaptation algorithms\nsuch as Minstrel-HT.\n","authors":["Ruben Queiros","Jose Ruela","Helder Fontes","Rui Campos"],"pdf_url":"https://arxiv.org/pdf/2307.06905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06872v1","updated":"2023-07-13T16:20:43Z","published":"2023-07-13T16:20:43Z","title":"Target Acquired? Evaluating Target Generation Algorithms for IPv6","summary":"  Internet measurements are a crucial foundation of IPv6-related research. Due\nto the infeasibility of full address space scans for IPv6 however, those\nmeasurements rely on collections of reliably responsive, unbiased addresses, as\nprovided e.g., by the IPv6 Hitlist service. Although used for various use\ncases, the hitlist provides an unfiltered list of responsive addresses, the\nhosts behind which can come from a range of different networks and devices,\nsuch as web servers, customer-premises equipment (CPE) devices, and Internet\ninfrastructure. In this paper, we demonstrate the importance of tailoring\nhitlists in accordance with the research goal in question. By using PeeringDB\nwe classify hitlist addresses into six different network categories, uncovering\nthat 42% of hitlist addresses are in ISP networks. Moreover, we show the\ndifferent behavior of those addresses depending on their respective category,\ne.g., ISP addresses exhibiting a relatively low lifetime. Furthermore, we\nanalyze different Target Generation Algorithms (TGAs), which are used to\nincrease the coverage of IPv6 measurements by generating new responsive targets\nfor scans. We evaluate their performance under various conditions and find\ngenerated addresses to show vastly differing responsiveness levels for\ndifferent TGAs.\n","authors":["Lion Steger","Liming Kuang","Johannes Zirngibl","Georg Carle","Oliver Gasser"],"pdf_url":"https://arxiv.org/pdf/2307.06872v1.pdf","comment":"Proceedings of the Network Traffic Measurement and Analysis\n  Conference (TMA)"},{"id":"http://arxiv.org/abs/2307.06838v1","updated":"2023-07-13T16:02:09Z","published":"2023-07-13T16:02:09Z","title":"Dynamic Capacity Enhancement using Air Computing: An Earthquake Case","summary":"  Earthquakes are one of the most destructive natural disasters harming life\nand the infrastructure of cities. After an earthquake, functioning\ncommunication and computational capacity are crucial for rescue teams and\nhealthcare of victims. Therefore, an earthquake can be investigated for dynamic\ncapacity enhancement in which additional resources are deployed since the\nsurviving portion of the infrastructure may not meet the demand of the users.\nIn this study, we propose a new computation paradigm, air computing, which is\nthe air vehicle assisted next generation edge computing through different air\nplatforms, in order to enhance the capacity of the areas affected by an\nearthquake. To this end, we put forward a novel paradigm that presents a\ndynamic, responsive, and high-resolution computation environment by explaining\nits corresponding components, air layers, and essential advantages. Moreover,\nwe focus on the unmanned aerial vehicle (UAV) deployment problem and apply\nthree different methods including the emergency method, the load balancing\nmethod, and the location selection index (LSI) method in which we take the\ndelay requirements of applications into account. To test and compare their\nperformance in terms of the task success rate, we developed an earthquake\nscenario in which three towns are affected with different severity. The\nexperimental results showed that each method can be beneficial considering the\ncircumstances, and goal of the rescue.\n","authors":["Baris Yamansavascilar","Atay Ozgovde","Cem Ersoy"],"pdf_url":"https://arxiv.org/pdf/2307.06838v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2307.06687v1","updated":"2023-07-13T11:14:46Z","published":"2023-07-13T11:14:46Z","title":"Towards Ubiquitous Semantic Metaverse: Challenges, Approaches, and\n  Opportunities","summary":"  In recent years, ubiquitous semantic Metaverse has been studied to\nrevolutionize immersive cyber-virtual experiences for augmented reality (AR)\nand virtual reality (VR) users, which leverages advanced semantic understanding\nand representation to enable seamless, context-aware interactions within\nmixed-reality environments. This survey focuses on the intelligence and\nspatio-temporal characteristics of four fundamental system components in\nubiquitous semantic Metaverse, i.e., artificial intelligence (AI),\nspatio-temporal data representation (STDR), semantic Internet of Things (SIoT),\nand semantic-enhanced digital twin (SDT). We thoroughly survey the\nrepresentative techniques of the four fundamental system components that enable\nintelligent, personalized, and context-aware interactions with typical use\ncases of the ubiquitous semantic Metaverse, such as remote education, work and\ncollaboration, entertainment and socialization, healthcare, and e-commerce\nmarketing. Furthermore, we outline the opportunities for constructing the\nfuture ubiquitous semantic Metaverse, including scalability and\ninteroperability, privacy and security, performance measurement and\nstandardization, as well as ethical considerations and responsible AI.\nAddressing those challenges is important for creating a robust, secure, and\nethically sound system environment that offers engaging immersive experiences\nfor the users and AR/VR applications.\n","authors":["Kai Li","Billy Lau","Xin Yuan","Wei Ni","Mohsen Guizani","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2307.06687v1.pdf","comment":"18 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2307.06645v1","updated":"2023-07-13T09:21:39Z","published":"2023-07-13T09:21:39Z","title":"Multivariate Time Series characterization and forecasting of VoIP\n  traffic in real mobile networks","summary":"  Predicting the behavior of real-time traffic (e.g., VoIP) in mobility\nscenarios could help the operators to better plan their network infrastructures\nand to optimize the allocation of resources. Accordingly, in this work the\nauthors propose a forecasting analysis of crucial QoS/QoE descriptors (some of\nwhich neglected in the technical literature) of VoIP traffic in a real mobile\nenvironment. The problem is formulated in terms of a multivariate time series\nanalysis. Such a formalization allows to discover and model the temporal\nrelationships among various descriptors and to forecast their behaviors for\nfuture periods. Techniques such as Vector Autoregressive models and machine\nlearning (deep-based and tree-based) approaches are employed and compared in\nterms of performance and time complexity, by reframing the multivariate time\nseries problem into a supervised learning one. Moreover, a series of auxiliary\nanalyses (stationarity, orthogonal impulse responses, etc.) are performed to\ndiscover the analytical structure of the time series and to provide deep\ninsights about their relationships. The whole theoretical analysis has an\nexperimental counterpart since a set of trials across a real-world LTE-Advanced\nenvironment has been performed to collect, post-process and analyze about\n600,000 voice packets, organized per flow and differentiated per codec.\n","authors":["Mario Di Mauro","Giovanni Galatro","Fabio Postiglione","Wei Song","Antonio Liotta"],"pdf_url":"https://arxiv.org/pdf/2307.06645v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2307.06636v1","updated":"2023-07-13T09:06:22Z","published":"2023-07-13T09:06:22Z","title":"Towards a 6G embedding sustainability","summary":"  From its conception, 6G is being designed with a particular focus on\nsustainability. The general philosophy of the H2020 Hexa-X project work on\nsustainability in 6G is based on two principles: to reduce direct negative life\ncycle impacts of 6G systems as much as possible (Sustainable 6G) and to analyze\nuse cases that maximize positive environmental, social, and economic effects in\nother sectors of society (6G for Sustainability or its enablement effect). To\napply this philosophy, Hexa-X is designing 6G with three sustainability\nobjectives in mind: to enable the reduction of emissions in 6G-powered sectors\nof society, to reduce the total cost of ownership and to improve energy\nefficiency. This paper describes these objectives, their associated KPIs and\nquantitative targets, and the levers to reach them. Furthermore, to maximize\nthe positive effects of 6G through the enablement effect, a link between 6G and\nthe United Nations' Sustainable Development Goals (UN SDGs) framework is\nproposed and illustrated by Hexa-X use case families.\n","authors":["Esteban Selva","Azeddine Gati","Marie- Hélène Hamon","Giorgio Calochira","Giuseppe Avino","Bahare Masood Khorsandi","Stefan Wunderer","Stefan Wänstedt","Pernilla Bergmark","Serge Bories","Tommy Svensson","Marja Matinmikko-Blue"],"pdf_url":"https://arxiv.org/pdf/2307.06636v1.pdf","comment":"IEEE ICC 2023 Second International Workshop on Green and Sustainable\n  Networking (GreenNet), May 2023, Rome, Italy"},{"id":"http://arxiv.org/abs/2307.06615v1","updated":"2023-07-13T08:33:02Z","published":"2023-07-13T08:33:02Z","title":"NLOS Dies Twice: Challenges and Solutions of V2X for Cooperative\n  Perception","summary":"  Multi-agent multi-lidar sensor fusion between connected vehicles for\ncooperative perception has recently been recognized as the best technique for\nminimizing the blind zone of individual vehicular perception systems and\nfurther enhancing the overall safety of autonomous driving systems. This\ntechnique relies heavily on the reliability and availability of\nvehicle-to-everything (V2X) communication. In practical sensor fusion\napplication scenarios, the non-line-of-sight (NLOS) issue causes blind zones\nfor not only the perception system but also V2X direct communication. To\ncounteract underlying communication issues, we introduce an abstract perception\nmatrix matching method for quick sensor fusion matching procedures and\nmobility-height hybrid relay determination procedures, proactively improving\nthe efficiency and performance of V2X communication to serve the upper layer\napplication fusion requirements. To demonstrate the effectiveness of our\nsolution, we design a new simulation framework to consider autonomous driving,\nsensor fusion and V2X communication in general, paving the way for end-to-end\nperformance evaluation and further solution derivation.\n","authors":["Lantao Li","Chen Sun"],"pdf_url":"https://arxiv.org/pdf/2307.06615v1.pdf","comment":"Submission to IEEE Vehicular Technology Magazine"},{"id":"http://arxiv.org/abs/2307.05888v2","updated":"2023-07-13T06:48:55Z","published":"2023-07-12T03:31:34Z","title":"Efficient Task Offloading Algorithm for Digital Twin in Edge/Cloud\n  Computing Environment","summary":"  In the era of Internet of Things (IoT), Digital Twin (DT) is envisioned to\nempower various areas as a bridge between physical objects and the digital\nworld. Through virtualization and simulation techniques, multiple functions can\nbe achieved by leveraging computing resources. In this process, Mobile Cloud\nComputing (MCC) and Mobile Edge Computing (MEC) have become two of the key\nfactors to achieve real-time feedback. However, current works only considered\nedge servers or cloud servers in the DT system models. Besides, The models\nignore the DT with not only one data resource. In this paper, we propose a new\nDT system model considering a heterogeneous MEC/MCC environment. Each DT in the\nmodel is maintained in one of the servers via multiple data collection devices.\nThe offloading decision-making problem is also considered and a new offloading\nscheme is proposed based on Distributed Deep Learning (DDL). Simulation results\ndemonstrate that our proposed algorithm can effectively and efficiently\ndecrease the system's average latency and energy consumption. Significant\nimprovement is achieved compared with the baselines under the dynamic\nenvironment of DTs.\n","authors":["Ziru Zhang","Xuling Zhang","Guangzhi Zhu","Yuyang Wang","Pan Hui"],"pdf_url":"https://arxiv.org/pdf/2307.05888v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06392v2","updated":"2023-07-13T02:33:05Z","published":"2022-09-14T03:18:23Z","title":"Joint User and Data Detection in Grant-Free NOMA with Attention-based\n  BiLSTM Network","summary":"  We consider the multi-user detection (MUD) problem in uplink grant-free\nnon-orthogonal multiple access (NOMA), where the access point has to identify\nthe total number and correct identity of the active Internet of Things (IoT)\ndevices and decode their transmitted data. We assume that IoT devices use\ncomplex spreading sequences and transmit information in a random-access manner\nfollowing the burst-sparsity model, where some IoT devices transmit their data\nin multiple adjacent time slots with a high probability, while others transmit\nonly once during a frame. Exploiting the temporal correlation, we propose an\nattention-based bidirectional long short-term memory (BiLSTM) network to solve\nthe MUD problem. The BiLSTM network creates a pattern of the device activation\nhistory using forward and reverse pass LSTMs, whereas the attention mechanism\nprovides essential context to the device activation points. By doing so, a\nhierarchical pathway is followed for detecting active devices in a grant-free\nscenario. Then, by utilising the complex spreading sequences, blind data\ndetection for the estimated active devices is performed. The proposed framework\ndoes not require prior knowledge of device sparsity levels and channels for\nperforming MUD. The results show that the proposed network achieves better\nperformance compared to existing benchmark schemes.\n","authors":["Saud Khan","Salman Durrani","Muhammad Basit Shahab","Sarah J. Johnson","Seyit Camtepe"],"pdf_url":"https://arxiv.org/pdf/2209.06392v2.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2307.06941v1","updated":"2023-07-13T17:57:21Z","published":"2023-07-13T17:57:21Z","title":"On the Connection between Game-Theoretic Feature Attributions and\n  Counterfactual Explanations","summary":"  Explainable Artificial Intelligence (XAI) has received widespread interest in\nrecent years, and two of the most popular types of explanations are feature\nattributions, and counterfactual explanations. These classes of approaches have\nbeen largely studied independently and the few attempts at reconciling them\nhave been primarily empirical. This work establishes a clear theoretical\nconnection between game-theoretic feature attributions, focusing on but not\nlimited to SHAP, and counterfactuals explanations. After motivating operative\nchanges to Shapley values based feature attributions and counterfactual\nexplanations, we prove that, under conditions, they are in fact equivalent. We\nthen extend the equivalency result to game-theoretic solution concepts beyond\nShapley values. Moreover, through the analysis of the conditions of such\nequivalence, we shed light on the limitations of naively using counterfactual\nexplanations to provide feature importances. Experiments on three datasets\nquantitatively show the difference in explanations at every stage of the\nconnection between the two approaches and corroborate the theoretical findings.\n","authors":["Emanuele Albini","Shubham Sharma","Saumitra Mishra","Danial Dervovic","Daniele Magazzeni"],"pdf_url":"https://arxiv.org/pdf/2307.06941v1.pdf","comment":"Accepted at AIES 2023"},{"id":"http://arxiv.org/abs/2307.06924v1","updated":"2023-07-13T17:46:15Z","published":"2023-07-13T17:46:15Z","title":"DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual\n  Language Grounding","summary":"  Persons with visual impairments (PwVI) have difficulties understanding and\nnavigating spaces around them. Current wayfinding technologies either focus\nsolely on navigation or provide limited communication about the environment.\nMotivated by recent advances in visual-language grounding and semantic\nnavigation, we propose DRAGON, a guiding robot powered by a dialogue system and\nthe ability to associate the environment with natural language. By\nunderstanding the commands from the user, DRAGON is able to guide the user to\nthe desired landmarks on the map, describe the environment, and answer\nquestions from visual observations. Through effective utilization of dialogue,\nthe robot can ground the user's free-form descriptions to landmarks in the\nenvironment, and give the user semantic information through spoken language. We\nconduct a user study with blindfolded participants in an everyday indoor\nenvironment. Our results demonstrate that DRAGON is able to communicate with\nthe user smoothly, provide a good guiding experience, and connect users with\ntheir surrounding environment in an intuitive manner.\n","authors":["Shuijing Liu","Aamir Hasan","Kaiwen Hong","Runxuan Wang","Peixin Chang","Zachary Mizrachi","Justin Lin","D. Livingston McPherson","Wendy A. Rogers","Katherine Driggs-Campbell"],"pdf_url":"https://arxiv.org/pdf/2307.06924v1.pdf","comment":"Webpage and videos are at\n  https://sites.google.com/view/dragon-wayfinding/home"},{"id":"http://arxiv.org/abs/2307.06687v1","updated":"2023-07-13T11:14:46Z","published":"2023-07-13T11:14:46Z","title":"Towards Ubiquitous Semantic Metaverse: Challenges, Approaches, and\n  Opportunities","summary":"  In recent years, ubiquitous semantic Metaverse has been studied to\nrevolutionize immersive cyber-virtual experiences for augmented reality (AR)\nand virtual reality (VR) users, which leverages advanced semantic understanding\nand representation to enable seamless, context-aware interactions within\nmixed-reality environments. This survey focuses on the intelligence and\nspatio-temporal characteristics of four fundamental system components in\nubiquitous semantic Metaverse, i.e., artificial intelligence (AI),\nspatio-temporal data representation (STDR), semantic Internet of Things (SIoT),\nand semantic-enhanced digital twin (SDT). We thoroughly survey the\nrepresentative techniques of the four fundamental system components that enable\nintelligent, personalized, and context-aware interactions with typical use\ncases of the ubiquitous semantic Metaverse, such as remote education, work and\ncollaboration, entertainment and socialization, healthcare, and e-commerce\nmarketing. Furthermore, we outline the opportunities for constructing the\nfuture ubiquitous semantic Metaverse, including scalability and\ninteroperability, privacy and security, performance measurement and\nstandardization, as well as ethical considerations and responsible AI.\nAddressing those challenges is important for creating a robust, secure, and\nethically sound system environment that offers engaging immersive experiences\nfor the users and AR/VR applications.\n","authors":["Kai Li","Billy Lau","Xin Yuan","Wei Ni","Mohsen Guizani","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2307.06687v1.pdf","comment":"18 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2307.06673v1","updated":"2023-07-13T10:49:02Z","published":"2023-07-13T10:49:02Z","title":"Overcoming the Mental Set Effect in Programming Problem Solving","summary":"  This paper adopts a cognitive psychology perspective to investigate the\nrecurring mistakes in code resulting from the mental set (Einstellung) effect.\nThe Einstellung effect is the tendency to approach problem-solving with a\npreconceived mindset, often overlooking better solutions that may be available.\nThis effect can significantly impact creative thinking, as the development of\npatterns of thought can hinder the emergence of novel and creative ideas. Our\nstudy aims to test the Einstellung effect and the two mechanisms of its\novercoming in the field of programming. The first intervention was the change\nof the color scheme of the code editor to the less habitual one. The second\nintervention was a combination of instruction to \"forget the previous solutions\nand tasks\" and the change in the color scheme. During the experiment,\nparticipants were given two sets of four programming tasks. Each task had two\npossible solutions: one using suboptimal code dictated by the mental set, and\nthe other using a less familiar but more efficient and recommended methodology.\nBetween the sets, participants either received no treatment or one of two\ninterventions aimed at helping them overcome the mental set. The results of our\nexperiment suggest that the tested techniques were insufficient to support\novercoming the mental set, which we attribute to the specificity of the\nprogramming domain. The study contributes to the existing literature by\nproviding insights into creativity support during problem-solving in software\ndevelopment and offering a framework for experimental research in this field.\n","authors":["Agnia Sergeyuk","Sergey Titov","Yaroslav Golubev","Timofey Bryksin"],"pdf_url":"https://arxiv.org/pdf/2307.06673v1.pdf","comment":"Accepted to PPIG'23, 15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2307.06551v1","updated":"2023-07-13T04:18:20Z","published":"2023-07-13T04:18:20Z","title":"What Exactly is an Insight? A Literature Review","summary":"  Insights are often considered the ideal outcome of visual analysis sessions.\nHowever, there is no single definition of what an insight is. Some scholars\ndefine insights as correlations, while others define them as hypotheses or aha\nmoments. This lack of a clear definition can make it difficult to build\nvisualization tools that effectively support insight discovery. In this paper,\nwe contribute a comprehensive literature review that maps the landscape of\nexisting insight definitions. We summarize key themes regarding how insight is\ndefined, with the goal of helping readers identify which definitions of insight\nalign closely with their research and tool development goals. Based on our\nreview, we also suggest interesting research directions, such as synthesizing a\nunified formalism for insight and connecting theories of insight to other\ncritical concepts in visualization research.\n","authors":["Leilani Battle","Alvitta Ottley"],"pdf_url":"https://arxiv.org/pdf/2307.06551v1.pdf","comment":"Technical report. arXiv admin note: text overlap with\n  arXiv:2206.04767"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2307.06949v1","updated":"2023-07-13T17:59:47Z","published":"2023-07-13T17:59:47Z","title":"HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image\n  Models","summary":"  Personalization has emerged as a prominent aspect within the field of\ngenerative AI, enabling the synthesis of individuals in diverse contexts and\nstyles, while retaining high-fidelity to their identities. However, the process\nof personalization presents inherent challenges in terms of time and memory\nrequirements. Fine-tuning each personalized model needs considerable GPU time\ninvestment, and storing a personalized model per subject can be demanding in\nterms of storage capacity. To overcome these challenges, we propose\nHyperDreamBooth-a hypernetwork capable of efficiently generating a small set of\npersonalized weights from a single image of a person. By composing these\nweights into the diffusion model, coupled with fast finetuning, HyperDreamBooth\ncan generate a person's face in various contexts and styles, with high subject\ndetails while also preserving the model's crucial knowledge of diverse styles\nand semantic modifications. Our method achieves personalization on faces in\nroughly 20 seconds, 25x faster than DreamBooth and 125x faster than Textual\nInversion, using as few as one reference image, with the same quality and style\ndiversity as DreamBooth. Also our method yields a model that is 10000x smaller\nthan a normal DreamBooth model. Project page: https://hyperdreambooth.github.io\n","authors":["Nataniel Ruiz","Yuanzhen Li","Varun Jampani","Wei Wei","Tingbo Hou","Yael Pritch","Neal Wadhwa","Michael Rubinstein","Kfir Aberman"],"pdf_url":"https://arxiv.org/pdf/2307.06949v1.pdf","comment":"project page: https://hyperdreambooth.github.io"},{"id":"http://arxiv.org/abs/2307.06947v1","updated":"2023-07-13T17:59:33Z","published":"2023-07-13T17:59:33Z","title":"Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action\n  Recognition","summary":"  Recent video recognition models utilize Transformer models for long-range\nspatio-temporal context modeling. Video transformer designs are based on\nself-attention that can model global context at a high computational cost. In\ncomparison, convolutional designs for videos offer an efficient alternative but\nlack long-range dependency modeling. Towards achieving the best of both\ndesigns, this work proposes Video-FocalNet, an effective and efficient\narchitecture for video recognition that models both local and global contexts.\nVideo-FocalNet is based on a spatio-temporal focal modulation architecture that\nreverses the interaction and aggregation steps of self-attention for better\nefficiency. Further, the aggregation step and the interaction step are both\nimplemented using efficient convolution and element-wise multiplication\noperations that are computationally less expensive than their self-attention\ncounterparts on video representations. We extensively explore the design space\nof focal modulation-based spatio-temporal context modeling and demonstrate our\nparallel spatial and temporal encoding design to be the optimal choice.\nVideo-FocalNets perform favorably well against the state-of-the-art\ntransformer-based models for video recognition on three large-scale datasets\n(Kinetics-400, Kinetics-600, and SS-v2) at a lower computational cost. Our\ncode/models are released at https://github.com/TalalWasim/Video-FocalNets.\n","authors":["Syed Talal Wasim","Muhammad Uzair Khattak","Muzammal Naseer","Salman Khan","Mubarak Shah","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2307.06947v1.pdf","comment":"Project page: https://TalalWasim.github.io/Video-FocalNets/"},{"id":"http://arxiv.org/abs/2307.06945v1","updated":"2023-07-13T17:59:21Z","published":"2023-07-13T17:59:21Z","title":"In-context Autoencoder for Context Compression in a Large Language Model","summary":"  We propose the In-context Autoencoder (ICAE) for context compression in a\nlarge language model (LLM). The ICAE has two modules: a learnable encoder\nadapted with LoRA from an LLM for compressing a long context into a limited\nnumber of memory slots, and a fixed decoder which is the target LLM that can\ncondition on the memory slots for various purposes. We first pretrain the ICAE\nusing both autoencoding and language modeling objectives on massive text data,\nenabling it to generate memory slots that accurately and comprehensively\nrepresent the original context. Then, we fine-tune the pretrained ICAE on a\nsmall amount of instruct data to enhance its interaction with various prompts\nfor producing desirable responses. Our experimental results demonstrate that\nthe ICAE learned with our proposed pretraining and fine-tuning paradigm can\neffectively produce memory slots with $4\\times$ context compression, which can\nbe well conditioned on by the target LLM to respond to various prompts. The\npromising results demonstrate significant implications of the ICAE for its\nnovel approach to the long context problem and its potential to reduce\ncomputation and memory overheads for LLM inference in practice, suggesting\nfurther research effort in context management for an LLM. Our code and data\nwill be released shortly.\n","authors":["Tao Ge","Jing Hu","Xun Wang","Si-Qing Chen","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2307.06945v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2307.06941v1","updated":"2023-07-13T17:57:21Z","published":"2023-07-13T17:57:21Z","title":"On the Connection between Game-Theoretic Feature Attributions and\n  Counterfactual Explanations","summary":"  Explainable Artificial Intelligence (XAI) has received widespread interest in\nrecent years, and two of the most popular types of explanations are feature\nattributions, and counterfactual explanations. These classes of approaches have\nbeen largely studied independently and the few attempts at reconciling them\nhave been primarily empirical. This work establishes a clear theoretical\nconnection between game-theoretic feature attributions, focusing on but not\nlimited to SHAP, and counterfactuals explanations. After motivating operative\nchanges to Shapley values based feature attributions and counterfactual\nexplanations, we prove that, under conditions, they are in fact equivalent. We\nthen extend the equivalency result to game-theoretic solution concepts beyond\nShapley values. Moreover, through the analysis of the conditions of such\nequivalence, we shed light on the limitations of naively using counterfactual\nexplanations to provide feature importances. Experiments on three datasets\nquantitatively show the difference in explanations at every stage of the\nconnection between the two approaches and corroborate the theoretical findings.\n","authors":["Emanuele Albini","Shubham Sharma","Saumitra Mishra","Danial Dervovic","Daniele Magazzeni"],"pdf_url":"https://arxiv.org/pdf/2307.06941v1.pdf","comment":"Accepted at AIES 2023"},{"id":"http://arxiv.org/abs/1912.13122v4","updated":"2023-07-13T17:56:30Z","published":"2019-12-31T00:10:50Z","title":"Declarative Mechanism Design","summary":"  Regulation of Multi-Agent Systems (MAS) and Declarative Electronic\nInstitutions (DEIs) was a multidisciplinary research topic of the past decade\ninvolving (Physical and Software) Agents and Law since the beginning, but\nrecently evolved towards News-claimed Robot Lawyer since 2016. One of these\nfirst proposals of restricting the behaviour of Software Agentswas Electronic\nInstitutions.However, with the recent reformulation of Artificial Neural\nNetworks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal\nissues regarding the use of DL has raised concerns in the Artificial\nIntelligence (AI) Community. Now that the Regulation of MAS is almost correctly\naddressed, we propose the Regulation of Artificial Neural Networks as\nAgent-based Training of a special type of regulated Artificial Neural Network\nthat we call Institutional Neural Network (INN).The main purpose of this paper\nis to bring attention to Artificial Teaching (AT) and to give a tentative\nanswer showing a proof-of-concept implementation of Regulated Deep Learning\n(RDL). This paper introduces the former concept and provide sI, a language\npreviously used to model declaratively and extend Electronic Institutions, as a\nmeans to regulate the execution of Artificial Neural Networks and their\ninteractions with Artificial Teachers (ATs)\n","authors":["Andrés García-Camino"],"pdf_url":"https://arxiv.org/pdf/1912.13122v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06924v1","updated":"2023-07-13T17:46:15Z","published":"2023-07-13T17:46:15Z","title":"DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual\n  Language Grounding","summary":"  Persons with visual impairments (PwVI) have difficulties understanding and\nnavigating spaces around them. Current wayfinding technologies either focus\nsolely on navigation or provide limited communication about the environment.\nMotivated by recent advances in visual-language grounding and semantic\nnavigation, we propose DRAGON, a guiding robot powered by a dialogue system and\nthe ability to associate the environment with natural language. By\nunderstanding the commands from the user, DRAGON is able to guide the user to\nthe desired landmarks on the map, describe the environment, and answer\nquestions from visual observations. Through effective utilization of dialogue,\nthe robot can ground the user's free-form descriptions to landmarks in the\nenvironment, and give the user semantic information through spoken language. We\nconduct a user study with blindfolded participants in an everyday indoor\nenvironment. Our results demonstrate that DRAGON is able to communicate with\nthe user smoothly, provide a good guiding experience, and connect users with\ntheir surrounding environment in an intuitive manner.\n","authors":["Shuijing Liu","Aamir Hasan","Kaiwen Hong","Runxuan Wang","Peixin Chang","Zachary Mizrachi","Justin Lin","D. Livingston McPherson","Wendy A. Rogers","Katherine Driggs-Campbell"],"pdf_url":"https://arxiv.org/pdf/2307.06924v1.pdf","comment":"Webpage and videos are at\n  https://sites.google.com/view/dragon-wayfinding/home"},{"id":"http://arxiv.org/abs/2307.06917v1","updated":"2023-07-13T17:31:41Z","published":"2023-07-13T17:31:41Z","title":"LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT","summary":"  Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.\n","authors":["Lars-Peter Meyer","Claus Stadler","Johannes Frey","Norman Radtke","Kurt Junghanns","Roy Meissner","Gordian Dziwis","Kirill Bulert","Michael Martin"],"pdf_url":"https://arxiv.org/pdf/2307.06917v1.pdf","comment":"to appear in conference proceedings of AI-Tomorrow-23, 29.+30.6.2023\n  in Leipzig, Germany"},{"id":"http://arxiv.org/abs/2307.03875v2","updated":"2023-07-13T17:29:48Z","published":"2023-07-08T01:42:22Z","title":"Large Language Models for Supply Chain Optimization","summary":"  Supply chain operations traditionally involve a variety of complex decision\nmaking problems. Over the last few decades, supply chains greatly benefited\nfrom advances in computation, which allowed the transition from manual\nprocessing to automation and cost-effective optimization. Nonetheless, business\noperators still need to spend substantial efforts in explaining and\ninterpreting the optimization outcomes to stakeholders. Motivated by the recent\nadvances in Large Language Models (LLMs), we study how this disruptive\ntechnology can help bridge the gap between supply chain automation and human\ncomprehension and trust thereof. We design OptiGuide -- a framework that\naccepts as input queries in plain text, and outputs insights about the\nunderlying optimization outcomes. Our framework does not forgo the\nstate-of-the-art combinatorial optimization technology, but rather leverages it\nto quantitatively answer what-if scenarios (e.g., how would the cost change if\nwe used supplier B instead of supplier A for a given demand?). Importantly, our\ndesign does not require sending proprietary data over to LLMs, which can be a\nprivacy concern in some circumstances. We demonstrate the effectiveness of our\nframework on a real server placement scenario within Microsoft's cloud supply\nchain. Along the way, we develop a general evaluation benchmark, which can be\nused to evaluate the accuracy of the LLM output in other scenarios.\n","authors":["Beibin Li","Konstantina Mellou","Bo Zhang","Jeevan Pathuri","Ishai Menache"],"pdf_url":"https://arxiv.org/pdf/2307.03875v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06913v1","updated":"2023-07-13T17:21:54Z","published":"2023-07-13T17:21:54Z","title":"Uncovering Unique Concept Vectors through Latent Space Decomposition","summary":"  Interpreting the inner workings of deep learning models is crucial for\nestablishing trust and ensuring model safety. Concept-based explanations have\nemerged as a superior approach that is more interpretable than feature\nattribution estimates such as pixel saliency. However, defining the concepts\nfor the interpretability analysis biases the explanations by the user's\nexpectations on the concepts. To address this, we propose a novel post-hoc\nunsupervised method that automatically uncovers the concepts learned by deep\nmodels during training. By decomposing the latent space of a layer in singular\nvectors and refining them by unsupervised clustering, we uncover concept\nvectors aligned with directions of high variance that are relevant to the model\nprediction, and that point to semantically distinct concepts. Our extensive\nexperiments reveal that the majority of our concepts are readily understandable\nto humans, exhibit coherency, and bear relevance to the task at hand. Moreover,\nwe showcase the practical utility of our method in dataset exploration, where\nour concept vectors successfully identify outlier training samples affected by\nvarious confounding factors. This novel exploration technique has remarkable\nversatility to data types and model architectures and it will facilitate the\nidentification of biases and the discovery of sources of error within training\ndata.\n","authors":["Mara Graziani","Laura O' Mahony","An-Phi Nguyen","Henning Müller","Vincent Andrearczyk"],"pdf_url":"https://arxiv.org/pdf/2307.06913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06908v1","updated":"2023-07-13T17:14:38Z","published":"2023-07-13T17:14:38Z","title":"Generating Benchmarks for Factuality Evaluation of Language Models","summary":"  Before deploying a language model (LM) within a given domain, it is important\nto measure its tendency to generate factually incorrect information in that\ndomain. Existing factual generation evaluation methods focus on facts sampled\nfrom the LM itself, and thus do not control the set of evaluated facts and\nmight under-represent rare and unlikely facts. We propose FACTOR: Factual\nAssessment via Corpus TransfORmation, a scalable approach for evaluating LM\nfactuality. FACTOR automatically transforms a factual corpus of interest into a\nbenchmark evaluating an LM's propensity to generate true facts from the corpus\nvs. similar but incorrect statements. We use our framework to create two\nbenchmarks: Wiki-FACTOR and News-FACTOR. We show that: (i) our benchmark scores\nincrease with model size and improve when the LM is augmented with retrieval;\n(ii) benchmark score correlates with perplexity, but the two metrics do not\nalways agree on model ranking; and (iii) when perplexity and benchmark score\ndisagree, the latter better reflects factuality in open-ended generation, as\nmeasured by human annotators. We make our data and code publicly available in\nhttps://github.com/AI21Labs/factor.\n","authors":["Dor Muhlgay","Ori Ram","Inbal Magar","Yoav Levine","Nir Ratner","Yonatan Belinkov","Omri Abend","Kevin Leyton-Brown","Amnon Shashua","Yoav Shoham"],"pdf_url":"https://arxiv.org/pdf/2307.06908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.05714v4","updated":"2023-07-13T16:59:31Z","published":"2021-09-13T05:36:14Z","title":"Autonomous Navigation of Underactuated Bipedal Robots in\n  Height-Constrained Environments","summary":"  Navigating a large-scaled robot in unknown and cluttered height-constrained\nenvironments is challenging. Not only is a fast and reliable planning algorithm\nrequired to go around obstacles, the robot should also be able to change its\nintrinsic dimension by crouching in order to travel underneath\nheight-constrained regions. There are few mobile robots that are capable of\nhandling such a challenge, and bipedal robots provide a solution. However, as\nbipedal robots have nonlinear and hybrid dynamics, trajectory planning while\nensuring dynamic feasibility and safety on these robots is challenging. This\npaper presents an end-to-end autonomous navigation framework which leverages\nthree layers of planners and a variable walking height controller to enable\nbipedal robots to safely explore height-constrained environments. A\nvertically-actuated Spring-Loaded Inverted Pendulum (vSLIP) model is introduced\nto capture the robot's coupled dynamics of planar walking and vertical walking\nheight. This reduced-order model is utilized to optimize for long-term and\nshort-term safe trajectory plans. A variable walking height controller is\nleveraged to enable the bipedal robot to maintain stable periodic walking gaits\nwhile following the planned trajectory. The entire framework is tested and\nexperimentally validated using a bipedal robot Cassie. This demonstrates\nreliable autonomy to drive the robot to safely avoid obstacles while walking to\nthe goal location in various kinds of height-constrained cluttered\nenvironments.\n","authors":["Zhongyu Li","Jun Zeng","Shuxiao Chen","Koushil Sreenath"],"pdf_url":"https://arxiv.org/pdf/2109.05714v4.pdf","comment":"Accepted in International Journal of Robotics Research (IJRR) 2023.\n  This is the author's version and will no longer be updated as the copyright\n  may get transferred at anytime"},{"id":"http://arxiv.org/abs/2307.06877v1","updated":"2023-07-13T16:25:04Z","published":"2023-07-13T16:25:04Z","title":"The complexity of non-stationary reinforcement learning","summary":"  The problem of continual learning in the domain of reinforcement learning,\noften called non-stationary reinforcement learning, has been identified as an\nimportant challenge to the application of reinforcement learning. We prove a\nworst-case complexity result, which we believe captures this challenge:\nModifying the probabilities or the reward of a single state-action pair in a\nreinforcement learning problem requires an amount of time almost as large as\nthe number of states in order to keep the value function up to date, unless the\nstrong exponential time hypothesis (SETH) is false; SETH is a widely accepted\nstrengthening of the P $\\neq$ NP conjecture. Recall that the number of states\nin current applications of reinforcement learning is typically astronomical. In\ncontrast, we show that just $\\textit{adding}$ a new state-action pair is\nconsiderably easier to implement.\n","authors":["Christos Papadimitriou","Binghui Peng"],"pdf_url":"https://arxiv.org/pdf/2307.06877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06870v1","updated":"2023-07-13T16:18:55Z","published":"2023-07-13T16:18:55Z","title":"Embodied Lifelong Learning for Task and Motion Planning","summary":"  A robot deployed in a home over long stretches of time faces a true lifelong\nlearning problem. As it seeks to provide assistance to its users, the robot\nshould leverage any accumulated experience to improve its own knowledge to\nbecome a more proficient assistant. We formalize this setting with a novel\nlifelong learning problem formulation in the context of learning for task and\nmotion planning (TAMP). Exploiting the modularity of TAMP systems, we develop a\ngenerative mixture model that produces candidate continuous parameters for a\nplanner. Whereas most existing lifelong learning approaches determine a priori\nhow data is shared across task models, our approach learns shared and\nnon-shared models and determines which to use online during planning based on\nauxiliary tasks that serve as a proxy for each model's understanding of a\nstate. Our method exhibits substantial improvements in planning success on\nsimulated 2D domains and on several problems from the BEHAVIOR benchmark.\n","authors":["Jorge A. Mendez","Leslie Pack Kaelbling","Tomás Lozano-Pérez"],"pdf_url":"https://arxiv.org/pdf/2307.06870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06869v1","updated":"2023-07-13T16:16:51Z","published":"2023-07-13T16:16:51Z","title":"DecompEval: Evaluating Generated Texts as Unsupervised Decomposed\n  Question Answering","summary":"  Existing evaluation metrics for natural language generation (NLG) tasks face\nthe challenges on generalization ability and interpretability. Specifically,\nmost of the well-performed metrics are required to train on evaluation datasets\nof specific NLG tasks and evaluation dimensions, which may cause over-fitting\nto task-specific datasets. Furthermore, existing metrics only provide an\nevaluation score for each dimension without revealing the evidence to interpret\nhow this score is obtained. To deal with these challenges, we propose a simple\nyet effective metric called DecompEval. This metric formulates NLG evaluation\nas an instruction-style question answering task and utilizes instruction-tuned\npre-trained language models (PLMs) without training on evaluation datasets,\naiming to enhance the generalization ability. To make the evaluation process\nmore interpretable, we decompose our devised instruction-style question about\nthe quality of generated texts into the subquestions that measure the quality\nof each sentence. The subquestions with their answers generated by PLMs are\nthen recomposed as evidence to obtain the evaluation result. Experimental\nresults show that DecompEval achieves state-of-the-art performance in untrained\nmetrics for evaluating text summarization and dialogue generation, which also\nexhibits strong dimension-level / task-level generalization ability and\ninterpretability.\n","authors":["Pei Ke","Fei Huang","Fei Mi","Yasheng Wang","Qun Liu","Xiaoyan Zhu","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2307.06869v1.pdf","comment":"Accepted by ACL 2023 (Main Conference)"},{"id":"http://arxiv.org/abs/2307.06865v1","updated":"2023-07-13T16:15:08Z","published":"2023-07-13T16:15:08Z","title":"Prompts Should not be Seen as Secrets: Systematically Measuring Prompt\n  Extraction Attack Success","summary":"  The generations of large language models are commonly controlled through\nprompting techniques, where a user's query to the model is prefixed with a\nprompt that aims to guide the model's behaviour on the query. The prompts used\nby companies to guide their models are often treated as secrets, to be hidden\nfrom the user making the query. They have even been treated as commodities to\nbe bought and sold. However, there has been anecdotal evidence showing that the\nprompts can be extracted by a user even when they are kept secret. In this\npaper, we present a framework for systematically measuring the success of\nprompt extraction attacks. In experiments with multiple sources of prompts and\nmultiple underlying language models, we find that simple text-based attacks can\nin fact reveal prompts with high probability.\n","authors":["Yiming Zhang","Daphne Ippolito"],"pdf_url":"https://arxiv.org/pdf/2307.06865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06845v1","updated":"2023-07-13T16:08:03Z","published":"2023-07-13T16:08:03Z","title":"Self-Supervised Learning for Interactive Perception of Surgical Thread\n  for Autonomous Suture Tail-Shortening","summary":"  Accurate 3D sensing of suturing thread is a challenging problem in automated\nsurgical suturing because of the high state-space complexity, thinness and\ndeformability of the thread, and possibility of occlusion by the grippers and\ntissue. In this work we present a method for tracking surgical thread in 3D\nwhich is robust to occlusions and complex thread configurations, and apply it\nto autonomously perform the surgical suture \"tail-shortening\" task: pulling\nthread through tissue until a desired \"tail\" length remains exposed. The method\nutilizes a learned 2D surgical thread detection network to segment suturing\nthread in RGB images. It then identifies the thread path in 2D and reconstructs\nthe thread in 3D as a NURBS spline by triangulating the detections from two\nstereo cameras. Once a 3D thread model is initialized, the method tracks the\nthread across subsequent frames. Experiments suggest the method achieves a 1.33\npixel average reprojection error on challenging single-frame 3D thread\nreconstructions, and an 0.84 pixel average reprojection error on two tracking\nsequences. On the tail-shortening task, it accomplishes a 90% success rate\nacross 20 trials. Supplemental materials are available at\nhttps://sites.google.com/berkeley.edu/autolab-surgical-thread/ .\n","authors":["Vincent Schorp","Will Panitch","Kaushik Shivakumar","Vainavi Viswanath","Justin Kerr","Yahav Avigal","Danyal M Fer","Lionel Ott","Ken Goldberg"],"pdf_url":"https://arxiv.org/pdf/2307.06845v1.pdf","comment":"International Conference on Automation Science and Engineering (CASE)\n  2023, 7 pages"},{"id":"http://arxiv.org/abs/2307.06825v1","updated":"2023-07-13T15:40:38Z","published":"2023-07-13T15:40:38Z","title":"A Causal Framework to Unify Common Domain Generalization Approaches","summary":"  Domain generalization (DG) is about learning models that generalize well to\nnew domains that are related to, but different from, the training domain(s). It\nis a fundamental problem in machine learning and has attracted much attention\nin recent years. A large number of approaches have been proposed. Different\napproaches are motivated from different perspectives, making it difficult to\ngain an overall understanding of the area. In this paper, we propose a causal\nframework for domain generalization and present an understanding of common DG\napproaches in the framework. Our work sheds new lights on the following\nquestions: (1) What are the key ideas behind each DG method? (2) Why is it\nexpected to improve generalization to new domains theoretically? (3) How are\ndifferent DG methods related to each other and what are relative advantages and\nlimitations? By providing a unified perspective on DG, we hope to help\nresearchers better understand the underlying principles and develop more\neffective approaches for this critical problem in machine learning.\n","authors":["Nevin L. Zhang","Kaican Li","Han Gao","Weiyan Xie","Zhi Lin","Zhenguo Li","Luning Wang","Yongxiang Huang"],"pdf_url":"https://arxiv.org/pdf/2307.06825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06822v1","updated":"2023-07-13T15:39:26Z","published":"2023-07-13T15:39:26Z","title":"TinyMetaFed: Efficient Federated Meta-Learning for TinyML","summary":"  The field of Tiny Machine Learning (TinyML) has made substantial advancements\nin democratizing machine learning on low-footprint devices, such as\nmicrocontrollers. The prevalence of these miniature devices raises the question\nof whether aggregating their knowledge can benefit TinyML applications.\nFederated meta-learning is a promising answer to this question, as it addresses\nthe scarcity of labeled data and heterogeneous data distribution across devices\nin the real world. However, deploying TinyML hardware faces unique resource\nconstraints, making existing methods impractical due to energy, privacy, and\ncommunication limitations. We introduce TinyMetaFed, a model-agnostic\nmeta-learning framework suitable for TinyML. TinyMetaFed facilitates\ncollaborative training of a neural network initialization that can be quickly\nfine-tuned on new devices. It offers communication savings and privacy\nprotection through partial local reconstruction and Top-P% selective\ncommunication, computational efficiency via online learning, and robustness to\nclient heterogeneity through few-shot learning. The evaluations on three TinyML\nuse cases demonstrate that TinyMetaFed can significantly reduce energy\nconsumption and communication overhead, accelerate convergence, and stabilize\nthe training process.\n","authors":["Haoyu Ren","Xue Li","Darko Anicic","Thomas A. Runkler"],"pdf_url":"https://arxiv.org/pdf/2307.06822v1.pdf","comment":"Accepted by the ECML PKDD 2023 workshop track: Simplification,\n  Compression, Efficiency, and Frugality for Artificial Intelligence (SCEFA)"},{"id":"http://arxiv.org/abs/2307.05766v2","updated":"2023-07-13T15:28:18Z","published":"2023-07-11T19:47:05Z","title":"Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology\n  Reporting","summary":"  Radiology reporting is a crucial part of the communication between\nradiologists and other medical professionals, but it can be time-consuming and\nerror-prone. One approach to alleviate this is structured reporting, which\nsaves time and enables a more accurate evaluation than free-text reports.\nHowever, there is limited research on automating structured reporting, and no\npublic benchmark is available for evaluating and comparing different methods.\nTo close this gap, we introduce Rad-ReStruct, a new benchmark dataset that\nprovides fine-grained, hierarchically ordered annotations in the form of\nstructured reports for X-Ray images. We model the structured reporting task as\nhierarchical visual question answering (VQA) and propose hi-VQA, a novel method\nthat considers prior context in the form of previously asked questions and\nanswers for populating a structured radiology report. Our experiments show that\nhi-VQA achieves competitive performance to the state-of-the-art on the medical\nVQA benchmark VQARad while performing best among methods without\ndomain-specific vision-language pretraining and provides a strong baseline on\nRad-ReStruct. Our work represents a significant step towards the automated\npopulation of structured radiology reports and provides a valuable first\nbenchmark for future research in this area. We will make all annotations and\nour code for annotation generation, model evaluation, and training publicly\navailable upon acceptance. Our dataset and code is available at\nhttps://github.com/ChantalMP/Rad-ReStruct.\n","authors":["Chantal Pellegrini","Matthias Keicher","Ege Özsoy","Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2307.05766v2.pdf","comment":"accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2212.00679v3","updated":"2023-07-13T15:07:23Z","published":"2022-12-01T17:36:30Z","title":"Formal Controller Synthesis for Markov Jump Linear Systems with\n  Uncertain Dynamics","summary":"  Automated synthesis of provably correct controllers for cyber-physical\nsystems is crucial for deployment in safety-critical scenarios. However, hybrid\nfeatures and stochastic or unknown behaviours make this problem challenging. We\npropose a method for synthesising controllers for Markov jump linear systems\n(MJLSs), a class of discrete-time models for cyber-physical systems, so that\nthey certifiably satisfy probabilistic computation tree logic (PCTL) formulae.\nAn MJLS consists of a finite set of stochastic linear dynamics and discrete\njumps between these dynamics that are governed by a Markov decision process\n(MDP). We consider the cases where the transition probabilities of this MDP are\neither known up to an interval or completely unknown. Our approach is based on\na finite-state abstraction that captures both the discrete (mode-jumping) and\ncontinuous (stochastic linear) behaviour of the MJLS. We formalise this\nabstraction as an interval MDP (iMDP) for which we compute intervals of\ntransition probabilities using sampling techniques from the so-called 'scenario\napproach', resulting in a probabilistically sound approximation. We apply our\nmethod to multiple realistic benchmark problems, in particular, a temperature\ncontrol and an aerial vehicle delivery problem.\n","authors":["Luke Rickard","Thom Badings","Licio Romao","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/2212.00679v3.pdf","comment":"15 pages, accepted to QEST"},{"id":"http://arxiv.org/abs/2307.06794v1","updated":"2023-07-13T15:03:48Z","published":"2023-07-13T15:03:48Z","title":"Negated Complementary Commonsense using Large Language Models","summary":"  Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.\n","authors":["Navid Rezaei","Marek Z. Reformat"],"pdf_url":"https://arxiv.org/pdf/2307.06794v1.pdf","comment":"Appeared in Natural Language Reasoning and Structured Explanations\n  Workshop (NLRSE) - ACL 2023"},{"id":"http://arxiv.org/abs/2307.05921v2","updated":"2023-07-13T14:53:24Z","published":"2023-07-12T05:36:47Z","title":"Reading Radiology Imaging Like The Radiologist","summary":"  Automated radiology report generation aims to generate radiology reports that\ncontain rich, fine-grained descriptions of radiology imaging. Compared with\nimage captioning in the natural image domain, medical images are very similar\nto each other, with only minor differences in the occurrence of diseases. Given\nthe importance of these minor differences in the radiology report, it is\ncrucial to encourage the model to focus more on the subtle regions of disease\noccurrence. Secondly, the problem of visual and textual data biases is serious.\nNot only do normal cases make up the majority of the dataset, but sentences\ndescribing areas with pathological changes also constitute only a small part of\nthe paragraph. Lastly, generating medical image reports involves the challenge\nof long text generation, which requires more expertise and empirical training\nin medical knowledge. As a result, the difficulty of generating such reports is\nincreased. To address these challenges, we propose a disease-oriented retrieval\nframework that utilizes similar reports as prior knowledge references. We\ndesign a factual consistency captioning generator to generate more accurate and\nfactually consistent disease descriptions. Our framework can find most similar\nreports for a given disease from the CXR database by retrieving a\ndisease-oriented mask consisting of the position and morphological\ncharacteristics. By referencing the disease-oriented similar report and the\nvisual features, the factual consistency model can generate a more accurate\nradiology report.\n","authors":["Yuhao Wang"],"pdf_url":"https://arxiv.org/pdf/2307.05921v2.pdf","comment":"There are data writing errors in the paper"},{"id":"http://arxiv.org/abs/2307.01316v2","updated":"2023-07-13T14:41:32Z","published":"2023-07-03T19:43:21Z","title":"Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep\n  Reinforcement Learning Approach","summary":"  The dynamic nature of driving environments and the presence of diverse road\nusers pose significant challenges for decision-making in autonomous driving.\nDeep reinforcement learning (DRL) has emerged as a popular approach to tackle\nthis problem. However, the application of existing DRL solutions is mainly\nconfined to simulated environments due to safety concerns, impeding their\ndeployment in real-world. To overcome this limitation, this paper introduces a\nnovel neuro-symbolic model-free DRL approach, called DRL with Symbolic Logics\n(DRLSL) that combines the strengths of DRL (learning from experience) and\nsymbolic first-order logics (knowledge-driven reasoning) to enable safe\nlearning in real-time interactions of autonomous driving within real\nenvironments. This innovative approach provides a means to learn autonomous\ndriving policies by actively engaging with the physical environment while\nensuring safety. We have implemented the DRLSL framework in autonomous driving\nusing the highD dataset and demonstrated that our method successfully avoids\nunsafe actions during both the training and testing phases. Furthermore, our\nresults indicate that DRLSL achieves faster convergence during training and\nexhibits better generalizability to new driving scenarios compared to\ntraditional DRL methods.\n","authors":["Iman Sharifi","Mustafa Yildirim","Saber Fallah"],"pdf_url":"https://arxiv.org/pdf/2307.01316v2.pdf","comment":"15 pages, 9 figures, 1 table, 1 algorithm. Under review as a journal\n  paper at IEEE transactions on Intelligent Transportation Systems"},{"id":"http://arxiv.org/abs/2207.04827v4","updated":"2023-07-13T14:06:40Z","published":"2022-07-11T12:51:27Z","title":"Classification and Generation of real-world data with an Associative\n  Memory Model","summary":"  Drawing from memory the face of a friend you have not seen in years is a\ndifficult task. However, if you happen to cross paths, you would easily\nrecognize each other. The biological memory is equipped with an impressive\ncompression algorithm that can store the essential, and then infer the details\nto match perception. The Willshaw Memory is a simple abstract model for\ncortical computations which implements mechanisms of biological memories. Using\nour recently proposed sparse coding prescription for visual patterns, this\nmodel can store and retrieve an impressive amount of real-world data in a\nfault-tolerant manner. In this paper, we extend the capabilities of the basic\nAssociative Memory Model by using a Multiple-Modality framework. In this\nsetting, the memory stores several modalities (e.g., visual, or textual) of\neach pattern simultaneously. After training, the memory can be used to infer\nmissing modalities when just a subset is perceived. Using a simple\nencoder-memory-decoder architecture, and a newly proposed iterative retrieval\nalgorithm for the Willshaw Model, we perform experiments on the MNIST dataset.\nBy storing both the images and labels as modalities, a single Memory can be\nused not only to retrieve and complete patterns but also to classify and\ngenerate new ones. We further discuss how this model could be used for other\nlearning tasks, thus serving as a biologically-inspired framework for learning.\n","authors":["Rodrigo Simas","Luis Sa-Couto","Andreas Wichert"],"pdf_url":"https://arxiv.org/pdf/2207.04827v4.pdf","comment":"10 pages, 15 figures. Neurocomputing, 2023"},{"id":"http://arxiv.org/abs/2307.06758v1","updated":"2023-07-13T13:56:27Z","published":"2023-07-13T13:56:27Z","title":"Layered controller synthesis for dynamic multi-agent systems","summary":"  In this paper we present a layered approach for multi-agent control problem,\ndecomposed into three stages, each building upon the results of the previous\none. First, a high-level plan for a coarse abstraction of the system is\ncomputed, relying on parametric timed automata augmented with stopwatches as\nthey allow to efficiently model simplified dynamics of such systems. In the\nsecond stage, the high-level plan, based on SMT-formulation, mainly handles the\ncombinatorial aspects of the problem, provides a more dynamically accurate\nsolution. These stages are collectively referred to as the SWA-SMT solver. They\nare correct by construction but lack a crucial feature: they cannot be executed\nin real time. To overcome this, we use SWA-SMT solutions as the initial\ntraining dataset for our last stage, which aims at obtaining a neural network\ncontrol policy. We use reinforcement learning to train the policy, and show\nthat the initial dataset is crucial for the overall success of the method.\n","authors":["Emily Clement","Nicolas Perrin-Gilbert","Philipp Schlehuber-Caissier"],"pdf_url":"https://arxiv.org/pdf/2307.06758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10081v3","updated":"2023-07-13T13:55:07Z","published":"2022-09-21T03:01:36Z","title":"Revisiting Discrete Soft Actor-Critic","summary":"  We study the adaption of soft actor-critic (SAC) from continuous action space\nto discrete action space. We revisit vanilla SAC and provide an in-depth\nunderstanding of its Q value underestimation and performance instability issues\nwhen applied to discrete settings. We thereby propose entropy-penalty and\ndouble average Q-learning with Q-clip to address these issues. Extensive\nexperiments on typical benchmarks with discrete action space, including Atari\ngames and a large-scale MOBA game, show the efficacy of our proposed method.\nOur code is at:https://github.com/coldsummerday/Revisiting-Discrete-SAC.\n","authors":["Haibin Zhou","Zichuan Lin","Junyou Li","Qiang Fu","Wei Yang","Deheng Ye"],"pdf_url":"https://arxiv.org/pdf/2209.10081v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00470v3","updated":"2023-07-13T13:46:30Z","published":"2023-07-02T04:32:41Z","title":"PatternGPT :A Pattern-Driven Framework for Large Language Model Text\n  Generation","summary":"  Large language models(LLMS) have shown excellent text generation\ncapabilities,capable of generating fluent responses for many downstream tasks.\nHowever,applying large language models to real-world critical tasks remains\nchallenging due to their susceptibility to hallucinations and inability to\ndirectly use external knowledge. To address the above challenges,this paper\nproposes PatternGPT, a pattern-driven text generation framework for large\nlanguage models. First,the framework utilizes the extraction capabilities of\nlarge language models to generate rich and diverse patterns and later draws on\nthe idea of federated learning. Using multiple agents to achieve sharing to\nobtain more diverse patterns. Finally, it searches for high-quality patterns\nusing judgment criteria and optimization algorithms and uses the searched\npatterns to guide the model for generation. This framework has the advantages\nof generating diversified patterns, protecting data privacy,combining external\nknowledge, and improving the quality of generation, which provides an effective\nmethod to optimize the text generation capability of large language models,and\nmake it better applied to the field of intelligent dialogue and content\ngeneration.\n","authors":["Le Xiao","Xin Shan"],"pdf_url":"https://arxiv.org/pdf/2307.00470v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06742v1","updated":"2023-07-13T13:31:01Z","published":"2023-07-13T13:31:01Z","title":"Vehicle Dispatching and Routing of On-Demand Intercity Ride-Pooling\n  Services: A Multi-Agent Hierarchical Reinforcement Learning Approach","summary":"  The integrated development of city clusters has given rise to an increasing\ndemand for intercity travel. Intercity ride-pooling service exhibits\nconsiderable potential in upgrading traditional intercity bus services by\nimplementing demand-responsive enhancements. Nevertheless, its online\noperations suffer the inherent complexities due to the coupling of vehicle\nresource allocation among cities and pooled-ride vehicle routing. To tackle\nthese challenges, this study proposes a two-level framework designed to\nfacilitate online fleet management. Specifically, a novel multi-agent feudal\nreinforcement learning model is proposed at the upper level of the framework to\ncooperatively assign idle vehicles to different intercity lines, while the\nlower level updates the routes of vehicles using an adaptive large neighborhood\nsearch heuristic. Numerical studies based on the realistic dataset of Xiamen\nand its surrounding cities in China show that the proposed framework\neffectively mitigates the supply and demand imbalances, and achieves\nsignificant improvement in both the average daily system profit and order\nfulfillment ratio.\n","authors":["Jinhua Si","Fang He","Xi Lin","Xindi Tang"],"pdf_url":"https://arxiv.org/pdf/2307.06742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06736v1","updated":"2023-07-13T13:16:01Z","published":"2023-07-13T13:16:01Z","title":"MPR-Net:Multi-Scale Pattern Reproduction Guided Universality Time Series\n  Interpretable Forecasting","summary":"  Time series forecasting has received wide interest from existing research due\nto its broad applications and inherent challenging. The research challenge lies\nin identifying effective patterns in historical series and applying them to\nfuture forecasting. Advanced models based on point-wise connected MLP and\nTransformer architectures have strong fitting power, but their secondary\ncomputational complexity limits practicality. Additionally, those structures\ninherently disrupt the temporal order, reducing the information utilization and\nmaking the forecasting process uninterpretable. To solve these problems, this\npaper proposes a forecasting model, MPR-Net. It first adaptively decomposes\nmulti-scale historical series patterns using convolution operation, then\nconstructs a pattern extension forecasting method based on the prior knowledge\nof pattern reproduction, and finally reconstructs future patterns into future\nseries using deconvolution operation. By leveraging the temporal dependencies\npresent in the time series, MPR-Net not only achieves linear time complexity,\nbut also makes the forecasting process interpretable. By carrying out\nsufficient experiments on more than ten real data sets of both short and long\nterm forecasting tasks, MPR-Net achieves the state of the art forecasting\nperformance, as well as good generalization and robustness performance.\n","authors":["Tianlong Zhao","Xiang Ma","Xuemei Li","Caiming Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.06736v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03109v4","updated":"2023-07-13T12:33:20Z","published":"2023-07-06T16:28:35Z","title":"A Survey on Evaluation of Large Language Models","summary":"  Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.\n","authors":["Yupeng Chang","Xu Wang","Jindong Wang","Yuan Wu","Kaijie Zhu","Hao Chen","Linyi Yang","Xiaoyuan Yi","Cunxiang Wang","Yidong Wang","Wei Ye","Yue Zhang","Yi Chang","Philip S. Yu","Qiang Yang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2307.03109v4.pdf","comment":"25 pages; more work is at: https://llm-eval.github.io/"},{"id":"http://arxiv.org/abs/2307.06709v1","updated":"2023-07-13T12:07:39Z","published":"2023-07-13T12:07:39Z","title":"GRAN is superior to GraphRNN: node orderings, kernel- and graph\n  embeddings-based metrics for graph generators","summary":"  A wide variety of generative models for graphs have been proposed. They are\nused in drug discovery, road networks, neural architecture search, and program\nsynthesis. Generating graphs has theoretical challenges, such as isomorphic\nrepresentations -- evaluating how well a generative model performs is\ndifficult. Which model to choose depending on the application domain?\n  We extensively study kernel-based metrics on distributions of graph\ninvariants and manifold-based and kernel-based metrics in graph embedding\nspace. Manifold-based metrics outperform kernel-based metrics in embedding\nspace. We use these metrics to compare GraphRNN and GRAN, two well-known\ngenerative models for graphs, and unveil the influence of node orderings. It\nshows the superiority of GRAN over GraphRNN - further, our proposed adaptation\nof GraphRNN with a depth-first search ordering is effective for small-sized\ngraphs.\n  A guideline on good practices regarding dataset selection and node feature\ninitialization is provided. Our work is accompanied by open-source code and\nreproducible experiments.\n","authors":["Ousmane Touat","Julian Stier","Pierre-Edouard Portier","Michael Granitzer"],"pdf_url":"https://arxiv.org/pdf/2307.06709v1.pdf","comment":"Preprint for The 9th International Conference on machine Learning,\n  Optimization and Data science - LOD 2023"},{"id":"http://arxiv.org/abs/2307.06701v1","updated":"2023-07-13T11:58:27Z","published":"2023-07-13T11:58:27Z","title":"S-HR-VQVAE: Sequential Hierarchical Residual Learning Vector Quantized\n  Variational Autoencoder for Video Prediction","summary":"  We address the video prediction task by putting forth a novel model that\ncombines (i) our recently proposed hierarchical residual vector quantized\nvariational autoencoder (HR-VQVAE), and (ii) a novel spatiotemporal PixelCNN\n(ST-PixelCNN). We refer to this approach as a sequential hierarchical residual\nlearning vector quantized variational autoencoder (S-HR-VQVAE). By leveraging\nthe intrinsic capabilities of HR-VQVAE at modeling still images with a\nparsimonious representation, combined with the ST-PixelCNN's ability at\nhandling spatiotemporal information, S-HR-VQVAE can better deal with chief\nchallenges in video prediction. These include learning spatiotemporal\ninformation, handling high dimensional data, combating blurry prediction, and\nimplicit modeling of physical characteristics. Extensive experimental results\non the KTH Human Action and Moving-MNIST tasks demonstrate that our model\ncompares favorably against top video prediction techniques both in quantitative\nand qualitative evaluations despite a much smaller model size. Finally, we\nboost S-HR-VQVAE by proposing a novel training method to jointly estimate the\nHR-VQVAE and ST-PixelCNN parameters.\n","authors":["Mohammad Adiban","Kalin Stefanov","Sabato Marco Siniscalchi","Giampiero Salvi"],"pdf_url":"https://arxiv.org/pdf/2307.06701v1.pdf","comment":"14 pages, 7 figures, 3 tables. Submitted to IEEE Transactions on\n  Pattern Analysis and Machine Intelligence on 2023-07-12"},{"id":"http://arxiv.org/abs/2307.06698v1","updated":"2023-07-13T11:54:32Z","published":"2023-07-13T11:54:32Z","title":"IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation","summary":"  Knowledge Graph Embedding (KGE) models are used to learn continuous\nrepresentations of entities and relations. A key task in the literature is\npredicting missing links between entities. However, Knowledge Graphs are not\njust sets of links but also have semantics underlying their structure.\nSemantics is crucial in several downstream tasks, such as query answering or\nreasoning. We introduce the subgraph inference task, where a model has to\ngenerate likely and semantically valid subgraphs. We propose IntelliGraphs, a\nset of five new Knowledge Graph datasets. The IntelliGraphs datasets contain\nsubgraphs with semantics expressed in logical rules for evaluating subgraph\ninference. We also present the dataset generator that produced the synthetic\ndatasets. We designed four novel baseline models, which include three models\nbased on traditional KGEs. We evaluate their expressiveness and show that these\nmodels cannot capture the semantics. We believe this benchmark will encourage\nthe development of machine learning models that emphasize semantic\nunderstanding.\n","authors":["Thiviyan Thanapalasingam","Emile van Krieken","Peter Bloem","Paul Groth"],"pdf_url":"https://arxiv.org/pdf/2307.06698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06687v1","updated":"2023-07-13T11:14:46Z","published":"2023-07-13T11:14:46Z","title":"Towards Ubiquitous Semantic Metaverse: Challenges, Approaches, and\n  Opportunities","summary":"  In recent years, ubiquitous semantic Metaverse has been studied to\nrevolutionize immersive cyber-virtual experiences for augmented reality (AR)\nand virtual reality (VR) users, which leverages advanced semantic understanding\nand representation to enable seamless, context-aware interactions within\nmixed-reality environments. This survey focuses on the intelligence and\nspatio-temporal characteristics of four fundamental system components in\nubiquitous semantic Metaverse, i.e., artificial intelligence (AI),\nspatio-temporal data representation (STDR), semantic Internet of Things (SIoT),\nand semantic-enhanced digital twin (SDT). We thoroughly survey the\nrepresentative techniques of the four fundamental system components that enable\nintelligent, personalized, and context-aware interactions with typical use\ncases of the ubiquitous semantic Metaverse, such as remote education, work and\ncollaboration, entertainment and socialization, healthcare, and e-commerce\nmarketing. Furthermore, we outline the opportunities for constructing the\nfuture ubiquitous semantic Metaverse, including scalability and\ninteroperability, privacy and security, performance measurement and\nstandardization, as well as ethical considerations and responsible AI.\nAddressing those challenges is important for creating a robust, secure, and\nethically sound system environment that offers engaging immersive experiences\nfor the users and AR/VR applications.\n","authors":["Kai Li","Billy Lau","Xin Yuan","Wei Ni","Mohsen Guizani","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2307.06687v1.pdf","comment":"18 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2307.06682v1","updated":"2023-07-13T11:02:55Z","published":"2023-07-13T11:02:55Z","title":"Explainable Artificial Intelligence driven mask design for\n  self-supervised seismic denoising","summary":"  The presence of coherent noise in seismic data leads to errors and\nuncertainties, and as such it is paramount to suppress noise as early and\nefficiently as possible. Self-supervised denoising circumvents the common\nrequirement of deep learning procedures of having noisy-clean training pairs.\nHowever, self-supervised coherent noise suppression methods require extensive\nknowledge of the noise statistics. We propose the use of explainable artificial\nintelligence approaches to see inside the black box that is the denoising\nnetwork and use the gained knowledge to replace the need for any prior\nknowledge of the noise itself. This is achieved in practice by leveraging\nbias-free networks and the direct linear link between input and output provided\nby the associated Jacobian matrix; we show that a simple averaging of the\nJacobian contributions over a number of randomly selected input pixels,\nprovides an indication of the most effective mask to suppress noise present in\nthe data. The proposed method therefore becomes a fully automated denoising\nprocedure requiring no clean training labels or prior knowledge. Realistic\nsynthetic examples with noise signals of varying complexities, ranging from\nsimple time-correlated noise to complex pseudo rig noise propagating at the\nvelocity of the ocean, are used to validate the proposed approach. Its\nautomated nature is highlighted further by an application to two field\ndatasets. Without any substantial pre-processing or any knowledge of the\nacquisition environment, the automatically identified blind-masks are shown to\nperform well in suppressing both trace-wise noise in common shot gathers from\nthe Volve marine dataset and colored noise in post stack seismic images from a\nland seismic survey.\n","authors":["Claire Birnie","Matteo Ravasi"],"pdf_url":"https://arxiv.org/pdf/2307.06682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.07372v2","updated":"2023-07-13T09:49:53Z","published":"2022-01-19T01:19:57Z","title":"Prospective Learning: Principled Extrapolation to the Future","summary":"  Learning is a process which can update decision rules, based on past\nexperience, such that future performance improves. Traditionally, machine\nlearning is often evaluated under the assumption that the future will be\nidentical to the past in distribution or change adversarially. But these\nassumptions can be either too optimistic or pessimistic for many problems in\nthe real world. Real world scenarios evolve over multiple spatiotemporal scales\nwith partially predictable dynamics. Here we reformulate the learning problem\nto one that centers around this idea of dynamic futures that are partially\nlearnable. We conjecture that certain sequences of tasks are not\nretrospectively learnable (in which the data distribution is fixed), but are\nprospectively learnable (in which distributions may be dynamic), suggesting\nthat prospective learning is more difficult in kind than retrospective\nlearning. We argue that prospective learning more accurately characterizes many\nreal world problems that (1) currently stymie existing artificial intelligence\nsolutions and/or (2) lack adequate explanations for how natural intelligences\nsolve them. Thus, studying prospective learning will lead to deeper insights\nand solutions to currently vexing challenges in both natural and artificial\nintelligences.\n","authors":["Ashwin De Silva","Rahul Ramesh","Lyle Ungar","Marshall Hussain Shuler","Noah J. Cowan","Michael Platt","Chen Li","Leyla Isik","Seung-Eon Roh","Adam Charles","Archana Venkataraman","Brian Caffo","Javier J. How","Justus M Kebschull","John W. Krakauer","Maxim Bichuch","Kaleab Alemayehu Kinfu","Eva Yezerets","Dinesh Jayaraman","Jong M. Shin","Soledad Villar","Ian Phillips","Carey E. Priebe","Thomas Hartung","Michael I. Miller","Jayanta Dey"," Ningyuan"," Huang","Eric Eaton","Ralph Etienne-Cummings","Elizabeth L. Ogburn","Randal Burns","Onyema Osuagwu","Brett Mensh","Alysson R. Muotri","Julia Brown","Chris White","Weiwei Yang","Andrei A. Rusu","Timothy Verstynen","Konrad P. Kording","Pratik Chaudhari","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2201.07372v2.pdf","comment":"Accepted at the 2nd Conference on Lifelong Learning Agents (CoLLAs),\n  2023"},{"id":"http://arxiv.org/abs/2307.06647v1","updated":"2023-07-13T09:23:21Z","published":"2023-07-13T09:23:21Z","title":"DeepIPCv2: LiDAR-powered Robust Environmental Perception and\n  Navigational Control for Autonomous Vehicle","summary":"  We present DeepIPCv2, an autonomous driving model that perceives the\nenvironment using a LiDAR sensor for more robust drivability, especially when\ndriving under poor illumination conditions. DeepIPCv2 takes a set of LiDAR\npoint clouds for its main perception input. As point clouds are not affected by\nillumination changes, they can provide a clear observation of the surroundings\nno matter what the condition is. This results in a better scene understanding\nand stable features provided by the perception module to support the controller\nmodule in estimating navigational control properly. To evaluate its\nperformance, we conduct several tests by deploying the model to predict a set\nof driving records and perform real automated driving under three different\nconditions. We also conduct ablation and comparative studies with some recent\nmodels to justify its performance. Based on the experimental results, DeepIPCv2\nshows a robust performance by achieving the best drivability in all conditions.\nCodes are available at https://github.com/oskarnatan/DeepIPCv2\n","authors":["Oskar Natan","Jun Miura"],"pdf_url":"https://arxiv.org/pdf/2307.06647v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.02819v2","updated":"2023-07-13T09:13:40Z","published":"2022-02-06T17:16:46Z","title":"Block shuffling learning for Deepfake Detection","summary":"  Deepfake detection methods based on convolutional neural networks (CNN) have\ndemonstrated high accuracy. \\textcolor{black}{However, these methods often\nsuffer from decreased performance when faced with unknown forgery methods and\ncommon transformations such as resizing and blurring, resulting in deviations\nbetween training and testing domains.} This phenomenon, known as overfitting,\nposes a significant challenge. To address this issue, we propose a novel block\nshuffling regularization method. Firstly, our approach involves dividing the\nimages into blocks and applying both intra-block and inter-block shuffling\ntechniques. This process indirectly achieves weight-sharing across different\ndimensions. Secondly, we introduce an adversarial loss algorithm to mitigate\nthe overfitting problem induced by the shuffling noise. Finally, we restore the\nspatial layout of the blocks to capture the semantic associations among them.\nExtensive experiments validate the effectiveness of our proposed method, which\nsurpasses existing approaches in forgery face detection. Notably, our method\nexhibits excellent generalization capabilities, demonstrating robustness\nagainst cross-dataset evaluations and common image transformations. Especially\nour method can be easily integrated with various CNN models. Source code is\navailable at\n\\href{https://github.com/NoWindButRain/BlockShuffleLearning}{Github}.\n","authors":["Sitong Liu","Zhichao Lian","Siqi Gu","Liang Xiao"],"pdf_url":"https://arxiv.org/pdf/2202.02819v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06630v1","updated":"2023-07-13T08:56:20Z","published":"2023-07-13T08:56:20Z","title":"Image Transformation Sequence Retrieval with General Reinforcement\n  Learning","summary":"  In this work, the novel Image Transformation Sequence Retrieval (ITSR) task\nis presented, in which a model must retrieve the sequence of transformations\nbetween two given images that act as source and target, respectively. Given\ncertain characteristics of the challenge such as the multiplicity of a correct\nsequence or the correlation between consecutive steps of the process, we\npropose a solution to ITSR using a general model-based Reinforcement Learning\nsuch as Monte Carlo Tree Search (MCTS), which is combined with a deep neural\nnetwork. Our experiments provide a benchmark in both synthetic and real\ndomains, where the proposed approach is compared with supervised training. The\nresults report that a model trained with MCTS is able to outperform its\nsupervised counterpart in both the simplest and the most complex cases. Our\nwork draws interesting conclusions about the nature of ITSR and its associated\nchallenges.\n","authors":["Enrique Mas-Candela","Antonio Ríos-Vila","Jorge Calvo-Zaragoza"],"pdf_url":"https://arxiv.org/pdf/2307.06630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06616v1","updated":"2023-07-13T08:34:09Z","published":"2023-07-13T08:34:09Z","title":"SecureFalcon: The Next Cyber Reasoning System for Cyber Security","summary":"  Software vulnerabilities leading to various detriments such as crashes, data\nloss, and security breaches, significantly hinder the quality, affecting the\nmarket adoption of software applications and systems. Although traditional\nmethods such as automated software testing, fault localization, and repair have\nbeen intensively studied, static analysis tools are most commonly used and have\nan inherent false positives rate, posing a solid challenge to developer\nproductivity. Large Language Models (LLMs) offer a promising solution to these\npersistent issues. Among these, FalconLLM has shown substantial potential in\nidentifying intricate patterns and complex vulnerabilities, hence crucial in\nsoftware vulnerability detection. In this paper, for the first time, FalconLLM\nis being fine-tuned for cybersecurity applications, thus introducing\nSecureFalcon, an innovative model architecture built upon FalconLLM.\nSecureFalcon is trained to differentiate between vulnerable and non-vulnerable\nC code samples. We build a new training dataset, FormAI, constructed thanks to\nGenerative Artificial Intelligence (AI) and formal verification to evaluate its\nperformance. SecureFalcon achieved an impressive 94% accuracy rate in detecting\nsoftware vulnerabilities, emphasizing its significant potential to redefine\nsoftware vulnerability detection methods in cybersecurity.\n","authors":["Mohamed Amine Ferrag","Ammar Battah","Norbert Tihanyi","Merouane Debbah","Thierry Lestable","Lucas C. Cordeiro"],"pdf_url":"https://arxiv.org/pdf/2307.06616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06608v1","updated":"2023-07-13T08:10:48Z","published":"2023-07-13T08:10:48Z","title":"Introducing Foundation Models as Surrogate Models: Advancing Towards\n  More Practical Adversarial Attacks","summary":"  Recently, the no-box adversarial attack, in which the attacker lacks access\nto the model's architecture, weights, and training data, become the most\npractical and challenging attack setup. However, there is an unawareness of the\npotential and flexibility inherent in the surrogate model selection process on\nno-box setting. Inspired by the burgeoning interest in utilizing foundational\nmodels to address downstream tasks, this paper adopts an innovative idea that\n1) recasting adversarial attack as a downstream task. Specifically, image noise\ngeneration to meet the emerging trend and 2) introducing foundational models as\nsurrogate models. Harnessing the concept of non-robust features, we elaborate\non two guiding principles for surrogate model selection to explain why the\nfoundational model is an optimal choice for this role. However, paradoxically,\nwe observe that these foundational models underperform. Analyzing this\nunexpected behavior within the feature space, we attribute the lackluster\nperformance of foundational models (e.g., CLIP) to their significant\nrepresentational capacity and, conversely, their lack of discriminative\nprowess. To mitigate this issue, we propose the use of a margin-based loss\nstrategy for the fine-tuning of foundational models on target images. The\nexperimental results verify that our approach, which employs the basic Fast\nGradient Sign Method (FGSM) attack algorithm, outstrips the performance of\nother, more convoluted algorithms. We conclude by advocating for the research\ncommunity to consider surrogate models as crucial determinants in the\neffectiveness of adversarial attacks in no-box settings. The implications of\nour work bear relevance for improving the efficacy of such adversarial attacks\nand the overall robustness of AI systems.\n","authors":["Jiaming Zhang","Jitao Sang","Qi Yi"],"pdf_url":"https://arxiv.org/pdf/2307.06608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.14838v3","updated":"2023-07-13T08:06:49Z","published":"2022-05-30T03:56:54Z","title":"Most Equitable Voting Rules","summary":"  In social choice theory, anonymity (all agents being treated equally) and\nneutrality (all alternatives being treated equally) are widely regarded as\n``minimal demands'' and ``uncontroversial'' axioms of equity and fairness.\nHowever, the ANR impossibility -- there is no voting rule that satisfies\nanonymity, neutrality, and resolvability (always choosing one winner) -- holds\neven in the simple setting of two alternatives and two agents. How to design\nvoting rules that optimally satisfy anonymity, neutrality, and resolvability\nremains an open question.\n  We address the optimal design question for a wide range of preferences and\ndecisions that include ranked lists and committees. Our conceptual contribution\nis a novel and strong notion of most equitable refinements that optimally\npreserves anonymity and neutrality for any irresolute rule that satisfies the\ntwo axioms. Our technical contributions are twofold. First, we characterize the\nconditions for the ANR impossibility to hold under general settings, especially\nwhen the number of agents is large. Second, we propose the\nmost-favorable-permutation (MFP) tie-breaking to compute a most equitable\nrefinement and design a polynomial-time algorithm to compute MFP when agents'\npreferences are full rankings.\n","authors":["Lirong Xia"],"pdf_url":"https://arxiv.org/pdf/2205.14838v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03044v2","updated":"2023-07-13T07:31:09Z","published":"2023-01-08T14:04:26Z","title":"A Survey on Transformers in Reinforcement Learning","summary":"  Transformer has been considered the dominating neural architecture in NLP and\nCV, mostly under supervised settings. Recently, a similar surge of using\nTransformers has appeared in the domain of reinforcement learning (RL), but it\nis faced with unique design choices and challenges brought by the nature of RL.\nHowever, the evolution of Transformers in RL has not yet been well unraveled.\nIn this paper, we seek to systematically review motivations and progress on\nusing Transformers in RL, provide a taxonomy on existing works, discuss each\nsub-field, and summarize future prospects.\n","authors":["Wenzhe Li","Hao Luo","Zichuan Lin","Chongjie Zhang","Zongqing Lu","Deheng Ye"],"pdf_url":"https://arxiv.org/pdf/2301.03044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06407v3","updated":"2023-07-13T06:56:16Z","published":"2022-11-11T18:44:41Z","title":"Control Transformer: Robot Navigation in Unknown Environments through\n  PRM-Guided Return-Conditioned Sequence Modeling","summary":"  Learning long-horizon tasks such as navigation has presented difficult\nchallenges for successfully applying reinforcement learning to robotics. From\nanother perspective, under known environments, sampling-based planning can\nrobustly find collision-free paths in environments without learning. In this\nwork, we propose Control Transformer that models return-conditioned sequences\nfrom low-level policies guided by a sampling-based Probabilistic Roadmap (PRM)\nplanner. We demonstrate that our framework can solve long-horizon navigation\ntasks using only local information. We evaluate our approach on\npartially-observed maze navigation with MuJoCo robots, including Ant, Point,\nand Humanoid. We show that Control Transformer can successfully navigate\nthrough mazes and transfer to unknown environments. Additionally, we apply our\nmethod to a differential drive robot (Turtlebot3) and show zero-shot sim2real\ntransfer under noisy observations.\n","authors":["Daniel Lawson","Ahmed H. Qureshi"],"pdf_url":"https://arxiv.org/pdf/2211.06407v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13339v2","updated":"2023-07-13T06:54:23Z","published":"2023-06-23T07:39:12Z","title":"TrustGuard: GNN-based Robust and Explainable Trust Evaluation with\n  Dynamicity Support","summary":"  Trust evaluation assesses trust relationships between entities and\nfacilitates decision-making. Machine Learning (ML) shows great potential for\ntrust evaluation owing to its learning capabilities. In recent years, Graph\nNeural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in\ndealing with graph data. This has motivated researchers to explore their use in\ntrust evaluation, as trust relationships among entities can be modeled as a\ngraph. However, current trust evaluation methods that employ GNNs fail to fully\nsatisfy the dynamic nature of trust, overlook the adverse effects of attacks on\ntrust evaluation, and cannot provide convincing explanations on evaluation\nresults. To address these problems, we propose TrustGuard, a GNN-based accurate\ntrust evaluation model that supports trust dynamicity, is robust against\ntypical attacks, and provides explanations through visualization. Specifically,\nTrustGuard is designed with a layered architecture that contains a snapshot\ninput layer, a spatial aggregation layer, a temporal aggregation layer, and a\nprediction layer. Among them, the spatial aggregation layer adopts a defense\nmechanism to robustly aggregate local trust, and the temporal aggregation layer\napplies an attention mechanism for effective learning of temporal patterns.\nExtensive experiments on two real-world datasets show that TrustGuard\noutperforms state-of-the-art GNN-based trust evaluation models with respect to\ntrust prediction across single-timeslot and multi-timeslot, even in the\npresence of attacks. In addition, TrustGuard can explain its evaluation results\nby visualizing both spatial and temporal views.\n","authors":["Jie Wang","Zheng Yan","Jiahe Lan","Elisa Bertino","Witold Pedrycz"],"pdf_url":"https://arxiv.org/pdf/2306.13339v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2211.00241v4","updated":"2023-07-13T06:37:29Z","published":"2022-11-01T03:13:20Z","title":"Adversarial Policies Beat Superhuman Go AIs","summary":"  We attack the state-of-the-art Go-playing AI system KataGo by training\nadversarial policies against it, achieving a >97% win rate against KataGo\nrunning at superhuman settings. Our adversaries do not win by playing Go well.\nInstead, they trick KataGo into making serious blunders. Our attack transfers\nzero-shot to other superhuman Go-playing AIs, and is comprehensible to the\nextent that human experts can implement it without algorithmic assistance to\nconsistently beat superhuman AIs. The core vulnerability uncovered by our\nattack persists even in KataGo agents adversarially trained to defend against\nour attack. Our results demonstrate that even superhuman AI systems may harbor\nsurprising failure modes. Example games are available https://goattack.far.ai/.\n","authors":["Tony T. Wang","Adam Gleave","Tom Tseng","Kellin Pelrine","Nora Belrose","Joseph Miller","Michael D. Dennis","Yawen Duan","Viktor Pogrebniak","Sergey Levine","Stuart Russell"],"pdf_url":"https://arxiv.org/pdf/2211.00241v4.pdf","comment":"Accepted to ICML 2023, see paper for changelog"},{"id":"http://arxiv.org/abs/2307.06577v1","updated":"2023-07-13T06:30:09Z","published":"2023-07-13T06:30:09Z","title":"RVD: A Handheld Device-Based Fundus Video Dataset for Retinal Vessel\n  Segmentation","summary":"  Retinal vessel segmentation is generally grounded in image-based datasets\ncollected with bench-top devices. The static images naturally lose the dynamic\ncharacteristics of retina fluctuation, resulting in diminished dataset\nrichness, and the usage of bench-top devices further restricts dataset\nscalability due to its limited accessibility. Considering these limitations, we\nintroduce the first video-based retinal dataset by employing handheld devices\nfor data acquisition. The dataset comprises 635 smartphone-based fundus videos\ncollected from four different clinics, involving 415 patients from 50 to 75\nyears old. It delivers comprehensive and precise annotations of retinal\nstructures in both spatial and temporal dimensions, aiming to advance the\nlandscape of vasculature segmentation. Specifically, the dataset provides three\nlevels of spatial annotations: binary vessel masks for overall retinal\nstructure delineation, general vein-artery masks for distinguishing the vein\nand artery, and fine-grained vein-artery masks for further characterizing the\ngranularities of each artery and vein. In addition, the dataset offers temporal\nannotations that capture the vessel pulsation characteristics, assisting in\ndetecting ocular diseases that require fine-grained recognition of hemodynamic\nfluctuation. In application, our dataset exhibits a significant domain shift\nwith respect to data captured by bench-top devices, thus posing great\nchallenges to existing methods. In the experiments, we provide evaluation\nmetrics and benchmark results on our dataset, reflecting both the potential and\nchallenges it offers for vessel segmentation tasks. We hope this challenging\ndataset would significantly contribute to the development of eye disease\ndiagnosis and early prevention.\n","authors":["MD Wahiduzzaman Khan","Hongwei Sheng","Hu Zhang","Heming Du","Sen Wang","Minas Theodore Coroneo","Farshid Hajati","Sahar Shariflou","Michael Kalloniatis","Jack Phu","Ashish Agar","Zi Huang","Mojtaba Golzan","Xin Yu"],"pdf_url":"https://arxiv.org/pdf/2307.06577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14905v2","updated":"2023-07-13T06:07:09Z","published":"2022-10-24T06:47:13Z","title":"RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding","summary":"  Knowledge graph (KG) reasoning is an important problem for knowledge graphs.\nIn this paper, we propose a novel and principled framework called \\textbf{RulE}\n(stands for {Rul}e {E}mbedding) to effectively leverage logical rules to\nenhance KG reasoning. Unlike knowledge graph embedding (KGE) methods, RulE\nlearns rule embeddings from existing triplets and first-order {rules} by\njointly representing \\textbf{entities}, \\textbf{relations} and \\textbf{logical\nrules} in a unified embedding space. Based on the learned rule embeddings, a\nconfidence score can be calculated for each rule, reflecting its consistency\nwith the observed triplets. This allows us to perform logical rule inference in\na soft way, thus alleviating the brittleness of logic. On the other hand, RulE\ninjects prior logical rule information into the embedding space, enriching and\nregularizing the entity/relation embeddings. This makes KGE alone perform\nbetter too. RulE is conceptually simple and empirically effective. We conduct\nextensive experiments to verify each component of RulE. Results on multiple\nbenchmarks reveal that our model outperforms the majority of existing\nembedding-based and rule-based approaches.\n","authors":["Xiaojuan Tang","Song-Chun Zhu","Yitao Liang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.14905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06566v1","updated":"2023-07-13T05:36:19Z","published":"2023-07-13T05:36:19Z","title":"Regression-Oriented Knowledge Distillation for Lightweight Ship\n  Orientation Angle Prediction with Optical Remote Sensing Images","summary":"  Ship orientation angle prediction (SOAP) with optical remote sensing images\nis an important image processing task, which often relies on deep convolutional\nneural networks (CNNs) to make accurate predictions. This paper proposes a\nnovel framework to reduce the model sizes and computational costs of SOAP\nmodels without harming prediction accuracy. First, a new SOAP model called\nMobile-SOAP is designed based on MobileNetV2, achieving state-of-the-art\nprediction accuracy. Four tiny SOAP models are also created by replacing the\nconvolutional blocks in Mobile-SOAP with four small-scale networks,\nrespectively. Then, to transfer knowledge from Mobile-SOAP to four lightweight\nmodels, we propose a novel knowledge distillation (KD) framework termed SOAP-KD\nconsisting of a novel feature-based guidance loss and an optimized synthetic\nsamples-based knowledge transfer mechanism. Lastly, extensive experiments on\nthe FGSC-23 dataset confirm the superiority of Mobile-SOAP over existing models\nand also demonstrate the effectiveness of SOAP-KD in improving the prediction\nperformance of four specially designed tiny models. Notably, by using SOAP-KD,\nthe test mean absolute error of the ShuffleNetV2x1.0-based model is only 8%\nhigher than that of Mobile-SOAP, but its number of parameters and\nmultiply-accumulate operations (MACs) are respectively 61.6% and 60.8% less.\n","authors":["Zhan Shi","Xin Ding","Peng Ding","Chun Yang","Ru Huang","Xiaoxuan Song"],"pdf_url":"https://arxiv.org/pdf/2307.06566v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06564v1","updated":"2023-07-13T05:31:40Z","published":"2023-07-13T05:31:40Z","title":"Prescriptive Process Monitoring Under Resource Constraints: A\n  Reinforcement Learning Approach","summary":"  Prescriptive process monitoring methods seek to optimize the performance of\nbusiness processes by triggering interventions at runtime, thereby increasing\nthe probability of positive case outcomes. These interventions are triggered\naccording to an intervention policy. Reinforcement learning has been put\nforward as an approach to learning intervention policies through trial and\nerror. Existing approaches in this space assume that the number of resources\navailable to perform interventions in a process is unlimited, an unrealistic\nassumption in practice. This paper argues that, in the presence of resource\nconstraints, a key dilemma in the field of prescriptive process monitoring is\nto trigger interventions based not only on predictions of their necessity,\ntimeliness, or effect but also on the uncertainty of these predictions and the\nlevel of resource utilization. Indeed, committing scarce resources to an\nintervention when the necessity or effects of this intervention are highly\nuncertain may intuitively lead to suboptimal intervention effects. Accordingly,\nthe paper proposes a reinforcement learning approach for prescriptive process\nmonitoring that leverages conformal prediction techniques to consider the\nuncertainty of the predictions upon which an intervention decision is based. An\nevaluation using real-life datasets demonstrates that explicitly modeling\nuncertainty using conformal predictions helps reinforcement learning agents\nconverge towards policies with higher net intervention gain\n","authors":["Mahmoud Shoush","Marlon Dumas"],"pdf_url":"https://arxiv.org/pdf/2307.06564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.13445v2","updated":"2023-07-13T04:23:23Z","published":"2021-09-28T02:48:00Z","title":"Emergent Neural Network Mechanisms for Generalization to Objects in\n  Novel Orientations","summary":"  The capability of Deep Neural Networks (DNNs) to recognize objects in\norientations outside the distribution of the training data is not well\nunderstood. We present evidence that DNNs are capable of generalizing to\nobjects in novel orientations by disseminating orientation-invariance obtained\nfrom familiar objects seen from many viewpoints. This capability strengthens\nwhen training the DNN with an increasing number of familiar objects, but only\nin orientations that involve 2D rotations of familiar orientations. We show\nthat this dissemination is achieved via neurons tuned to common features\nbetween familiar and unfamiliar objects. These results implicate brain-like\nneural mechanisms for generalization.\n","authors":["Avi Cooper","Xavier Boix","Daniel Harari","Spandan Madan","Hanspeter Pfister","Tomotake Sasaki","Pawan Sinha"],"pdf_url":"https://arxiv.org/pdf/2109.13445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06541v1","updated":"2023-07-13T03:06:36Z","published":"2023-07-13T03:06:36Z","title":"On the Effective Horizon of Inverse Reinforcement Learning","summary":"  Inverse reinforcement learning (IRL) algorithms often rely on (forward)\nreinforcement learning or planning over a given time horizon to compute an\napproximately optimal policy for a hypothesized reward function and then match\nthis policy with expert demonstrations. The time horizon plays a critical role\nin determining both the accuracy of reward estimate and the computational\nefficiency of IRL algorithms. Interestingly, an effective time horizon shorter\nthan the ground-truth value often produces better results faster. This work\nformally analyzes this phenomenon and provides an explanation: the time horizon\ncontrols the complexity of an induced policy class and mitigates overfitting\nwith limited data. This analysis leads to a principled choice of the effective\nhorizon for IRL. It also prompts us to reexamine the classic IRL formulation:\nit is more natural to learn jointly the reward and the effective horizon\ntogether rather than the reward alone with a given horizon. Our experimental\nresults confirm the theoretical analysis.\n","authors":["Yiqing Xu","Finale Doshi-Velez","David Hsu"],"pdf_url":"https://arxiv.org/pdf/2307.06541v1.pdf","comment":"9 pages, under review"},{"id":"http://arxiv.org/abs/2208.07734v5","updated":"2023-07-13T02:50:36Z","published":"2022-08-16T13:09:25Z","title":"Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision\n  for Unsupervised Anomaly Detection is Creating the Illusion of Success","summary":"  Self-supervised learning (SSL) has emerged as a promising alternative to\ncreate supervisory signals to real-world problems, avoiding the extensive cost\nof manual labeling. SSL is particularly attractive for unsupervised tasks such\nas anomaly detection (AD), where labeled anomalies are rare or often\nnonexistent. A large catalog of augmentation functions has been used for\nSSL-based AD (SSAD) on image data, and recent works have reported that the type\nof augmentation has a significant impact on accuracy. Motivated by those, this\nwork sets out to put image-based SSAD under a larger lens and investigate the\nrole of data augmentation in SSAD. Through extensive experiments on 3 different\ndetector models and across 420 AD tasks, we provide comprehensive numerical and\nvisual evidences that the alignment between data augmentation and\nanomaly-generating mechanism is the key to the success of SSAD, and in the lack\nthereof, SSL may even impair accuracy. To the best of our knowledge, this is\nthe first meta-analysis on the role of data augmentation in SSAD.\n","authors":["Jaemin Yoo","Tiancheng Zhao","Leman Akoglu"],"pdf_url":"https://arxiv.org/pdf/2208.07734v5.pdf","comment":"Accepted to Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2307.06521v1","updated":"2023-07-13T01:51:26Z","published":"2023-07-13T01:51:26Z","title":"Artificial Intelligence for Drug Discovery: Are We There Yet?","summary":"  Drug discovery is adapting to novel technologies such as data science,\ninformatics, and artificial intelligence (AI) to accelerate effective treatment\ndevelopment while reducing costs and animal experiments. AI is transforming\ndrug discovery, as indicated by increasing interest from investors, industrial\nand academic scientists, and legislators. Successful drug discovery requires\noptimizing properties related to pharmacodynamics, pharmacokinetics, and\nclinical outcomes. This review discusses the use of AI in the three pillars of\ndrug discovery: diseases, targets, and therapeutic modalities, with a focus on\nsmall molecule drugs. AI technologies, such as generative chemistry, machine\nlearning, and multi-property optimization, have enabled several compounds to\nenter clinical trials. The scientific community must carefully vet known\ninformation to address the reproducibility crisis. The full potential of AI in\ndrug discovery can only be realized with sufficient ground truth and\nappropriate human intervention at later pipeline stages.\n","authors":["Catrin Hasselgren","Tudor I. Oprea"],"pdf_url":"https://arxiv.org/pdf/2307.06521v1.pdf","comment":"30 pages, 4 figures, 184 references"},{"id":"http://arxiv.org/abs/2307.06513v1","updated":"2023-07-13T01:22:18Z","published":"2023-07-13T01:22:18Z","title":"Leveraging Contextual Counterfactuals Toward Belief Calibration","summary":"  Beliefs and values are increasingly being incorporated into our AI systems\nthrough alignment processes, such as carefully curating data collection\nprinciples or regularizing the loss function used for training. However, the\nmeta-alignment problem is that these human beliefs are diverse and not aligned\nacross populations; furthermore, the implicit strength of each belief may not\nbe well calibrated even among humans, especially when trying to generalize\nacross contexts. Specifically, in high regret situations, we observe that\ncontextual counterfactuals and recourse costs are particularly important in\nupdating a decision maker's beliefs and the strengths to which such beliefs are\nheld. Therefore, we argue that including counterfactuals is key to an accurate\ncalibration of beliefs during alignment. To do this, we first segment belief\ndiversity into two categories: subjectivity (across individuals within a\npopulation) and epistemic uncertainty (within an individual across different\ncontexts). By leveraging our notion of epistemic uncertainty, we introduce `the\nbelief calibration cycle' framework to more holistically calibrate this\ndiversity of beliefs with context-driven counterfactual reasoning by using a\nmulti-objective optimization. We empirically apply our framework for finding a\nPareto frontier of clustered optimal belief strengths that generalize across\ndifferent contexts, demonstrating its efficacy on a toy dataset for credit\ndecisions.\n","authors":[" Qiuyi"," Zhang","Michael S. Lee","Sherol Chen"],"pdf_url":"https://arxiv.org/pdf/2307.06513v1.pdf","comment":"ICML (International Conference on Machine Learning) Workshop on\n  Counterfactuals in Minds and Machines, 2023"},{"id":"http://arxiv.org/abs/2307.06507v1","updated":"2023-07-13T01:14:08Z","published":"2023-07-13T01:14:08Z","title":"Improving Nonalcoholic Fatty Liver Disease Classification Performance\n  With Latent Diffusion Models","summary":"  Integrating deep learning with clinical expertise holds great potential for\naddressing healthcare challenges and empowering medical professionals with\nimproved diagnostic tools. However, the need for annotated medical images is\noften an obstacle to leveraging the full power of machine learning models. Our\nresearch demonstrates that by combining synthetic images, generated using\ndiffusion models, with real images, we can enhance nonalcoholic fatty liver\ndisease (NAFLD) classification performance. We evaluate the quality of the\nsynthetic images by comparing two metrics: Inception Score (IS) and Fr\\'{e}chet\nInception Distance (FID), computed on diffusion-generated images and generative\nadversarial networks (GANs)-generated images. Our results show superior\nperformance for the diffusion-generated images, with a maximum IS score of\n$1.90$ compared to $1.67$ for GANs, and a minimum FID score of $69.45$ compared\nto $99.53$ for GANs. Utilizing a partially frozen CNN backbone (EfficientNet\nv1), our synthetic augmentation method achieves a maximum image-level ROC AUC\nof $0.904$ on a NAFLD prediction task.\n","authors":["Romain Hardy","Cornelia Ilin","Joe Klepich","Ryan Mitchell","Steve Hall","Jericho Villareal"],"pdf_url":"https://arxiv.org/pdf/2307.06507v1.pdf","comment":"24 pages, 9 figures"},{"id":"http://arxiv.org/abs/2307.06501v1","updated":"2023-07-13T00:53:09Z","published":"2023-07-13T00:53:09Z","title":"Hybrid Control Policy for Artificial Pancreas via Ensemble Deep\n  Reinforcement Learning","summary":"  Objective: The artificial pancreas (AP) has shown promising potential in\nachieving closed-loop glucose control for individuals with type 1 diabetes\nmellitus (T1DM). However, designing an effective control policy for the AP\nremains challenging due to the complex physiological processes, delayed insulin\nresponse, and inaccurate glucose measurements. While model predictive control\n(MPC) offers safety and stability through the dynamic model and safety\nconstraints, it lacks individualization and is adversely affected by\nunannounced meals. Conversely, deep reinforcement learning (DRL) provides\npersonalized and adaptive strategies but faces challenges with distribution\nshifts and substantial data requirements. Methods: We propose a hybrid control\npolicy for the artificial pancreas (HyCPAP) to address the above challenges.\nHyCPAP combines an MPC policy with an ensemble DRL policy, leveraging the\nstrengths of both policies while compensating for their respective limitations.\nTo facilitate faster deployment of AP systems in real-world settings, we\nfurther incorporate meta-learning techniques into HyCPAP, leveraging previous\nexperience and patient-shared knowledge to enable fast adaptation to new\npatients with limited available data. Results: We conduct extensive experiments\nusing the FDA-accepted UVA/Padova T1DM simulator across three scenarios. Our\napproaches achieve the highest percentage of time spent in the desired\neuglycemic range and the lowest occurrences of hypoglycemia. Conclusion: The\nresults clearly demonstrate the superiority of our methods for closed-loop\nglucose management in individuals with T1DM. Significance: The study presents\nnovel control policies for AP systems, affirming the great potential of\nproposed methods for efficient closed-loop glucose control.\n","authors":["Wenzhou Lv","Tianyu Wu","Luolin Xiong","Liang Wu","Jian Zhou","Yang Tang","Feng Qi"],"pdf_url":"https://arxiv.org/pdf/2307.06501v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2307.03198v2","updated":"2023-07-13T00:27:55Z","published":"2023-07-04T03:59:16Z","title":"A multilevel framework for AI governance","summary":"  To realize the potential benefits and mitigate potential risks of AI, it is\nnecessary to develop a framework of governance that conforms to ethics and\nfundamental human values. Although several organizations have issued guidelines\nand ethical frameworks for trustworthy AI, without a mediating governance\nstructure, these ethical principles will not translate into practice. In this\npaper, we propose a multilevel governance approach that involves three groups\nof interdependent stakeholders: governments, corporations, and citizens. We\nexamine their interrelationships through dimensions of trust, such as\ncompetence, integrity, and benevolence. The levels of governance combined with\nthe dimensions of trust in AI provide practical insights that can be used to\nfurther enhance user experiences and inform public policy related to AI.\n","authors":["Hyesun Choung","Prabu David","John S. Seberger"],"pdf_url":"https://arxiv.org/pdf/2307.03198v2.pdf","comment":"This paper has been accepted for publication and is forthcoming in\n  The Global and Digital Governance Handbook. Cite as: Choung, H., David, P., &\n  Seberger, J.S. (2023). A multilevel framework for AI governance. The Global\n  and Digital Governance Handbook. Routledge, Taylor & Francis Group"},{"id":"http://arxiv.org/abs/2307.06496v1","updated":"2023-07-13T00:08:52Z","published":"2023-07-13T00:08:52Z","title":"Microbial Genetic Algorithm-based Black-box Attack against Interpretable\n  Deep Learning Systems","summary":"  Deep learning models are susceptible to adversarial samples in white and\nblack-box environments. Although previous studies have shown high attack\nsuccess rates, coupling DNN models with interpretation models could offer a\nsense of security when a human expert is involved, who can identify whether a\ngiven sample is benign or malicious. However, in white-box environments,\ninterpretable deep learning systems (IDLSes) have been shown to be vulnerable\nto malicious manipulations. In black-box settings, as access to the components\nof IDLSes is limited, it becomes more challenging for the adversary to fool the\nsystem. In this work, we propose a Query-efficient Score-based black-box attack\nagainst IDLSes, QuScore, which requires no knowledge of the target model and\nits coupled interpretation model. QuScore is based on transfer-based and\nscore-based methods by employing an effective microbial genetic algorithm. Our\nmethod is designed to reduce the number of queries necessary to carry out\nsuccessful attacks, resulting in a more efficient process. By continuously\nrefining the adversarial samples created based on feedback scores from the\nIDLS, our approach effectively navigates the search space to identify\nperturbations that can fool the system. We evaluate the attack's effectiveness\non four CNN models (Inception, ResNet, VGG, DenseNet) and two interpretation\nmodels (CAM, Grad), using both ImageNet and CIFAR datasets. Our results show\nthat the proposed approach is query-efficient with a high attack success rate\nthat can reach between 95% and 100% and transferability with an average success\nrate of 69% in the ImageNet and CIFAR datasets. Our attack method generates\nadversarial examples with attribution maps that resemble benign samples. We\nhave also demonstrated that our attack is resilient against various\npreprocessing defense techniques and can easily be transferred to different DNN\nmodels.\n","authors":["Eldor Abdukhamidov","Mohammed Abuhamad","Simon S. Woo","Eric Chan-Tin","Tamer Abuhmed"],"pdf_url":"https://arxiv.org/pdf/2307.06496v1.pdf","comment":null}]}}